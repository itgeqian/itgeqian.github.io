<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>geqian&#39;s Blog🍭</title>
  
  
  <link href="https://itgeqian.github.io/atom.xml" rel="self"/>
  
  <link href="https://itgeqian.github.io/"/>
  <updated>2025-11-10T03:42:00.000Z</updated>
  <id>https://itgeqian.github.io/</id>
  
  <author>
    <name>geqian&#39;s Blog🍭</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>设计模式的相关面试题</title>
    <link href="https://itgeqian.github.io/posts/79.html"/>
    <id>https://itgeqian.github.io/posts/79.html</id>
    <published>2025-11-09T00:19:03.000Z</published>
    <updated>2025-11-10T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-设计模式">GQ 设计模式</h1><h2 id="什么是设计模式？请简述其作用。">什么是设计模式？请简述其作用。</h2><p><strong>什么是设计模式?</strong><br>设计模式是<strong>前人总结出的可复用解决方案</strong>，用于在<strong>面对常见设计问题</strong>时，<strong>减少试错成本</strong>、<strong>提升开发效率和代码可维护性</strong>。</p><h2 id="23-种设计模式分为哪三大类？">23 种设计模式分为哪三大类？</h2><p>23 种设计模式可以分为创建型、行为型、结构型三大类：</p><p>1）创建者模式</p><p>用于对象的创建，同时隐藏对象创建的逻辑。避免在代码中出现大量的 new 操作和创建对象的逻辑。目的是实现对象创建的解耦；</p><p>常见的有单例模式、工厂模式、建造者模式；</p><p>2）结构型模式</p><p>用于处理对象组合的结构，主要用于类和对象的组合。目的是通过类或对象的组合，实现更大的结构；</p><p>常见的有桥接模式、适配器模式、组合模式、代理模式、装饰器模式；</p><p>3）行为型模式</p><p>用于定义对象如何相互协作实现单个对象无法单独完成的任务，目的是定义类和对象之间的通信方式；</p><p>常见的有策略模式、模板模式、状态模式、责任链模式、观察者模式、迭代器模式</p><h2 id="请解释什么是单例模式，并给出一个使用场景">请解释什么是单例模式，并给出一个使用场景</h2><p>单例模式就是<strong>保证一个类在整个系统中只有一个实例</strong>，<strong>并且提供一个全局访问点</strong>。它在像数据库连接池、线程池、配置中心这种场景中非常常见。</p><h2 id="单例模式有哪几种实现？如何保证线程安全？">单例模式有哪几种实现？如何保证线程安全？</h2><p>单例模式就是<strong>保证一个类在整个系统中只有一个实例</strong>，<strong>并且提供一个全局访问点</strong>。它在像数据库连接池、线程池、配置中心这种场景中非常常见。</p><p>单例常见有几种实现方式：</p><ul><li>饿汉式：<strong>类加载时就创建实例</strong>，<strong>线程安全</strong>，但可能会浪费资源。</li><li>懒汉式：<strong>用到的时候才创建实例</strong>，节省资源，但要<strong>注意线程安全问题</strong>。</li><li><strong>双重检查锁</strong>（DCL）：在<strong>懒汉的基础上加锁优化</strong>，<strong>只在第一次创建时加锁</strong>，提高性能，实际开发中最常用。</li><li><strong>静态内部类</strong>：<strong>利用类加载机制来实现延迟加载</strong>和线程安全，代码优雅，也很推荐。</li><li><strong>枚举单例</strong>：<strong>Java中最安全、最简单的写法</strong>，可以防止反射和反序列化破坏，是面试中经常提到的最佳实践。</li></ul><blockquote><p>如何保证线程安全：</p></blockquote><p>主要就是控制实例创建过程的并发访问：</p><ul><li>Java 里可以用 synchronized、volatile 关键字，或者静态内部类；</li><li>C++ 用 std::call_once；</li><li>Python 用 <strong>new</strong> 或锁；</li><li>Go 用 sync.Once。</li></ul><blockquote><p>为什么说枚举是实现单例最好的方式</p></blockquote><p>究其原因，主要有以下三个好处：</p><p>1、枚举实现的单例写法简单</p><p>2、枚举实现的单例天然是线程安全的</p><p>3、枚举实现的单例可避免被反序列化破坏</p><h2 id="工厂模式和抽象工厂模式有什么区别？">工厂模式和抽象工厂模式有什么区别？</h2><p>工厂模式和抽象工厂模式其实都是用来“创建对象”的，只是它们关注的范围不一样。</p><p>简单来说，<strong>工厂模式是创建某一类产品，而抽象工厂模式是创建一整套相关产品</strong>。</p><h3 id="工厂模式">工厂模式</h3><p>工厂模式更像是“一个老板开了很多工厂”，每个工厂负责生产一种产品。</p><ul><li><p>举个例子，比如黄老板负责做显卡，有华硕 5090、七彩虹 5090 等不同型号。那我们就可以定义一个“显卡工厂接口”，再让不同品牌的工厂去实现它，各自生产自己的显卡。</p></li><li><p>这种模式的好处是：<strong>新增一种显卡，只要新增一个工厂类就行，不用动原来的逻辑，符合开闭原则</strong>。</p></li><li><p>使用场景一般是:当创建过程复杂、想让对象创建和使用解耦时，比如数据库连接对象、日志对象等。</p></li></ul><h3 id="抽象工厂模式">抽象工厂模式</h3><p>抽象工厂更像是“一个集团开了多个配套工厂”，它不仅造显卡，还顺带造配套的主板、电源和散热器。</p><ul><li>比如说我们要生产一个“二次元风格套装”和一个“赛博风格套装”，每个套装里都包含主机显卡电源等多个关联对象。那就可以让“抽象工厂”定义生产整套组件的接口，每个具体工厂负责生产自己那一套。</li><li>所以，<strong>抽象工厂主要用于创建一系列相关或相互依赖的对象</strong>，并保证这些对象之间能搭配使用，比如游戏开发、UI 风格统一、跨平台组件等。</li></ul><p>简单来说</p><ul><li>工厂模式：<strong>创建单一类型的对象</strong>，像“显卡工厂”。</li><li>抽象工厂模式：<strong>创建一整套相关对象</strong>，像“整机制造厂”。</li><li><strong>前者更关注“一个产品的多种实现”，后者更关注“一系列产品的整体搭配”</strong>。</li></ul><h2 id="什么是享元模式？一般用在什么场景？">什么是享元模式？一般用在什么场景？</h2><h3 id="什么是享元模式？">什么是享元模式？</h3><p>享元模式其实很好理解，它的核心思想就是一句话：</p><p><strong>“能共享就共享，别重复创建没必要的对象。”</strong><br>这样做的目的就是节省内存、提升性能。</p><p>为什么要共享？<br>因为有时候我们系统里会出现成千上万、内容完全一样的小对象，如果统统 new 出来，内存就爆了。<br>那享元模式就会把“不会变的部分”抽出来做成一份共享，多个地方一起用，而“会变化的部分”则由外部传进来。</p><p>简单理解：</p><ul><li><strong>内部状态（可共享）</strong>：不会变化、大家都一样的部分</li><li><strong>外部状态（不共享）</strong>：每次不同的部分，由调用方传入</li></ul><p>这样就能把对象数量大幅减少。</p><h3 id="一般用在什么场景？">一般用在什么场景？</h3><p>享元模式其实在我们日常开发里随处可见，只是你可能没注意到：</p><h4 id="①-Java-的-String-常量池（String-Pool）"><strong>① Java 的 String 常量池（String Pool）</strong></h4><p>相同的字符串不会重复创建，比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">a</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;</span><br><span class="line"><span class="type">String</span> <span class="variable">b</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;</span><br></pre></td></tr></table></figure><p>这俩其实是同一个对象。<br>这是最经典的享元模式。</p><h4 id="②-各种包装类的缓存（Integer-valueOf-等）"><strong>② 各种包装类的缓存（Integer.valueOf 等）</strong></h4><p>像 Integer、Long、Byte 这些基本类型包装类，用 <code>valueOf()</code> 都会复用 -128~127 范围内的对象。<br>比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Integer</span> <span class="variable">a</span> <span class="operator">=</span> Integer.valueOf(<span class="number">100</span>);</span><br><span class="line"><span class="type">Integer</span> <span class="variable">b</span> <span class="operator">=</span> Integer.valueOf(<span class="number">100</span>);</span><br><span class="line"><span class="comment">// a == b  true</span></span><br></pre></td></tr></table></figure><p>这是典型的享元。</p><h4 id="③-数据库连接池-线程池（池化技术）"><strong>③ 数据库连接池 / 线程池（池化技术）</strong></h4><p>池化技术本质上也是享元模式：</p><ul><li>连接对象创建成本大</li><li>线程创建成本也大</li></ul><p>因此都不会每次 new，而是通过池来复用已有对象。</p><p>像 Druid、HikariCP、JedisPool，本质都在用享元思想（共享连接资源）。</p><h4 id="④-游戏开发里的精灵-图元共享"><strong>④ 游戏开发里的精灵/图元共享</strong></h4><p>比如一万个同样树木、一万个同样子弹，不可能每个都 new 一个对象，会耗死内存。<br>享元模式会把不变的模型、纹理共享，只存储变化的位置、角度等状态。</p><h3 id="一句话总结">一句话总结</h3><p><strong>享元模式就是为了减少对象数量、节省内存，把不变的部分做成共享的对象，让大量相似对象共用一份数据。常见应用场景包括 Java 字符串池、包装类缓存、池化技术（连接池、线程池）以及游戏中的模型共享等。</strong></p><h2 id="什么是代理模式？一般用在什么场景？">什么是代理模式？一般用在什么场景？</h2><p>代理模式是一种<strong>结构设计模式</strong>，<strong>通过引入一个代理对象来控制对原始对象的访问</strong>。它允许客户端通过代理对象间接访问原始对象，可以在访问过程中加入额外的逻辑或控制。常见的代理模式有以下几种应用场景：</p><ol><li><p><strong>远程代理</strong>：在分布式系统中，代理模式常用于代理远程对象。例如，Dubbo框架就使用了代理模式来实现远程方法调用，使客户端像调用本地方法一样访问远程服务。</p></li><li><p><strong>动态代理</strong>：动态代理通过在运行时创建代理对象并将方法调用分发给不同的处理器。Spring的AOP就是使用动态代理来实现通用的代理逻辑，不需要为每个对象单独创建代理。</p></li><li><p><strong>缓存代理</strong>：代理对象可以在访问真实对象前，先查询缓存，避免重复计算或访问资源。如果缓存中没有结果，再去查询真实对象。</p></li><li><p><strong>日志代理</strong>：可以在代理对象中统一处理日志记录，简化代码，并且保证日志的一致性。</p></li><li><p><strong>异常代理</strong>：统一处理异常的捕获和转换，例如通过代理对象来捕获异常并进行相应的处理。</p></li></ol><p>这些应用场景可以帮助我们在软件开发中更灵活、可扩展地处理一些通用逻辑，如缓存、日志记录和异常处理等。</p><h2 id="什么是观察者模式？一般用在什么场景？">什么是观察者模式？一般用在什么场景？</h2><p>观察者模式：</p><ul><li>核心思想：建立“一对多”的依赖关系，当一个对象状态改变时，自动通知所有观察者更新。</li><li>应用场景：<ul><li>GUI 事件监听（按钮点击通知多个监听器）</li><li>消息推送系统（发布-订阅）</li><li>股票价格更新、缓存失效广播等</li><li>优点：实现对象间的低耦合通信。</li></ul></li></ul><h2 id="什么是模板方法模式？一般用在什么场景？">什么是模板方法模式？一般用在什么场景？</h2><h3 id="什么是模板方法模式？">什么是模板方法模式？</h3><p>模板方法模式是一种<strong>行为型设计模式</strong>，它的核心思想就是：<strong>在父类中定义算法的骨架（流程），把其中可变的部分交给子类去实现</strong>。</p><ul><li>即<strong>父类定流程，子类定细节</strong>。这样代码的复用和扩展性更好</li></ul><h3 id="举例说明">举例说明</h3><p>比如我们有一个优惠券系统，不同类型的优惠券（满减、折扣）都有相同的申请流程，比如：</p><ol><li>校验优惠券是否有效；</li><li>判断用户是否符合条件；</li><li>执行优惠逻辑；</li><li>显示确认信息。</li></ol><p>这些步骤的流程是固定的，但每种优惠券的具体实现不同。<br><strong>我们就可以把整个流程定义在父类的模板方法里，而让不同的优惠券类去实现自己的细节逻辑</strong>。<br>这样一来，公共流程就能复用，差异部分也能灵活扩展。</p><h3 id="模板方法模式的核心特点">模板方法模式的核心特点</h3><ul><li><strong>流程固定、细节可变</strong> —— 把算法流程定义好，不同子类决定具体实现。</li><li><strong>复用性高</strong> —— 公共逻辑在父类实现，减少重复代码。</li><li><strong>可扩展性强</strong> —— 新增子类就能新增新逻辑，不影响旧代码。</li></ul><h3 id="一般应用场景：">一般应用场景：</h3><ul><li><strong>有固定流程但部分步骤需要自定义的业务</strong>，比如<strong>数据处理、报表生成、文件导入导出</strong>；</li><li><strong>多个类之间有公共逻辑但部分细节不同</strong>时，比如<strong>支付流程、审批流程</strong>；</li><li><strong>框架类库中非常常见</strong>，比如：<ul><li>Java 的 JdbcTemplate 处理数据库操作；</li><li>HttpServlet 的 service() 方法就是模板方法，doGet、doPost 是子类实现的具体逻辑。</li></ul></li></ul><h2 id="什么是策略模式？一般用在什么场景？">什么是策略模式？一般用在什么场景？</h2><h3 id="什么是策略模式">什么是策略模式</h3><p>策略模式是一种<strong>行为型设计模式</strong>，它的核心思想是：<strong>定义一系列算法，把它们一个个封装起来，让它们可以互相替换，而不影响客户端的使用</strong>。</p><p>简单来说，就是<strong>用不同的策略类去封装不同的算法逻辑，这样我们就不用在代码里堆满 if-else 或 switch</strong>，而是<strong>让系统在运行时动态地选择具体的算法</strong></p><h3 id="举个例子：">举个例子：</h3><p>比如我们做一个支付系统，用户可以选择微信、支付宝、信用卡等不同支付方式。<br>传统写法会是：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (payType <span class="operator">=</span><span class="operator">=</span> <span class="string">&quot;wechat&quot;</span>) &#123; ... &#125;</span><br><span class="line">else if (payType <span class="operator">=</span><span class="operator">=</span> <span class="string">&quot;alipay&quot;</span>) &#123; ... &#125;</span><br><span class="line">else if (payType <span class="operator">=</span><span class="operator">=</span> <span class="string">&quot;credit&quot;</span>) &#123; ... &#125;</span><br></pre></td></tr></table></figure><p>1.<strong>用策略模式的话，我们可以给每种支付方式都建一个独立的策略类</strong>，比如：</p><ul><li>WechatPayStrategy</li><li>AlipayStrategy</li><li>CreditCardPayStrategy</li></ul><p>2.<strong>然后统一定义一个 PayStrategy 接口</strong>，客户端只要调用统一的接口就行，底层自动根据用户选择去调用对应的策略类。<br>3.<strong>这样增加一种新的支付方式时，只需要加一个新策略类，不用改原来的代码</strong>，符合“<strong>开闭原则</strong>”。</p><h3 id="策略模式的核心优点：">策略模式的核心优点：</h3><ul><li>消灭 if-else：<strong>让代码更清晰</strong>、可维护。</li><li><strong>易于扩展</strong>：新增算法只要新增类，不改旧逻辑。</li><li><strong>更高复用性</strong>：策略类可以被不同场景共用。</li></ul><h3 id="一般用在什么场景：">一般用在什么场景：</h3><ul><li><strong>多算法可互换</strong>：比如排序策略、压缩算法、支付方式；</li><li><strong>业务逻辑多分支</strong>：替代大量 if-else；</li><li><strong>客户端不关心算法细节</strong>：只需要知道用哪个策略就行。</li></ul><p>小结：策略模式其实就是<strong>把一堆 if-else 拆成不同的策略类，让系统可以灵活切换算法，同时让代码更优雅、更容易扩展</strong>。</p><h2 id="什么是责任链模式？一般用在什么场景？">什么是责任链模式？一般用在什么场景？</h2><p>责任链模式是一种<strong>行为型设计模式</strong>，它通过<strong>将多个处理对象串联成一条链，依次传递请求，直到某个处理对象处理完请求为止</strong>。每个处理对象会检查自己是否能处理该请求，如果不能，它会把请求转发给下一个处理对象，直到链中的某个对象处理了请求，或者整个链无法处理请求。</p><p>常见应用场景包括：</p><ol><li><strong>过滤器链</strong>：在Web开发中，Spring框架中的FilterChain就是一个责任链，它允许多个过滤器依次处理请求。</li><li><strong>日志记录</strong>：日志记录系统可以使用责任链模式将多个日志处理器串联起来，灵活选择不同的记录方式。</li><li><strong>异常处理</strong>：在应用程序中，异常处理器链可以按顺序处理各种类型的异常。</li><li><strong>授权认证</strong>：可以通过责任链模式实现多个认证过程，比如检查用户身份、权限等。</li></ol><p>例如，在一个在线商店中，订单处理可以通过责任链模式实现：</p><ol><li>检查订单信息是否完整。</li><li>检查库存是否足够。</li><li>检查用户余额是否足够。</li><li>最后确认订单并更新库存和余额。</li></ol><p>每个步骤封装成一个处理器对象，通过链式调用依次执行，确保每个步骤按照顺序处理订单。如果某个步骤失败，整个链会终止并返回错误信息。</p><p>这种模式的优势是能够使代码更加灵活、扩展性强，同时避免了请求发送者与接收者之间的紧密耦合。</p><h2 id="谈谈你了解的最常见的几种设计模式，说说他们的应用场景">谈谈你了解的最常见的几种设计模式，说说他们的应用场景</h2><p><strong>什么是设计模式?</strong><br>设计模式是<strong>前人总结出的可复用解决方案</strong>，用于在<strong>面对常见设计问题</strong>时，<strong>减少试错成本</strong>、<strong>提升开发效率和代码可维护性</strong>。</p><p>常见的几种设计模式及其应用如下：<br>1.<strong>单例模式</strong>：</p><ul><li>核心思想：<strong>保证一个类在系统中只有一个实例，并提供全局访问点</strong>。</li><li>应用场景：<ul><li><strong>日志管理器</strong>（全局唯一）</li><li><strong>数据库连接池</strong>（避免重复连接）</li><li><strong>线程池、配置中心、缓存管理</strong>等</li><li>优点：节省系统资源，控制全局状态一致性。</li><li>注意点：多线程场景要注意加锁或双重检查机制（Double-Check Locking）。</li></ul></li></ul><p>2.<strong>策略模式</strong>：</p><ul><li>核心思想：<strong>定义一系列算法，将它们封装起来，使它们可以互相替换，且客户端不必关心具体实现</strong>。</li><li>应用场景：<ul><li><strong>电商支付方式</strong>（支付宝、微信、银行卡）</li><li>推荐算法、压缩算法、<strong>日志输出策略</strong>等</li><li>优点：<strong>避免大量 if-else/switch 判断</strong>，扩展性好；</li></ul></li></ul><p>3.<strong>模板方法模式</strong>：</p><ul><li>核心思想：<strong>在父类中定义算法的骨架（流程），把其中可变的部分交给子类去实现</strong>。</li><li>应用场景：<ul><li>数据处理（统一流程但不同实现）</li><li>支付前置后置工作，优惠卷校验等等</li><li>抽象类定义框架，如爬虫、编译器、Hook 机制</li><li>优点：复用固定流程，提高一致性，子类只需重写差异部分。</li></ul></li></ul><p>4.<strong>工厂模式</strong>：</p><ul><li>核心思想：<strong>定义创建对象的接口，由子类决定实例化哪一个类</strong>。</li><li>分类：简单工厂、工厂方法、抽象工厂。</li><li>应用场景：<ul><li>数据库驱动加载（MySQLFactory、OracleFactory）</li><li>UI 组件创建、日志输出实例化等</li><li>优点：解耦对象创建和使用逻辑，方便扩展和维护。</li></ul></li></ul><p>5.<strong>观察者模式</strong>：</p><ul><li>核心思想：建立“一对多”的依赖关系，<strong>当一个对象状态改变时，自动通知所有观察者更新</strong>。</li><li>应用场景：<ul><li>GUI 事件监听（按钮点击通知多个监听器）</li><li><strong>消息推送系统</strong>（发布-订阅）</li><li><strong>股票价格更新</strong>、缓存失效广播等</li><li>优点：实现对象间的低耦合通信。</li></ul></li></ul><h2 id="你认为好的代码应该是什么样的？">你认为好的代码应该是什么样的？</h2><p>我觉得好的代码首先要<strong>清晰易懂</strong>，逻辑直观、命名规范，让别人一看就能理解。<br>其次是<strong>高内聚低耦合</strong>，<strong>模块内部功能集中、模块之间尽量独立</strong>，这样修改或扩展时影响最小。<br>同时要<strong>易测试、易扩展</strong>，遵循像 SOLID、KISS 这些设计原则，保持结构简单又灵活。<br>在<strong>性能和错误处理上</strong>，选择<strong>合适的算法和数据结构</strong>，<strong>异常要有预判和日志记录</strong>，避免系统出错。<br>最后，<strong>保持规范和一致性，该有的注释和文档要完善</strong>。</p><p>简单来说，好的代码就是——<strong>简单、清晰、稳定、可维护</strong>。</p><blockquote><p>补充：<br>SOLID、KISS 设计原则<br>SOLID是面向对象设计的五大基础原则，由Robert C. Martin提出，旨在提高代码的可维护性和扩展性：<br>1.单一职责原则（SRP）‌<br>一个类只负责一个职责，避免功能混杂。例如，用户信息类若包含地址、登录等属性，可能需拆分为多个类。 ‌<br>‌2.开闭原则（OCP）‌<br>对扩展开放，对修改关闭。新功能应通过新增代码实现，而非修改现有代码。 ‌<br>3.里氏替换原则（LSP）‌<br>子类应能替换父类而不破坏程序行为。例如，子类实现的接口需符合父类定义的“协议”。 ‌<br>‌4.接口隔离原则（ISP）‌<br>接口应保持职责单一，避免强制依赖未使用的接口。 ‌<br>‌5.依赖倒置原则（DIP）‌<br>高层模块不依赖低层模块，二者均依赖抽象接口。 ‌<br>KISS原则<br>KISS（Keep It Simple, Stupid）强调代码应简洁易懂，避免过度设计： 优先使用简单解决方案，减少复杂逻辑。例如，避免冗余的嵌套条件判断。 ‌与SOLID互补：SOLID解决结构问题，KISS确保实现简洁。 ‌</p></blockquote>]]></content>
    
    
    <summary type="html">我对设计模式的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="设计模式" scheme="https://itgeqian.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>操作系统相关面试题</title>
    <link href="https://itgeqian.github.io/posts/72.html"/>
    <id>https://itgeqian.github.io/posts/72.html</id>
    <published>2025-11-01T00:19:03.000Z</published>
    <updated>2025-11-05T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-操作系统">GQ 操作系统</h1><h2 id="操作系统在进行线程切换时需要进行哪些动作？">操作系统在进行线程切换时需要进行哪些动作？</h2><ol><li>保存当前线程的上下文，比如CPU寄存器、栈指针等到线程控制块中</li><li>更新当前线程的状态</li><li>选择下一个要执行的线程</li><li>恢复下一个要执行的线程的上下文，恢复CPU寄存器、栈指针、程序计数器等信息</li></ol><h2 id="什么是用户态和内核态？">什么是用户态和内核态？</h2><h3 id="用户态和内核态是什么？">用户态和内核态是什么？</h3><p>在操作系统里，其实所有程序不是随便跑的，它们分为两种“运行等级”：<strong>用户态（User Mode）<strong>和</strong>内核态（Kernel Mode）</strong>。</p><h3 id="一句话总结">一句话总结</h3><p><strong>用户态负责“正常干活”，内核态负责“有权限的活”。</strong><br>为了保证系统安全、稳定，CPU 给了这两种模式不同的权限。</p><h3 id="1-用户态和内核态分别是什么？">1. 用户态和内核态分别是什么？</h3><h4 id="用户态（权限低的模式）">用户态（权限低的模式）</h4><ul><li>就是普通应用程序运行的地方，比如浏览器、微信、业务代码。</li><li>权限有限，<strong>不能直接操作硬件</strong>（比如磁盘、网络、内存管理等）。</li><li>如果应用要访问系统资源，<strong>必须通过系统调用</strong>让内核帮忙。</li></ul><p>你可以把它想象成：<br>“只能敲前台窗口的顾客，不能自己跑到后台翻文件。”</p><h4 id="内核态（权限最高的模式）">内核态（权限最高的模式）</h4><ul><li>是操作系统内核运行的区域。</li><li>有<strong>最高权限</strong>，可以访问所有硬件和系统资源。</li><li>驱动、进程管理、内存管理、文件系统等关键逻辑都在这里执行。</li></ul><p>对应比喻：<br>“后台管理员，可以直接接触所有资源。”</p><h3 id="2-为什么要区分用户态和内核态？">2. 为什么要区分用户态和内核态？</h3><p>主要是为了 <strong>安全</strong> 和 <strong>稳定</strong>：</p><ul><li>如果普通程序能直接操作硬件，一行错误代码就能让系统崩溃。</li><li>内核可以集中管理资源，让系统更可靠。</li><li>用户态崩了，只挂一个进程；内核态崩了，整个系统蓝屏/重启。</li></ul><p>简单说：<br>“保护好内核，系统才能稳。”</p><h3 id="3-用户态和内核态如何切换？">3. 用户态和内核态如何切换？</h3><p><strong>只有三种情况能从用户态切到内核态：</strong></p><h4 id="①-系统调用（最常见）">① 系统调用（最常见）</h4><p>比如：</p><ul><li>read/write 文件</li><li>网络操作</li><li>创建进程</li><li>分配内存</li></ul><p>流程是这样：</p><ol><li>用户态应用发起系统调用（比如 read）</li><li>CPU 触发中断/异常机制</li><li>保存当前执行上下文（PC、寄存器、栈等）</li><li>CPU 切换到内核态</li><li>内核执行操作</li><li>执行完毕再切回用户态继续运行</li></ol><h4 id="②-中断（如硬件中断）">② 中断（如硬件中断）</h4><p>比如鼠标、键盘、网卡收到数据，也会强制切到内核态处理。</p><h4 id="③-异常（如除零异常）">③ 异常（如除零异常）</h4><p>出现错误也要交给内核处理。</p><p>可以简单记：<br>“用户态做不了的事，内核态帮你干。”</p><h3 id="4-举例让你秒懂">4. 举例让你秒懂</h3><h4 id="写文件">写文件</h4><p>用户态业务代码 → 发起 write 系统调用 → 内核态执行 IO → 回到用户态。</p><h4 id="网络收包">网络收包</h4><p>网卡收到数据（中断）→ 内核态处理 TCP → 应用程序 read 取数据。</p><h4 id="创建线程">创建线程</h4><p>业务代码调用 pthread_create → 内核创建 PCB → 返回用户态继续执行。</p><h3 id="5-补充">5. 补充</h3><h4 id="为什么需要上下文切换？">为什么需要上下文切换？</h4><p>因为 CPU 要从“普通权限”切换到“超级权限”，必须保存/恢复当前状态，避免执行乱套。</p><h4 id="内核态一定开销更大吗？">内核态一定开销更大吗？</h4><p>对，切换成本高，不是免费操作：</p><ul><li>保存/恢复寄存器</li><li>模式切换</li><li>TLB 刷新等</li></ul><p>所以框架（如 Netty）常减少系统调用次数，就是为了减这个开销。</p><h3 id="总结">总结</h3><blockquote><p>用户态和内核态是操作系统的两种运行模式。<br><strong>普通应用程序跑在用户态，权限有限，不能直接操作硬件</strong>；<strong>内核态是操作系统内核运行的区域，权限最高，可以访问全部硬件资源</strong>。</p></blockquote><blockquote><p>之所以要分层，是<strong>为了保证系统安全和稳定</strong>。如果用户程序可以直接操控硬件，一旦写错就可能把整个系统搞崩。</p></blockquote><blockquote><p>当应用程序需要执行像 <strong>IO、进程管理这类特权操作时，会通过系统调用、中断或异常切换到内核态</strong>，操作系统<strong>处理完再切回用户态</strong>继续执行。</p></blockquote><blockquote><p>所以可以简单理解：用户态负责“<strong>普通工作</strong>”，内核态负责“<strong>特权工作</strong>”，两者通过系统调用机制安全地切换。</p></blockquote><h2 id="进程之间的通信方式有哪些？">进程之间的通信方式有哪些？</h2><p>在操作系统里，不同进程是隔离的，不能直接访问对方的数据，所以需要各种 <strong>IPC（Inter-Process Communication）机制</strong> 来交换数据、做同步、甚至协作。常用的进程间通信方式主要有下面这几类：</p><ol><li><strong>管道（Pipe）——最基础、最经典的 IPC</strong></li></ol><ul><li>管道就是一个内存中的“单向传输带”，一端写、一端读。</li><li>常用于 <strong>父子进程之间</strong>的简单通信。</li><li>如果要跨进程通信，就要用 <strong>命名管道</strong>（FIFO），它支持不相关进程之间通过一个特殊的文件来通信。</li></ul><blockquote><p>“管道就像水管，只有前后两个进程能用，一个写，一个读；如果想让不相关的两个进程通信，就用带名字的水管，也就是 FIFO。”</p></blockquote><ol start="2"><li><strong>消息队列（Message Queue）——带结构的异步通信</strong></li></ol><ul><li>系统维护一个消息列表，进程可以往里面“投递消息”，别的进程可以从中“取消息”。</li><li>支持不同类型的消息、有优先级。</li><li>可以实现异步解耦，不需要双方同时在线。</li></ul><blockquote><p>“消息队列就像邮局，你发一封消息扔进去，收的人什么时候取都可以，是一种典型的异步通信机制。”</p></blockquote><ol start="3"><li><strong>共享内存（Shared Memory）——最快的 IPC</strong></li></ol><ul><li>多个进程直接共享同一块物理内存。</li><li>数据不用复制 → <strong>速度最快</strong>。</li><li>但必须搭配锁（信号量、互斥锁、读写锁）来保证同步。</li></ul><blockquote><p>“共享内存就像几个人一起看同一张纸，最快，但必须约定好写的时候不能抢，要配合锁用。”</p></blockquote><ol start="4"><li><strong>信号量（Semaphore）——资源访问的红绿灯</strong></li></ol><ul><li>本质是计数器，用来控制多个进程之间的“互斥”和“同步”。</li><li>常与共享内存一起使用，防止并发冲突。</li></ul><blockquote><p>“信号量就是一组红绿灯，用来保证多个进程访问同一资源时不冲突。”</p></blockquote><ol start="5"><li><strong>信号（Signal）——用于通知、异常处理</strong></li></ol><ul><li>多用于异常事件通知，例如 SIGINT、SIGKILL。</li><li>可以看作“操作系统发给进程的中断消息”。</li></ul><blockquote><p>“信号就像操作系统给进程发的一条短信，告诉你发生异常了，比如要终止、要暂停。”</p></blockquote><ol start="6"><li><strong>套接字（Socket）——支持跨主机通信</strong></li></ol><ul><li>不只用于网络，也可用于本地 IPC（如 UNIX Domain Socket）。</li><li>支持跨机器、跨进程通信，应用范围最广。</li></ul><blockquote><p>“Socket 最强大，可以本地通信也可以跨网络通信，是分布式系统里最常用的方式。”</p></blockquote><ol start="7"><li>内存映射（MMAP / Memory-Mapped Files）</li></ol><ul><li>通过把一个文件映射到多个进程的地址空间实现共享。</li><li>适合进程间共享较大数据。</li></ul><blockquote><p>“内存映射就是把一个文件当成‘共享内存’，读写文件等于读写内存。”</p></blockquote><h3 id="小结">小结</h3><p>IPC 主要有 6 类：管道、消息队列、共享内存、信号量、信号、Socket。<br>管道最简单；消息队列支持异步；共享内存最快；信号量管互斥同步；信号做事件通知；Socket 最通用，支持跨主机。<br>本地大量数据用共享内存，跨进程解耦用消息队列，跨机器就用 Socket。</p><h2 id="操作系统中的进程有哪几种状态？">操作系统中的进程有哪几种状态？</h2><p>5种</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/JzMDI0sV_Snipaste_2025-11-16_14-41-30_mianshiya.png" alt="Snipaste_2025-11-16_14-41-30.png" width="100%" /><h2 id="进程的调度算法你知道吗？">进程的调度算法你知道吗？</h2><h3 id="1-先来先服务（FCFS）">1.先来先服务（FCFS）</h3><p>按<strong>进程到达的先后顺序调度</strong>，简单易实现，<strong>但可能让短任务被长任务“拖死”</strong>，叫做“长任务占坑”。</p><h3 id="2-短作业优先（SJF）-最短剩余时间优先（SRTF）">2.短作业优先（SJF）/ 最短剩余时间优先（SRTF）</h3><p><strong>优先让运行时间最短的任务先执行</strong>，可以显著降低平均等待时间；但<strong>缺点是必须能预估执行时间</strong>，而且不适合交互式系统。</p><h3 id="3-优先级调度（Priority-Scheduling）">3. 优先级调度（Priority Scheduling）</h3><p><strong>按优先级调度，高优先级先执行</strong>。适合有紧急任务的系统，但可能导致低优先级任务长期得不到运行，引发“<strong>饥饿</strong>”。</p><h3 id="4-时间片轮转（RR）">4. 时间片轮转（RR）</h3><p><strong>每个任务轮流按时间片执行</strong>，是典型的交互式系统调度方式。时间片越短响应越快，<strong>但上下文切换开销越大</strong>。</p><h3 id="5-最高响应比优先（HRRN）">5. 最高响应比优先（HRRN）</h3><p>通过“响应比 =（等待时间 + 运行时间）/ 运行时间”来决定调度谁。有效避免短作业优先导致的长任务饥饿问题。</p><h3 id="6-多级反馈队列（MLFQ）——最常用">6. 多级反馈队列（MLFQ）——最常用</h3><p><strong>结合多个队列，根据任务表现动态调整优先级</strong>：<br>短任务快速完成，高优先级队列跑；<br>长任务逐渐降级，跑到低优先级队列。</p><blockquote><p>它结合了 RR、优先级、SJF 的优点，也是现代系统默认使用的算法</p></blockquote><h3 id="小结-2">小结</h3><p>常见调度算法有六个：</p><ul><li>FCFS（先来先服务），简单但容易被长任务拖慢；</li><li>SJF 和 SRTF（短作业优先），平均等待时间最低，但需要预估执行时间；</li><li>Priority（优先级调度），高优先级先执行，但可能导致饥饿；</li><li>RR（时间片轮转），适合交互式系统，响应快但切换开销大；</li><li>HRRN（最高响应比优先），解决了饥饿问题；</li><li><strong>最后是最常用的 MLFQ 多级反馈队列，结合时间片和优先级，短任务跑得快，长任务逐渐降级，是现代系统常用策略。</strong></li></ul><h2 id="线程和进程有什么区别？">线程和进程有什么区别？</h2><h3 id="进程、线程、协程的区别">进程、线程、协程的区别</h3><p>进程负责“资源”，线程负责“执行”，协程负责“更轻量的执行方式”。</p><h3 id="进程是什么？（资源隔离-独立内存）">进程是什么？（资源隔离+独立内存）</h3><ul><li>进程<strong>就是一个程序的运行实例</strong>，<strong>比如你打开一个微信，就是一个进程</strong>。</li><li><strong>每个进程有自己独立的内存空间、文件句柄</strong>等资源，<strong>是操作系统中资源分配的最小单位</strong>。</li><li>不同进程之间互不影响，因此<strong>稳定性高，但创建和切换成本大</strong>。</li></ul><h3 id="线程是什么？（执行单元-更轻量）">线程是什么？（执行单元+更轻量）</h3><p><strong>线程是进程内部的“执行流”，一个进程可以有多个线程</strong>。<br><strong>线程之间共享同一个进程的内存</strong>，因此通信非常方便，但安全性要靠加锁保证。<br>线程是<strong>CPU 调度的最小单位</strong>，切换比进程轻量，但仍需要 OS 参与调度。</p><h3 id="协程是什么？（用户态、极轻、高并发）">协程是什么？（用户态、极轻、高并发）</h3><p><strong>协程是比线程更轻量的“用户态调度”的执行方式，不会被 OS 感知。</strong><br>它把切换时机交给程序自己决定，而不是让 OS 抢占式调度，因此切换开销极低。<br>常用于大量 I/O 任务，比如 Go 的 goroutine、Java 的虚拟线程。</p><ul><li>进程：资源独立、安全但重 → “房子”</li><li>线程：共享资源、切换轻 → “房子里的房间”</li><li>协程：极轻量、用户态调度 → “房间里的小隔断，不需要 OS 管”</li></ul><h3 id="执行成本对比">执行成本对比</h3><table><thead><tr><th>对比项</th><th>进程</th><th>线程</th><th>协程</th></tr></thead><tbody><tr><td>创建成本</td><td>高</td><td>中</td><td>很低</td></tr><tr><td>切换成本</td><td>高（OS 切换）</td><td>中（OS 切换）</td><td>极低（用户态切换）</td></tr><tr><td>内存隔离</td><td>完全隔离</td><td>共享</td><td>共享，逻辑更轻</td></tr><tr><td>调度者</td><td>OS</td><td>OS</td><td>程序自身</td></tr></tbody></table><h3 id="小结-3">小结</h3><ul><li><strong>进程是操作系统分配资源的单位，每个进程有独立的内存，因此安全但切换成本高</strong>。</li><li><strong>线程是进程里的执行单元，共享进程资源，切换比进程快但需要同步锁来保证安全</strong>。</li><li><strong>协程更轻量，它在用户态调度，不需要 OS 参与，所以切换成本非常低，非常适合 I/O 密集的高并发场景，比如 Go 的 goroutine 或 Java 的虚拟线程</strong>。</li></ul><h2 id="什么是软中断、什么是硬中断？">什么是软中断、什么是硬中断？</h2><h3 id="什么是软中断、什么是硬中断？-2"><strong>什么是软中断、什么是硬中断？</strong></h3><p>简单来说，<strong>硬中断是由硬件触发的，软中断是由软件触发的</strong>。</p><p>像键盘、网卡、定时器这些外设，每当有事件发生时，会主动给 CPU 发一个“硬中断信号”。<strong>CPU 收到后会立刻暂停当前执行的程序，去处理对应的中断逻辑</strong>，所以<strong>硬中断优先级一般比较高</strong>。</p><blockquote><p>硬中断就像外卖小哥敲你家门CPU 不管在干什么，都得先暂停下来去处理</p></blockquote><p>而<strong>软中断</strong>是程序自己触发的，比如系统调用、int 指令，它们本质上是通过软件的方式，让 CPU 去执行一段内核服务逻辑，比如文件读写、进程调度等。软中断通常<strong>优先级低于硬中断</strong>。</p><blockquote><p>软中断更像是主动打电话给客服 程序或操作系统自己发起一个“请求”</p></blockquote><blockquote><p>一句话总结：<br><strong>硬中断来自外设，实时性强、优先级高；软中断来自软件，用来请求内核服务。</strong></p></blockquote><h2 id="为什么要有虚拟内存？">为什么要有虚拟内存？</h2><h3 id="为什么要有虚拟内存？-2"><strong>为什么要有虚拟内存？</strong></h3><p>虚拟内存的出现，主要是为了解决三个问题：<strong>内存不够用、进程之间要隔离、安全性不好管理</strong>。我们可以把它理解成：<strong>给每个程序造一个“假的、大内存空间”，再由系统负责把“假地址”映射到真实物理内存里。</strong></p><p>这样做的好处非常明显：</p><h3 id="1-内存变大了（扩容能力）"><strong>1. 内存变大了（扩容能力）</strong></h3><p>物理内存只有那么一点，但虚拟内存能把程序看到的地址空间放得很大。</p><p>比如：</p><ul><li>程序觉得自己有 4GB 内存</li><li>实际上机器可能只有 8GB 内存同时跑十几个程序</li><li>系统不够用时还能把不常用的内存换到磁盘（swap）</li></ul><p><strong>总结一句话：虚拟内存让“内存看起来很大”，不够用就上磁盘，程序丝毫感觉不到。</strong></p><h3 id="2-进程之间互不干扰（强隔离）"><strong>2. 进程之间互不干扰（强隔离）</strong></h3><p>每个进程都看到自己独立的虚拟地址空间：</p><ul><li>A 程序不能直接访问 B 程序内存</li><li>也不能乱改系统内核的内存</li><li>内核能给不同区域设置访问权限（只读、可执行、不可写等）</li></ul><p><strong>这就像每个人住单间房，互相进不了对方房间，安全性大大提高。</strong></p><h3 id="3-让内存管理更简单（系统更好调度）"><strong>3. 让内存管理更简单（系统更好调度）</strong></h3><p>虚拟内存让操作系统可以随心所欲：</p><ul><li>想把程序的某个地址映射到哪块物理内存，全由系统决定</li><li>程序不需要关心物理内存是怎么分布的</li><li>更易做内存回收、页调度、统一管理</li></ul><p><strong>对应用来说是“假地址”，对系统是“真实物理地址”，两边都更自由了。</strong></p><h3 id="扩展一下（面试加分用）">扩展一下（面试加分用）</h3><p><strong>1）虚拟地址怎么变成物理地址？</strong></p><p>靠硬件 MMU + 页表。</p><p>流程大概是：</p><ul><li>CPU 生成虚拟地址</li><li>MMU 查页表 → 得到物理地址</li><li>找不到就触发 Page Fault</li><li>系统把磁盘里的页面交换回来继续执行</li></ul><p><strong>虚拟内存底层核心：页表 + MMU</strong></p><p><strong>2）为什么页表要多级？</strong></p><p>因为地址空间巨大，一个巨大页表会占用很多内存。</p><p>多级页表能做到：</p><ul><li>稀疏内存不需要分配页表</li><li>节省内存开销</li></ul><p><strong>3）Copy-on-Write（写时复制）为什么重要？</strong></p><p>比如 <code>fork()</code>：</p><p>父进程和子进程先“共享”内存，直到某一方真正写入才复制。</p><p>大大减少内存占用。</p><p><strong>4）TLB（快表）是什么？</strong></p><p>TLB 是缓存页表的东西，加速地址映射。</p><p>没有命中（TLB Miss）时才去查页表。</p><h3 id="总结-2"><strong>总结</strong></h3><blockquote><p>虚拟内存就是给每个进程提供一个独立、巨大的“假地址空间”，由系统把虚拟地址翻译成物理地址。这样能扩容内存、隔离进程、提高安全性，还让内存管理更灵活。真正落地是靠页表、MMU、Page Fault、TLB 等机制共同完成。</p></blockquote><h2 id="什么是分段、什么是分页？">什么是分段、什么是分页？</h2><p>在操作系统里，分段和分页都是用来管理内存的，但出发点完全不同。</p><p><strong>首先说分段（Segmentation）：</strong></p><p>我自己理解分段就是<strong>按照程序的逻辑结构来切内存</strong>。<br>比如一个程序自然会分成 <em><strong>代码段、数据段、栈段</strong></em> 等，每一段都是独立的、大小也不一样，而且段与段之间不要求连续。</p><p>所以分段的好处是：</p><ul><li>更贴近程序的逻辑结构，可读性强、好维护；</li><li>每段可以按需增长，比如栈往下长、堆往上长，互不干扰；</li><li>内存访问会带上“段号 + 段内偏移”。</li></ul><p>但分段的问题是段的大小不固定，容易造成<strong>外部碎片</strong>。</p><p><strong>再说分页（Paging）：</strong></p><p>分页就是<strong>把虚拟内存和物理内存都切成固定大小的“页”</strong>（比如 4KB）。固定大小让内存管理特别简单，不会有外部碎片。</p><p>分页的特点是：</p><ul><li>进程看到的是虚拟地址，虚拟页通过<strong>页表</strong>映射到物理页；</li><li>虚拟页不存在时会触发缺页中断，把页面从磁盘换入；</li><li>页面大小固定，所以方便分配与回收。</li></ul><p>分页的核心目的，就是让<strong>系统可以高效使用物理内存</strong>，并支持更大、更独立的虚拟地址空间。</p><p><strong>一句话总结：</strong></p><ul><li><strong>分段更关注“程序结构”</strong>（逻辑切分，大小不固定）；</li><li><strong>分页更关注“内存利用”</strong>（固定大小的页，更容易管理）。</li></ul><p>很多现代系统是段页式结合使用：<strong>先按段划分，再在每段内部用分页</strong>。</p><h3 id="小结-4">小结</h3><p>分段和分页都是操作系统的内存管理方式。</p><p>分段是按程序的逻辑结构切内存，比如代码段、数据段、栈段等，每段大小都不一样，更贴近程序的真实结构，好理解、好维护，但容易产生外部碎片。</p><p>分页则是把虚拟内存和物理内存都切成固定大小的页，通过页表做映射，不会有外部碎片，内存利用率更高，也方便换页和内存回收。</p><p>一句话总结就是：<br><strong>分段关注“程序结构”，分页关注“内存管理与效率”。<br>现代系统一般是两者结合使用</strong>。</p><h2 id="说下你常用的-Linux-命令？">说下你常用的 Linux 命令？</h2><p>一般分为<strong>文件操作、系统管理、网络调试、日志查看</strong>这几个维度</p><h3 id="文件和目录相关的基本操作">文件和目录相关的基本操作</h3><p>日常开发中最常用的就是这些：</p><ul><li>ls / ll：查看目录内容，ll 会显示详细信息；ls -a 会显示隐藏文件。</li><li>cd / pwd：切换目录、查看当前路径。</li><li>mkdir / rm / cp / mv：创建目录、删除、复制、移动文件。</li><li>find：查找文件很常用，比如查找最近 7 天的日志：</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">find</span> . -name <span class="string">&quot;*.log&quot;</span> -mtime -7</span><br></pre></td></tr></table></figure><p>这些命令主要用来<strong>定位文件、管理项目</strong>目录。</p><h3 id="文件内容查看（排查-bug-必备）">文件内容查看（排查 bug 必备）</h3><ul><li>cat：看小文件。</li><li>more / less：看大文件，less 可以翻页。</li><li>head / tail：看文件开头和结尾，尤其 tail -f 实时看日志非常常用：</li></ul><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f <span class="keyword">app</span>.<span class="keyword">log</span> | grep <span class="keyword">ERROR</span></span><br></pre></td></tr></table></figure><ul><li>grep：文本搜索神器，排查问题最常用。</li></ul><h3 id="系统管理相关（定位线上问题最常用）">系统管理相关（定位线上问题最常用）</h3><ul><li>top/htop：查看 CPU、内存占用，一般线上性能问题都从 top 先看。</li><li>ps aux | grep：看指向的 java 进程、服务有没有启动：</li></ul><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ps</span> aux | <span class="keyword">grep</span> java</span><br></pre></td></tr></table></figure><ul><li>kill / kill -9：杀进程（线上谨慎使用 -9）。</li><li>df -h：看磁盘空间。</li><li>du -sh：看某个目录大小，比如排查日志占满磁盘：</li></ul><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -<span class="keyword">sh</span> /<span class="keyword">var</span>/<span class="keyword">log</span>/</span><br></pre></td></tr></table></figure><p>这些主要用来<strong>看资源、查进程、排查线上故障</strong>。</p><h3 id="用户、权限相关">用户、权限相关</h3><ul><li>chmod：改权限，比如给脚本加执行权限：</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">chmod</span> <span class="number">755</span> start.sh</span><br></pre></td></tr></table></figure><ul><li>chown：改文件所属用户。</li><li>passwd：改密码。</li></ul><h3 id="网络相关（排查联通问题）">网络相关（排查联通问题）</h3><ul><li>ping：是否能 ping 通机房、目标服务。</li><li>curl / wget：发 HTTP 请求、下载文件，curl 更适合调接口。</li><li>netstat / ss：查看端口是否被占用、服务连通状态。</li><li>ifconfig / ip addr：查看服务器 IP 信息。</li><li>telnet：测试端口是否能访问。</li></ul><p>线上连通性问题基本都靠这些来定位。</p><h3 id="压缩与解压">压缩与解压</h3><ul><li>tar -xvf / tar -cvf：解压 / 压缩</li><li>zip / unzip</li><li>gzip / gunzip</li></ul><h3 id="Git、Maven-这些我也会用">Git、Maven 这些我也会用</h3><p>因为开发环境也在 Linux 上，所以 Git 和 Maven 也算常用命令。</p><ul><li>git pull / git push / git checkout</li><li>mvn clean install -Dmaven.test.skip=true</li></ul><h3 id="其他性能分析命令（生产排查很有用）">其他性能分析命令（生产排查很有用）</h3><ul><li>vmstat：内存、CPU 细节</li><li>iostat：IO 负载</li><li>dmesg：查看系统级错误（比如 OOM）</li></ul><blockquote><p>常用的 Linux 命令基本覆盖了文件管理、系统监控、网络调试、日志排查几个维度，像 ls/ps/top/grep/tail/curl/df/du 这些几乎每天都在用；线上排查问题时主要依赖 top + ps + grep + tail -f 这一套组合拳，处理高 CPU、磁盘满、进程挂掉等典型问题。</p></blockquote><h3 id="小结-5">小结</h3><p>我平时在开发和排查问题时，其实 Linux 命令用得很频繁。</p><p>首先是<strong>文件和目录操作</strong>，ls、ll、cd、mkdir、rm 这些是最基本的；比如我经常用 ls -l 看文件权限和大小，用 find 去查最近生成的日志。</p><p>在<strong>查看文件内容上</strong>，我最常用的是 cat、less、grep、tail -f 这些组合，尤其 tail -f app.log | grep ERROR，基本是我线上排查日志的常用招式。</p><p><strong>系统监控和进程管理</strong>方面，我会用 top 或 htop 看 CPU、内存；用 ps aux | grep java 查看某个服务的进程状态，必要的时候会用 kill 杀掉异常进程。磁盘占满时我通常用 df -h 和 du -sh * 查哪块目录空间过大。</p><p><strong>网络相关</strong>我会用 ping、curl、telnet、ss -lntp 来排查端口和网络连通性。例如接口不通，我一般会先 curl 一下看响应，再用 ss 确认端口有没有被正常监听。</p><p><strong>权限管理</strong>方面，chmod 755 给脚本加执行权限，chown 修改文件所属用户，这些在部署服务时非常常用。</p><p>整体来说，我用 Linux 命令主要是围绕 <strong>文件管理、日志排查、系统监控、网络调试</strong>这几个核心场景，特别是排查线上问题时，top + ps + grep + tail -f 是我最常用的一套组合拳。</p><h2 id="I-O是什么">I/O是什么?</h2><p>I/O（Input/Output，输入/输出）是<strong>计算机系统中用于数据传输的机制</strong>，指的是在<strong>计算机和外部设备</strong>（如键盘、显示器、磁盘等）<strong>之间</strong>，或在计算机内部组件（如内存和CPU）<strong>之间</strong>的数据传输过程</p><h2 id="为什么网络-I-O-会被阻塞？">为什么网络 I/O 会被阻塞？</h2><p>网络 I/O 会被阻塞的主要原因有几个。</p><ul><li>首先是 <strong>等待数据发送或接收完成</strong>，例如，当程序试图从网络套接字中读取数据时，<strong>如果数据还没有到达，它就会阻塞，直到数据传输完成</strong>；</li><li>其次是 <strong>系统资源限制</strong>，当系统的资源（如网络带宽、连接数等）达到最大限制时，进程会被迫等待资源可用，导致阻塞；</li><li>第三是 <strong>默认的阻塞行为</strong>，大多数网络 API（如 <code>recv</code>、<code>send</code>、<code>accept</code>）默认是阻塞模式，即在没有数据可以处理时，它们会一直等待。<ul><li>另外，还有 <strong>异步 I/O</strong> 模型可以用来解决这些问题。通过这种方式，可以在 I/O 操作时不阻塞程序，继续执行其他任务，直到数据准备好。这种方式通常使用事件驱动模型（如 Node.js、libevent）来实现高效的非阻塞 I/O 操作。</li></ul></li></ul><h2 id="I-O模型有哪些？">I/O模型有哪些？</h2><p>I/O模型通常有以下几种：</p><ol><li><p><strong>阻塞I/O（Blocking I/O）</strong>：<strong>在执行I/O操作时，进程会被阻塞</strong>，直到数据准备好或操作完成才能继续执行。就像<strong>在银行排队办理业务</strong>，只有等到轮到你时才能办。</p></li><li><p><strong>非阻塞I/O（Non-blocking I/O）</strong>：<strong>I/O操作不会阻塞进程，如果数据没有准备好，立刻返回错误</strong>或状态，进程可以继续执行其他任务。像<strong>去银行办理业务，如果柜台忙，离开后稍候再来</strong>。</p></li><li><p><strong>I/O多路复用（I/O Multiplexing）</strong>：通过<code>select</code>、<code>poll</code>、<code>epoll</code>等系统调用，可以<strong>同时处理多个I/O操作</strong>。当数据准备好时，进程才会处理。<strong>类似银行大堂经理告知你哪个柜台有空，你再去办理</strong>。</p></li><li><p><strong>信号驱动I/O（Signal-driven I/O）</strong>：内核通过<strong>信号通知进程，数据准备好了，进程就可以去处理数据</strong>。像<strong>银行通知VIP会员可以直接去专属柜台办理业务</strong>。</p></li><li><p><strong>异步I/O（Asynchronous I/O）</strong>：<strong>发起I/O请求后，进程继续做其他事，直到数据准备好后，内核通知进程去处理数据</strong>。就像让<strong>银行工作人员办理好业务后通知你来取结果，你可以做其他事</strong>。</p></li></ol><p>这些模型各有优缺点，适用于不同的场景。</p><h2 id="同步和异步的区别？">同步和异步的区别？</h2><p>同步操作<strong>需要等待任务完成后才能继续执行</strong>；异步操作则<strong>不需要等待任务完成，可以继续执行其他任务</strong>，提高系统的效率</p><h2 id="到底什么是-Reactor？">到底什么是 Reactor？</h2><h3 id="到底什么是-Reactor？-2">到底什么是 Reactor？</h3><p>简单说，<strong>Reactor 就是一种“事件驱动 + I/O 多路复用”的服务器处理模型</strong>。<br>它的核心目标是：<strong>让一个线程就能高效处理大量并发连接。</strong></p><p>如果用一句话总结：</p><p><strong>Reactor 就是“一个线程等事件、多个处理器处理事件”的模式。</strong></p><h3 id="Reactor-解决的本质问题是什么？">Reactor 解决的本质问题是什么？</h3><p>传统 BIO 是一连接一线程，几万连接就死定了。</p><p>Reactor 让你做到：</p><ul><li>一个或少量线程统一监听所有 I/O 事件（连接、读、写）</li><li>一旦有事件发生，就分发给对应的处理器去处理</li></ul><p><strong>也就是：监听事件和处理事件彻底解耦了。</strong></p><h3 id="Reactor-的-3-大核心角色">Reactor 的 3 大核心角色</h3><p>Reactor 架构里永远是下面三个角色：</p><h4 id="①-Reactor（事件反应器）">① <strong>Reactor（事件反应器）</strong></h4><ul><li>负责监听所有事件（通过 select/epoll）</li><li>一旦有事件发生，就分发给对应 Handler<br>（就像一个总调度 / 事件分发器）</li></ul><h4 id="②-Handler（事件处理器）">② <strong>Handler（事件处理器）</strong></h4><ul><li>和某个 I/O 事件绑定，比如“连接事件”“可读事件”“可写事件”</li><li>事件来了就负责真正的业务逻辑（读、写、处理、回包）</li></ul><h4 id="③-Acceptor（连接处理器）">③ <strong>Acceptor（连接处理器）</strong></h4><ul><li>专门处理新连接</li><li>给新连接分配一个 Handler（让后续的读写事件有人负责）</li></ul><p><strong>一句话记住：<br>Reactor 负责“盯着事件”，Handler 负责“干活”。</strong></p><h3 id="Reactor-的工作流程">Reactor 的工作流程</h3><p>你可以这样讲，非常顺：</p><ol><li><strong>Reactor 用一个 selector 一直等事件发生</strong>（连接、可读、可写）</li><li><strong>事件来了</strong>，Reactor 会判断这是哪个连接、什么事件</li><li><strong>把事件分发给对应的 Handler</strong></li><li><strong>Handler 进行处理，比如读消息→业务逻辑→写回客户端</strong></li><li><strong>处理完继续返回 Reactor，继续等下一个事件</strong></li></ol><p>和 GUI 程序的“按钮点击触发事件”其实是一个思想。</p><h3 id="Reactor-vs-Proactor">Reactor vs Proactor</h3><table><thead><tr><th>模式</th><th>谁负责处理 I/O？</th><th>应用程序什么时候被调用？</th><th>典型场景</th></tr></thead><tbody><tr><td><strong>Reactor（同步非阻塞）</strong></td><td>应用程序自己完成读写</td><td>事件就绪时被通知，然后自己做 I/O</td><td>Linux（epoll）常用</td></tr><tr><td><strong>Proactor（异步 I/O）</strong></td><td>内核帮你完成读写</td><td>I/O 完成后通知应用程序处理结果</td><td>Windows IOCP</td></tr></tbody></table><p>一句话总结：</p><p><strong>Reactor 是“事件来了我去读”</strong><br><strong>Proactor 是“你帮我读好了再通知我”</strong></p><h3 id="单-Reactor-多-Reactor-怎么选？">单 Reactor / 多 Reactor 怎么选？</h3><h4 id="单-Reactor-单线程">单 Reactor 单线程</h4><ul><li>结构简单，但性能有限</li><li>适合低并发场景</li></ul><h4 id="单-Reactor-多线程">单 Reactor 多线程</h4><ul><li>Reactor 负责分发</li><li>具体读写交给线程池</li><li>常用，性能还不错</li></ul><h4 id="多-Reactor-多线程（Nginx-Netty）">多 Reactor 多线程（Nginx / Netty）</h4><ul><li>主 Reactor 管理连接（Acceptor）</li><li>多个子 Reactor 管理读写</li><li>吞吐量最高，面试最喜欢问</li></ul><h3 id="最容易理解的类比">最容易理解的类比</h3><p>你可以这样比喻：</p><blockquote><p>想象有一家银行。</p><ul><li>大堂经理 = Reactor（等客户、把客户分配给窗口）</li><li>每个窗口 = Handler（真正办业务）</li><li>迎宾人员 = Acceptor（处理新客户）</li></ul></blockquote><p>Reactor 本质就是：<br><strong>让一个线程（大堂经理）处理大量连接，而不是一个客户一个窗口。</strong></p><h3 id="总结-3">总结</h3><blockquote><p>Reactor 是一种典型的<strong>事件驱动模型</strong>，广泛用于<strong>高并发的网络服务器</strong>。<br>它的核心思想是：<strong>用一个或少量线程统一监听所有 I/O 事件（通过 select/epoll），一旦有事件发生，就把事件分发给对应的 Handler 处理，从而实现高并发、非阻塞的事件处理。</strong></p><p>它包含三个核心角色：Reactor 负责事件监听与分发、Handler 负责处理读写逻辑、Acceptor 专门处理新连接。</p><p>在实现上，Reactor 有单线程、单 Reactor 多线程、多 Reactor 多线程等模式，像 Netty、Nginx、Node.js 都使用了多 Reactor 模型。</p><p>总结来说，<strong>Reactor 让服务器能用少量线程就支撑高并发连接，适合所有基于非阻塞 I/O 的场景</strong>。</p></blockquote><h2 id="Select、Poll、Epoll-之间有什么区别？">Select、Poll、Epoll 之间有什么区别？</h2><p>Select、Poll 和 Epoll 都是操作系统中<strong>用于多路复用 I/O 的方法</strong>，它们各有优缺点，<strong>主要区别在于它们如何处理文件描述符</strong>（fd）。</p><ol><li><p><strong>Select</strong>：</p><ul><li><strong>优点</strong>：<strong>广泛支持</strong>，几乎所有平台都支持。</li><li><strong>缺点</strong>：最多只能监听 1024 个文件描述符，<strong>文件描述符多了效率会低</strong>；每次调用时需要复制整个文件描述符数组，在大量文件描述符时效率下降。</li></ul></li><li><p><strong>Poll</strong>：</p><ul><li><strong>优点</strong>：<strong>没有文件描述符的最大数量限制</strong>，支持更多文件描述符。</li><li><strong>缺点</strong>：<strong>每次调用时仍需遍历所有的文件描述符</strong>，效率随着文件描述符数量增多而降低。</li></ul></li><li><p><strong>Epoll</strong>：</p><ul><li><strong>优点</strong>：<strong>Linux 系统中的最优解，支持更多文件描述符，且效率更高</strong>。它通过内核和用户空间之间的高效数据交换避免了 select 和 poll 的效率问题。</li><li><strong>工作原理</strong>：Epoll 使用事件通知的方式，当文件描述符就绪时通知应用程序，而不是每次都遍历所有 fd，这使得它在处理大量文件描述符时性能更好。</li><li><strong>模式</strong>：Epoll 支持两种模式，<strong>LT（Level Triggered）</strong> 和 <strong>ET（Edge Triggered）</strong>，其中 ET 模式效率更高，但需要配合非阻塞 I/O 使用。</li></ul></li></ol><blockquote><p>总结来说，Select 更基础但限制多，Poll 解决了 Select 的数量问题，Epoll 则是处理大量 I/O 操作时最高效的选择，尤其是在处理大量并发连接时。</p></blockquote><h2 id="OSI-七层模型是什么？">OSI 七层模型是什么？</h2><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Biy2nnhl_1679215465250-69585686-78e5-4dba-a4b8-517d2e887bb3-226603_mianshiya.png" alt="1679215465250-69585686-78e5-4dba-a4b8-517d2e887bb3-226603.png" width="50%" /></p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/bvBmWkuR_1679215512409-97a70e95-730c-4e33-9aa9-b32958e39a92-618922_mianshiya.png" alt="1679215512409-97a70e95-730c-4e33-9aa9-b32958e39a92-618922.png" width="50%" /></p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/U4VmqMby_1679215841660-1221d7ed-9d65-4237-9b41-a8f35fc5f540-665820_mianshiya.png" alt="1679215841660-1221d7ed-9d65-4237-9b41-a8f35fc5f540-665820.png" width="50%" /></p><h3 id="一、OSI-七层模型">一、OSI 七层模型</h3><p>OSI 模型是一个标准化的网络通信参考模型，共七层，从下到上分别为：</p><p><strong>1. 物理层（Physical）</strong></p><ul><li>传输电信号、光信号、比特流</li><li>设备：网线、光纤、网卡</li><li>协议：RS232、V.35、以太网物理标准</li></ul><p><strong>2. 数据链路层（Data Link）</strong></p><ul><li>负责成帧、差错检测</li><li>协议：PPP、HDLC、交换机、以太网帧格式</li></ul><p><strong>3. 网络层（Network）</strong></p><ul><li>负责寻址、路由</li><li>协议：IP、ARP、RIP、OSPF、BGP</li></ul><p><strong>4. 传输层（Transport）</strong></p><ul><li>端到端通信、流量控制</li><li>协议：TCP、UDP</li></ul><p><strong>5. 会话层（Session）</strong></p><ul><li>建立、管理和终止会话<br>-协议：NetBIOS</li></ul><p><strong>6. 表示层（Presentation）</strong></p><ul><li>数据格式转换、加密解密</li><li>协议：JPEG、MPEG</li></ul><p><strong>7. 应用层（Application）</strong></p><ul><li>各种应用服务</li><li>协议：HTTP、FTP、SMTP、DNS、TELNET、SNMP</li></ul><h3 id="二、TCP-IP-五层模型">二、TCP/IP <strong>五层模型</strong></h3><p>五层模型实际上是：</p><blockquote><p><strong>物理层 + 数据链路层 + 网络层 + 运输层 + 应用层</strong></p></blockquote><h4 id="对应关系如下：">对应关系如下：</h4><table><thead><tr><th><strong>TCP/IP 五层</strong></th><th><strong>作用</strong></th><th><strong>对应 OSI</strong></th></tr></thead><tbody><tr><td>物理层</td><td>传输比特流</td><td>OSI 物理层</td></tr><tr><td>数据链路层</td><td>成帧、MAC 地址传输</td><td>OSI 数据链路层</td></tr><tr><td>网络层</td><td>IP、路由</td><td>OSI 网络层</td></tr><tr><td>传输层</td><td>TCP、UDP</td><td>OSI 传输层</td></tr><tr><td>应用层</td><td>HTTP/FTP/SMTP 等</td><td>OSI 会话 + 表示 + 应用</td></tr></tbody></table><h4 id="记忆口诀">记忆口诀</h4><blockquote><p><strong>上三合一，下两拆分</strong></p></blockquote><h3 id="三、TCP-IP-四层模型（最常见、最实用）">三、TCP/IP <strong>四层模型</strong>（最常见、最实用）</h3><p>四层模型是从五层模型简化而来</p><p>四层为：</p><ol><li><p><strong>网络接口层（Network Interface Layer）</strong></p><p>= 物理层 + 数据链路层</p><ul><li>负责比特传输、成帧</li></ul></li><li><p><strong>网络层（Internet Layer）</strong></p><ul><li>包括 IP、ICMP、ARP</li><li>路由选择</li></ul></li><li><p><strong>传输层（Transport Layer）</strong></p><ul><li>TCP、UDP</li></ul></li><li><p><strong>应用层（Application Layer）</strong></p><ul><li>HTTP、FTP、DNS、SMTP</li><li>= OSI 的应用 + 表示 + 会话</li></ul></li></ol><h3 id="一张表搞定三种模型的区别">一张表搞定三种模型的区别</h3><table><thead><tr><th>模型</th><th>层数</th><th>特点</th><th>是否实际使用</th></tr></thead><tbody><tr><td><strong>OSI 七层</strong></td><td>7 层</td><td>理论模型，层次最细</td><td>❌ 理论为主</td></tr><tr><td><strong>TCP/IP 五层</strong></td><td>5 层</td><td>教学 &amp; 面试常用</td><td>✔️ 常见</td></tr><tr><td><strong>TCP/IP 四层</strong></td><td>4 层</td><td>实际互联网标准</td><td>✔️ 真正使用</td></tr></tbody></table><h2 id="什么是物理地址，什么是逻辑地址？">什么是物理地址，什么是逻辑地址？</h2><p>物理地址 vs 逻辑地址</p><ul><li><strong>物理地址</strong>就是内存条上的真实存储位置，是硬件实际访问的地址；</li><li><strong>逻辑地址</strong>（虚拟地址）是程序运行时看到的地址，由 CPU 生成，需要通过操作系统的页表映射成物理地址。</li></ul><p>逻辑地址让每个进程都有自己的独立地址空间，更安全，也更容易管理；最终 CPU 访问内存时，一定会转换成物理地址。</p>]]></content>
    
    
    <summary type="html">我对操作系统的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="操作系统" scheme="https://itgeqian.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>场景题汇总</title>
    <link href="https://itgeqian.github.io/posts/70.html"/>
    <id>https://itgeqian.github.io/posts/70.html</id>
    <published>2025-10-17T00:19:03.000Z</published>
    <updated>2025-10-25T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-场景题">GQ 场景题</h1><h2 id="如何设计一个秒杀功能？">如何设计一个秒杀功能？</h2><h3 id="1-秒杀系统要解决哪几个核心问题？">1.秒杀系统要解决哪几个核心问题？</h3><p>秒杀本质上要解决 5 类问题：</p><ul><li>瞬时高并发的流量</li><li>热点数据（商品库存）访问集中</li><li>库存扣减的准确性（不能超卖、不能少卖）</li><li>防刷、防黄牛、防作弊</li><li>保护下游系统、避免把整个系统冲垮</li></ul><p>这是所有秒杀系统共同面临的本质问题。<br>明确完问题后，才能谈架构。</p><h3 id="2-前端侧设计（流量提前拦截）">2.前端侧设计（流量提前拦截）</h3><p>前端是非常关键的一层，因为越早过滤，越能保护后端。</p><p>我一般从三个方向处理：</p><p>1）<strong>CDN 静态资源分发</strong><br>把活动页、商品页、脚本都提前丢到 CDN，减少对源站的压力。</p><p>2）前端随机丢弃/限流<br><strong>前端可以做一些“轻度限流”</strong>，比如<strong>随机拒绝一部分请求</strong>，直接减少后端压力。</p><p>3）<strong>按钮防抖</strong>、避免频繁点击减少重复请求。</p><h3 id="3-Nginx-接入层（第二段防线）">3.Nginx 接入层（第二段防线）</h3><p>Nginx 是系统的第一道网关，可以做到：</p><ul><li>IP 限流（限制同一 IP 在某时间窗口内的请求数）</li><li>黑白名单过滤</li><li>简单的防刷策略（User-Agent、Referer 校验）</li><li>负载均衡，将请求分散到多节点</li></ul><p>这一层会挡掉大部分恶意流量。</p><h3 id="4-应用服务层（核心：限流-缓存-削峰）">4. 应用服务层（核心：限流 + 缓存 + 削峰）</h3><p>这里是<strong>秒杀系统的关键层</strong>，需要重点展开讲。</p><p>1）<strong>动态限流</strong>（Guava / <strong>Sentinel</strong>）<br>根据实时 QPS 自动限流，避免雪崩。</p><p>2）<strong>本地缓存 + 分布式缓存</strong><br>热点商品必须提前做“<strong>缓存预热</strong>”：</p><ul><li>本地缓存（Caffeine 等）速度最快</li><li>Redis 做分布式缓存</li><li>双层缓存避免 Redis 热点 Key 打挂</li></ul><p>3）削峰（异步排队）<br>用户请求先进入「秒杀队列」，后端异步消费，防止请求直接冲数据库。</p><p>典型做法：</p><ul><li><strong>Redis List</strong></li><li><strong>RocketMQ / Kafka 秒杀队列</strong></li><li>内存队列</li></ul><h3 id="4-库存扣减（最核心）">4.库存扣减（最核心）</h3><p>库存扣减的关键目标：</p><p><strong>不超卖、不少卖、性能高</strong><br>常见方案 3 选 1：</p><p>方案 A：<strong>Redis 原子扣减</strong><br>使用 Decr + 库存预热，性能最好。<br>缺点：需要兜底保证与数据库最终一致。</p><p>方案 B：<strong>分段库存</strong>（热点拆分）<br>把一个热点库存拆成多个，分散压力。</p><p>方案 C：数据库乐观锁（不推荐）<br>性能不够，秒杀场景不适合。</p><h3 id="6-防刷、防黄牛（风控层）">6. 防刷、防黄牛（风控层）</h3><p>一般会分两类说：</p><ol><li>技术防刷</li></ol><ul><li>token 校验（生成一次性 token）</li><li>图形验证码 / 点选验证码</li><li>限制同 IP / 设备访问频率</li><li>识别脚本请求（User-Agent、Cookie 行为）</li></ul><ol start="2"><li>模型风控（大厂经常用）</li></ol><ul><li>基于 IP、设备、行为路径做分析</li><li><strong>风控规则触发</strong> → 加入黑名单</li><li>Nginx / 应用端提前拦截</li></ul><h3 id="7-避免重复下单-幂等性">7. 避免重复下单 &amp; 幂等性</h3><p>防止用户疯狂点按钮下多单。</p><ol><li><p><strong>token 防重</strong>（最常见）<br><strong>每次下单需要带同一个 token，用后即失效</strong>。</p></li><li><p><strong>限购策略</strong> + 在途订单判断<br>同一个用户一分钟内只能成功一次。</p></li><li><p><strong>幂等性锁</strong></p></li></ol><ul><li>Redis setnx</li><li>数据库唯一索引</li><li>消息队列幂等消费</li></ul><h3 id="8-保护下游系统-降级与兜底">8. 保护下游系统 / 降级与兜底</h3><p>要考虑：<strong>一旦秒杀打挂了下游服务，会导致整个网站一起挂掉</strong>。</p><p>所以：</p><ul><li>秒杀服务与主交易服务进行隔离（物理隔离最佳）</li><li>所有调用必须有<strong>降级策略</strong></li><li>Redis 扣减失败 → <strong>兜底为“库存不足”</strong></li><li>MQ 异常 → <strong>存入失败队列</strong></li></ul><h3 id="9-业务侧的简化策略-加分项">9. 业务侧的简化策略(加分项)</h3><p>技术不一定把所有事都做掉，业务可以帮大忙。</p><p>常见的业务策略：</p><ul><li>预约制（先预约，才能参与秒杀）</li><li>预售</li><li>验证码</li><li>强制限购（每人只能买一个）</li></ul><h3 id="小结">小结</h3><p>秒杀的核心是<strong>抗瞬时高并发、避免超卖、保护下游</strong>。我一般从三层做设计：<br>第一层：<strong>前端 + 网关限流</strong>，用 CDN 静态化、按钮防抖、Nginx IP/UA 限流，把 80% 的无效流量挡在入口。<br>第二层：<strong>应用层削峰</strong>，所有请求先进 Redis 或 MQ 排队，动态限流（Sentinel/Guava），缓存预热 + 本地缓存避免 Redis 打爆。<br>第三层：<strong>库存扣减</strong>，用 Redis 原子扣减保证不超卖，再异步写数据库做最终一致，订单侧加幂等、防重、限购。<br>另外再加上<strong>风控防刷</strong>（验证码、token、防脚本）、隔离下游 + 降级兜底，整体实现“快速失败、削峰填谷、限流保护、精确扣库存”，确保系统稳住不崩。</p><h3 id="面试官：库存最终一致性怎么保证？">面试官：库存最终一致性怎么保证？</h3><p>我秒杀这块是这样做的：<strong>Redis 负责高性能扣减，数据库是最终的准绳，通过消息保证两者最终对上。</strong></p><ol><li><strong>正向流程</strong><ul><li>请求进来先走 <strong>Redis 原子扣减库存</strong>，如果扣失败直接返回“抢完了”，这里保证不超卖。</li><li>扣减成功后，<strong>在同一个本地事务里写订单、写一条“扣库存消息”到消息表 / 事务消息 MQ</strong>，事务提交再把消息发出去。</li><li>下游消费者收到消息后，<strong>给 MySQL 做真实扣减</strong>，并把订单状态从“冻结/待支付”改成正常。</li><li>消费端做 <strong>幂等</strong>（比如订单号唯一、扣减前先查是否处理过），保证消息重试不会多扣。</li></ul></li><li><strong>异常与补偿</strong><ul><li>消息发不出去有 <strong>事务消息 / 本地消息表 + 定时补发</strong>。</li><li>消息消费失败有 <strong>重试 + 死信队列</strong>，人工或任务做重放。</li><li>另外会有一个 <strong>对账/补偿任务</strong>，定时对比「Redis 库存 + 已扣订单」和数据库真实库存，发现不一致就回滚或补扣一次。</li></ul></li></ol><p>这样设计的结果是：<br><strong>短时间内允许缓存和数据库有一点点“时间差”，但通过消息 + 幂等 + 补偿，保证最终库存数字是一致的，也不会超卖。</strong></p><h2 id="让你设计一个消息队列，怎么设计？">让你设计一个消息队列，怎么设计？</h2><p>遵循着<strong>先搭骨架，再补细节</strong>的原则</p><p><strong>1. 先把整体角色说清楚</strong></p><p>我会先说明一个典型 MQ 里有哪些角色：</p><ul><li><strong>Producer</strong>：负责发消息</li><li><strong>Broker / MQ 集群</strong>：负责存消息、路由消息、做高可用</li><li><strong>Consumer</strong>：负责订阅 &amp; 消费消息</li><li><strong>Topic + 分区/队列</strong>：Topic 做业务分类，分区/队列做物理拆分和并行度提升</li></ul><p>简单说：<strong>生产者发到某个 Topic 的某个分区，Broker 落盘，消费者按订阅拉/收这个分区的消息。</strong></p><p><strong>2. 说一下消息流转过程</strong></p><p>按步骤讲一遍“从发送到消费”的链路：</p><ol><li>Producer 根据路由规则（Topic + 分区）把消息发给 Broker。</li><li>Broker 先写 <strong>预写日志 / commit log</strong>，成功才回 ACK，保证“不 ACK 就不算发成功”。</li><li>Consumer 通过拉（pull）或推（push 模式底层本质也是长轮询拉）从 Broker 拿消息，执行业务。</li><li>业务处理 OK 后回一个 <strong>消费确认</strong>，Broker 才会把这条标记为可删除或已消费。</li><li>Consumer 自己维护 <strong>offset</strong>，实现「至少一次」，配合幂等可以做到「逻辑上只一次」。</li></ol><p><strong>3. 可靠性怎么设计</strong></p><p>围绕“不丢、不乱、可恢复”展开：</p><ul><li><strong>落盘 + 刷盘策略</strong>：消息先写磁盘顺序日志，可以选择同步刷盘（更安全）或异步刷盘（更快）。</li><li><strong>主从复制 / 多副本</strong>：Broker 做副本，主挂了可以选举新主；消费者只对外提供“已同步到多数副本”的消息。</li><li><strong>ACK + 重试</strong>：<ul><li>生产端：发送失败自动重试，必要时走幂等 key 防止插入多条。</li><li>消费端：消费异常不确认，Broker 重新投递，超阈值进 <strong>死信队列</strong>，后面人工或后台任务重放。</li></ul></li><li><strong>顺序消费</strong>：需要顺序时，同一业务 key（比如订单号）路由到同一个队列，消费端单线程 + FIFO 处理。</li></ul><p><strong>4. 性能和扩展性</strong></p><p>然后说性能的手段，基本照着 Kafka 那一套讲：</p><ul><li><strong>分区/多队列并行</strong>：一个 Topic 拆很多分区，多个 Broker 分摊，多个 Consumer Group 并发消费。</li><li><strong>顺序写 + 批量</strong>：消息顺序写磁盘 + 批量刷盘、批量发送，减少系统调用。</li><li><strong>零拷贝</strong>：发消息时用 sendfile 之类的技术，减少内核态/用户态拷贝。</li><li><strong>负载均衡 &amp; rebalance</strong>：Consumer 数量变化时，自动 reblance 分区的归属，保证消费能力能随集群扩缩。</li></ul><p><strong>5. 功能层面的增强</strong></p><p>再补几类常见“加分项”能力：</p><ul><li><strong>两种消费模型</strong>：<ul><li>队列/点对点：一条消息只被一个消费者处理（典型任务队列）。</li><li>发布订阅：同一个 Topic 下多个订阅者都能收到一条消息（广播、通知）。</li></ul></li><li><strong>延时消息 / 定时消息</strong>：消息先进一个特殊的延时队列，到点再投递到真实 Topic。</li><li><strong>事务消息</strong>：先发一条“半消息”，本地事务成功后再 commit 让它对消费者可见；如果不确定，由 Broker 发起事务回查。</li><li><strong>去重 &amp; 幂等</strong>：给消息一个业务唯一 key（比如 orderId+type），消费端用 DB 唯一索引或 Redis set 去重。</li><li><strong>监控 &amp; 运维</strong>：可视化看到堆积量、TPS、失败率；支持按 Topic/分区扩容、限流、降级。</li></ul><p><strong>6. 最后收个口：整体思路</strong></p><p>用一句话收尾：</p><blockquote><p>总结一下，我会把消息队列拆成 Producer / Broker / Consumer 三块，先把<strong>存储、协议、ACK 与 offset</strong>这条主链路设计好，再在其上叠加<strong>多副本、高可用、顺序/延时/事务消息、死信队列与监控</strong>，既保证消息<strong>不丢不乱</strong>，又能靠<strong>分区 + 批量 + 顺序写</strong>把吞吐拉上去。</p></blockquote><p>这样一套说完，架构、可靠性、性能和高级特性都覆盖到了。</p><h2 id="消息队列设计成推消息还是拉消息？推拉模式的优缺点？">消息队列设计成推消息还是拉消息？推拉模式的优缺点？</h2><p>消息队列有两种消费模式：推（Push） 和 拉（Pull）。</p><ul><li>推模式：Broker 主动把消息推给消费者。</li><li>拉模式：消费者主动去 Broker 拉取消息。</li></ul><p>RocketMQ 和 Kafka 其实都选择了“<strong>拉模式</strong>”，只是 <strong>RocketMQ 的“推”其实是封装了长轮询的拉模式</strong>，<strong>也就是消费者在后台不断长轮询去拉消息，看起来像是 Broker 在推</strong>。<br>所以本质上还是拉，只是体验像推。</p><h3 id="优缺点对比一下">优缺点对比一下</h3><ul><li><p>推模式优点：消息能实时送达，延迟很低；</p><ul><li>缺点是如果消费者处理慢，Broker 一直推消息，容易把消费者压垮，尤其是高并发时不好做流控。</li></ul></li><li><p>拉模式优点：消费者自己掌握节奏，可以根据自身负载调节拉取速率，避免过载，还能做批量拉取；</p><ul><li>缺点就是实时性稍差，拉得太慢可能延迟会高一点。</li></ul></li></ul><h3 id="为什么-RocketMQ-选拉模式">为什么 RocketMQ 选拉模式</h3><p>RocketMQ 和 Kafka 一样，选择拉模式主要是为了<strong>稳定</strong>和<strong>可控</strong>。<br>因为现在 MQ 都有“<strong>消息持久化</strong>”的需求——消息要先存好，再被消费。<br>所以用拉模式更安全，消费者按能力来拉，不会被推爆；再加上长轮询机制，也能兼顾实时性。</p><blockquote><p>一句话总结：<br>推模式实时但容易压垮消费者，<br>拉模式可控但实时性略差。<br>RocketMQ 实际上是“伪推真拉”，底层用长轮询实现拉取，这样既能稳又能快。</p></blockquote><h2 id="让你设计一个短链系统，怎么设计？">让你设计一个短链系统，怎么设计？</h2><h3 id="一、先解释一下什么是短链系统">一、先解释一下什么是短链系统</h3><blockquote><p>短链系统的本质，就是把一个<strong>长 URL 映射为一个短 URL</strong>。<br>用户访问短链时，系统会根据短链字符串查到对应的长链，然后 <strong>301/302 重定向</strong> 去真正的地址。</p></blockquote><h3 id="二、系统整体架构">二、系统整体架构</h3><p>短链系统一般分三部分：</p><ul><li><strong>前端</strong>：输入长链、展示生成的短链</li><li><strong>后端</strong>：生成短链、保存映射、跳转重定向、统计访问</li><li><strong>数据库</strong>：存储长链与短链的映射关系</li></ul><p>这是一个典型的<strong>读多写少的系统</strong>。</p><h3 id="三、短链生成方案">三、短链生成方案</h3><p>例如短链总共只有 24 个字符，域名占掉大部分，实际只剩 <strong>6 位可用字符</strong> 给短链编码 。<br>因此需要一个高效高密度的编码方式，最常用的是 <strong>Base62（62 进制）编码</strong>。</p><h3 id="下发短链的步骤："><strong>下发短链的步骤</strong>：</h3><ol><li><strong>插入一条长链记录</strong>（带 md5 去重）</li><li>拿到自增 ID（long 类型）</li><li>用 <strong>Base62 算法</strong>把 ID 编码成 6 位字符（如 “ABCDEF”）</li><li>拼成短链 <code>https://xxx.xxx/ABCDEF</code></li><li>返回给用户</li></ol><p>为什么 6 位够用？<br>6 位 Base62 的最大值是 <code>62^6 ≈ 568 亿</code>，完全够用 。</p><h3 id="四、短链跳转流程（访问时）">四、短链跳转流程（访问时）</h3><p>当用户访问短链：</p><ol><li>根据短链字符串查询数据库</li><li>找到对应的长链</li><li>返回 HTTP 302 重定向到真实地址</li></ol><p>可以加缓存（Redis）提升跳转速度。</p><h3 id="五、数据库设计要点">五、数据库设计要点</h3><ul><li><code>id</code>：自增主键（短链数字 source）</li><li><code>long_url</code>：原始长链</li><li><code>long_url_md5</code>：便于做长链去重（unique）</li><li><code>short_url_str</code>：短链的 6 位字符（unique）</li></ul><p>两列做唯一索引保证：</p><ul><li>相同长链不重复创建短链</li><li>短链字符串绝对唯一</li></ul><blockquote><p>短链系统的本质是 <strong>建立长链与短链的双向映射</strong>。核心难点在于：</p><ol><li>如何生成紧凑、无冲突的短链（Base62 + unique）</li><li>如何加速跳转（缓存）</li><li>如何保证高并发下不重复生成（数据库唯一约束或分布式 ID）</li></ol></blockquote><h3 id="小结-2">小结</h3><blockquote><p>短链系统的本质就是把一个长链接映射为一个短链接，访问短链时再重定向回原始 URL。</p></blockquote><p>我的设计思路是：</p><ol><li><p><strong>生成短链</strong>：<br>长链写入数据库得到自增 ID，然后使用 <strong>Base62 编码</strong>把这个 ID 转成 6 位短链字符串（因为 62⁶ ≈ 568 亿，完全够用）。</p></li><li><p><strong>存储映射</strong>：<br>数据库存两类唯一索引：</p><ul><li>长链的 MD5（避免重复生成）</li><li>短链字符串（保证唯一）</li></ul></li><li><p><strong>访问跳转</strong>：<br>用户访问短链 <code>/ABCDEF</code> → 查数据库或 Redis → 找到长链 → 302 重定向跳转。</p></li><li><p><strong>性能优化</strong>：<br>热链加 Redis 缓存；高并发可以用分库分表、分布式 ID 或号段模式。</p></li></ol><blockquote><p>长链入库 → ID Base62 编码 → 生成短链 → 查映射 → 重定向，这就是完整的短链系统。</p></blockquote><h2 id="分布式锁一般都怎样实现？">分布式锁一般都怎样实现？</h2><p>常见依赖 Redis、ZooKeeper 来实现分布式锁。</p><h2 id="如果让你统计每个接口每分钟调用次数怎么统计？">如果让你统计每个接口每分钟调用次数怎么统计？</h2><p>第三方工具库</p><p>SkyWalking</p><p>Prometheus Grafana</p><h2 id="让你设计一个文件上传系统，怎么设计？">让你设计一个文件上传系统，怎么设计？</h2><p><strong>1. 先说目标：</strong></p><p>“一个文件上传系统，核心要解决三件事：</p><ul><li>能稳定传很大的文件；</li><li>不浪费存储空间（去重、断点续传）；</li><li>不把后端和带宽打垮（限流、分片、异步处理）。”</li></ul><p><strong>2. 整体架构先给一笔：</strong></p><p>“整体上就是：前端 → 上传网关/Nginx → 上传服务 → 存储（对象存储/分布式文件系统），旁边配个 Redis + DB 做状态和元数据。”</p><p><strong>3. 大文件怎么传？——分片上传</strong></p><blockquote><p>关键词：切片 + 记录分片 + 合并</p></blockquote><ul><li><strong>前端切片</strong><br>比如统一按 2MB 一片，生成 fileId / uploadId + 分片序号 seq。</li><li><strong>分片上传</strong><br>每个分片带上：用户ID、uploadId、seq、总分片数、md5 等，走普通 HTTP/表单上传。</li><li><strong>服务端落地 &amp; 记录</strong><br>分片先写到临时存储（本地磁盘 / 临时桶），<br>同时在 Redis 记一条：<code>uploadId -&gt; &#123;已收到的分片集合、总分片数、文件大小&#125;</code>，设置过期时间。</li><li><strong>合并</strong><br>当某个接口或最后一个分片上来时，检查 “已收分片 == 总分片数”，<br>就顺序把分片按 seq 合并成一个完整文件，写到正式存储，更新 DB 里的文件元数据（fileId、大小、md5、存储路径等），<br>然后删掉 Redis 记录和临时分片。</li></ul><p>顺带一提，这套结构天然支持 <strong>断点续传</strong>：<br>客户端凭 uploadId 请求“我已经传过哪些分片”，然后只补传缺的。</p><p><strong>4. 怎么避免重复存储？——文件去重</strong></p><blockquote><p>关键词：md5 摘要 + 秒传</p></blockquote><ul><li>上传前/合并后计算一次文件 <strong>md5</strong>（或别的 hash）。</li><li>合并前：先去 DB/缓存里查这个 md5 是否已经存在：<ul><li><strong>存在</strong>：说明别人传过同一份文件了，本次只写一条“引用关系”（用户文件表指向同一个物理文件），可以直接返回 “秒传成功”。</li><li><strong>不存在</strong>：正常合并、落库，并把 md5 → 文件记录 这个映射写进去。</li></ul></li></ul><p>这样同一份视频/图片上传一千次，只占一份物理空间。</p><p><strong>5. 怎么控住资源？——限流 + 配额</strong></p><blockquote><p>关键词：网关限流 + 业务配额</p></blockquote><ul><li><strong>网关/负载均衡层限流</strong>：<ul><li>限制单个文件最大尺寸；</li><li>限制上传 QPS、并发连接数；</li><li>可以按 IP/用户做滑动窗口限流（防止恶意刷接口）。</li></ul></li><li><strong>业务级限流</strong>：<ul><li>每个用户每天可上传的总大小、总文件数；</li><li>超过就拒绝或排队。</li></ul></li></ul><p><strong>6. 其他细节顺带带一下：</strong></p><ul><li><strong>安全</strong>：校验登录态、白名单文件类型，有需要的话加个病毒扫描/内容审核异步任务。</li><li><strong>回调/异步处理</strong>：<br>比如视频上传完要做转码、截图，就发一条 MQ 消息给“多媒体处理服务”，跟“上传成功”解耦。</li><li><strong>监控 &amp; 清理</strong>：<ul><li>定时任务清理长时间未完成的 uploadId 和临时分片；</li><li>监控上传成功率、平均耗时、失败原因等。</li></ul></li></ul><p><strong>一句话总结：</strong><br>“我会用 <strong>‘前端分片 + Redis 记录状态 + 服务端合并 + md5 去重 + 网关限流’</strong> 这一套来设计，既能扛大文件、支持断点续传，又节省存储、把流量和后端压力控制在可预期范围里，后面要扩展转码、审核也只需要在 MQ 上挂新消费者就行。”</p><h2 id="什么是限流？限流算法有哪些？怎么实现的？">什么是限流？限流算法有哪些？怎么实现的？</h2><p>限流是一种<strong>控制请求量的技术</strong>，用于确保系统能在一定的负载下稳定运行，避免因请求过多导致系统崩溃。简单来说，限流的目标是限制单位时间内的请求数量。</p><p>常见的限流算法有几种：</p><ol><li><p><strong>漏桶算法</strong>：系统请求先进入一个“漏桶”，然后按固定速率从桶里取出请求并执行。如果请求量大于桶的容量，超出的请求会被丢弃或延迟处理。</p></li><li><p><strong>令牌桶算法</strong>：系统请求会从一个“令牌桶”中获取令牌来执行，桶里定期生成令牌，控制令牌桶中的令牌数。令牌桶适用于需要突发流量的场景。</p></li><li><p><strong>计数器算法</strong>：直接通过计数请求数，若请求数超过阈值，则限制请求。这种方法比较简单，适用于流量控制较为松散的场景。</p></li><li><p><strong>阻塞算法</strong>：当请求数量达到阈值时，系统会拒绝新请求，直到请求数降到阈值以下，再恢复接收新请求。</p></li><li><p><strong>令牌环算法</strong>：类似于令牌桶，但它将多个令牌桶连接成一个环形结构，适用于平衡不同请求速率的场景。</p></li><li><p><strong>最小延迟算法</strong>：通过预测每个请求的处理时间，选择最少延迟的请求执行，从而控制请求的处理速率。</p></li><li><p><strong>滑动窗口算法</strong>：通过设定一个固定大小的时间窗口，窗口内的请求数不能超过设定的阈值。随着时间的推移，窗口不断滑动，这使得不同时间段内的请求量得以灵活控制。</p></li></ol><p>总的来说，限流算法可以帮助你确保系统的稳定性，避免因为流量暴增造成的系统负担过重。选择合适的限流算法，能够根据不同的应用场景和需求平衡性能与资源消耗。</p><h2 id="让你设计一个-HashMap-，怎么设计？">让你设计一个 HashMap ，怎么设计？</h2><p>我设计 HashMap 会从<strong>定位、冲突、扩容、性能</strong>四点来说：</p><p><strong>1）核心结构</strong>：底层是 <strong>数组 + 链表/红黑树</strong>。先对 key 做 hash，再对数组长度取模定位桶位置。</p><p><strong>2）冲突解决</strong>：采用<strong>拉链法</strong>。当链表太长（比如超过 8），转成红黑树，提高查询性能到 O(logN)。</p><p><strong>3）扩容机制</strong>：当负载因子超过阈值，比如 0.75，触发扩容为原来的 2 倍。扩容时重新计算桶位置，必要时可以学习 Redis 做<strong>渐进式扩容</strong>避免阻塞。</p><p><strong>4）hash 优化</strong>：hash 函数要分布均匀</p><h2 id="线上-CPU-飙高如何排查？">线上 CPU 飙高如何排查？</h2><blockquote><p>线上 CPU 飙高其实是一个非常常见、但排查流程非常固定的问题。我一般会按照 <strong>“定位进程 → 定位线程 → 定位代码 → 修复问题”</strong> 这套方法走。</p></blockquote><h4 id="①-定位哪个进程占用-CPU"><strong>① 定位哪个进程占用 CPU</strong></h4><p>第一步用：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">top</span></span><br></pre></td></tr></table></figure><p>看到哪个进程 CPU 最高，比如 Java 进程占了 180%+，就说明是应用本身的问题。</p><h4 id="②-定位哪个线程占用-CPU"><strong>② 定位哪个线程占用 CPU</strong></h4><p>继续用：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp <span class="tag">&lt;<span class="name">进程ID</span>&gt;</span></span><br></pre></td></tr></table></figure><p>找到 CPU 占用最高的线程，比如线程号 4519。</p><p>然后将线程号转成 16 进制：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">printf</span> <span class="string">&quot;<span class="variable">%x</span>\n&quot;</span> <span class="number">4519</span></span><br></pre></td></tr></table></figure><h4 id="③-打印线程栈，定位到底是哪段代码造成的"><strong>③ 打印线程栈，定位到底是哪段代码造成的</strong></h4><p>用 jstack 或 Arthas：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">jstack</span> &lt;pid&gt; | grep -A <span class="number">200</span> &lt;<span class="number">16</span>进制线程号&gt;</span><br></pre></td></tr></table></figure><p>再查看堆栈最顶层，看代码卡在哪个方法。</p><h4 id="④-修复-CPU-热点代码"><strong>④ 修复 CPU 热点代码</strong></h4><ul><li><strong>把高频创建的对象提前到应用启动时初始化一次</strong><br>（如：Sequence、Validator）</li><li>避免不必要的反射、正则、序列号获取</li><li>检查是否有死循环、大量 JSON 解析、大对象创建等</li></ul><h3 id="小结-3">小结</h3><blockquote><p>CPU 飙高我一般按固定流程排查：先找进程、再找线程、最后定位到具体代码。</p></blockquote><ol><li><p><strong>定位高 CPU 进程</strong><br>用 <code>top</code> 看是哪个进程占满 CPU。</p></li><li><p><strong>定位高 CPU 线程</strong><br><code>top -Hp &lt;pid&gt;</code> 找出最耗 CPU 的线程号。</p></li><li><p><strong>定位具体代码</strong><br>把线程号转成 16 进制：<br><code>printf &quot;%x\n&quot; &lt;tid&gt;</code><br>再用：<br><code>jstack &lt;pid&gt; | grep -A 200 &lt;16进制tid&gt;</code><br>或 Arthas <code>thread -n 3</code>，直接找到热点方法。</p></li><li><p><strong>根据堆栈优化代码</strong><br>多数根因都是：频繁创建对象、正则/反射过多、DB/IO 阻塞、死循环等。</p></li></ol><p><strong>一句话总结：</strong></p><blockquote><p><strong>top 找进程 → top -Hp 找线程 → jstack/Arthas 找热点方法 → 优化代码</strong>，这是排查 CPU 飙高最标准、最高效的流程。</p></blockquote><h2 id="让你设计一个线程池，怎么设计？">让你设计一个线程池，怎么设计？</h2><blockquote><p>线程池本质就是<strong>复用一批线程来执行大量任务</strong>，减少频繁创建/销毁线程的开销。</p></blockquote><ol><li><strong>核心参数</strong>：<ul><li>核心线程数 coreSize（常驻工作线程），</li><li>最大线程数 maxSize，</li><li>任务队列（有界队列），</li><li>线程空闲存活时间 keepAliveTime，</li><li>线程工厂（起名、设置守护/优先级），</li><li>拒绝策略（丢弃、抛异常、调用方执行、丢最旧等）。</li></ul></li><li><strong>调度流程</strong>：<ul><li>提交任务时，先看核心线程是否满；</li><li>未满就<strong>新建工作线程</strong>执行；</li><li>满了就<strong>进队排队</strong>；</li><li>队列也满了再看是否还能扩到 maxSize，能扩就新建线程；</li><li>都满了就按照拒绝策略处理。</li></ul></li><li><strong>扩缩容与监控</strong>：<ul><li>支持动态调 coreSize / maxSize，空闲线程超时自动回收；</li><li>暴露指标：队列长度、活动线程数、任务耗时、拒绝次数，用于监控和报警。</li></ul></li><li><strong>队列选择</strong>：<ul><li>CPU 密集型用<strong>无界队列 + 较小线程数</strong>；</li><li>IO 密集型用<strong>有界队列 + 较大线程数</strong>，防止把内存打爆。</li></ul></li></ol><blockquote><p>一句话总结：我会按「<strong>核心/最大线程数 + 有界队列 + 拒绝策略 + 动态扩缩容 + 监控</strong>」这套框架去设计线程池，既兼顾性能也能控风险。</p></blockquote><h2 id="如何实现数据库的不停服迁移？">如何实现数据库的不停服迁移？</h2><p>使用双写方案<br>双写方案意味着同时向原数据库和目标数据库写入数据，确保数据的迁移不会中断业务。<br>1.搞一个云上数据库，作为从库，同步数据<br>2.改写业务代码，使写数据的操作，要同时写入主库和从库。要加个开关，可以随时开启以及关闭双写。<br>3.在业务低峰期，主从完全同步的时候，开启双写，这时候读数据还是在主库上<br>4.进行数据核对，写代码进行抽样调查，看主库和从库数据是否一致，不一致就告警<br>5.如果数据核对一致，则进行灰度切流，将一部分比例的用户的读请求切到从库上，逐渐的增加比例到100%<br>6.跑一段时间，如果没有问题了，关闭双写，只写新库</p><h2 id="MySQL-中如何进行-SQL-调优？">MySQL 中如何进行 SQL 调优？</h2><p>MySQL 中如何进行 SQL 调优？</p><p>答：SQL 调优我一般分两步走：“先定位问题，再针对性优化”。</p><ol><li>第一步：定位性能瓶颈</li></ol><ul><li><p>开启慢查询日志（slow query log）<br>用来记录执行时间超过设定阈值的 SQL，快速找出慢查询语句。</p><p><code>set global slow_query_log = 'ON';   </code></p></li><li><p>使用 EXPLAIN 分析执行计划<br>查看 SQL 是否使用了索引、扫描了多少行、有没有出现 Using filesort 或 Using temporary 这些低效操作。</p></li></ul><ol start="2"><li>第二步：优化 SQL 语句</li></ol><ul><li><p>合理设计索引：<br>建立合适的单列索引或联合索引，满足“最左前缀匹配原则”；常用字段可使用覆盖索引减少回表。</p></li><li><p>避免索引失效：</p><p>1.避免 SELECT *（只查必要字段）</p><p>2.避免 LIKE ‘%xxx’ 模糊匹配</p><p>3.避免在索引字段上进行函数或计算</p><p>4.注意不同字符集、类型转换导致索引失效</p></li><li><p>减少不必要的操作：</p><p>1.减少多表 JOIN</p><p>2.避免复杂的 OR 条件（可以用 UNION ALL 替代）</p><p>3.GROUP BY、ORDER BY 尽量排序字段建索引</p></li><li><p>优化表结构与缓存：</p><p>1.字段类型尽量精简</p><p>2.避免大字段频繁查询</p><p>3.适当使用缓存机制（如 Redis）减轻数据库压力</p></li></ul><p>总结：<br>“我会先通过慢查询日志和 EXPLAIN 找出性能瓶颈，然后从索引设计、SQL写法和表结构三方面去优化。<br>比如合理用联合索引、避免 SELECT *、避免索引字段函数计算，让查询走索引、少回表、少排序，从而显著提升性能。”</p><p>速答版：<br>我做 SQL 调优一般分两步：先定位问题，再优化语句。<br>首先我会开启 慢查询日志 找出执行慢的 SQL，然后用 EXPLAIN 查看执行计划，看是否走了索引、有没有全表扫描或 filesort。<br>优化时我主要关注 索引设计和写法，比如建立合适的联合索引、遵守最左前缀原则、避免 SELECT *、LIKE ‘%xx’、函数计算等导致索引失效的情况。<br>同时控制多表 join、group by、order by 的使用，必要时加缓存或优化表结构，让查询更高效。</p><h2 id="MySQL-中如何解决深度分页的问题？">MySQL 中如何解决深度分页的问题？</h2><p>MYSQL中深度分页常常遇到的一个问题是，随着分页的深入，查询的效率会变得非常低，因为<strong>每次需要跳过很多数据行</strong>，尤其是当 LIMIT 和 OFFSET 结合使用时，OFFSET 会导致数据库扫描大量无用的记录，造成性能下降。<br>为了优化这一点，通常可以采用以下两种方法</p><ol><li><strong>子查询优化分页</strong>：</li></ol><p>比如，如果我们要查询第100000页的数据，每页10条记录，我们可以先通过一个子查询找到第100000页的第一条记录的ID。然后，在实际的查询中，使用这个ID作为起始点来查询接下来的10条记录。这样我们就避免了从头开始扫描所有记录，查询效率大大提升。<br>例子：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> users <span class="keyword">WHERE</span> id &gt;= (</span><br><span class="line">  <span class="keyword">SELECT</span> id <span class="keyword">FROM</span> users <span class="keyword">ORDER</span> <span class="keyword">BY</span> id <span class="keyword">LIMIT</span> <span class="number">99999990</span>, <span class="number">1</span></span><br><span class="line">) <span class="keyword">ORDER</span> <span class="keyword">BY</span> id <span class="keyword">LIMIT</span> <span class="number">10</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li><strong>记录最后查询的ID</strong>：<br>每次分页查询时，我们记录下上一次查询结果的最后一条记录的ID，下一次查询时，直接从这个ID开始查询。这样每次分页查询都避免了大范围的跳过操作，直接从上一次查询的位置开始，显著提高了查询性能。</li></ol><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> users <span class="keyword">WHERE</span> id &gt; last_id <span class="keyword">ORDER</span> <span class="keyword">BY</span> id <span class="keyword">LIMIT</span> <span class="number">10</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过这两种方法，我们可以避免传统的 LIMIT + OFFSET 的性能问题，尤其是在数据量大的时候，查询速度会更快，系统的负担也会减轻。</p><h2 id="怎么分析-JVM-当前的内存占用情况？OOM-后怎么分析？">怎么分析 JVM 当前的内存占用情况？OOM 后怎么分析？</h2><blockquote><p>我一般会分两步：<strong>先看实时内存情况</strong>，再分析 <strong>OOM dump 文件</strong> 去定位根因。</p></blockquote><h3 id="一、如何分析-JVM-当前的内存占用情况？">一、如何分析 JVM 当前的内存占用情况？</h3><p>主要用自带工具：</p><h4 id="1）jstat-——-看-JVM-内存实时情况"><strong>1）jstat —— 看 JVM 内存实时情况</strong></h4><p><code>jstat -gc &lt;pid&gt;</code><br>可以看到：</p><ul><li>Eden、Survivor、Old 区的使用情况</li><li>GC 次数和耗时<br>方便判断是不是某块内存持续上涨、GC 频繁等问题。</li></ul><h4 id="2）jmap-——-查看堆的详细结构"><strong>2）jmap —— 查看堆的详细结构</strong></h4><p><code>jmap -heap &lt;pid&gt;</code> 查看：</p><ul><li>堆大小配置</li><li>当前各区占用情况</li><li>GC 类别</li></ul><p><code>jmap -histo &lt;pid&gt;</code> 可以看到：</p><ul><li>哪些类实例最多、占用最大<br>用来判断是否有往堆里塞大量对象的风险。</li></ul><h3 id="二、OOM-后怎么分析？">二、OOM 后怎么分析？</h3><p>OOM 时最关键的是 <strong>拿到 heap dump 文件</strong>。</p><h3 id="1）开启自动-dump"><strong>1）开启自动 dump</strong></h3><p>在启动参数加：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+HeapDumpOnOutOfMemoryError</span> </span><br><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:HeapDumpPath=/tmp/heapdump</span>.hprof</span><br></pre></td></tr></table></figure><p>发生 OOM 时 JVM 会自动生成 <code>.hprof</code> 文件。</p><h3 id="2）用专业工具分析-dump"><strong>2）用专业工具分析 dump</strong></h3><p>常用工具：</p><ul><li><strong>MAT（Eclipse Memory Analyzer）</strong></li><li><strong>VisualVM</strong></li><li><strong>GCeasy</strong></li><li><strong>YourKit</strong></li></ul><p>这些工具可以告诉你：</p><ul><li>哪些对象占了最多内存</li><li>哪些对象存在强引用链无法被清理</li><li>是否存在缓存未清理、连接未关闭、集合无限膨胀等问题<br>最后定位到具体代码并修复。</li></ul><h3 id="小结-4">小结</h3><blockquote><p>分析 JVM 内存我主要用两类工具：<strong>在线看实时内存</strong> + <strong>OOM 后看 dump 文件</strong>。</p></blockquote><p><strong>① 在线分析（实时内存占用）</strong></p><ul><li><code>jstat -gc &lt;pid&gt;</code> 看 Eden、Survivor、Old 区的使用情况和 GC 情况。</li><li><code>jmap -heap &lt;pid&gt;</code> 看堆大小、配置、当前占用情况。</li><li><code>jmap -histo &lt;pid&gt;</code> 找占内存最多的类。</li></ul><p><strong>② OOM 之后怎么分析</strong></p><ul><li>启动参数加上：<br><code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heap.hprof</code><br>OOM 时自动生成 dump。</li><li>用 <strong>MAT / VisualVM / GCeasy</strong> 打开 dump，找占用最大的对象、引用链，定位内存泄漏或对象膨胀的代码。</li></ul><p><strong>一句话总结：</strong></p><blockquote><p>在线靠 jstat/jmap 看趋势，OOM 靠 dump 文件找大对象和引用链，这两步就能定位大部分 JVM 内存问题。</p></blockquote><h2 id="如果发现-Redis-内存溢出了？你会怎么做？请给出排查思路和解决方案">如果发现 Redis 内存溢出了？你会怎么做？请给出排查思路和解决方案</h2><p>如果线上 Redis 内存溢出，我的第一反应是：<strong>先扩容，保证业务不受影响；然后再排查根因，做长期优化</strong>。</p><h3 id="一、第一步：止血（确保服务正常）">一、第一步：止血（确保服务正常）</h3><p>如果错误提示是 used memory &gt; maxmemory，说明 Redis 达到最大内存限制，继续写入被拒绝。</p><p>所以第一时间我会：</p><ul><li>扩容 Redis 实例内存 或</li><li>增加新的 Redis 节点分担压力</li><li>先保证线上业务不挂，再排查根因。</li></ul><h3 id="二、第二步：排查-Redis-内存为什么涨满？">二、第二步：排查 Redis 内存为什么涨满？</h3><p>常见的几种情况</p><ol><li>数据量太多</li></ol><ul><li>存入 Redis 的 key/数据本身太大，超过内存容量。</li></ul><ol start="2"><li>大量 key 没有设置过期时间</li></ol><ul><li>数据长期堆积不释放，导致内存持续增长。</li></ul><ol start="3"><li>大对象 / 大型数据结构滥用</li></ol><ul><li>比如 hash、list、set 里塞了大量内容，占用极大空间。</li></ul><ol start="4"><li>持久化策略影响</li></ol><ul><li>RDB fork 时会额外占一份内存（写时复制机制），高峰容易炸。</li></ul><ol start="5"><li>业务代码误用 Redis 当数据库</li></ol><ul><li>比如把日志、明细表全写进 Redis。</li></ul><h3 id="第三步：解决方案（短期-长期）">第三步：解决方案（短期 + 长期）</h3><p>（1）<strong>短期优化</strong></p><ul><li><p><strong>启用合适的淘汰策略</strong><br>如 allkeys-lru、volatile-lru，让 Redis 自动删除不常用 key。</p></li><li><p><strong>为 key 设置合理的 TTL</strong><br>避免无过期数据永远占内存。</p></li></ul><p>（2）<strong>长期优化</strong></p><ul><li><p><strong>优化数据结构设计</strong></p><ul><li>大 hash 拆分成小 hash，减少单个结构的内存占用。</li></ul></li><li><p><strong>水平扩展 Redis</strong></p><ul><li>分库分槽，将数据打散到多个 Redis 节点降低单机压力。</li></ul></li><li><p><strong>优化持久化策略</strong></p><ul><li>减少 RDB 在高峰期触发并导致额外内存开销。</li></ul></li></ul><p>下面是 <strong>30 秒极速口语版</strong>，面试时直接说就能拿高分👇</p><h3 id="小结-5">小结</h3><blockquote><p>如果发现 Redis 内存溢出，我的第一反应是<strong>先扩容保证业务不挂</strong>，然后再排查原因。</p></blockquote><p>常见根因主要有三类：</p><ol><li><strong>数据太多</strong>：写入的数据量超出 Redis 内存限制。</li><li><strong>无过期时间</strong>：大量 key 没 TTL，越积越多。</li><li><strong>大对象滥用</strong>：比如一个 hash、list、set 塞几十万条数据。</li></ol><p>解决也很简单：</p><ul><li><strong>开启合适的淘汰策略</strong>（allkeys-lru 等）</li><li><strong>给 key 设置合理 TTL</strong></li><li><strong>拆分大对象，优化数据结构</strong></li><li><strong>必要时做 Redis 水平扩容</strong>（分片/集群）</li><li><strong>优化 RDB/AOF 配置，避免高峰期 fork 占用额外内存</strong></li></ul><p><strong>一句话总结：</strong></p><blockquote><p>先扩容止血，再找无 TTL、大对象、数据堆积等根因；最后通过淘汰策略、TTL、拆分数据结构和扩容彻底解决。</p></blockquote><h2 id="让你设计一个购物车功能，怎么设计？">让你设计一个购物车功能，怎么设计？</h2><p>为了设计一个购物车功能，我们首先要理解其核心需求：<strong>在用户选购商品后，允许用户暂时将商品存放在购物车中，直到完成购买。接下来，我会根据已登录与未登录的用户分别设计存储方案</strong>。</p><h3 id="未登录用户购物车">未登录用户购物车</h3><ul><li><p><strong>存储方式</strong>：<strong>未登录的用户</strong>信息一般不存储在后端，而是<strong>使用客户端技术</strong>，比如<code>Cookie</code>或<code>LocalStorage</code>来临时保存。</p></li><li><p><strong>数据格式</strong>：保存的信息可以<strong>是一个JSON对象</strong>，包括<code>SKUID</code>、<code>count</code>（数量）、<code>timestamp</code>（添加时间）。</p><p>示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;cart&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span> <span class="attr">&quot;SKUID&quot;</span><span class="punctuation">:</span> <span class="number">10086</span><span class="punctuation">,</span> <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="number">1666513990</span><span class="punctuation">,</span> <span class="attr">&quot;count&quot;</span><span class="punctuation">:</span> <span class="number">2</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span> <span class="attr">&quot;SKUID&quot;</span><span class="punctuation">:</span> <span class="number">10010</span><span class="punctuation">,</span> <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="number">1666513990</span><span class="punctuation">,</span> <span class="attr">&quot;count&quot;</span><span class="punctuation">:</span> <span class="number">10</span> <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="已登录用户购物车">已登录用户购物车</h3><ul><li><p><strong>存储方式</strong>：对于<strong>已登录用户</strong>，<strong>购物车数据需要存储在后端</strong>，避免用户更换设备后购物车数据丢失。</p></li><li><p><strong>数据库</strong>：可以使用数据库表来存储每个用户的购物车信息，包括<code>user_id</code>、<code>sku_id</code>、<code>count</code>、<code>timestamp</code>等。</p></li><li><p><strong>Redis缓存</strong>：为了提升性能，<strong>使用Redis缓存也很常见</strong>。将<code>user_id</code>作为Redis的<code>key</code>，购物车的商品信息作为<code>value</code>存储。</p><p>示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;KEY&quot;</span><span class="punctuation">:</span> <span class="number">12343123</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;VALUE&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="punctuation">&#123;</span> <span class="attr">&quot;SKUID&quot;</span><span class="punctuation">:</span> <span class="number">10086</span><span class="punctuation">,</span> <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="number">1666513990</span><span class="punctuation">,</span> <span class="attr">&quot;count&quot;</span><span class="punctuation">:</span> <span class="number">2</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="punctuation">&#123;</span> <span class="attr">&quot;SKUID&quot;</span><span class="punctuation">:</span> <span class="number">10010</span><span class="punctuation">,</span> <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="number">1666513990</span><span class="punctuation">,</span> <span class="attr">&quot;count&quot;</span><span class="punctuation">:</span> <span class="number">10</span> <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 存储方案对比</span><br><span class="line"></span><br><span class="line">* **Redis**：快速响应，适合高并发访问。性能较好，但数据丢失的风险较大。</span><br><span class="line">* **MySQL**：数据可靠性高，支持事务和复杂查询，适用于需要数据持久化的场景，但性能相对较低，处理并发的能力有限。</span><br><span class="line"></span><br><span class="line">总结来说，对于未登录用户，数据使用临时存储，减少对后端的依赖；对于已登录用户，使用数据库或Redis结合的方式，保证数据的持久化和高效访问。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 商家想要知道自己店铺卖的最好的 top <span class="number">50</span> 商品，如何实现这个功能？</span><br><span class="line"></span><br><span class="line">**商家想知道自己店铺卖得最好的 Top <span class="number">50</span> 商品，怎么实现？”**</span><br><span class="line"></span><br><span class="line">如果要做一个店铺销量 Top50 排行榜，为了兼顾实时性和性能，我会用 **Redis 的 ZSet 来做动态排行榜**。每个商品卖出一次，就对它对应的 score 做一次 ZINCRBY，value 存商品 ID，这样写入是 O(<span class="number">1</span>)，非常高效。</span><br><span class="line"></span><br><span class="line">查前 <span class="number">50</span> 名时，用 `ZREVRANGE key <span class="number">0</span> <span class="number">49</span>` 就能直接按销量倒序取出，时间复杂度是 `O(logN + <span class="number">50</span>)`，对百万级数据也能快速返回。</span><br><span class="line"></span><br><span class="line">如果商品非常多，我会加一些优化：</span><br><span class="line"></span><br><span class="line">- **按店铺维度拆分 ZSet**，避免 big key；</span><br><span class="line">- 高频写入可以走 **异步/队列批量更新**，减轻 Redis 压力；</span><br><span class="line">- 热门榜单可以做 **本地缓存 + 定时刷新**，进一步提升查询速度；</span><br><span class="line">- 如果要全国榜或多维榜，可以用 **Top-K 合并**策略，比如“先取各分片前<span class="number">100</span>，再综合排序”。</span><br><span class="line"></span><br><span class="line">整体方案简单、高效、可横向扩展，也易于应对大流量场景。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## MySQL 中 如果我 select * from 一个有 <span class="number">1000</span> 万行的表，内存会飙升么？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">不会的。</span><br><span class="line">MySQL 执行 SELECT * FROM ... 时，并不会把 <span class="number">1000</span> 万行一次性全部加载到内存里，而是 **边查询、边取数据、边通过网络发给客户端**，属于 **流式输出**。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">###  为什么不会把 <span class="number">1000</span> 万行一次性放进内存？</span><br><span class="line"></span><br><span class="line">MySQL 是按照 **批次**（batch）从磁盘读取数据的，每批的数据量由 `net_buffer_length` 控制，默认只有 **<span class="number">16</span>KB**。</span><br><span class="line"></span><br><span class="line">实际流程是：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> MySQL 从磁盘取一行数据</span><br><span class="line"><span class="number">2.</span> 写入 `net_buffer`（最多 <span class="number">16</span>KB）</span><br><span class="line"><span class="number">3.</span> buffer 满了就发送给客户端</span><br><span class="line"><span class="number">4.</span> 继续下一批直到结束</span><br><span class="line"></span><br><span class="line">所以服务器端内存始终是小批小批地用，不会因为 <span class="number">1000</span> 万行而爆炸。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 什么时候可能卡住？</span><br><span class="line"></span><br><span class="line">**不是 MySQL 内存飙升，而是客户端读得太慢。**</span><br><span class="line"></span><br><span class="line">如果客户端处理得慢，导致服务器端的 **socket send buffer 写满了**，那么 MySQL 会暂时停住发送数据，但依然不会导致 MySQL 内存暴涨。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 总结</span><br><span class="line"></span><br><span class="line">&gt; `SELECT *` 大表不会导致 MySQL 内存飙升，因为 MySQL 是**流式传输、批量发送数据**，不会把所有行一次性加载到内存。</span><br><span class="line"></span><br><span class="line">## 让你实现一个订单超时取消功能，怎么设计？</span><br><span class="line"></span><br><span class="line">### <span class="number">1.</span> 先说本质</span><br><span class="line"></span><br><span class="line">订单超时取消，本质就是一个**延迟任务**问题：</span><br><span class="line"></span><br><span class="line">&gt; 创建订单时记录一个“到期时间”，到点后触发一次关单逻辑（改状态、回库存、记日志），并且要**可持久、可扩展、不丢不重**。</span><br><span class="line"></span><br><span class="line">设计时我会先问 <span class="number">3</span> 个约束：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 允许多大误差？（几秒 / 几十秒 / 几分钟）</span><br><span class="line"><span class="number">2.</span> 订单量级多大？（几十万 / 几千万 / 上亿）</span><br><span class="line"><span class="number">3.</span> 是单体还是分布式、有没有 Redis / MQ 这类基础设施。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### <span class="number">2.</span> 给几种典型方案 + 评价</span><br><span class="line"></span><br><span class="line">#### 方案一：定时任务扫表（最常用、易实现）</span><br><span class="line"></span><br><span class="line">**做法：**</span><br><span class="line"></span><br><span class="line">- 下单时写入订单表：`order_status=未支付、expire_time=now+<span class="number">15</span>min`。</span><br><span class="line">- 用 xxl-job / Quartz / 自写 ScheduledThreadPoolExecutor 做一个**周期任务**：</span><br><span class="line">   每分钟扫一次 `WHERE status=&#x27;未支付&#x27; AND expire_time &lt;= now` 的订单，批量关闭。</span><br><span class="line"></span><br><span class="line">**优点：**</span><br><span class="line"></span><br><span class="line">- 实现最简单，依赖最少；对时间精度要求不高时很好用。</span><br><span class="line">- 扩展到分布式也简单：任务只在一台调度机跑就行。</span><br><span class="line"></span><br><span class="line">**缺点 &amp; 优化点：**</span><br><span class="line"></span><br><span class="line">- 时间不够精确（可能晚几秒～几十秒）。</span><br><span class="line">- 大量订单集中扫表，会对 DB 有压力，分库分表时要做**分片扫描**，可以按 `order_id hash`、`expire_time 分段` 分批查。</span><br><span class="line">- 需要做好**幂等**：重复扫同一订单只会从“未支付→已关闭”一次。</span><br><span class="line"></span><br><span class="line">&gt; 结论：**业务量中等、时间精确度要求不高**时，定时任务是首选。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 方案二：Redis / Redisson 延迟队列（分布式、精度更高）</span><br><span class="line"></span><br><span class="line">**做法（Redis ZSet 思路）：**</span><br><span class="line"></span><br><span class="line">- 下单时，往 Redis 的 zset 写一条：</span><br><span class="line">   `zadd order_timeout_zset (expire_timestamp) orderId`。</span><br><span class="line">- 起一个后台任务，定期从 zset 里拿出 `score &lt;= 当前时间` 的订单号，做关单逻辑。</span><br><span class="line"></span><br><span class="line">**问题：**</span><br><span class="line"></span><br><span class="line">- 多个消费者同时取任务会有**重复关单**，通常用分布式锁 + 幂等解决。</span><br><span class="line"></span><br><span class="line">**Redisson 优化：**</span><br><span class="line"></span><br><span class="line">- Redisson 提供了 `RDelayedQueue`，内部就是 **zset + 内存延时队列**：</span><br><span class="line">  - 你只需要 `queue.offer(orderId<span class="punctuation">,</span> <span class="number">15</span><span class="punctuation">,</span> MINUTES)`；</span><br><span class="line">  - 到点后 Redisson 自动把数据投到真正的队列，你的消费者监听队列做关单即可。</span><br><span class="line">- 帮你处理了并发、重复、调度等细节，天然支持持久化、高可用。</span><br><span class="line"></span><br><span class="line">&gt; 结论：**分布式 + 订单量较大 + 业务已经依赖 Redis** 时，</span><br><span class="line">&gt; 我会优先考虑 **Redisson 延迟队列**，代码简洁、伸缩性好。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 方案三：MQ 延迟消息 / 死信队列（能用，但我会慎选）</span><br><span class="line"></span><br><span class="line">常见做法有：</span><br><span class="line"></span><br><span class="line">- RocketMQ 延迟消息：下单发一条“延迟 <span class="number">15</span> 分钟”的关单消息，消费者收到后关单。</span><br><span class="line">- RabbitMQ 死信队列或延迟插件：设置 TTL，到期后进入死信队列，消费者处理。</span><br><span class="line"></span><br><span class="line">**优点：**</span><br><span class="line"></span><br><span class="line">- 天然支持分布式和高并发，扩机器就能扛量。</span><br><span class="line">- 时间精度比较高。</span><br><span class="line"></span><br><span class="line">**缺点：**</span><br><span class="line"></span><br><span class="line">- **订单关闭是高“空跑率”的场景**：大部分订单都会按时支付，延迟消息却还是要发、要路由、要持久化，造成大量无效调度。</span><br><span class="line">- RocketMQ 自带延迟级别有限制（<span class="number">1</span>s、<span class="number">5</span>s、<span class="number">10</span>s…<span class="number">20</span>m、<span class="number">30</span>m…），不一定匹配业务；</span><br><span class="line">   RabbitMQ 死信队列会有队头阻塞等问题，需要额外治理。</span><br><span class="line"></span><br><span class="line">&gt; 所以文档里建议：**订单到期关闭这类业务，一般不优先用 MQ**，更多是用在已经强依赖 MQ、且量级适中时作为备选。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### <span class="number">3.</span> 我会怎么选？</span><br><span class="line"></span><br><span class="line">如果让我设计，我通常会这样跟面试官收尾：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> **小体量 / 单体应用**</span><br><span class="line">   - 直接用 **定时任务扫表**，实现简单、足够稳定。</span><br><span class="line"><span class="number">2.</span> **分布式 + 中等体量**</span><br><span class="line">   - 优先 **定时任务 + 分库分表分片扫描**；</span><br><span class="line">   - 若已有 Redis 集群，会考虑 **Redisson 延迟队列** 做更精细的触发。</span><br><span class="line"><span class="number">3.</span> **大体量 / 高并发**</span><br><span class="line">   - 订单写 DB，**定时任务按分片分段扫表关单**，</span><br><span class="line">   - 或者 **Redisson 延迟队列 + 多消费者集群**，同时在关单接口上做好状态机 + 幂等控制。</span><br><span class="line"></span><br><span class="line">同时还会强调 <span class="number">3</span> 点工程细节：</span><br><span class="line"></span><br><span class="line">- **幂等**：关单接口按 `orderId + 状态` 控制，多次执行结果一致。</span><br><span class="line">- **状态机**：订单状态流转只允许 `未支付→已关闭` 这条路径。</span><br><span class="line">- **监控告警**：统计超时订单量、失败量、任务延迟时间，有问题能快速定位。</span><br><span class="line"></span><br><span class="line">这样答，一方面说明你知道各种**实现方式和 trade-off**，另一方面也给出了一套自己会落地的**工程方案**。</span><br><span class="line"></span><br><span class="line">## 朋友圈点赞功能如何实现，简单说说？</span><br><span class="line"></span><br><span class="line">实现朋友圈点赞，其实就围绕三个核心动作：**点赞、取消点赞、查询点赞列表**。</span><br><span class="line">在项目上最关键的问题是：**如何存储点赞数据、如何按时间顺序展示、如何避免重复点赞**。</span><br><span class="line"></span><br><span class="line">我一般会用 Redis 的 **ZSet** 来做，因为它天然支持去重、排序，性能也非常高。</span><br><span class="line"></span><br><span class="line">### <span class="number">1.</span>数据结构设计</span><br><span class="line">- key：用朋友圈的动态 ID</span><br><span class="line">- value：点赞用户的 userId</span><br><span class="line">- score：点赞时间的时间戳</span><br><span class="line"></span><br><span class="line">这样有几个好处：</span><br><span class="line"><span class="number">1</span> 用户重复点赞不会插入新记录（天然去重）</span><br><span class="line"><span class="number">2</span> 可以按时间排序，显示谁先点的赞</span><br><span class="line"><span class="number">3</span> 删除用户也很简单，直接 zrem 即可</span><br><span class="line"></span><br><span class="line">### <span class="number">2.</span>核心操作</span><br><span class="line">#### **点赞**</span><br><span class="line"></span><br><span class="line">```redis</span><br><span class="line">ZADD like<span class="punctuation">:</span><span class="punctuation">&#123;</span>postId<span class="punctuation">&#125;</span> 时间戳 userId</span><br></pre></td></tr></table></figure></li></ul><h4 id="取消点赞"><strong>取消点赞</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZREM like:&#123;postId&#125; userId</span><br></pre></td></tr></table></figure><h4 id="查询点赞列表（按时间倒序）"><strong>查询点赞列表（按时间倒序）</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZREVRANGE like:&#123;postId&#125; 0 -1</span><br></pre></td></tr></table></figure><h3 id="3-这样设计的优点">3.这样设计的优点</h3><ul><li><strong>速度快</strong>：ZSet 的增删查都是 O(logN)，非常适合高并发</li><li><strong>顺序明确</strong>：前端可以直接展示按时间排序的点赞列表</li><li><strong>天然去重</strong>：用户重复点赞不会造成脏数据</li><li><strong>可扩展性高</strong>：以后想做点赞数排行榜也很容易（比如按用户做 top K）</li></ul><h3 id="小结-6">小结</h3><blockquote><p>“朋友圈点赞我一般用 Redis 的 ZSet 实现。每条动态用一个 ZSet 存点赞用户，value 是 userId，score 用时间戳。点赞就是 zadd，取消点赞是 zrem，查询按时间排序直接 zrevrange。这样能保证点赞天然去重、按时间有序，增删查都特别快，也方便以后扩展点赞排行榜。”</p></blockquote>]]></content>
    
    
    <summary type="html">我对场景题的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="场景题" scheme="https://itgeqian.github.io/tags/%E5%9C%BA%E6%99%AF%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Spring的相关面试题</title>
    <link href="https://itgeqian.github.io/posts/81.html"/>
    <id>https://itgeqian.github.io/posts/81.html</id>
    <published>2025-10-15T00:19:03.000Z</published>
    <updated>2025-10-17T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-Spring">GQ Spring</h1><h2 id="什么是循环依赖">什么是循环依赖</h2><p>循环依赖指的是<strong>两个或多个模块、类或组件之间相互依赖，从而形成一个闭环</strong>。<br>简单来说：</p><ul><li>模块 A 依赖模块 B，</li><li>模块 B 又依赖模块 A，</li><li>这样就会导致系统在加载或初始化时，无法确定先创建哪个对象。<br>循环依赖本身不是语法错误，但在依赖注入或对象构建时会导致程序启动失败或逻辑异常。</li></ul><p>和死锁（Deadlock）的区别</p><table><thead><tr><th>对比项</th><th>循环依赖</th><th>死锁</th></tr></thead><tbody><tr><td><strong>定义</strong></td><td>代码层面或模块层面的相互依赖关系</td><td>运行时线程相互等待资源，谁也不释放</td></tr><tr><td><strong>发生阶段</strong></td><td><strong>编译期或启动期</strong>（比如 Spring Bean 创建阶段）</td><td><strong>运行期</strong>（线程执行过程中）</td></tr><tr><td><strong>结果表现</strong></td><td>程序无法完成依赖注入或初始化</td><td>程序卡死、不再响应但不报错</td></tr><tr><td><strong>解决方式</strong></td><td>拆分依赖、使用懒加载（<code>@Lazy</code>）、构造改为 setter 注入</td><td>通过加锁顺序、超时锁或死锁检测机制避免</td></tr></tbody></table><p>循环依赖是代码设计上的问题，而死锁是运行时线程竞争资源的问题。<br>前者在启动就会出错，后者是运行中卡死。</p><p>小结：<br><strong>循环依赖就是两个或多个类互相依赖，导致系统在初始化时无法确定先创建谁，比如 A 依赖 B，B 又依赖 A</strong>它常见于依赖注入框架（比如 Spring）中，可能导致启动失败。</p><blockquote><p>而死锁是运行时两个线程互相占用资源不释放，导致程序卡死。<br>简单说：循环依赖是‘启动时互等’，死锁是‘运行时互等’。</p></blockquote><h2 id="Spring-如何解决循环依赖？">Spring 如何解决循环依赖？</h2><p>在 Spring 中，循环依赖指的是：</p><blockquote><p>Bean A 依赖 Bean B，而 Bean B 又依赖 Bean A。</p></blockquote><p>如果两者都在实例化阶段互相等待，就会导致创建失败。<br>Spring 为了解决这个问题，引入了 <strong>三级缓存机制</strong>（Three-Level Cache），来打破这种“互等”局面。</p><h3 id="Spring-的三级缓存机制">Spring 的三级缓存机制</h3><p>Spring 的三级缓存位于 DefaultSingletonBeanRegistry 中，分别是：</p><table><thead><tr><th>缓存层级</th><th>名称</th><th>作用</th></tr></thead><tbody><tr><td><strong>一级缓存</strong></td><td><code>singletonObjects</code></td><td>存放<strong>完全初始化好的 Bean（成品）</strong></td></tr><tr><td><strong>二级缓存</strong></td><td><code>earlySingletonObjects</code></td><td>存放<strong>实例化但未完成依赖注入的 Bean（半成品）</strong></td></tr><tr><td><strong>三级缓存</strong></td><td><code>singletonFactories</code></td><td>存放<strong>可以创建早期 Bean 引用的工厂对象</strong>（ObjectFactory）</td></tr></tbody></table><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/yDy23o3T_Snipaste_2025-11-08_17-34-04_mianshiya.png" alt="Snipaste_2025-11-08_17-34-04.png" width="100%" /><p>可以把它想成一个生产车间：</p><ul><li>一级区是‘成品区’，</li><li>二级区是‘半成品区’，</li><li>三级区是‘工厂区’，能提前生产半成品出来救急。</li></ul><h3 id="Spring-解决循环依赖的核心流程（以-A-↔-B-为例）">Spring 解决循环依赖的核心流程（以 A ↔ B 为例）</h3><p>① 创建 A<br>Spring 发现 A 还没创建，于是调用 createBean(A)。</p><p>把 “A 正在创建中” 标记进三级缓存（工厂区）。</p><p>实例化 A（这时只是空壳，没有注入属性）。</p><p>② A 注入属性时发现依赖 B<br>Spring 去创建 B，同样走 createBean(B) 流程。</p><p>实例化 B 时，发现它依赖 A。</p><p>此时 Spring 检查缓存：</p><p>一级缓存中没有（成品还没完成）；</p><p>二级缓存也没有；</p><p>但在 三级缓存中找到了 A 的 ObjectFactory。</p><p>Spring 调用 getObject() 获取 A 的早期引用，放进二级缓存（半成品区）。<br>这样 B 可以顺利完成依赖注入。</p><p>③ B 初始化完成后放入一级缓存<br>此时 B 已经是成品。</p><p>④ 回到 A<br>A 继续完成剩余属性注入和初始化。<br>此时 B 已经是成品，因此注入成功。<br>最终，A 也放入一级缓存，循环依赖解除。</p><p>通俗来说：Spring 会先查成品区，找不到再查半成品区，还找不到才动用工厂区提前生产一个早期对象引用。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/VkXNEOm1_image_mianshiya.png" alt="image.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/cqKbuRa9_Snipaste_2025-11-08_17-38-21_mianshiya.png" alt="Snipaste_2025-11-08_17-38-21.png" width="100%" /><h3 id="Spring-不能解决的循环依赖">Spring 不能解决的循环依赖</h3><p>Spring 的三级缓存机制只对 <strong>单例</strong>（Singleton）<strong>Bean + Setter</strong> 注入 有效。<br>但以下场景无法解决：</p><ul><li>构造器注入的循环依赖：<ul><li>因为在实例化阶段就需要依赖对方，此时还没放入缓存。</li></ul></li><li>原型（Prototype）作用域的 Bean：<ul><li>每次创建新实例，不共享缓存，无法打破循环。</li></ul></li></ul><p>Setter 注入可以救，但构造器注入救不了。因为你还没造出对象，就已经要拿它用。</p><h3 id="小结：">小结：</h3><p>Spring 是通过三级缓存来解决大部分循环依赖问题的。<br>它维护了三个 Map：一级缓存放成品 Bean，二级缓存放半成品 Bean，三级缓存放可以创建早期对象的工厂。</p><p><strong>当 Bean A 依赖 Bean B，而 B 又依赖 A 时，Spring 会从三级缓存提前拿出 A 的早期引用注入到 B 中，等 B 创建完后再回头把 A 初始化完成，这样就打破了互相等待。</strong></p><p>但注意，这种机制<strong>只适用于单例 + Setter 注入</strong>，构造器注入的循环依赖仍然会报错。</p><h2 id="为什么-Spring-循环依赖需要三级缓存，二级不够吗？">为什么 Spring 循环依赖需要三级缓存，二级不够吗？</h2><p>Spring 之所以要设计三级缓存，是为了同时解决两类问题：<br>1️ 循环依赖问题（让 Bean 能互相注入），<br>2️ AOP 代理的提前暴露问题（保证注入的是代理对象而不是原始对象）。<br>简单说：</p><blockquote><p>二级缓存能解决“互相依赖”，<br>但只有三级缓存才能让“代理对象”参与循环依赖，<br>保证最终 Bean 是对的那个代理版本。</p></blockquote><h3 id="为什么二级缓存不够用？">为什么二级缓存不够用？</h3><p>如果只有二级缓存（成品 + 半成品），确实可以解决大部分循环依赖问题。<br>但问题出在 <strong>AOP 代理场景</strong></p><p>假如 A 被代理（比如加了事务、切面）：</p><ol><li>Spring 在创建 A 的时候，A 还没完成初始化；</li><li>但此时 B 又依赖 A，于是去缓存里找：</li></ol><ul><li>一级缓存：没有；</li><li>二级缓存：A 还没放进去；</li></ul><ol start="3"><li>如果直接放原始 A（未代理）进二级缓存，</li></ol><ul><li>那 B 注入的就是原始对象，而不是代理对象 。</li></ul><p>所以 Spring 必须提前暴露一个能生成代理的“工厂”，<br>即放进<strong>三级缓存</strong>的 ObjectFactory。<br>当 B 要 A 时，就能通过这个工厂拿到最终的代理对象 。</p><h3 id="三级缓存解决流程">三级缓存解决流程</h3><p>1️ 创建 A → 放入“正在创建集合”<br>2️ 提前将 A 的 ObjectFactory 放入三级缓存<br>3️ 创建 B，发现依赖 A<br>4️ 从三级缓存中拿到 getObject() 工厂 → 生成 A 的代理对象 → 放入二级缓存<br>5️ B 成功注入 A → B 完成 → 放入一级缓存<br>6️ A 也完成属性注入 → 从二级缓存移到一级缓存<br>此时两个 Bean 都是正常可用的，且代理生效。</p><h3 id="小结">小结</h3><p>Spring 用三级缓存来解决循环依赖。<br>一级放成品 Bean，二级放半成品 Bean，三级放能生成 Bean 的工厂对象。<br>如果只用二级缓存，在有 AOP 时 B 会拿到未代理的原始对象。<br>有了三级缓存，Spring 就能在注入时通过工厂提前生成代理对象，保证注入的永远是最终版本的 Bean。</p><h2 id="看过源码吗？说下-Spring-由哪些重要的模块组成？">看过源码吗？说下 Spring 由哪些重要的模块组成？</h2><p>Spring 整体是一个<strong>分层、模块化设计的框架</strong>，核心是 <strong>IoC</strong> 和 <strong>AOP</strong>。<br>Spring 整体可以分为五大核心模块：<strong>Core Container、AOP、Data Access、Web、以及扩展模块</strong>。<br>各模块之间松耦合、可独立使用，也能协同组合，这就是 Spring 灵活和可扩展的关键。</p><p>核心模块</p><h3 id="1️-Core-Container（核心容器层）">1️. Core Container（核心容器层）</h3><p>这是整个 Spring 的基础，主要负责 依赖注入（DI） 和 Bean 管理。</p><table><thead><tr><th>模块</th><th>作用</th></tr></thead><tbody><tr><td><strong>Spring Core</strong></td><td>提供 IoC（控制反转）功能，实现 Bean 的创建与依赖注入，是最底层的核心。</td></tr><tr><td><strong>Spring Beans</strong></td><td>定义 Bean、依赖关系和生命周期的基础类。</td></tr><tr><td><strong>Spring Context</strong></td><td>提供上下文容器（<code>ApplicationContext</code>），支持事件、国际化、资源加载等。</td></tr><tr><td><strong>Spring Expression Language（SpEL）</strong></td><td>表达式语言，用于动态注入属性或条件配置。</td></tr></tbody></table><p>核心容器相当于 Spring 的‘心脏’，它负责 Bean 的创建、注入和管理，所有功能模块都依赖它。</p><h3 id="2️-AOP（面向切面编程）">2️ AOP（面向切面编程）</h3><p>用来在不修改业务代码的情况下，实现通用功能复用，比如日志、事务、安全控制等。</p><table><thead><tr><th>模块</th><th>作用</th></tr></thead><tbody><tr><td><strong>Spring AOP</strong></td><td>提供切面编程能力，用代理机制动态地在方法前后插入逻辑。</td></tr></tbody></table><p>AOP 就像在方法外面包了一层壳，能在执行前后加上日志、安全校验或事务控制。</p><h3 id="3️-Data-Access（数据访问层）">3️ Data Access（数据访问层）</h3><p>用于整合各种数据访问技术，对外提供一致的事务与数据访问接口。</p><table><thead><tr><th>模块</th><th>作用</th></tr></thead><tbody><tr><td><strong>Spring JDBC</strong></td><td>简化原生 JDBC 操作，自动处理连接与资源释放。</td></tr><tr><td><strong>Spring ORM</strong></td><td>集成 Hibernate、MyBatis、JPA 等 ORM 框架。</td></tr><tr><td><strong>Spring Transaction</strong></td><td>提供声明式事务管理机制。</td></tr></tbody></table><p>Spring 对数据层做了统一封装，不管你用 JDBC 还是 MyBatis，事务都能用同一套机制管理。</p><h3 id="4️-Web（Web-层）">4️ Web（Web 层）</h3><p>提供 Web 开发的基础支持，包括 MVC 架构、REST API、响应式编程等。</p><table><thead><tr><th>模块</th><th>作用</th></tr></thead><tbody><tr><td><strong>Spring Web</strong></td><td>封装基础的 Web 功能，如多层架构和上下文集成。</td></tr><tr><td><strong>Spring MVC</strong></td><td>实现 MVC 模式，是构建 Web 应用的核心模块。</td></tr><tr><td><strong>Spring WebFlux</strong></td><td>基于 Reactor 的响应式编程框架，适合高并发、异步场景。</td></tr></tbody></table><p>Web 层就是 Spring 做前后端交互的地方，MVC 适合传统请求，WebFlux 适合异步流式请求。</p><h3 id="5️-扩展模块（Advanced-Modules）">5️ 扩展模块（Advanced Modules）</h3><table><thead><tr><th>模块</th><th>作用</th></tr></thead><tbody><tr><td><strong>Spring Batch</strong></td><td>支持批量任务处理。</td></tr><tr><td><strong>Spring Integration</strong></td><td>实现企业集成模式（EAI），支持消息、服务编排。</td></tr><tr><td><strong>Spring Cloud</strong></td><td>面向分布式系统的服务治理和微服务支持。</td></tr></tbody></table><p>这些模块是为企业级或分布式场景准备的，比如批处理、消息通信、微服务等。</p><h3 id="模块化设计的灵活性">模块化设计的灵活性</h3><p>Spring 模块化设计的核心思想是<strong>按需引入、低耦合高复用</strong>。<br>比如如果我只想用 IoC 功能，可以只引入 spring-core 和 spring-beans，不需要整个 Web 模块，这保证了 Spring 的轻量化和扩展性。</p><h3 id="Spring-Boot-与-Spring-Framework-的关系">Spring Boot 与 Spring Framework 的关系</h3><p>Spring Boot 是对 Spring Framework 的进一步封装，它帮我们做了<strong>自动配置和模块整合</strong>。开发者不再需要手动写 XML 或 JavaConfig，大量默认配置让 Spring 应用启动更快、更简单。<br><strong>Spring 是引擎，Spring Boot 是启动器。</strong></p><h3 id="小结-2">小结</h3><p>Spring 框架主要由五大模块组成：<br>核心容器（Core、Beans、Context、SpEL）负责 IoC；<br>AOP 模块 负责切面编程；<br>数据访问模块（JDBC、ORM、Transaction）管理数据操作和事务；<br>Web 模块（MVC、WebFlux）支撑 Web 应用；<br>还有扩展模块（Batch、Integration、Cloud）提供企业级支持。<br>模块之间松耦合、按需加载，这也是 Spring 灵活和强大的原因。</p><h2 id="什么是-Spring-IOC？">什么是 Spring IOC？</h2><p>“Spring IOC，也叫控制反转（Inversion of Control），是 Spring 框架的核心思想之一。</p><ul><li><p>控制反转（IoC）：<br>原本对象之间的依赖关系是由我们手动控制的，比如在代码里 A a = new A();。<br>而现在这种“控制权”被反转给 Spring 容器 —— 它负责创建对象，并把需要的依赖注入进去。<br>所以叫 “控制反转”。</p></li><li><p>依赖注入（DI）：<br>实现控制反转的具体方式。Spring 会通过 构造器注入 或 Setter 注入<br>把对象需要的依赖传进去，而不是让对象自己去 new。</p></li></ul><blockquote><p>以前我自己去超市买材料做饭（手动 new 对象）；<br>现在我点了外卖，Spring 容器帮我准备好并送上门（IoC 容器负责创建和注入）。<br>这就是控制反转的本质。</p></blockquote><h3 id="Spring-IOC-的核心原理">Spring IOC 的核心原理</h3><p>Spring IOC 底层是基于 <strong>工厂模式</strong>（Factory Pattern） 实现的：</p><ul><li>Spring 容器其实就是一个 <strong>工厂</strong>（<strong>BeanFactory</strong> 或 <strong>ApplicationContext</strong>）。</li><li>它在启动时会解析配置文件或注解（如 @Component, @Bean），然后根据配置创建 Bean 实例，并维护它们的依赖关系。</li><li>当我们需要一个 Bean 时，直接从容器里拿（getBean()），而不是自己去创建。</li></ul><blockquote><p>Spring 容器其实就像一个智能工厂，我们只需要告诉它要什么对象，<br>它会自动帮我们创建好、装配好依赖。<br>所以我们在用的时候不需要关心 new 的过程，这就是 IoC 的思想。</p></blockquote><h3 id="IOC-带来的好处">IOC 带来的好处</h3><p>IOC 的核心价值就是<strong>解耦</strong>，程序员不用再管理对象生命周期，Spring 帮我们管一切。</p><h3 id="小结-3">小结</h3><p>Spring IOC，也就是控制反转，是通过依赖注入实现的。<br>它把对象的创建和依赖管理交给 Spring 容器完成，而不是由代码自己去 new。<br>容器通过工厂模式创建 Bean，并自动注入依赖。<br>这样让程序更解耦、更灵活、更好维护。<br>简单来说，IOC 就是 Spring 在帮我们管理对象之间的依赖关系。</p><h2 id="Spring-中的-DI-是什么？">Spring 中的 DI 是什么？</h2><p>DI是实现控制反转的具体方式。Spring 会通过 构造器注入 或 Setter 注入 把对象需要的依赖传进去，而不是让对象自己去 new。</p><h2 id="什么是-Spring-Bean？">什么是 Spring Bean？</h2><p>在 Spring 中，<strong>Bean 就是由 Spring 容器创建、管理和装配的对象</strong>。<br>换句话说，<strong>只要一个 Java 对象被交给 Spring 管理，它就是一个 Bean</strong>。<br>它的整个生命周期（创建、初始化、依赖注入、销毁）都由容器负责。</p><h3 id="Spring-Bean-的生命周期大致可以分为四个阶段">Spring Bean 的生命周期大致可以分为四个阶段</h3><table><thead><tr><th>阶段</th><th>说明</th></tr></thead><tbody><tr><td><strong>1️ 实例化（Instantiation）</strong></td><td>容器启动时，根据配置或注解解析，Spring 会先创建 Bean 实例。</td></tr><tr><td><strong>2️ 依赖注入（Dependency Injection）</strong></td><td>实例化后，Spring 会通过构造器、setter 方法等把所需依赖注入进去。</td></tr><tr><td><strong>3️ 初始化（Initialization）</strong></td><td>如果 Bean 实现了 <code>InitializingBean</code> 接口，或使用了 <code>@PostConstruct</code> 注解，会在依赖注入完成后调用初始化方法。</td></tr><tr><td><strong>4️ 销毁（Destruction）</strong></td><td>容器关闭时，如果实现了 <code>DisposableBean</code> 接口，或使用了 <code>@PreDestroy</code> 注解，会调用销毁逻辑。</td></tr></tbody></table><p>可以把 Spring Bean 想象成‘由容器养大的对象’，<br>它从出生（实例化）到长大（初始化）再到被销毁，全程都由容器照顾。</p><h3 id="Spring-Bean-的定义方式">Spring Bean 的定义方式</h3><table><thead><tr><th>定义方式</th><th>示例</th><th>特点</th></tr></thead><tbody><tr><td><strong>XML 配置</strong></td><td><code>&lt;bean id=&quot;userService&quot; class=&quot;com.xxx.UserService&quot;/&gt;</code></td><td>早期常用方式，现在较少用。</td></tr><tr><td><strong>注解方式</strong></td><td><code>@Component</code>, <code>@Service</code>, <code>@Repository</code>, <code>@Controller</code></td><td>Spring 会自动扫描并注册为 Bean，主流做法。</td></tr><tr><td><strong>Java 配置方式</strong></td><td><code>@Configuration</code> + <code>@Bean</code></td><td>代码方式定义，类型安全、灵活度高。</td></tr></tbody></table><p>以前我们在 XML 里写 <bean>，现在更常用 @Component 或 @Bean 注解来声明 Bean，Spring 会自动识别并注册。</p><h3 id="Bean-与-IoC-的关系">Bean 与 IoC 的关系</h3><p><strong>Spring Bean 是 IoC 容器管理的最小单位</strong>。<br>IOC 解决的是谁来创建对象、谁来管理依赖的问题，而 Bean 就是被管理的那些对象。<br>所以说：<strong>Spring 管容器，容器管 Bean</strong>。</p><h3 id="小结-4">小结</h3><p>Spring Bean 就是被 Spring 容器创建和管理的对象。<br>它的生命周期包括实例化、依赖注入、初始化和销毁四个阶段。<br>我们可以通过注解、XML 或 Java 配置来定义 Bean。<br>简单说，Spring Bean 是 IOC 容器中最基本的管理单元，容器负责帮我们创建和维护它。</p><h2 id="Spring-中的-BeanFactory-是什么？">Spring 中的 BeanFactory 是什么？</h2><p>BeanFactory 是 Spring IoC 容器的底层接口，负责 Bean 的创建、依赖注入和生命周期管理。<br>它采用<strong>延迟加载机制</strong>，只有在第一次请求 Bean 时才会创建对象。<br>它有多个实现类，比如 DefaultListableBeanFactory。<br>平时我们更常用的 ApplicationContext 实际上是对 BeanFactory 的增强版，提供了更丰富的功能，比如国际化、事件发布等。</p><ul><li>简单说，BeanFactory 就是 Spring 管 Bean 的‘工厂’，它负责生产和管理所有的 Bean。</li></ul><h2 id="Spring-中的-FactoryBean-是什么？">Spring 中的 FactoryBean 是什么？</h2><p>FactoryBean 是 Spring 中一种特殊的 Bean，<strong>用来创建其他 Bean 的工厂</strong>。<br>它允许我们通过实现 getObject() 方法自定义 Bean 的创建逻辑。<br>当我们通过 getBean() 获取时，<strong>拿到的是它生产的对象，而不是 FactoryBean 自身</strong>。</p><ul><li>就像你点外卖，你拿到的不是厨师（FactoryBean 本身），<br>而是厨师做出来的菜（它生成的 Bean 对象）。</li></ul><p>如果要获取工厂本身，需要在 Bean 名称前加上 &amp;。<br>它常用于像 AOP、MyBatis 这种需要动态生成代理对象的场景</p><h2 id="Spring-中的-ObjectFactory-是什么？">Spring 中的 ObjectFactory 是什么？</h2><p>ObjectFactory 是 Spring 提供的一个轻量级工厂接口，用来延迟获取 Bean 实例。<br>它只有一个 getObject() 方法，调用时才真正从容器中取出 Bean。<br>这样可以避免容器启动时就创建所有 Bean，提高性能。<br>Spring 内部也大量使用 ObjectFactory，比如在解决循环依赖时，它就是二级缓存的核心组件之一。</p><ul><li>简单说，ObjectFactory 是一个懒加载的小工厂，用来在需要时再取出 Bean。</li></ul><h3 id="一句话串讲记忆">一句话串讲记忆</h3><blockquote><p>BeanFactory 是“仓库”，<br>FactoryBean 是“定制工厂”，<br>ObjectFactory 是“取货券”。</p></blockquote><p>口语化表达：</p><blockquote><p>“Spring 的世界里，BeanFactory 管理所有 Bean；</p></blockquote><h2 id="Spring-中的-ApplicationContext-是什么？">Spring 中的 ApplicationContext 是什么？</h2><p>ApplicationContext 是 Spring 容器的高级接口，它<strong>是 BeanFactory 的增强版</strong>。<br>它不仅能管理 Bean 的创建和生命周期，还提供了事件机制、国际化、资源加载等高级功能。<br>简单来说，BeanFactory 是基础仓库，而 ApplicationContext 是功能更强的‘智能仓库’。</p><blockquote><p>BeanFactory 更偏底层，而我们日常开发中几乎都用 ApplicationContext因为它不仅能帮我们管 Bean，还能帮我们做配置、国际化、事件广播，甚至支持 AOP</p></blockquote><h3 id="ApplicationContext-的五大核心功能">ApplicationContext 的五大核心功能</h3><ol><li>Bean 管理：负责所有 Bean 的创建、配置和生命周期。</li><li>资源加载：可以方便地加载文件、XML、属性文件等。</li><li>国际化支持：根据不同语言环境加载不同资源，实现多语言切换。</li><li>事件机制：可以发布、监听和处理事件，实现模块间解耦。</li><li>AOP 支持：与 Spring AOP 深度集成，支持切面逻辑织入。</li></ol><blockquote><p>ApplicationContext 不只是管 Bean 的，它其实是整个应用的‘上下文环境’，负责帮我们管理配置文件、监听事件、加载资源，甚至支持 AOP</p></blockquote><h3 id="ApplicationContext常见实现类">ApplicationContext常见实现类</h3><table><thead><tr><th>实现类</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>ClassPathXmlApplicationContext</strong></td><td>从类路径加载 XML 配置文件（常见于本地项目）</td></tr><tr><td><strong>FileSystemXmlApplicationContext</strong></td><td>从文件系统加载配置文件（适用于外部配置）</td></tr><tr><td><strong>AnnotationConfigApplicationContext</strong></td><td>基于注解配置（现代 Spring Boot 常用）</td></tr><tr><td><strong>WebApplicationContext</strong></td><td>专为 Web 应用设计的上下文环境</td></tr></tbody></table><blockquote><p>不同的 ApplicationContext 实现类就像不同版本的容器，<br>你在 Web 环境、命令行工具或 Spring Boot 项目里都能选到合适的那一个</p></blockquote><h3 id="和-BeanFactory-的区别">和 BeanFactory 的区别</h3><p>BeanFactory 只是‘仓库’，<br>ApplicationContext 是‘智能仓库 + 管理中心’。</p><table><thead><tr><th>对比项</th><th>BeanFactory</th><th>ApplicationContext</th></tr></thead><tbody><tr><td><strong>加载时机</strong></td><td>懒加载（第一次 getBean 才创建）</td><td>启动时立即创建所有单例 Bean</td></tr><tr><td><strong>功能性</strong></td><td>仅负责 Bean 管理</td><td>附带国际化、事件机制、AOP、资源加载等</td></tr><tr><td><strong>使用场景</strong></td><td>底层或轻量级容器</td><td>实际开发主流选择</td></tr></tbody></table><h3 id="小结-5">小结</h3><ul><li>ApplicationContext 是 Spring 的高级容器接口，是 BeanFactory 的增强版本。</li><li>它除了负责 Bean 的创建、配置和生命周期管理外，还提供国际化、资源加载、事件发布、AOP 支持等高级功能。</li><li>它是我们在 Spring 应用中最常用的上下文环境接口，比如常见的 AnnotationConfigApplicationContext、ClassPathXmlApplicationContext 等实现类</li></ul><h2 id="Spring-Bean-一共有几种作用域？">Spring Bean 一共有几种作用域？</h2><p>Spring Bean 一共有 6 种作用域（scope），其中前两种是 <strong>常规的</strong>（几乎所有应用都有），后四种是 <strong>Web 环境专</strong>属（Spring Web 应用中才有效）</p><ol><li><p>singleton（单例）<br>singleton 就是全局只造一个对象，整个容器里共用这一个。</p></li><li><p>prototype（原型 / 多实例）<br>prototype 就是每次都新建一个，谁来要我就给谁造一个新的。</p></li><li><p>request（请求级）<br>request 就是一次请求一个新 Bean，请完就销毁。</p></li><li><p>session（会话级）<br>session 就是每个用户一份 Bean，自己用自己的。</p></li><li><p>application（应用级）<br>application 就是整个 Web 应用共享一个 Bean。</p></li><li><p>websocket（WebSocket 级）<br>websocket 就是一个连接一个 Bean，断了就销毁。</p></li></ol><table><thead><tr><th>作用域</th><th>是否默认</th><th>适用环境</th><th>生命周期说明</th></tr></thead><tbody><tr><td><strong>singleton</strong></td><td>✅ 是</td><td>所有 Spring 应用</td><td>全局单例</td></tr><tr><td><strong>prototype</strong></td><td>❌ 否</td><td>所有 Spring 应用</td><td>每次创建新实例</td></tr><tr><td><strong>request</strong></td><td>❌ 否</td><td>Spring Web</td><td>每个请求一个实例</td></tr><tr><td><strong>session</strong></td><td>❌ 否</td><td>Spring Web</td><td>每个会话一个实例</td></tr><tr><td><strong>application</strong></td><td>❌ 否</td><td>Spring Web</td><td>整个应用一个实例</td></tr><tr><td><strong>websocket</strong></td><td>❌ 否</td><td>Spring WebSocket</td><td>每个 WebSocket 一个实例</td></tr></tbody></table><h3 id="小结-6">小结</h3><p>Spring 一共有 6 种作用域。最常用的是 singleton（默认单例）和 prototype（多实例）。<br>另外四种——request、session、application、websocket——是 Web 环境下特有的，分别对应一次请求、一次会话、整个应用和一次 WebSocket 连接的生命周期。</p><h2 id="Spring-一共有几种注入方式？">Spring 一共有几种注入方式？</h2><p>Spring 一共有 四种常见的依赖注入方式：<br><strong>构造器注入、Setter 注入、字段/方法注入、接口回调注入</strong>。<br>其中官方推荐使用构造器注入（Constructor-based Injection）</p><h3 id="构造器注入（Constructor-based-Injection）">构造器注入（Constructor-based Injection）</h3><p>原理：通过类的构造函数传入依赖对象。<br>优点：依赖是“强制性的”，在对象创建时就必须提供；<br>保证了 Bean 的完整性与不可变性。<br>实现方式：</p><ul><li>使用 @Autowired 标注构造器，或</li><li>使用 Lombok 的 @RequiredArgsConstructor 简化。</li></ul><p>Spring 推荐的就是构造器注入，依赖是<strong>强制性</strong>的,对象一创建就完整，不可能少依赖。</p><h3 id="Setter-注入（Setter-based-Injection）">Setter 注入（Setter-based Injection）</h3><ul><li>原理：通过 setter 方法注入依赖对象。</li><li>优点：依赖可选，可在运行时动态替换。</li><li>适用场景：部分依赖在某些情况下才需要时。</li></ul><p>Setter 注入适合可选依赖，比如某个组件有就用，没有也能运行。</p><h3 id="字段-方法注入（Field-Injection）">字段/方法注入（Field Injection）</h3><ul><li>原理：直接在字段/方法上用 @Autowired 注解，由 Spring 反射注入依赖。</li><li>优点：写法最简单，代码量最少。</li><li>缺点：不利于单元测试，不符合依赖倒置原则。</li></ul><p>字段注入虽然方便，但不推荐用在复杂项目里，测试不好写。</p><h3 id="接口回调注入（接口注入-Aware-接口）">接口回调注入（接口注入 / Aware 接口）</h3><ul><li>原理：实现 Spring 的某些接口（如 BeanFactoryAware、ApplicationContextAware），容器会在初始化时回调注入容器对象。</li><li>用途：通常用于框架级开发或工具类，不常用于业务代码。</li></ul><p>Aware 系列接口属于 Spring 内部机制，开发者一般少用。</p><h3 id="小结-7">小结</h3><p>Spring 的依赖注入主要有四种方式：构造器注入、Setter 注入、字段/方法注入和接口回调注入。<br>官方推荐构造器注入，因为它能保证依赖完整、易测试；Setter 适合可选依赖；<br>字段注入虽然简单，但不建议在正式项目中使用；而接口回调主要用于框架内部。</p><h2 id="什么是-AOP？">什么是 AOP？</h2><p>AOP（Aspect-Oriented Programming，面向切面编程）是一种编程思想。<br><strong>它的目标是把程序中与业务无关但又经常重复出现的逻辑</strong>（比如日志、安全检查、事务管理等），<strong>从业务代码里分离出来，用‘切面（Aspect）’统一管理</strong>。<br>简单来说，就是把<strong>共性逻辑抽取出来，动态地织入到业务流程</strong>中。</p><blockquote><p>AOP 就像是在程序运行时‘偷偷加点料’。<br>不改动原来的业务逻辑，就能在某些方法前后加上日志、事务、校验这些通用操作。</p></blockquote><h3 id="AOP-的核心思想与组成">AOP 的核心思想与组成</h3><table><thead><tr><th>名称</th><th>说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>切面（Aspect）</strong></td><td>切面是一个模块，封装了一组通用功能，比如日志、事务等。</td><td><code>@Aspect public class LogAspect &#123; ... &#125;</code></td></tr><tr><td><strong>连接点（Join Point）</strong></td><td>程序执行的具体位置，比如方法调用或异常抛出。</td><td>方法执行前、执行后等位置</td></tr><tr><td><strong>通知（Advice）</strong></td><td>定义在连接点要执行的操作。</td><td><code>@Before</code>, <code>@After</code>, <code>@Around</code> 等</td></tr><tr><td><strong>切入点（Pointcut）</strong></td><td>定义要拦截哪些方法或类。</td><td><code>@Pointcut(&quot;execution(* com.demo.service.*.*(..))&quot;)</code></td></tr><tr><td><strong>织入（Weaving）</strong></td><td>把切面逻辑“织入”到目标对象的过程。</td><td>通过代理机制在运行时完成织入</td></tr></tbody></table><p>AOP 的核心就是：<br>我先声明我要在哪个地方（Pointcut）加什么逻辑（Advice），<br>然后由 Spring 帮我在运行时自动把这段逻辑织进去（Weaving）。</p><h3 id="AOP-的底层原理">AOP 的底层原理</h3><p>AOP 的实现其实就是代理模式的应用。Spring AOP 主要用两种代理机制：</p><ul><li>JDK 动态代理：基于接口的代理。</li><li>CGLIB 代理：基于类继承的代理。</li></ul><blockquote><p>你可以把它理解成 Spring 在运行时帮你‘包了一层壳’，<br>在你执行目标方法前后，自动执行切面逻辑。</p></blockquote><h3 id="AOP-常见的应用场景">AOP 常见的应用场景</h3><table><thead><tr><th>场景</th><th>说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>日志记录</strong></td><td>在方法执行前后记录日志，避免每个类都手写日志代码。</td><td>打印调用方法名、参数等</td></tr><tr><td><strong>事务管理</strong></td><td>在方法执行前开启事务，执行后提交或回滚。</td><td><code>@Transactional</code></td></tr><tr><td><strong>安全检查</strong></td><td>在方法执行前检查权限，未授权则阻止访问。</td><td>权限验证逻辑</td></tr><tr><td><strong>性能监控</strong></td><td>统计方法执行耗时，方便系统调优。</td><td><code>@Around</code> 环绕通知</td></tr></tbody></table><p>像日志、事务、安全、性能这些功能，其实都属于‘横切逻辑’，有了 AOP，我们就能一处定义，到处生效。</p><h3 id="小结-8">小结</h3><ul><li>AOP 是一种面向切面编程思想，它把像日志、事务、安全检查这些通用逻辑从业务代码里抽取出来，用‘切面’统一管理。</li><li>它通过代理机制，在方法执行前后动态地插入额外逻辑，实现了业务逻辑与系统服务的解耦。</li><li>常见的应用场景包括日志记录、事务管理、权限验证和性能监控。</li></ul><h3 id="你的项目中哪里用到了AOP？">你的项目中哪里用到了AOP？</h3><p>在 xxx 这个项目里，我确实把 AOP 用在了两类典型的横切场景。</p><ul><li><p>第一类是“登录校验”的全局拦截。我做了一个自定义注解 <code>@GlobalInterceptor</code>，控制器方法只要打上这个注解并把 <code>checkLogin=true</code>，切面 <code>GlobalOperationAspect</code> 就会在方法执行前先跑一遍登录校验：从请求头里拿 <code>token</code>，到 Redis 里校验用户信息，不通过就直接抛业务异常。这样业务方法完全不用重复写登录判断，后期如果登录策略调整，只改切面一处就能全局生效。</p></li><li><p>第二类是“把用户行为自动转成站内消息”。我定义了 <code>@RecordUserMessage</code> 注解，像收藏、评论、审核这类会触发通知的行为，只要在方法上打注解，<code>UserMessageOperationAspect</code> 会用 <code>@Around</code> 在方法成功返回后读取方法入参（比如 <code>videoId</code>、<code>actionType</code>、<code>replyCommentId</code>、<code>content</code>），归一化成对应的 <code>MessageType</code>，然后调用消息服务落一条站内消息。失败或抛异常的情况不会记消息，保证幂等和一致性。管理端那边也有同名切面，做的事是一致的，只是调用方不同（通过 <code>InteractClient</code> 触发消息）。</p></li></ul><p>这两处 AOP 的好处非常直观：</p><ul><li>一是把“登录校验”“行为转消息”这种跟业务强相关、但又应该统一收口的共性逻辑，从每个接口里抽出来集中管理，业务代码更干净；</li><li>二是灵活性高，新增/调整规则都不需要改散落在各处的控制器；</li><li>三是天然适合做“只在成功时记录”的事情，用 <code>@Around</code> 能拿到返回值与异常，更好地保证边界与一致性。</li></ul><p>为什么用 AOP 而不是过滤器/拦截器：</p><ul><li>我会强调登录这类是“业务前置规则”，需要在方法级拿到注解、参数等上下文，AOP 在方法颗粒度更合适；</li><li>网关 Filter/Servlet Filter/HandlerInterceptor 更偏协议层或路由层，做限流、跨域、鉴权粗粒度拦截很好，但像“成功后落一条站内消息”这种强业务语义，用切面在目标方法周围处理最自然。</li></ul><p>最后，我也预留了扩展位：以后要做“操作审计”“性能埋点”“权限细粒度校验”，直接再加注解和切面就行，跟现有两套模式完全一致。</p><h2 id="能说说-Spring-拦截链的实现吗？">能说说 Spring 拦截链的实现吗？</h2><p>Spring 的拦截链本质上是<strong>一系列拦截器按顺序执行</strong>的机制，<br>主要包括 Filter（过滤器）、HandlerInterceptor（MVC 拦截器） 和 AOP 切面拦截 三种，<br>它们从外到内一层层包裹，实现请求前后和方法调用前后的统一处理。</p><ul><li>Filter（过滤器） 是最外层的守门员，拦得最早，一般负责安全验证、跨域这些全局性的事。</li><li>MVC 拦截器像一个环环相扣的链条，请求进来先经过 preHandle，再到 Controller，然后按顺序调用 postHandle、afterCompletion。</li><li>AOP 拦截器更细粒度，是方法级别的拦截。Spring 会把所有切面按顺序放进一个集合，然后递归调用，就形成了完整的拦截链。</li></ul><h3 id="小结-9">小结</h3><p>Spring 拦截链分三层：Filter、HandlerInterceptor 和 AOP。<br>Filter 是基于 Servlet 的全局拦截；<br>HandlerInterceptor 是 MVC 层的请求拦截，控制请求的前后处理；<br>AOP 是方法级别的动态拦截，通过切面实现。<br>它们组合起来形成一条完整的请求链，从外到内层层进入，再按反方向返回，<br>就像一个洋葱模型一样，既灵活又强大。</p><h2 id="说下-Spring-Bean-的生命周期？">说下 Spring Bean 的生命周期？</h2><h3 id="一句话总结">一句话总结</h3><blockquote><p>“Spring Bean 从创建到销毁，大致会经历 <strong>实例化 → 属性注入 → 初始化 → 使用 → 销毁</strong> 这五个阶段，</p></blockquote><hr><h3 id="二、详细生命周期阶段">二、详细生命周期阶段</h3><h4 id="1️⃣-实例化（Instantiation）">1️⃣ <strong>实例化（Instantiation）</strong></h4><ul><li>Spring 根据配置文件或注解，创建 Bean 实例对象（相当于执行 <code>new</code>）。</li><li>此时 Bean 还没被依赖注入。</li></ul><blockquote><p>“Spring 先把 Bean 给造出来，这时还只是个空壳对象。”</p></blockquote><hr><h4 id="2️⃣-属性注入（Populate-Properties）">2️⃣ <strong>属性注入（Populate Properties）</strong></h4><ul><li>Spring 通过 setter 方法或反射，把依赖对象注入到 Bean 中。</li><li>相当于给这个“空壳对象”装上它需要的组件。</li></ul><blockquote><p>“接下来 Spring 会往 Bean 里面塞依赖，比如注入 Service 或 Dao。”</p></blockquote><hr><h4 id="3️⃣-Aware-接口回调（可选）">3️⃣ <strong>Aware 接口回调（可选）</strong></h4><ul><li>如果 Bean 实现了类似 <code>BeanNameAware</code>、<code>BeanFactoryAware</code> 等接口，<br>Spring 会在这里回调这些方法，让 Bean 获取容器信息。</li></ul><blockquote><p>“如果 Bean 想知道自己叫什么、在哪个容器里，这一步 Spring 会告诉它。”</p></blockquote><hr><h4 id="4️⃣-BeanPostProcessor：初始化前（Before-Initialization）">4️⃣ <strong>BeanPostProcessor：初始化前（Before Initialization）</strong></h4><ul><li>在 Bean 初始化前，会调用所有注册的 <code>BeanPostProcessor</code> 的 <code>postProcessBeforeInitialization()</code> 方法。</li><li>常用于在初始化前修改 Bean 的属性或增强功能。</li></ul><blockquote><p>“初始化前，Spring 会让一些后置处理器先动手，比如 AOP 或注解增强。”</p></blockquote><hr><h4 id="5️⃣-初始化（Initialization）">5️⃣ <strong>初始化（Initialization）</strong></h4><ul><li>Bean 如果实现了 <code>InitializingBean</code> 接口，会执行 <code>afterPropertiesSet()</code> 方法；</li><li>或者配置了 <code>init-method</code>，Spring 会调用它。</li><li>这一步 Bean 已经准备好，可以开始使用。</li></ul><blockquote><p>“这一步是真正的‘激活’，Spring 会执行 Bean 的初始化逻辑，比如加载缓存、开启任务。”</p></blockquote><hr><h4 id="6️⃣-BeanPostProcessor：初始化后（After-Initialization）">6️⃣ <strong>BeanPostProcessor：初始化后（After Initialization）</strong></h4><ul><li>调用 <code>postProcessAfterInitialization()</code>，<br>通常在这里完成 AOP 代理对象的生成。</li></ul><blockquote><p>“初始化完，Spring 再让后置处理器做最后加工，比如创建代理对象。”</p></blockquote><hr><h4 id="7️⃣-Bean-使用阶段（In-Use）">7️⃣ <strong>Bean 使用阶段（In Use）</strong></h4><ul><li>Bean 被正常使用，可能被别的 Bean 引用，也可能参与业务逻辑。</li></ul><blockquote><p>“到这一步 Bean 就‘上线’了，正式参与业务。”</p></blockquote><hr><h4 id="8️⃣-销毁阶段（Destroy）">8️⃣ <strong>销毁阶段（Destroy）</strong></h4><ul><li><p>当 Spring 容器关闭时：</p><ul><li>如果 Bean 实现了 <code>DisposableBean</code> 接口，会执行 <code>destroy()</code>；</li><li>或者定义了 <code>destroy-method</code>，Spring 会调用该方法。</li></ul></li></ul><blockquote><p>“最后容器关闭，Spring 会优雅地销毁 Bean，比如释放资源、关闭连接。”</p></blockquote><hr><h3 id="📊-三、完整生命周期流程图（逻辑顺序）">📊 三、完整生命周期流程图（逻辑顺序）</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">实例化 → 属性注入 → Aware接口回调</span><br><span class="line">→ <span class="keyword">BeanPostProcessor（前） </span>→ 初始化（init）</span><br><span class="line">→ <span class="keyword">BeanPostProcessor（后） </span>→ 使用</span><br><span class="line">→ 销毁（destroy）</span><br></pre></td></tr></table></figure><hr><h3 id="四、小结">四、小结</h3><blockquote><p>“Spring Bean 的生命周期可以分为五个阶段：实例化、属性注入、初始化、使用、销毁。<br>初始化前后会执行 BeanPostProcessor，<br>如果实现了 Aware、InitializingBean、DisposableBean 等接口，也会有对应回调。<br>整个流程由 Spring 容器全程托管，开发者只需关注初始化和销毁逻辑。”</p></blockquote><h2 id="说下对-Spring-MVC-的理解？">说下对 Spring MVC 的理解？</h2><h3 id="一、一句话总结">一、一句话总结</h3><blockquote><p>“Spring MVC 是 Spring 框架对经典 MVC 模式的扩展实现，它通过前端控制器 <code>DispatcherServlet</code> 统一接收和分发请求，把传统的 Servlet + JSP 模式彻底解耦，让 Web 开发更清晰、更高效。”</p></blockquote><hr><h3 id="二、核心理解">二、核心理解</h3><h4 id="1️-本质是什么">1️ 本质是什么</h4><p>Spring MVC 就是一个 <strong>基于 MVC 模式的 Web 框架</strong>，<br>MVC 分为：</p><ul><li><strong>Model（模型层）</strong>：负责业务逻辑和数据处理</li><li><strong>View（视图层）</strong>：负责页面展示</li><li><strong>Controller（控制层）</strong>：负责接收请求、调用业务、返回结果</li></ul><p>SpringMVC 让这三层之间职责清晰、解耦合。</p><blockquote><p>“Spring MVC 就是帮你把 Controller、业务逻辑、视图展示这几部分分开管理的 Web 框架。”</p></blockquote><hr><h4 id="2️-Spring-MVC-的核心组件">2️ Spring MVC 的核心组件</h4><p>Spring MVC 的核心是 <strong><code>DispatcherServlet</code></strong>（前端控制器）。<br>它就像整个 Web 请求的“总调度员”，负责：</p><ul><li>接收 HTTP 请求</li><li>调用合适的 Controller</li><li>处理业务、封装数据</li><li>再把结果交给 View 层渲染返回</li></ul><blockquote><p>“<code>DispatcherServlet</code> 就像快递分拣中心，所有请求先送到它手上，再由它分发到对应的 Controller。”</p></blockquote><hr><h4 id="3️-相比传统-MVC-的改进">3️ 相比传统 MVC 的改进</h4><p>传统 Servlet + JSP 模式要自己写大量 Servlet、手动解析参数，代码冗余。<br>Spring MVC 把这些工作都交给框架自动处理，比如：</p><ul><li>请求映射（<code>@RequestMapping</code>）</li><li>参数绑定</li><li>异常处理</li><li>视图解析</li></ul><p>极大简化了开发工作。</p><blockquote><p>“以前写 Web 要自己写一堆 Servlet，现在有了 Spring MVC，只要写 Controller 方法，框架帮你搞定剩下的。”</p></blockquote><hr><h4 id="4️-Spring-MVC-中的分层思想">4️ Spring MVC 中的分层思想</h4><p>虽然传统 MVC 是三层（Model、View、Controller），<br>但在 Spring 体系中，Model 层又被进一步细分：</p><ul><li><strong>Service 层</strong>：负责业务逻辑</li><li><strong>Repository 层</strong>：负责数据库访问</li><li><strong>Controller 层</strong>：负责 Web 层请求</li></ul><p>这种分层更贴合实际项目架构，也让职责更清晰。</p><blockquote><p>“Spring 把 MVC 又细化了，Model 层里再分业务层（Service）和数据层（Repository），真正做到清晰分工。”</p></blockquote><hr><h3 id="三、面试回答">三、面试回答</h3><blockquote><p>“Spring MVC 是 Spring 框架基于经典 MVC 模式实现的 Web 开发框架。<br>它通过前端控制器 DispatcherServlet 统一接收和分发请求，把传统 Servlet+JSP 模式中繁琐的请求处理、参数绑定、视图解析都交给框架完成。<br>在 Spring 体系中，MVC 被进一步细化成 Controller、Service 和 Repository 三层，职责更清晰、开发更高效。”</p></blockquote><h2 id="Spring-MVC-具体的工作原理？">Spring MVC 具体的工作原理？</h2><h3 id="简要流程">简要流程</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/iXHwgmUc_image-1532-1024x698_mianshiya.png" alt="image-1532-1024x698.png" width="100%" /><p>1.“所有请求先到 DispatcherServlet（前端控制器），它就像一个总调度员，统一安排后续处理。<br>2.DispatcherServlet 会问 HandlerMapping：这次请求该哪个 Controller 来管？<br>3.找到对应的处理器（Handler，也就是 Controller 方法）后,Spring 会生成一个 HandlerExecutionChain（执行链）<br>4.根据执行链会得到一个适配器HandlerAdapter（处理器适配器）,什么样的请求处理得到什么样的适配器<br>5.在执行 目标方法 之前，会先经过拦截器链的前置流程 然后执行目标方法，执行完目标方法之后再执行拦截器的后置。<br>6.执行完会返回目标方法的返回结果<br>7.</p><ul><li>如果是页面跳转（比如返回 ModelAndView），就交给 ViewResolver（视图解析器）（8），得到视图进行页面渲染（9）</li><li>如果是前后端分离接口（带 @ResponseBody），就交给 HttpMessageConverter（消息转换器），把对象转成 JSON 返回（8）。</li></ul><p>10,11：如果执行过程中抛异常，会交给HandlerExceptionResolver 来捕获处理，<br>比如跳到错误页或者返回统一的异常 JSON。</p><h3 id="小结：-2">小结：</h3><p>浏览器一进来，请求发过来，由 DispatcherServlet 处理，它会去 HandlerMapping 里边，根据每一个请求路径的这个 map 去找这个请求由谁处理，找到由谁处理以后会返回执行链，根据执行链会得到一个适配器，什么样的请求处理得到什么样的适配器，适配器就是大型反射工具，适配器在执行目标方法之前，其实会有一个拦截器的流程（前置）然后再执行目标方法，目标方法执行完后再执行拦截器的后置，执行完这个流程后得到目标方法的返回结果，如果你是页面跳转就会有 ModelAndView 这一套，这一套就交给视图解析器，得到视图进行页面渲染。如果是前后端分离交给消息转换器，消息转换器把这个 JSON 写出去。如果在这期间出现任何异常，异常解析器就会捕获处理期间的所有异常，得到错误的异常内容，再返回</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/pzMru1u5_image_mianshiya.png" alt="image.png" width="100%" /><h3 id="完整流程">完整流程</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/QPDzU9cQ_image-1534-683x1024_mianshiya.png" alt="image-1534-683x1024.png" width="100%" /><p>DispatcherServlet 进来先是文件上传解析器，判定是不是文件上传请求，在这里做处理，然后再获取处理器，从 HandlerMapping 里边挨个找映射，如果找到了就会拿到目标方法的执行链，找不到响应 404，最终把找到还是找不到封装到 mappedHandler，如果它是 Null 就代表没找到，即 404，找到了就再找到它的适配器，适配器最终处理目标方法，处理目标方法之前它还会判断是否有请求缓存，如果请求缓存就直接结束，如果请求不缓存就接着往下走，看拦截器是不是 preHandle，但凡有一个返回 false，代表拦截器炸了，炸了之后从中断位置执行 afterCompletion 然后结束，如果全部返回 true，就往下走，执行目标方法，目标方法里边参数处理会有参数解析器，返回值处理会有返回值解析器，这两个目标方法执行完如果目标方法执行完出现了异常咋办，有异常会把异常封装起来，没异常逆序执行拦截器 postHandler。无论有无异常最终都会执行最终处理 processDispatchResult，有异常是封装异常，没异常执行 postHandler，最后都会来到 processDispatchResult，最终处理的话有异常处理异常，有页面渲染页面，在以上所有步骤中，但凡有异常，拦截器逆序执行 afterCompletion</p><h2 id="Spring-事务有几个隔离级别？">Spring 事务有几个隔离级别？</h2><p>Spring 提供了五种事务隔离级别：</p><p>DEFAULT（默认）：使用底层数据库的默认隔离级别。如果数据库没有特定的设置，通常默认为 READ_COMMITTED。<br>READ_UNCOMMITTED（读未提交）：最低的隔离级别，允许事务读取尚未提交的数据，可能会导致脏读、不可重复读和幻读。<br>READ_COMMITTED（读已提交）：仅允许读取已经提交的数据，避免了脏读，但可能会出现不可重复读和幻读问题。<br>REPEATABLE_READ（可重复读）：确保在同一个事务内的多次读取结果一致，避免脏读和不可重复读，但可能会有幻读问题。<br>SERIALIZABLE（可串行化）：最高的隔离级别，通过强制事务按顺序执行，完全避免脏读、不可重复读和幻读，代价是性能显著下降。</p><p>spring 事务隔离级别 和 数据库事务隔离级别不一致时以 spring中设定的为准，数据库connection链接可以设置数据库隔离级别</p><h2 id="Spring-有哪几种事务传播行为">Spring 有哪几种事务传播行为?</h2><p>Spring的事务传播机制用于控制事务方法在相互调用时如何共享事务或创建新的事务。在复杂的业务逻辑中，<strong>事务传播机制能够确保事务的一致性和完整性，避免出现数据丢失或重复提交等问题</strong>。</p><p>Spring 提供了7种事务传播行为，默认的传播方式是 <strong>REQUIRED</strong>：</p><ol><li><strong>REQUIRED（默认）</strong>：如果当前存在事务，方法就在该事务中执行；如果没有事务，则创建新事务。</li><li><strong>REQUIRES_NEW</strong>：每次执行都会开启新事务，若已有事务则挂起当前事务，独立执行。</li><li><strong>SUPPORTS</strong>：如果有事务，方法加入该事务；如果没有事务，方法就不在事务中执行。</li><li><strong>NOT_SUPPORTED</strong>：如果当前存在事务，则暂停事务，若没有事务，则方法在没有事务的环境中执行。</li><li><strong>MANDATORY</strong>：强制当前有事务，若没有事务则会抛出异常。</li><li><strong>NEVER</strong>：如果当前存在事务，则抛出异常；如果没有事务，则执行。</li><li><strong>NESTED</strong>：如果当前有事务，则创建嵌套事务，嵌套事务回滚时不影响父事务，反之，父事务回滚时会影响嵌套事务。</li></ol><h3 id="使用场景：">使用场景：</h3><ul><li><strong>REQUIRED</strong>：常用在方法需要共享事务时，确保多个方法在同一事务中执行。</li><li><strong>REQUIRES_NEW</strong>：当你希望某个方法执行时不受外部事务影响时使用。</li><li><strong>SUPPORTS</strong>、<strong>NOT_SUPPORTED</strong>、<strong>MANDATORY</strong>、<strong>NEVER</strong>：适用于特定业务逻辑需要控制事务行为的情况。</li><li><strong>NESTED</strong>：用于复杂的业务逻辑中，特别是当一个方法的失败不应该影响外部事务时，使用嵌套事务来实现更细粒度的回滚控制。</li></ul><h3 id="示例：">示例：</h3><p>假设有两个方法A和B，方法A执行数据库更新操作，方法B在A之后被调用。如果发生异常，需要确保两个方法的操作一起回滚。你可以在这两个方法上都使用 <strong>REQUIRED</strong> 传播行为，确保它们在同一事务中执行。如果方法A或B中的任一方法失败，整个事务都会回滚。</p><h2 id="Spring-IOC-容器初始化过程？">Spring IOC 容器初始化过程？</h2><p>Spring 容器启动其实就是在做一件事：创建并管理 Bean 的生命周期。整个过程可以简单分为 12 步</p><h3 id="第一阶段：准备和工厂创建">第一阶段：准备和工厂创建</h3><ol><li>prepareRefresh() —— 做准备，比如环境变量检查。</li><li>obtainFreshBeanFactory() —— 创建一个新的 BeanFactory。</li><li>prepareBeanFactory() —— 给 BeanFactory 加一些基础组件。</li><li>postProcessBeanFactory() —— 让子类可以进一步定制 BeanFactory。</li></ol><h3 id="第二阶段：处理和注册-Bean-定义">第二阶段：处理和注册 Bean 定义</h3><ol start="5"><li>invokeBeanFactoryPostProcessors() —— 执行 Bean 工厂的后置处理器，比如修改 Bean 定义。</li><li>registerBeanPostProcessors() —— 注册 Bean 的后置处理器，负责 Bean 创建前后的增强逻辑（比如 AOP）。</li></ol><h3 id="第三阶段：国际化、事件与监听器">第三阶段：国际化、事件与监听器</h3><ol start="7"><li>initMessageSource() —— 初始化国际化组件。</li><li>initApplicationEventMulticaster() —— 初始化事件广播器。</li><li>onRefresh() —— 留给子类扩展，比如 Web 容器会在这步创建 Web 环境。</li><li>registerListeners() —— 注册事件监听器。</li></ol><h3 id="第四阶段：Bean-创建与刷新完成">第四阶段：Bean 创建与刷新完成</h3><ol start="11"><li>finishBeanFactoryInitialization() —— 实例化所有单例 Bean，调用 getBean()。</li><li>finishRefresh() —— 发布事件，标志容器启动完成。</li></ol><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/JiNawjn2_6mvwnwdo10_mianshiya.png" alt="Spring - 源码分析ioc启动12大步.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/kDUwxukK_Snipaste_2025-11-10_13-18-56_mianshiya.png" alt="Snipaste_2025-11-10_13-18-56.png" width="100%" /><h2 id="Bean和-Component有什么区别？">@Bean和@Component有什么区别？</h2><ul><li>@Bean<strong>作用在方法上</strong>，在configuration类中；</li><li>@Component<strong>作用在类上</strong>，作用于自动扫描</li></ul><h2 id="Component、-Controller、-Repository和-Service-的区别？">@Component、@Controller、@Repository和@Service 的区别？</h2><p>本质上没区别，他们都是@Component的衍生注解，<strong>名字不同是为了区分不同业务场景</strong>。</p><ul><li>@Component：通用注解，用于将任何类标记为 Spring Bean。</li><li>@Controller：特定于 Spring MVC，<strong>处理 Web 层请求</strong>。</li><li>@Service：特定于业务逻辑层，用于<strong>处理服务逻辑</strong>。</li><li>@Repository：特定于持久层，通常用于<strong>数据访问对象</strong>（DAO）。</li></ul><h2 id="Spring中的-Primary注解的作用是什么？">Spring中的@Primary注解的作用是什么？</h2><p>@Primary 注解的作用是:在多个候选Bean存在时,标记一个Bean为默认Bean,Spring 会优先选择它进行注入。</p><h2 id="Spring中的-Value注解的作用是什么？">Spring中的@Value注解的作用是什么？</h2><p>@value的主要作用是用于属性注入<br>1: 为当前注解的字段 设定默认值<br>2: 获取配置文件的配置<br>3、将系统变量和环境变量中的值注入到bean中</p><h2 id="Spring-中的-Profile-注解的作用是什么？">Spring 中的 @Profile 注解的作用是什么？</h2><p>@Profile 用于定义一组 Bean 的配置文件所属的环境，比如 dev,prod</p><h2 id="Spring-中的-RequestBody-和-ResponseBody-注解的作用是什么？">Spring 中的 @RequestBody 和 @ResponseBody 注解的作用是什么？</h2><p>@RequestBody是接受Http的请求，<strong>将前端JSON对象转化为Java对象</strong><br>@ResponseBody是将<strong>Java对象转化为前端的JSON格式，返回给前端</strong></p><h2 id="Spring-中的-PathVariable-注解的作用是什么？">Spring 中的 @PathVariable 注解的作用是什么？</h2><p>@PathVariable：获取URL路径中的参数，如 /users/123。<br>@RequestParam：获取URL地址栏中的参数 ，通常用于处理表单数据或查询参数,如 /users?id=123。</p><h2 id="Spring-MVC-中如何处理异常？">Spring MVC 中如何处理异常？</h2><p>Spring MVC 主要有两种核心异常处理机制：</p><ol><li><p>局部异常处理（@ExceptionHandler）<br>在某个控制器里，用 @ExceptionHandler 注解定义方法来捕获特定异常。<br>它只作用在当前 Controller，可以返回自定义错误信息或 JSON 响应。</p></li><li><p>全局异常处理（@ControllerAdvice + @ExceptionHandler）<br>如果想统一处理所有 Controller 的异常，可以定义一个带 @ControllerAdvice 的类，在里面写带 @ExceptionHandler 的方法。<br>这样就不用在每个控制器重复写异常处理逻辑。</p></li></ol><p>3.自定义异常<br>一般我们还会结合四步最佳实践：</p><ol><li>定义异常枚举类（统一异常码和提示信息）</li><li>定义自定义异常类（继承 RuntimeException）接收枚举参数，记录异常码</li><li>业务中按需抛出自定义异常</li><li>统一用全局异常处理器捕获并返回标准格式的错误响应</li></ol>]]></content>
    
    
    <summary type="html">我对Spring的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="Spring" scheme="https://itgeqian.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>7分钟彻底搞懂Java各种锁</title>
    <link href="https://itgeqian.github.io/posts/65.html"/>
    <id>https://itgeqian.github.io/posts/65.html</id>
    <published>2025-10-14T02:09:03.000Z</published>
    <updated>2025-10-14T03:01:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>原视频地址【【程序员必看】Java各种锁详解：7分钟彻底搞懂Java各种锁！】<a href="https://www.bilibili.com/video/BV1yzs3zQEvD?vd_source=46212c2d164ea5464f361bff483cf8f6">https://www.bilibili.com/video/BV1yzs3zQEvD?vd_source=46212c2d164ea5464f361bff483cf8f6</a></p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-20-1024x411.png" alt="img"></p><h2 id="1-悲观锁vs乐观锁">1.悲观锁vs乐观锁</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-21-1024x673.png" alt="img"></p><p>这一组锁是根据并发冲突的假设不同而进行区分，我们用上厕所来理解</p><p>悲观锁是被害妄想症（总假设会冲突），它就会锁上门再办事（先加锁再操作），java中我们熟悉的synchronized和Reentrantlock就是这种类型，只要一个线程抢到了锁，别的线程就只能阻塞等待，这种锁用在像秒杀减库存这种场景特别合适，虽然有点笨重但胜在绝对安全</p><p>那乐观锁呢，正好相反，它去上厕所，门都不锁，直接推门进去。等办完事出来检查一下，我进来时放的纸巾还是原来的品牌吗。如何还是，说明没人来过，万事大吉。如果被人换了，之前的就是白上了，需要重新再来一次。这个检查并替换的动作就是java中的CAS（Compare-And-Swap），咱们常用的AtomicInterger、AtomicLong这些原子类就是靠的这手绝活，它特别适合更新帖子阅读数这种竞争不太激烈的场景，性能起飞。不过它也有个坑就是经典的ABA问题。就是你女朋友找你分手了，她又找了个新男友，然后又分手了，最后来找你复合，她还是那个她，但中间发生过啥，你还真不知道。想解决也很简单，加个版本号就行，AtomicStampedReference就是干这个的</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-22.png" alt="img"></p><p>口述版本：</p><p><strong>悲观锁</strong>：</p><blockquote><p>悲观锁假设冲突总是会发生，因此每次操作时都加锁，确保没有其他线程干扰。<code>synchronized</code> 和 <code>ReentrantLock</code> 都是悲观锁的实现，适合数据一致性要求高的场景，但性能较低，因为每个线程都需要等待锁释放。</p></blockquote><p><strong>乐观锁</strong>：</p><blockquote><p>乐观锁假设冲突不会发生，线程不加锁，操作前后检查数据是否被修改。如果没被修改，就完成操作；如果被修改，就重新尝试。CAS（Compare-And-Swap）是乐观锁的典型实现，像 <code>AtomicInteger</code> 就是通过 CAS 实现的。适合冲突较少的场景，但存在ABA问题，可以通过版本号来解决。</p></blockquote><h2 id="2-公平锁vs非公平锁">2.公平锁vs非公平锁</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-24-1024x684.png" alt="img"></p><p>这一组是根据排队的规矩来分的，公平锁就像银行叫号，主打的就是先来先到，非公平锁就像路边招手打车，谁快谁上。</p><p>公平锁的优点：童叟无欺，确保每个线程都有出头之日，但是坏处也很明显，银行叫号中一个老太太办业务又慢又麻烦，其他人也只能在那之后乖乖等着，队伍不长才怪（吞吐量低），常用的ReentrantLock可以添加一个布尔型的参数true就表示采用的公平锁</p><p>非公平锁的优点：就像路边打车他才不管有没有人排队，谁动作快抢到了车谁就上，这么做的好处很明显，相比于公平锁省去了叫号、线程唤醒的麻烦，整个系统吞吐量一下就上去了，而锁的最大敌人就是吞吐量，所以ReentrantLock默认就是非公平锁，同样的synchronized也是默认非公平锁，因此除非你的业务有严格的先后顺序要求，否则就用默认的非公平锁，因为它更快</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-25.png" alt="img"></p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-26.png" alt="img"></p><p>口述版本：</p><p><strong>公平锁</strong>：</p><blockquote><p>公平锁保证线程按照请求锁的顺序来获取锁，先来先得。一个典型的例子就是 <code>ReentrantLock(true)</code>，它通过队列来保证每个线程都能公平地获取锁。适合需要严格控制线程获取顺序的场景，但性能相对较低，因为线程管理开销较大。</p></blockquote><p><strong>非公平锁</strong>：</p><p>非公平锁允许线程在竞争时插队，后到的线程有可能抢到锁。<code>ReentrantLock</code> 默认就是非公平锁，性能较高，因为不需要维护严格的线程顺序。适合高并发、吞吐量要求高的场景，但有可能导致某些线程长时间无法获取锁（线程饥饿）。</p><h2 id="3-排他锁vs共享锁">3.排他锁vs共享锁</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-27-1024x698.png" alt="img"></p><p>排他锁和共享锁，它们的核心区别就是是否允许有线程并发。</p><p>排他锁（写锁）顾名思义就是排斥他人，它就像你去KTV的包间，你一个人进去了，不管你在里面唱歌跳舞还是睡觉，反正门一关谁也别想进来。在系统当中这就是独占锁，一个线程把资源占住了，其他的读写操作全部排斥，都只能乖乖等着，synchronized和ReentrantLock都是这种锁</p><p>但有时候我们不需要这么霸道，比如大家一起看报纸，这就是一种不影响报纸内容的读操作，多少人看都无所谓这就是共享锁（读锁），一个线程占住了读锁其他线程也可以同样拿到读锁，这就是读读并发，但是这个时候如果想要在报纸上涂鸦，这就变成了改变报纸内容的写操作了，他必须得所有看书的人都走了才行，而且他涂鸦的时候谁都不能看。java你想实现共享锁也很容易，可以用ReentrantReadWriteLock，这个强大的工具，它里面就同时维护了读锁和写锁，在读多写少的场景，更多的是使用读锁，能让并发性能原地起飞，这对于性能调优非常的重要</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-29-779x1024.png" alt="img"></p><table><thead><tr><th>对比项</th><th>排他锁（写锁）</th><th>共享锁（读锁）</th></tr></thead><tbody><tr><td>并发性</td><td>只允许一个线程持有</td><td>可允许多个线程同时读取</td></tr><tr><td>是否阻塞</td><td>阻塞其他读写线程</td><td>仅阻塞写线程，不阻塞其他读线程</td></tr><tr><td>性能表现</td><td>并发度低</td><td>并发度高，适合读多写少场景</td></tr><tr><td>Java 实现</td><td><code>synchronized</code>、<code>ReentrantLock</code></td><td><code>ReentrantReadWriteLock.readLock()</code></td></tr><tr><td>应用场景</td><td>秒杀扣库存、数据修改</td><td>配置读取、缓存访问</td></tr></tbody></table><p>补充：</p><ul><li><code>ReentrantReadWriteLock</code> 内部使用 <strong>AQS（AbstractQueuedSynchronizer）</strong> 来实现不同模式的同步控制。</li><li>在实际开发中，<strong>读多写少的业务逻辑</strong>（如缓存读取、系统配置查询）使用共享锁可以显著提升系统吞吐量。</li><li>而在<strong>写操作频繁或强一致性要求高</strong>的场景（如订单状态更新），则更适合使用排他锁。</li></ul><p>精简版口述答案：排他锁（写锁）是独占的，一个线程获取后其他线程不能再访问，典型实现是 <code>synchronized</code> 和 <code>ReentrantLock</code>；<br>共享锁（读锁）允许多个线程同时读取，但写线程必须等待所有读线程释放锁才能写，<code>ReentrantReadWriteLock</code> 就是典型实现。<br>简单来说，写锁防冲突，读锁提性能，读多写少时用读写锁效果最佳。</p><h2 id="4-可重入锁">4.可重入锁</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-28-1024x848.png" alt="img"></p><p>可重入锁表示同一线程是否可以重复持有自己的锁，这个非常重要因为java中天天用的这个<code>Reentrant</code>它的意思就是可重入的意思，啥叫可重入呢？就是你拿你的钥匙打开了大门进屋了，然后发现你的卧室门也需要同一把钥匙打开，这时候你不需要去找其他钥匙，直接用手里的钥匙去开卧室门。一个线程拿到锁以后，就可以反复进入这个锁保护的代码块而不会被自己锁住，<code>synchronized</code>、<code>ReentrantLock</code>都是可重入的，它们内部有个计数器，你每进去一层就+1出去一层就-1，直到计数器变成0，才算真正把锁还回去。</p><p>要是锁是不可重入的，那你进入大门想再开卧室门的时候，发现钥匙已经被大门锁占住了，结果自己把自己锁死在了客厅</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-31.png" alt="img"></p><p>口述版本：</p><p><strong>可重入锁</strong>：</p><p>可重入锁允许一个线程多次获取自己已经持有的锁，而不会导致死锁。它通过内部计数器来实现，每进入一次锁，计数器加 1，退出一次减 1，直到计数器为 0 锁才被释放。</p><p><strong>举个例子</strong>：你有一把钥匙（锁），先打开大门（获取锁），再用同一把钥匙打开卧室门（再次进入锁保护的区域），不需要重新找钥匙。</p><p><strong>Java 实现</strong>：<code>synchronized</code> 和 <code>ReentrantLock</code> 都是可重入锁，<code>ReentrantLock</code> 通过计数器管理锁的重入。</p><h2 id="5-synchronized的智能升级">5.<code>synchronized</code>的智能升级</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-30-1024x516.png" alt="img"></p><p>核心维度：根据“竞争激烈程度”自动优化锁状态，实现了强大的自动升级功能</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-32.png" alt="img"></p><p>我们以一个小故事来讲清楚偏向锁-&gt;轻量级锁-&gt;重量级锁的演化过程</p><p>你们公司有一台<strong>共享打印机</strong>（表示<strong>临界资源</strong>），程序员小王和其他同事每天都要用它打印资料。为了不冲突，公司安排了三种打印控制机制来「优化效率」，正好对应 JVM 中的三种锁状态。</p><p>锁优化三种形态对比类比</p><table><thead><tr><th>JVM 锁类型</th><th>类比打印控制机制</th><th>特点</th></tr></thead><tbody><tr><td>偏向锁（Biased）</td><td><strong>打印机记住上一个用户是谁</strong> 如果是同一个人再次使用，<strong>不做任何检查</strong>，直接打印</td><td>无竞争时性能最好（零开销）</td></tr><tr><td>轻量级锁（Lightweight）</td><td>多人要打印，先<strong>排队轮询查看是否空闲</strong>，只要打印机还没结束上一个人的工作，就<strong>自旋等待</strong>几次</td><td>低冲突下仍能保持高性能（无阻塞）</td></tr><tr><td>重量级锁（Heavyweight）</td><td>冲突太多了，打印任务就被<strong>挂起 / 唤醒</strong>，由操作系统调度谁先打印</td><td>冲突激烈时保障正确性，但性能最差</td></tr></tbody></table><hr><p>场景详解</p><p>偏向锁（Biased Lock）</p><ul><li>小王是第一个用打印机的人</li><li>打印机会<strong>记住小王的身份</strong></li><li>后面只要小王再次来打印，打印机就<strong>直接开工，不检查排队系统</strong>，因为它 “偏向” 小王</li></ul><blockquote><p>就像对象 MarkWord 中记录了某个线程的 ID，只有当其他线程来竞争才撤销偏向锁</p></blockquote><hr><p>轻量级锁（Lightweight Lock）</p><ul><li>小王打印时，小李也来了</li><li>打印机会说：“先别挂起，等等看小王是不是很快结束”</li><li>小李就在打印机旁边 “<strong>自旋等待</strong>”</li><li>如果小王很快结束了，小李就立即上，<strong>没有阻塞、也没有上下文切换</strong></li></ul><blockquote><p>自旋锁本质：用 CPU 忙等来换取线程不挂起</p></blockquote><hr><p>重量级锁（Heavyweight Lock）</p><ul><li>现在来了十几个人都要打印，等太久了</li><li>打印机会说：“别等了，我排个队号，通知你们一个个来”</li><li>系统就开始用 <strong>阻塞 → 唤醒 → 再阻塞</strong>的方式调度线程</li></ul><blockquote><p>操作系统介入调度，线程切换代价高，效率最低</p></blockquote><hr><p>最后总结：</p><table><thead><tr><th>情况</th><th>JVM 锁</th><th>打印类比</th><th>特点</th></tr></thead><tbody><tr><td>单线程使用资源</td><td>偏向锁</td><td>打印机只认上一次的使用者</td><td>零开销，最快</td></tr><tr><td>少量线程争用</td><td>轻量级锁</td><td>排队观察是否释放</td><td>快速尝试获取锁</td></tr><tr><td>多线程激烈争用</td><td>重量级锁</td><td>线程挂起等待系统调度</td><td>安全但慢</td></tr></tbody></table><p>补充：Java为了提升<code>synchronized</code>的性能，其实自己也在不断优化，JDK17取消了偏向锁，锁升级变得更加的顺滑</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-34.png" alt="img"></p><p>口述版本：</p><p><strong>synchronized的智能升级</strong>：</p><p><code>synchronized</code> 锁会根据线程竞争的情况自动升级，从而优化性能：</p><ol><li><strong>偏向锁（Biased Lock）</strong>：<br>当没有线程竞争时，偏向锁会让同一线程重复获取锁时几乎没有开销。就像打印机记住了上一个用户，下一次他直接使用，不用排队。</li><li><strong>轻量级锁（Lightweight Lock）</strong>：<br>当有少量线程竞争时，轻量级锁通过自旋等待的方式减少阻塞，性能较高。类似于多个用户排队等待打印机，只有前一个操作完成才能继续。</li><li><strong>重量级锁（Heavyweight Lock）</strong>：<br>当线程竞争激烈时，使用重量级锁，操作系统介入调度线程，代价较高。就像多人争抢打印机时，需要挂起线程排队等候。</li></ol><p><strong>总结</strong>：</p><ul><li><strong>偏向锁</strong>：适用于没有竞争的场景，零开销。</li><li><strong>轻量级锁</strong>：适用于竞争较少的场景，高效但不阻塞。</li><li><strong>重量级锁</strong>：适用于激烈竞争的场景，但性能最差。</li></ul><p>JDK17去掉了偏向锁，使锁的升级过程更加顺畅。</p><h2 id="总结">总结</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-33-1024x529.png" alt="img"></p>]]></content>
    
    
    <summary type="html">7分钟彻底搞懂Java各种锁，全程干货无废话</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="java面试题" scheme="https://itgeqian.github.io/tags/java%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>7分钟速通mysql的核心面试题</title>
    <link href="https://itgeqian.github.io/posts/64.html"/>
    <id>https://itgeqian.github.io/posts/64.html</id>
    <published>2025-10-14T02:09:03.000Z</published>
    <updated>2025-10-14T03:01:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>原视频地址：<a href="https://www.bilibili.com/video/BV1asx6zUEge/?spm_id_from=333.1007.top_right_bar_window_default_collection.content.click&amp;vd_source=95e42b15b90c31bd4e580b92f2c79b91">【程序员必看】MySQL各种锁详解：7分钟彻底搞懂MySQL的各种锁_哔哩哔哩_bilibili</a></p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-12-1024x496.png" alt="img"></p><p>首先要有大局观，比如你要锁东西是把整栋楼锁住还是只锁一个房间，或者干脆只锁一个抽屉呢，这就是锁的粒度，也就是锁的范围大小，在MYSQL中锁的粒度如下</p><h2 id="MYSQL锁的粒度">MYSQL锁的粒度</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-13-1024x512.png" alt="img"></p><ul><li>全局锁：锁住整个数据库（相当于给整个大楼给封了），一个命令下来整个库谁也别想写数据，<ul><li>作用：显而易见用于全库备份时使用，全库备份需要保证数据一动不动，这就是全局锁的作用了</li></ul></li><li>表锁：锁住整张表（相当于锁一个房间），像老一点的MyISAM引擎默认就是表锁。<ul><li>好处：简单直接，开销小</li><li>坏处：只要有一个人在房间操作其他所有人都要在门口排队，即并发差</li></ul></li><li>行锁：锁住当行数据（相当于只锁一个抽屉），这也是目前InnoDB用的<ul><li>好处：并发高，你给你的数据我改我的数据只要不是同一行数据咱两就互不影响</li><li>坏处：开销大（管一堆钥匙，要比只管大门钥匙要麻烦很多），可能死锁（你拿着我的钥匙我拿着你的钥匙两人就卡着不动了）</li></ul></li></ul><h2 id="MYSQL锁的派别">MYSQL锁的派别</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-14-1024x583.png" alt="img"></p><ul><li>悲观锁：它认为只要我改数据肯定就有人给我抢，所以它在干活前就用select…for update语句来锁住把数据锁的死死的，谁也别想动<ul><li>场景:用在秒杀，抢库存这一类高并发的场景中（写多读少），并发写操作多，冲突概率极大必须先下手为强</li></ul></li><li>乐观锁：它是乐天派，认为改数据时没那么多人跟我抢，所以它不加锁，直接去操作数据，只在最后要提交的时候，用版本号或者时间戳来比对一下，看看我干活的这期间有没有人都过我的数据，如果有人改了，这次提交就失败<ul><li>场景：适合像改文章，改商品信息这一类读多写少的场景，因为它省去了加锁的开销，性能就会好很多</li></ul></li></ul><h2 id="MYSQL中锁自带的两种基本类型">MYSQL中锁自带的两种基本类型</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-15-1024x600.png" alt="img"></p><p>相当于在图书馆看书时</p><p>共享锁（S锁/读锁）：它就等于大家一起看书，一本书可以被很多人同时看，只要大家不在上面写字就行，即读读共享，读写互斥，在mysql中可以用lock in share mode这个语句加的就是一个读锁</p><p>排他锁（X锁/写锁）：当我要改书的时候必须要把这本书拿走，自己一个人改，在你改完还回来之前，别人既不能看也不能改，即写写互斥，读写互斥，在mysql中可以用for update这个语句加的就是一个读锁</p><h2 id="MYSQL中意向锁（Intention-Lock）">MYSQL中意向锁（Intention Lock）</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-16-1024x398.png" alt="img"></p><p>但它想成一个挂在表门口的通知牌，它的作用就是为了提高效率，如果事务A锁了表里面的某一行数据，这个时候事务B它想要给整个表加一个锁，那MYSQL咋办呢，难道一行一行去检查有没有行锁吗，那表里面如果有上千万行数据查到猴年马月去，这数据库直接就会被卡死，所以InnoDB就设计了这个通知牌，当事务A给某一行加锁的时候，InnoDB会自动在这个表的门口上面挂个牌子，上面写着里面有人正在操作请注意，这样当事务B想来锁整张表的时候抬头一看这张表的门口上有个牌子，立刻就知道里面有行锁，有冲突，自己得等着，效率一下就上来了，所以意向锁本身它是一个表级锁，但它不是用来锁数据的，而是用来打配合提高效率的，</p><p>有了意向锁这个帮手我们再来看看InnoDB真正在一线干活的几个核心武器</p><h2 id="MYSQL中记录锁（Record-Lock）">MYSQL中记录锁（Record Lock）</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-17-1024x327.png" alt="img"></p><p>第一个记录锁，记录锁这就是最纯粹的行锁，指哪打哪，只锁定你查询命中的那一条记录，比如能用注解where id = 10去更新，那他就只锁ID等于10这一行，这是我们最希望看到的最理想的情况</p><p>但是如果查询条件不是唯一的呢，比如查age&gt;18这样的范围，这时候面试必考的知识点就来了-<strong>幻读</strong></p><p>为了解决幻读InnoDB就掏出来他的大杀器间隙锁&amp;临键锁</p><h2 id="MYSQL中的间隙锁-临键锁">MYSQL中的间隙锁&amp;临键锁</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-18-1024x361.png" alt="img"></p><p>间隙锁它不锁任何已经存在的数据，就是一个开区间，它只是锁住记录和记录之间的那个缝，比如说索引里面有10和20，那他就锁住10-20这一个区间，让你没法在这个缝隙里面插入新的数据，它就像给数据之间放了个结界，任何新的换的数据都不允许冒出来。</p><p>而临键锁呢，他就是记录锁+间隙锁，它不但锁住记录本身，还把这条记录前面的那个缝也锁住了，这才是InnoDB在可重复读隔离级别下默认使用的锁，它就像一张大网，把记录和它旁边的缝全给罩住，让幻读无处遁形</p><h2 id="所以说为什么有了MVCC还需要锁来防止幻读呢">所以说为什么有了MVCC还需要锁来防止幻读呢</h2><p>MVCC保证了你读的时候看不到幻影，而临键锁保证了在别人写的时候造不出幻影，一个防读，一个防写</p><p>详细的解释：</p><hr><h3 id="🌱-背景：MVCC-与-幻读">🌱 背景：MVCC 与 幻读</h3><p>在 MySQL 的 <strong>可重复读（REPEATABLE READ）</strong> 隔离级别中，主要通过 <strong>MVCC（多版本并发控制）</strong> 来解决「脏读」和「不可重复读」问题。</p><ul><li><strong>MVCC 的核心思想</strong> 是：每个事务在开始时，会看到一个“快照”（Snapshot）——也就是数据库在那个时间点上的一致性视图。</li><li>因此，当事务读取时，不管其他事务后来插入/修改了什么，它都<strong>不会看到新数据</strong>（这是 MVCC 的作用）。</li></ul><p>但是：<br>MVCC 只能保证<strong>读到的内容一致</strong>，却<strong>不能防止别的事务在你读的同时插入新的记录</strong>。这就导致了“幻读”的问题。</p><hr><h3 id="🧩-幻读（Phantom-Read）">🧩 幻读（Phantom Read）</h3><p>假设事务 A 执行：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> users <span class="keyword">WHERE</span> age &gt; <span class="number">20</span>;</span><br></pre></td></tr></table></figure><p>此时事务 B 在事务 A 未提交期间执行：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO <span class="built_in">users</span>(age) <span class="built_in">VALUES</span>(<span class="number">25</span>);</span><br></pre></td></tr></table></figure><p>那么事务 A <strong>再次执行相同的 SELECT</strong> 时，会发现多了一行——这就是“幻影行”，即<strong>幻读</strong>。</p><hr><h3 id="🔒-那为什么-MVCC-不够？">🔒 那为什么 MVCC 不够？</h3><p>MVCC 只解决了“读一致性”的问题，它的作用是：</p><blockquote><p>“你在读时，看不到别人已经提交的新数据。”</p></blockquote><p>但它<strong>不能阻止别人去插入新行</strong>。换句话说：</p><ul><li>你读时，看不到幻影（MVCC 起作用）；</li><li>但别人写时，可能造出幻影（MVCC 无法阻止）。</li></ul><p>所以当你要防止别人“造幻影”时，必须依赖 <strong>锁（尤其是 Next-Key Lock 临键锁）</strong>。</p><hr><h3 id="⚙️-临键锁（Next-Key-Lock）的作用">⚙️ 临键锁（Next-Key Lock）的作用</h3><p>在 InnoDB 中，<strong>Next-Key Lock = 行锁 + 间隙锁</strong>。<br>它不只锁住已有的行，还锁住这些行之间的间隙（gap），从而阻止别的事务往这些间隙插入新行。</p><blockquote><p>举例：</p><p>如果表中有 <code>age = 18, 25, 30</code> 三行，<br>那么查询 <code>age &gt; 20</code> 时，InnoDB 可能会锁住区间 <code>(20, 30)</code>，<br>这使得别人无法在 20~30 之间插入新数据。</p></blockquote><hr><h3 id="🧠-理解那句话：">🧠 理解那句话：</h3><blockquote><p>“MVCC 保证了你读的时候看不到幻影，而临键锁保证了在别人写的时候造不出幻影，一个防读，一个防写。”</p></blockquote><p>意思是：</p><ul><li><strong>MVCC</strong>：让你在读时看到的世界是稳定的，不会因为别的事务插入/修改而“看见幻影”；</li><li><strong>临键锁（Next-Key Lock）</strong>：防止别人在你事务期间插入“幻影行”，即从“写的角度”避免幻读的出现。</li></ul><p>换句话说：</p><ul><li>MVCC 是 <strong>“读一致性”</strong> 的机制；</li><li>锁是 <strong>“写互斥”</strong> 的机制；<br>两者配合，才能在高并发下既读得快又能保证事务隔离性。</li></ul><hr><h3 id="✅-小结类比">✅ 小结类比</h3><table><thead><tr><th>机制</th><th>防止什么</th><th>方式</th><th>说明</th></tr></thead><tbody><tr><td>MVCC</td><td>读到幻影（读时不一致）</td><td>读快照</td><td>“别人改了也不影响我现在看的”</td></tr><tr><td>临键锁</td><td>别人造幻影（写时插入）</td><td>锁定间隙</td><td>“别人不能在我查过的范围插入新行”</td></tr></tbody></table><hr><h2 id="总结">总结</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-19-1024x403.png" alt="img"></p><p>总结;锁这个东西从来没有绝对的好与坏，全局锁虽然暴力，但是在备份的时候离不开它，行锁虽然精细，但你得承担死锁的风险，临键锁虽然能解决幻读，但它也可能锁住没有必要的范围，牺牲了一些性能</p>]]></content>
    
    
    <summary type="html">7分钟速通mysql的核心面试题，全程干货无废话</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="mysql面试题" scheme="https://itgeqian.github.io/tags/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>7分钟速通RocketMQ的核心面试题</title>
    <link href="https://itgeqian.github.io/posts/63.html"/>
    <id>https://itgeqian.github.io/posts/63.html</id>
    <published>2025-10-14T02:09:03.000Z</published>
    <updated>2025-10-14T03:01:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>原视频地址：<a href="https://www.bilibili.com/video/BV1pXnwz7EGY/?spm_id_from=333.1387.favlist.content.click&amp;vd_source=95e42b15b90c31bd4e580b92f2c79b91">程序员必看：7分钟一次性讲透RocketMQ核心面试题，全程干货无废话，吊打面试官！_哔哩哔哩_bilibili</a></p><h2 id="第一问：什么是消息队列？有什么用？">第一问：什么是消息队列？有什么用？</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-3-1024x697.png" alt="img"></p><p>我们先从一个场景开始，服务A需要远程调用服务B的服务，但A服务每秒发送两百个请求，但B服务每秒只能处理一百个请求，那么B服务就会分分钟被压垮，怎么办呢，那就在中间加一层中间件-消息队列，A是生产者，负责发送消息，B是消费者，负责处理消息。生产者发送的消息在消息队列中排队，并且给它分配一个编号，消费者按照自己的速度从消息队列中拉取消息来进行消费，并且记录自己的处理进度，称为offset偏移量，有了中间的消息队列作为缓冲，那B服务就可以按照自己的速度来处理消息，这样一个基础的消息队列就成型了。</p><h2 id="第二问：如何扩展性能？">第二问：如何扩展性能？</h2><p>但这是一个简陋的消息队列，当消费者多了，怎么提升性能，机器挂了数据丢了怎么办？</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-4-1024x692.png" alt="img"></p><p>第一步处理性能瓶颈，B处理不过来，消息会产生堆积。我们就找多个业务逻辑相同的B组成一个消费者组ConsumerGroup大家一起干，那问题来了，所有人都在抢一个队列，还是会有性能瓶颈，解决分案就是给消息进行分类，就是Topic，一个Topic再分成多个实际存储消息的message queue，生产者指定Topic发送消息，消息会尽量均匀地写入到不同的message queue队列中，每个队列再去分配给消费者组当中的某一个消费者进行消费，这样呢每个message queue的消费进度互不干涉，自然就能分工协作了，就好比超市结账原本一个收银台，现在开了多个，效率就快很多了</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-5-1024x542.png" alt="img"></p><p>然后在消息队列的服务端分别记录每个message queue上消息写入的进度，称为代理者位点，还有每个消费者组的消费进度，称为消费者位点，这样就能够有效的监控每个message queue上的消息的消费进度了，RocketMQ就是通过这些位点来监控消息的处理进度，如果发现了消息的堆积，也可以通过这些位点数据快速的分析出来</p><h2 id="第三问：如果所有的message-queue队列都在一台机器上，那消息一多磁盘不就爆了吗">第三问：如果所有的message queue队列都在一台机器上，那消息一多磁盘不就爆了吗</h2><p>没错！所以我们要搞broker集群实现水平扩展，由于每个message queue都是在单独管理自己的数据和位点，我们可以把一个Topic下的多个message queue尽量均匀的分配到不同的broker上，这样就可以减少每一个服务端的读写压力。</p><h2 id="第四问：如何保证高可用？">第四问：如何保证高可用？</h2><p>第二步，来解决高可用问题</p><p>如果一个broker挂了，那么上面的数据就全都没了，高可用怎么谈呢？</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-6-1024x706.png" alt="img"></p><p>这就涉及到RocketMQ的主从架构了，在RocketMQ中每个主的broker称为master，从的broker称为slave，master节点负责干活，实际处理客户端读写消息的请求，slave只负责一件事，拼命同步master的数据，当master挂了之后，slave立刻顶上变成新的master，这样就保证了服务不中断</p><h2 id="第五问：那生产者怎么知道我的消息要发送到哪个broker呢？消费者又从哪里去拉取消息呢？如果broker挂了主从发生了切换它们怎么知道呢？">第五问：那生产者怎么知道我的消息要发送到哪个broker呢？消费者又从哪里去拉取消息呢？如果broker挂了主从发生了切换它们怎么知道呢？</h2><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-7-1024x793.png" alt="img"></p><p>这个问题涉及到了集群的大脑，在RocketMQ中这个大脑就是自主设计的NameServer，NameServer就是RocketMQ的注册中心，它极其轻量但干着非常重要的工作，第一管户口，所有的broker都需要向NameServer报到，并且通过心跳告诉NameServer，它是不是还活着。第二管地图，NameServer手中有张完美的路由信息表，就知道每个topic的队列在哪些机器上。第三当向导，生产者和消费者都要问它要地图，然后才能找到正确的broker通道，接下来进行后续的消息通讯。为了保证向导自己不出事，NameServer自己也是得做集群部署的</p><h2 id="第六问：RocketMQ为什么要自主设计一个NameServer，而不用其他现成的注册中心zookeeper，nacos？">第六问：RocketMQ为什么要自主设计一个NameServer，而不用其他现成的注册中心zookeeper，nacos？</h2><p>这个问题直击RocketMQ的设计核心，因为RocketMQ的核心是金融，电商这类非常灵活的业务场景服务的，这使得RocketMQ的整个设计思想和Kafka这样追求极致的吞吐的消息中间件有根本的区别，在保证高性能的同时，对于服务的可靠性也要做到极致。一方面NameServer采用一种极为轻量级的集群方案，每个NameServer节点之间不需要和集群当中的其他节点发生任何的数据交互，这样可以保证NameServer集群当中只要有任何一个节点正常工作，那么整个NameServer集群就能够保持正常。另一方面，业务的频繁更迭，使得RocketMQ也需要及时进行升级，自主研发的NameServer可以更灵活的应对新的业务场景</p><p>其他面试题</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-8-1024x198.png" alt="img"></p><p>例如面试官常问，RocketMQ为什么要设计生产者组呢？而Kafka中却不需要呢</p><p>这本质上还是因为RocketMQ的核心是为金融，电商这类严肃的业务场景服务的，而Kafka的核心则是为了分布式日志这一类对吞吐量要求极高的业务场景服务的，在RocketMQ的业务场景下，事务消息是刚需，比如下单这个操作就要保证生产者本地的创建订单和基于RocketMQ发送的扣减库存的消息要么都处理成功要么都失败，不允许有中间状态。RocketMQ中的broker在处理这类事务时就需要反向来检查生产者的状态，这时生产者组的作用就来了，它会告诉broker我们是同一个业务的，你随便向我们组里的任何一个人问，都能知道这个事务最终是成功还是失败，如果某一个生产者实例挂了，broker可以通过回查同一个生产者组内的其他实例，来确定事务的最终状态，这就是RocketMQ为了保证业务万无一失做的独特设计</p><p>其他常见的高阶面试题：</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-9-1024x475.png" alt="img"></p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-10-1024x325.png" alt="img"></p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-11-1024x231.png" alt="img"></p>]]></content>
    
    
    <summary type="html">7分钟速通RocketMQ的核心面试题，全程干货无废话</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="RocketMQ面试题" scheme="https://itgeqian.github.io/tags/RocketMQ%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Redis分布式锁的理解</title>
    <link href="https://itgeqian.github.io/posts/66.html"/>
    <id>https://itgeqian.github.io/posts/66.html</id>
    <published>2025-10-14T02:09:03.000Z</published>
    <updated>2025-10-14T03:01:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>背景：小徐是一个程序员，他开发了一个秒杀功能，但出现了超卖问题。</p><ul><li>超卖问题的出现：多线程并发环境下，如果同时对一个共享资源进行读写，数据会出现错乱的问题</li></ul><p>这一次他加了一个同步锁 synchronized，这次终于不会超卖了，那我们都知道当多线程并发情况下我们加了同步锁，在同一时刻保证只有一个线程能拿到锁，其他进程进来会进行一个互斥，需要排队等待需要等持有锁线程处理完释放锁</p><p>但是随着用户量越来越多小徐发现服务器压力越来越大，性能达到了瓶颈，于是小徐通过nginx进行了负载均衡，他将服务器进行了水平扩展，通过nginx进行了分布式集群部署，但是测试时吞吐量确实上来了，但是秒杀功能又出现了超卖问题，经过发现原来是同步锁的问题，<strong>因为同步锁它是JVM级别的，它只能锁住单个进程，但是经过分布式部署之后呢，每台服务器在并发的情况下只能锁住一个线程</strong></p><p>所以要解决这个问题我们就要用到分布式锁，分布式锁，顾名思义，<strong>分布式锁就是分布式场景下的锁，比如多台不同服务器上的进程，去竞争同一项资源，就是分布式锁。</strong></p><p>主流的分布式锁的解决方案有Redis和zookeeper</p><p>这里我们主要讲解Redis的分布式锁</p><h3 id="1-我们先实现一个最简单的分布式锁">1.我们先实现一个最简单的分布式锁</h3><p>直接用Redis的setnx命令，这个命令的语法是：setnx key value如果key不存在，则会将key设置为value，并返回1；如果key存在，不会有任务影响，返回0。</p><p>基于这个特性，我们就可以用setnx实现加锁的目的：通过setnx加锁，加锁之后其他服务无法加锁，用完之后，再通过delete解锁。</p><p>但是一定要加过期时间，<strong>因为如果用户在请求的过程中，服务器挂了，那么其他的服务器正常请求时，就会出现一个阻塞的情况</strong>，因为其他服务器的线程通过setnx进行上锁的时候，发现这个键里面一直有值，就会永远不会上锁成功，之前挂掉的服务器它一直持有锁从而造成了一个死锁的现象，所以此时我们要加上一个过期时间进行兜底，经过这个时间后锁就会自动释放，从而不影响其他服务器的正常请求</p><h3 id="二个问题的解决（锁续期与锁误删）以及Lua脚本">二个问题的解决（锁续期与锁误删）以及Lua脚本</h3><p>虽然业务的扩展，我们又发现了问题，<strong>当业务（线程1）的处理时间超过了这把锁的过期时间时，此时业务还没有处理完，锁就释放掉了</strong>，其他的线程（线程2）就会趁虚而入，线程1处理完业务后，回来释放锁，此时释放的就是线程2的锁，而其他的线程此时又会趁虚而入，以此类推。<strong>总结下来就是有两个问题：</strong></p><ul><li><strong>锁过期时线程还在处理业务当中</strong></li><li><strong>存在线程1释放掉线程2的锁，即锁误删现象</strong>（<strong>分布式锁需要满足谁申请谁释放原则，不能释放别人的锁，也就是说，分布式锁，是要有归属的</strong>。）</li></ul><p>我们先来解决第一个问题-锁过期时线程还在处理业务当中怎么办呢</p><ul><li>我们可以加长锁的一个过期时间，并且我们还需要考虑到如果我加长的这个时间还是不够怎么办呢，我们增加一个兜底的方案，在业务代码当中我们添加一个子线程，每10秒去确认主线程是不是在线，如果在线则将过期时间重置，也就是将锁续期</li></ul><p>我们再来解决第二个问题-锁误删现象怎么解决</p><ul><li>就是我们给锁增加一个唯一ID（UUID），这样就能保证每一把锁的它的KEY是绑定的自己的那一个线程，从而业务执行完毕后会先检查锁是不是自己的，最后进行释放。就不会释放其他线程的锁</li></ul><h4 id="Lua脚本">Lua脚本</h4><p>也就是说我们完整的流程是竞争者获取锁执行任务，执行完毕后检查锁是不是自己的，最后进行释放。但是执行完毕后，检查锁，再释放，这些操作如何保证它是原子化的操作呢？Redis还有个特性，专门整合原子操作，就是Lua脚本。</p><p>Lua脚本可以保证原子性，因为Redis会将Lua脚本封装成一个单独的事务，而这个单独的事务会在Redis客户端运行时，由Redis服务器自行处理并完成整个事务，如果在这个进程中有其他客户端请求的时候，Redis将会把它暂存起来，等到 Lua 脚本处理完毕后，才会再把被暂存的请求恢复。</p><p>但是我们发现如果我们自己实现锁误删和锁续期这些代码非常的麻烦，还要保证它的一个健壮性，所以Redis有没有提供相关的组件来完成这些功能呢，有的兄弟有的，这就是Redisson</p><h3 id="Redisson原理">Redisson原理</h3><p>Redis提供了一个Redisson完成我们刚刚说到的功能，实现起来也非常的简单，只要添加Redisson相关的一个依赖，把Redisson的客户端自动装配起来通过lock.lock（）就可以实现Redisson的分布式锁</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/11/image-20251103140343453-1024x624.png" alt="img"></p><p>我们来说说Redisson的原理是什么，同样的多个线程请求同一资源，当然只有一个线程才能获取这把锁，比如线程1获取到了这把锁，它的key呢就如我们刚刚所说，它用的是UUID+线程ID合并起来保证我们的key和当前线程绑定在一起，这样就不会出现锁误删的问题，当线程1获取锁成功去处理业务的时候，它内部会有一个看门狗机制，它呢会每隔10秒看一下当前线程是否还持有锁，如果持有的话就延长生存时间，从而给这把锁续命。如果我们实现了Redis的集群呢，它就会选择Redis当中的某一个集群</p><p>那如果没有获取到锁的话，线程就会不停的自旋尝试获取锁只到超时为止</p><p>以上就是Redisson的实现原理</p><h4 id="红锁的实现">红锁的实现</h4><p>在Redis中如果使用了主从集群的一个模式，因为Redis采用的是AP模式，也就是<strong>它只能保证这个高可用和高性能，但是不能保证高一致性</strong>，当我们设置一个锁的时候它其实只会往一个节点去设置一个锁，设置完了就会立马告诉你设置成功，然后内部进行主从同步，<strong>如果我们把这个key设置到了主节点，我们主从同步的时候正好主节点挂了，从节点并没有同步到这把锁</strong>，<strong>导致新的主节点也没有同步过来锁信息，客户端可能重新获取新的主节点的锁，出现了多客户端同时持锁，导致数据不一致的问题</strong>。（<strong>主从异步复制+主从切换可能出现“旧主没释放锁，新主也没这把锁”的锁丢失/多客户端同时持锁问题。</strong>）这个时候应该怎么做呢</p><p>其实Redis也提供了相应的解决方法，那就是红锁RedLock，Redlock 是 Redis 官方提出的分布式锁算法，<strong>通过在N个（通常为5）相互独立的 master 上同时加锁，并且拿到多数派的锁(≥ N/2+1) 才算成功</strong>，来提升锁的安全性和可用性。<strong>如果没有RedLock就如我们刚刚所说，我们往一个主节点去设置一个锁，设置完了就会立马响应设置成功，而不去管从节点是否完成了同步，我们使用了RedLock，它要保证你提供的多数派节点（5个主节点，其中要5/2+1,即4个）都存储完毕了，它才会给你响应设置完成，来提升锁的安全性和可用性</strong></p>]]></content>
    
    
    <summary type="html">Redis分布式锁的理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="Redis面试题" scheme="https://itgeqian.github.io/tags/Redis%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>SpringCloud的相关面试题</title>
    <link href="https://itgeqian.github.io/posts/80.html"/>
    <id>https://itgeqian.github.io/posts/80.html</id>
    <published>2025-10-13T00:19:03.000Z</published>
    <updated>2025-10-15T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-SpringCloud">GQ SpringCloud</h1><h2 id="什么是配置中心？有哪些常见的配置中心？">什么是配置中心？有哪些常见的配置中心？</h2><p>每⼀个服务最终都有⼤量的配置，并且每个服务都可能部署在多台机器上。我们经常需要变更配置，我们可以让每个服务在配置中⼼获取⾃⼰的配置。<br>配置中⼼<strong>⽤来集中管理微服务的配置信息</strong>，常用的有nacos和zookeeper</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Tx0sOq2f_Snipaste_2025-11-10_20-55-50_mianshiya.png" alt="Snipaste_2025-11-10_20-55-50.png" width="100%" /><h2 id="为什么需要服务注册发现？">为什么需要服务注册发现？</h2><ul><li>A 服务调⽤ B 服务，A 服务并不知道 B 服务当前在哪⼏台服务器有，哪些正常的，哪些服务已经下线。解决这个问题可以引⼊注册中⼼</li><li>注册中⼼中在远程调用之前，需要发现对方在哪，注册中心会根据服务注册的清单给发起者返回信息告诉它对方在哪个服务器中</li><li>经过了服务发现后，发起者知道了需求的业务在哪些服务器中，就可以利用负载均衡的思想，把请求分摊给不同的服务器中</li><li>如果某些服务下线，我们其他⼈可以实时的感知到其他服务的状态，从⽽避免调⽤不可⽤的服务<br><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/erPjc8i3_Snipaste_2025-11-10_20-57-42_mianshiya.png" alt="Snipaste_2025-11-10_20-57-42.png" width="100%" /></li></ul><h2 id="Spring-Cloud-的优缺点有哪些？">Spring Cloud 的优缺点有哪些？</h2><p>优点：集成度高，功能全面，生态丰富，扩展性强<br>缺点：学习成本高，组件迭代快版本多，性能开销大，管理复杂</p><h2 id="Spring-Boot-和-Spring-Cloud-之间的区别？">Spring Boot 和 Spring Cloud 之间的区别？</h2><p>springboot 是基础，springcloud 将多个 springboot 服务构建为微服务架构</p><h2 id="Spring-Cloud-由什么组成？">Spring Cloud 由什么组成？</h2><p>1.服务发现和注册:Nacos<br>2.负载均衡:LoadBalance<br>3.服务容错:Sentinel<br>4.远程调用:OpenFeign<br>5.服务网关:GateWay<br>6.事务处理:Seata</p><h2 id="你是怎么理解微服务的？">你是怎么理解微服务的？</h2><p>微服务是一种<strong>架构风格</strong>，核心思想是<strong>把一个大型的单体应用，按照“单一职责原则”拆分成一组独立、自治的小服务</strong>。每个服务只负责一件事，可以自由选择技术栈，拥有独立的数据库，支持独立部署、独立扩缩容。</p><p>服务之间通过轻量级通信协议（比如 HTTP、RPC）交互，从而让整个系统更灵活、可维护、可扩展。<br>好处是提升敏捷性、降低耦合，但同时也会带来分布式架构的复杂性，比如服务治理、链路追踪、容错、部署运维等问题，需要配套的 DevOps 和自动化基础设施。</p><p>一句话总结：<br>微服务就是“拒绝大型单体应用，把业务拆成松耦合的小服务，各自独立迭代和部署”。</p><h2 id="什么情况下需要使用分布式事务，有哪些方案？">什么情况下需要使用分布式事务，有哪些方案？</h2><p>当一次业务操作跨<strong>多个微服务/多个数据库/多种资源</strong>（如 DB + MQ、DB 分库分表）<strong>且需要保证跨资源的一致性时，需要分布式事务</strong>。典型场景：</p><ul><li>下单同时扣库存、扣余额（订单服务 + 库存服务 + 账户服务）</li><li>电商拆库（分库分表）后的多库写一致</li><li>DB 与 MQ 之间要保证“消息发送与本地写库”一致</li></ul><h2 id="你们的服务是怎么做日志收集的？">你们的服务是怎么做日志收集的？</h2><ul><li>我当前项目的的做法很简单：利用Logback，既打控制台，也打本地文件。每个服务把运行日志按固定格式写到本机的 logs 目录，按“日期+大小”自动切分，保留一段时间。出问题就直接看这些日志，定位很快。</li><li>需要集中查看时，也不用改代码，只要在服务器上加个日志收集器Logstash、，把这些文件统一送到一个搜索平台（比如 ES），再用一个网页（比如 Kibana）来搜、画图、做告警就行。（也就是ELK）</li><li>一句话流程：服务写文件 → 收集器把文件送到搜索库 → 网页上一搜就能看到所有服务的日志。</li></ul><p>这样做的好处是：实现简单、出问题好排查；要升级成“像 ELK 那样的集中日志系统”也很容易，基本是平台侧加收集与展示，不用动业务代码。</p><h2 id="什么是-Seata？">什么是 Seata？</h2><p>Seata一款分布式事务解决方案。主要用于解决微服务架构下的分布式事务问题。<br>在 Seata 中有三个很重要的角色：事务协调者（TC）、事务管理者（TM）以及事务的作业管理器（RM）。</p><ul><li>TC: 相当于项目经理，TC 去来感知全局事务和分支事务的状态，基于它们的状态，然后驱动谁来提交，谁来回滚，TC 是一个中间件，需要下载 TC 服务器启动起来</li><li>TM：负责发起任务，开启全局事务，全局事务要调用每一个微服务，做自己的分支事情</li><li>RM：每一个微服务里面去控制事务的在 Seata 中称为 RM 资源管理器，只管理自己的资源，它的作用就是处理好它的分支事务，它分支事务的提交回滚都是 RM 来做，RM 也要跟 TC 及时通信，去来及时的报告它的事务状态，方便 TC 进行总体管控</li></ul><h2 id="Seata-支持哪些模式的分布式事务？">Seata 支持哪些模式的分布式事务？</h2><h3 id="Seata-AT-模式（默认）">Seata AT 模式（默认）</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/GIO8yOVU_at_mianshiya.png" alt="at.png" width="100%" /><h3 id="Seata-XA-模式">Seata XA 模式</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/yvRaGLj8_XA_mianshiya.png" alt="XA.png" width="100%" />XA 模式也是一种二阶提交协议，不同的是第一阶段它并不会给本地数据库真正的提交数据，它会阻塞住这个事务请求，只有在第二阶段确认要提交以后才会真正去提交<img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/rRMB3C6m__mianshiya.png" alt=".png" width="100%" />补充：AT->XA （不推荐）<img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/EuF5a20C_image_mianshiya.png" alt="image.png" width="100%" /><h3 id="Seata-TCC-模式">Seata TCC 模式</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/1d5Ju5Hq_image_mianshiya.png" alt="image.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/6aYTlm50_image_mianshiya.png" alt="image.png" width="100%" />第一阶段叫准备，我该给数据库里面存什么或删什么，第一阶段给它执行完<p>第二阶段提交或回滚，大家都成了提交，有一个败了回滚 这里的 prepare，commit，rollback 需要程序员去定义每一个阶段的实现代码</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/ulILWZqn_image_mianshiya.png" alt="image.png" width="100%" />TCC 模式适合于一些夹杂了非数据库的事务代码。需要我们全程手写，TC 服务器仅帮我们协调调用每一个阶段### Seata Saga 模式<img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/YlxoSpXB_Snipaste_2025-11-11_17-56-00_mianshiya.png" alt="Snipaste_2025-11-11_17-56-00.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/TdVLdOoW_Snipaste_2025-11-11_17-56-23_mianshiya.png" alt="Snipaste_2025-11-11_17-56-23.png" width="100%" /><h3 id="小结">小结</h3><p>Seata 目前支持四种事务模式，分别是 <strong>AT、TCC、Saga、XA</strong>，不同模式适合不同场景</p><p>1️ <strong>AT 模式</strong><br>最常用的一种模式，通过代理数据库操作实现分布式事务。<br>它在业务操作前后自动生成回滚日志，提交时直接提交本地事务，回滚时通过日志恢复数据。</p><ul><li><strong>优点：</strong> 无侵入、使用简单，只适合关系型数据库。</li><li><strong>缺点：</strong> 不能同时操作非关系型数据，比如 Redis。</li></ul><p>2️ <strong>TCC 模式</strong><br>三阶段提交模型（Try、Confirm、Cancel），开发者自己实现每个步骤的逻辑。</p><ul><li><strong>优点：</strong> 可跨多种资源（如 Redis、ES 等），性能高。</li><li><strong>缺点：</strong> 代码侵入性大，需要自己写补偿逻辑。<br>3️ <strong>Saga 模式</strong><br>适合“长事务”场景，比如涉及外部系统（如支付、接口调用）。<br>把全局事务拆分成多个小事务，每个小事务都有补偿操作，按顺序执行或回滚。</li><li><strong>优点：</strong> 适合异步、长流程；</li><li><strong>缺点：</strong> 一致性是最终一致，不是强一致。</li></ul><p>4️ <strong>XA 模式</strong><br>基于两阶段提交协议（2PC）的强一致模型。</p><ul><li><strong>优点：</strong> 一致性最强；</li><li><strong>缺点：</strong> 性能相对较差，适合银行或高一致性业务场景。</li></ul><h3 id="一句话总结">一句话总结</h3><blockquote><p>Seata 有四种模式：<strong>AT 最常用、TCC 性能高、Saga 适合长事务、XA 保证强一致性</strong></p></blockquote><h2 id="了解-Seata-的实现原理吗？">了解 Seata 的实现原理吗？</h2><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/gCOeCl23_Snipaste_2025-11-11_17-40-16_mianshiya.png" alt="Snipaste_2025-11-11_17-40-16.png" width="100%" />三个核心组件：事务协调者TC,事务管理器TM,资源管理器RM### TCTC: 相当于项目经理，TC 去来感知全局事务和分支事务的状态，基于它们的状态，然后驱动谁来提交，谁来回滚，TC 是一个中间件，需要下载 TC 服务器启动起来- 管理所有事务（全局 + 分支）状态；- 决定：谁提交、谁回滚；- 是一个中间件，需要独立部署；- 所有 RM、TM 都要和 TC 通信。### TMTM：负责发起任务，开启全局事务，全局事务要调用每一个微服务，做自己的分支事情<p>是全局事务的发起者；<br>一般存在于<strong>业务服务</strong>（如：下单服务、支付服务）中；<br>负责：</p><ul><li>开启一个 <strong>全局事务</strong>；</li><li>调用多个子服务（每个服务执行自己的 “分支事务”）；</li><li>最终由 TC 统一控制提交或回滚。</li></ul><h3 id="RM">RM</h3><p>RM：每一个微服务里面去控制事务的在 Seata 中称为 RM 资源管理器，只管理自己的资源，它的作用就是处理好它的分支事务，它分支事务的提交回滚都是 RM 来做，RM 也要跟 TC 及时通信，去来及时的报告它的事务状态，方便 TC 进行总体管控</p><p>每个微服务里负责<strong>自己的本地数据库事务</strong>；<br>通过 <strong>undo_log</strong> 实现回滚（哪怕之前已经提交，也能改回来）。</p><h3 id="简述一下流程：">简述一下流程：</h3><p>整个工作流程就是：首先全局事务如果要开始，业务的入口会开启一个 global transaction（全局事务），全局事务的开启也要告诉 TC，TC 知道我们要开始做一个全局事务了，接下来我们每调用的一个远程微服务它们就是一个分支事务，如果它们的事务开始，它们要注册自己的分支事务给 TC，那么 TC 也知道我们当前全局事务的当前状态正在做某一个分支事务，而且这个分支事务的状态也要汇报给 TC（分支事务是提交了还是回滚了），每一个微服务都一样，那这样的话如果某一个环节出现问题例如 accout，TC 就会要求那个出问题的微服务 accout 对他的事务进行回滚，而且由于 TC 知道 accout 出了问题，而其他微服务可能不知道，它们可能已经提交了，但就算你提交了，TC 会要求你们把提交的数据再改回去，已提交的事务怎么改回去，它是基于一个 undo_log 机制，Seata 的工作原理就是这样的</p><h3 id="小结-2">小结</h3><p>步骤 1：开始全局事务（TM 发起）</p><ul><li><p>比如业务入口是 Business 服务（下单）；</p></li><li><p>TM 开启一个 Global Transaction（全局事务）；</p></li><li><p>并通知 TC：我们开始做全局事务了。<br>步骤 2：调用其他微服务（产生分支事务）</p></li><li><p>TM 在事务中调用了 Storage、Order、Account 等服务；</p></li><li><p>每个服务的 RM 会：</p><ul><li>注册自己的分支事务到 TC；</li><li>执行自己的本地事务（如扣库存）；</li><li>上报执行状态（成功 / 失败）给 TC。<br>步骤 3：TC 做决策（统一协调）</li></ul></li><li><p>如果所有分支都成功 → TC 通知所有 RM 执行 提交；</p></li><li><p>如果有一个服务失败（比如 Account 余额不足） → TC 通知所有服务 回滚。<br>步骤 4：RM 根据命令执行提交 / 回滚</p></li><li><p>即使某个服务已经提交了事务，只要 TC 要求回滚；</p></li><li><p>RM 会用 undo_log 把已提交的数据 “改回去”；</p></li><li><p>保证全局事务的最终一致性。</p></li></ul><p>总结一句话：</p><blockquote><p>Seata 就像一个指挥系统，TM 发起事务，RM 执行本地操作，TC 统一管理事务命运（提交或回滚），通过 undo_log 实现真正的分布式事务一致性。</p></blockquote><h2 id="Seata-的事务回滚是怎么实现的？">Seata 的事务回滚是怎么实现的？</h2><h3 id="AT-模式下的二阶提交协议">AT 模式下的二阶提交协议</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/jf8IFbt6_image-786-675x1024_mianshiya.png" alt="image-786-675x1024.png" width="100%" />二阶事务的第一阶段就是每一个分支事务先去自己的数据库本地提交，但是要提交两个东西：第一个你业务修改后的数据和第二个 undo_log 回滚日志，这样 Seata（TC 服务器）就知道谁在第一阶段成了，谁在第一阶段败了<p>第二阶段，如果每个分支事务都成了，TC 会通知每个微服务，告知它们可以提交本次分支事务，而每一个微服务只需要把自己的 undo_log 日志一删就可以了。如果某个事务失败了，Seata 就会通知每一个已经成功本地提交的微服务去回滚，一旦每一个微服务收到了 Seata 服务器的回滚通知该怎么办，那么每一个微服务就会开启一个回滚任务，这个任务也是一个事务，主要做这么几件事：第一件步，找到 undo_log 记录（根据全局事务 id 和分支事务 id）我的 undo_log 记录我的前镜像和后镜像。第二步，做一个数据校验，后镜像和当前数据进行一个对比，如果一致就可以放心大胆的回滚，如果不一致，说明外部有一些其他渠道修改了，需要在 Seata 里配置相应的策略（只要编码正确的话一般不会出现这种情况）。第三步，数据校验完成，回滚数据，拿到它的前镜像，执行修改，完成后删除 undo_log</p><p>只要我们的总事务没有执行完成，总事务期间用到的所有全局锁都不会被释放，在并发的情况下很有效。</p><h3 id="总结一下就是">总结一下就是</h3><p>一阶段：执行本地业务并生成回滚日志<br>每个微服务（分支事务）要做以下几件事：</p><ol><li>执行业务操作（例如减库存、扣余额、创建订单）；</li><li>查询并记录前镜像数据（操作前的快照）；</li><li>执行 SQL 修改数据；</li><li>记录后镜像数据；</li><li>将前镜像和后镜像写入 undo_log 表；</li><li>向 TC 注册分支事务并锁定数据（记录全局锁）；</li><li>提交本地事务：业务数据 + undo_log 一起提交；</li><li>将执行结果上报给 TC（成功 / 失败）。<br>此时，数据已修改，但可以 “回滚”，因为 undo_log 记录了变更前后状态。</li></ol><p>二阶段：根据 TC 指令提交或回滚<br>✅ 情况一：所有分支事务都成功</p><ol><li>TC 统一发出 “提交” 通知；</li><li>各服务在本地执行：</li></ol><ul><li>删除对应的 undo_log 日志；</li><li>表示数据最终确认生效；</li></ul><ol start="3"><li>无需其他额外操作。<br>注意：提交是非常轻量的操作，只是删除日志。</li></ol><p>❌ 情况二：某个分支事务失败，需要全局回滚</p><ol><li>TC 向所有已经成功提交的服务发送 “回滚” 指令；</li><li>每个微服务执行 “回滚事务”，包含：</li></ol><ul><li>找日志：根据全局事务 ID（XID）+ 分支事务 ID 定位 undo_log；</li><li>数据校验：<ul><li>把 undo_log 的 “后镜像” 与数据库当前值做对比；</li><li>如果一致，说明数据没有被修改过，可以安全回滚；</li><li>如果不一致，要根据配置策略判断如何处理（可能是并发或手动干预导致）；</li></ul></li><li>数据还原：用 “前镜像” 覆盖当前数据，完成回滚；</li><li>删除 undo_log，表示回滚完成。</li></ul><p>全局锁说明<br>在整个全局事务未完成前（无论提交还是回滚），相关数据持有全局锁，不能被其他事务访问，确保数据一致性。</p><h3 id="总结一句话：">总结一句话：</h3><p>Seata 的 2PC 模型中，一阶段提交业务数据 + 回滚日志，二阶段根据 TC 决定是删除日志（提交）还是回滚数据（根据日志还原），最终实现分布式事务的一致性。</p><h2 id="分布式和微服务有什么区别？">分布式和微服务有什么区别？</h2><ul><li>分布式是一种<strong>架构方式</strong>或工作模式，它把一个大型系统拆分成多个独立的小模块，<strong>部署在不同的机器上</strong>，通过网络协同工作。<ul><li>比如：用户服务在 A 机器、订单服务在 B 机器，它们通过接口通信。</li></ul></li><li><strong>微服务是分布式架构的一种设计思想</strong>。它把一个完整的系统拆分成多个独立的小服务，每个服务都可以独立开发、部署和扩展。<ul><li>比如：用户微服务、订单微服务、支付微服务等，每个都可以单独运行、独立维护。</li></ul></li><li>集群强调的是<strong>物理形态</strong>，指多台机器协同处理同一个应用或任务。<ul><li>比如你有三台机器同时部署同一个服务，做负载均衡或高可用——这就叫集群。</li></ul></li></ul><blockquote><p>分布式是架构方式，微服务是架构风格，集群是部署形态。<br>三者关系：<br>微服务通常跑在分布式架构上；<br>分布式系统可以通过集群来提高性能和可靠性。</p></blockquote><h2 id="为什么需要负载均衡？">为什么需要负载均衡？</h2><p><strong>负载均衡</strong>主要用于<strong>将网络请求和流量分发到多台服务器或服务实例上</strong>，从而提高系统的<strong>高可用性和性能</strong>。它能够确保系统在高并发访问下保持稳定，避免单个服务器因负载过高而导致性能下降或宕机。</p><h2 id="负载均衡算法有哪些？">负载均衡算法有哪些？</h2><h3 id="常见的负载均衡算法">常见的负载均衡算法</h3><p>负载均衡的核心目标是<strong>让请求在多台服务器之间尽量分配得更均匀</strong>，提高系统的性能和可靠性。<br>常见的算法主要有以下几种</p><p>1️ <strong>轮询算法（Round Robin）</strong><br>最简单的算法，按顺序把请求分配到各服务器上。<br>适合服务器性能相近的场景，但不考虑负载差异。</p><p>2️ <strong>加权轮询（Weighted Round Robin）</strong><br>给不同服务器分配不同权重，权重大说明性能好，处理请求也多。<br>常用于服务器性能差异较大的情况。</p><p>3️ <strong>随机算法（Random）</strong><br>随机选一台服务器处理请求，简单易实现。<br>但性能差异大的情况下容易出现“强的更忙，弱的闲”。</p><p>4️ <strong>加权随机（Weight Random）</strong><br>在随机的基础上加权，性能越好的服务器被选中的概率越高。</p><p>5️ <strong>最少连接（Least Connection）</strong><br>优先选择当前连接数最少的服务器，确保负载均衡。<br>特别适合请求处理时间不一致的业务，比如文件上传或接口耗时不同的场景。</p><p>6️ <strong>哈希算法（Hash）</strong><br>根据请求的某个特征（如 IP、URL、用户 ID）进行哈希计算，固定分配到某台服务器。<br>适合需要会话保持的场景，比如 Redis、登录服务。</p><h3 id="一句话总结-2">一句话总结</h3><blockquote><p>常见负载均衡算法有：<strong>轮询、加权轮询、随机、加权随机、最少连接、哈希</strong>。<br>轮询最简单，加权适配性能差异，最少连接更智能，哈希适合会话保持。</p></blockquote><h2 id="什么是服务雪崩？">什么是服务雪崩？</h2><p>服务雪崩是指在微服务架构或分布式系统中，由于某个服务不可用或性能下降，导致依赖它的其他服务也出现连锁故障，最终使整个系统或大部分服务不可用的现象。</p><p>要解决服务雪崩的问题就需要引入服务熔断，底层也就是断路器</p><blockquote><p>断路器是一个防止雪崩的机制，当调用方 A 发现被调服务 B 表现不佳（比如慢响应 / 出错），就会暂时停止调用，等服务恢复后再恢复正常调用。</p></blockquote><h3 id="扩展-断路器原理">扩展-断路器原理</h3><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/7S9dPTce_image_mianshiya.png" alt="image.png" width="50%" /></p><p>熔断降级去保护系统稳定性的工作原理（依靠断路器）：</p><p>如果服务 B 是稳定的，调用就应该通过，所以断路器的默认状态是闭合状态，此时所有的远程调用都会通过。如果某一天 B 服务炸了，我们断路器就可以打开，一打开我们的调用就不会通过，A 就不会真正的发起远程调用，当 A 发请求时断路器开着，会快速得到一个错误返回，快速返回保证了请求积压不了，系统就具有很强的稳定性。</p><p>那么 B 如果哪天恢复了，A 怎么知道 B 恢复了呢？断路器有种状态就半开，会先放请求试一试就能知道 B 是否恢复了</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/kiiBdKmC_Snipaste_2025-11-11_18-15-17_mianshiya.png" alt="Snipaste_2025-11-11_18-15-17.png" width="100%" /><p>断路器有 <strong>三种状态</strong>：</p><ul><li><strong>Closed（关闭）</strong>：<br>一切正常，请求可以正常发送到服务 B。</li><li><strong>Open（打开）</strong>：<br>服务 B 被认为不可用，所有请求都立即失败，不再发送。</li><li><strong>Half-Open（半开）</strong>：<br>断路器试着 “放一个请求” 到服务 B 进行探测，判断是否恢复。</li></ul><p><strong>断路器的触发条件：</strong></p><p>在 <strong>关闭状态</strong> 下，会监控一些指标：</p><ul><li><strong>慢调用比例</strong>（比如：超过 1 秒才响应的请求）</li><li><strong>异常比例</strong></li><li><strong>异常请求数</strong></li></ul><p>只有满足两个条件才会触发统计：</p><ol><li>达到设定的 <strong>统计时长</strong>（如 5 秒）</li><li>达到 <strong>最小请求数</strong>（如 5 个请求）</li></ol><p>举例：</p><ul><li>如果在 5 秒内有 100 个请求，其中 70 个超过了 “慢调用阈值”，就认为慢调用比例是 70%；</li><li>如果这个比例超过设定的阈值（如 70%），断路器就 “<strong>打开</strong>”。</li></ul><p><strong>打开（Open）状态行为：</strong></p><ul><li>一旦进入 Open 状态，所有对 B 的请求都被拒绝（快速失败）；</li><li>会保持打开一段 <strong>熔断时长</strong>（如 30 秒）；</li><li>在这段时间内，不会再尝试调用服务 B。</li></ul><p><strong>半开（Half-Open）状态行为：</strong></p><ul><li><p>熔断时长结束后，断路器会进入半开状态；</p></li><li><p>只允许一个请求</p><p>过去试探服务 B 是否恢复；</p><ul><li>如果<strong>成功</strong>：断路器变回关闭状态，恢复正常调用；</li><li>如果<strong>失败</strong>：断路器再次进入打开状态，继续熔断 30 秒。</li></ul></li></ul><p><strong>循环机制：</strong></p><p>断路器会在 “关闭 → 打开 → 半开 → 关闭 / 打开” 之间循环：</p><ul><li>成功 → 回到正常（关闭）</li><li>失败 → 再次熔断（打开）</li></ul><p>而且即便是关闭状态，也会继续统计指标。如果又超过阈值，就会重新触发熔断。</p><p><strong>总结一句话：</strong></p><blockquote><p>断路器是一个<strong>防止雪崩</strong>的机制，当调用方 A 发现被调服务 B 表现不佳（比如慢响应 / 出错），就会暂时停止调用，等服务恢复后再恢复正常调用。</p></blockquote><h2 id="什么是服务熔断？">什么是服务熔断？</h2><p><strong>服务熔断指的是当某个服务的调用失败率持续升高时，通过中断对该服务的请求，防止系统资源被不断消耗，进而保护整个系统不受影响。</strong></p><p>要解决服务雪崩的问题就需要引入服务熔断，底层也就是断路器（熔断器）</p><blockquote><p>断路器是一个防止雪崩的机制，当调用方 A 发现被调服务 B 表现不佳（比如慢响应 / 出错），就会暂时停止调用，等服务恢复后再恢复正常调用。</p></blockquote><h2 id="扩展-断路器原理-2">扩展-断路器原理</h2><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/7S9dPTce_image_mianshiya.png" alt="image.png" width="50%" /></p><p>熔断降级去保护系统稳定性的工作原理（依靠断路器）：</p><p>如果服务 B 是稳定的，调用就应该通过，所以断路器的默认状态是闭合状态，此时所有的远程调用都会通过。如果某一天 B 服务炸了，我们断路器就可以打开，一打开我们的调用就不会通过，A 就不会真正的发起远程调用，当 A 发请求时断路器开着，会快速得到一个错误返回，快速返回保证了请求积压不了，系统就具有很强的稳定性。</p><p>那么 B 如果哪天恢复了，A 怎么知道 B 恢复了呢？断路器有种状态就半开，会先放请求试一试就能知道 B 是否恢复了</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/kiiBdKmC_Snipaste_2025-11-11_18-15-17_mianshiya.png" alt="Snipaste_2025-11-11_18-15-17.png" width="100%" /><p>断路器有 <strong>三种状态</strong>：</p><ul><li><strong>Closed（关闭）</strong>：<br>一切正常，请求可以正常发送到服务 B。</li><li><strong>Open（打开）</strong>：<br>服务 B 被认为不可用，所有请求都立即失败，不再发送。</li><li><strong>Half-Open（半开）</strong>：<br>断路器试着 “放一个请求” 到服务 B 进行探测，判断是否恢复。</li></ul><p><strong>断路器的触发条件：</strong></p><p>在 <strong>关闭状态</strong> 下，会监控一些指标：</p><ul><li><strong>慢调用比例</strong>（比如：超过 1 秒才响应的请求）</li><li><strong>异常比例</strong></li><li><strong>异常请求数</strong></li></ul><p>只有满足两个条件才会触发统计：</p><ol><li>达到设定的 <strong>统计时长</strong>（如 5 秒）</li><li>达到 <strong>最小请求数</strong>（如 5 个请求）</li></ol><p>举例：</p><ul><li>如果在 5 秒内有 100 个请求，其中 70 个超过了 “慢调用阈值”，就认为慢调用比例是 70%；</li><li>如果这个比例超过设定的阈值（如 70%），断路器就 “<strong>打开</strong>”。</li></ul><p><strong>打开（Open）状态行为：</strong></p><ul><li>一旦进入 Open 状态，所有对 B 的请求都被拒绝（快速失败）；</li><li>会保持打开一段 <strong>熔断时长</strong>（如 30 秒）；</li><li>在这段时间内，不会再尝试调用服务 B。</li></ul><p><strong>半开（Half-Open）状态行为：</strong></p><ul><li><p>熔断时长结束后，断路器会进入半开状态；</p></li><li><p>只允许一个请求</p><p>过去试探服务 B 是否恢复；</p><ul><li>如果<strong>成功</strong>：断路器变回关闭状态，恢复正常调用；</li><li>如果<strong>失败</strong>：断路器再次进入打开状态，继续熔断 30 秒。</li></ul></li></ul><p><strong>循环机制：</strong></p><p>断路器会在 “关闭 → 打开 → 半开 → 关闭 / 打开” 之间循环：</p><ul><li>成功 → 回到正常（关闭）</li><li>失败 → 再次熔断（打开）</li></ul><p>而且即便是关闭状态，也会继续统计指标。如果又超过阈值，就会重新触发熔断。</p><p><strong>总结一句话：</strong></p><blockquote><p>断路器是一个<strong>防止雪崩</strong>的机制，当调用方 A 发现被调服务 B 表现不佳（比如慢响应 / 出错），就会暂时停止调用，等服务恢复后再恢复正常调用。</p></blockquote><h2 id="什么是服务降级？">什么是服务降级？</h2><p>服务降级是一种在<strong>分布式系统</strong>和<strong>微服务架构</strong>中常用的容错机制，用于在系统压力过大或部分服务出现故障时，<strong>暂时减少或关闭某些不必要的功能</strong>，从而确保核心功能的正常运行，避免系统崩溃。</p><h2 id="什么是服务限流？">什么是服务限流？</h2><p>服务限流是一种流量控制策略,<strong>它通过限制每秒请求的数量(QPS)、请求频率、并发数等,来保护服务的处理能力,防止系统因为流量过大而出现性能问题或资源耗尽</strong>。</p><h2 id="Sentinel-是怎么实现限流的？">Sentinel 是怎么实现限流的？</h2><p>Sentinel 实现限流的核心思路是通过定义流量控制规则来保护服务。它主要通过以下方式实现限流：</p><ul><li><strong>流量控制规则</strong>：包括设置 QPS（每秒请求数）限制、并发线程数控制等。</li><li><strong>统计与监控</strong>：它会实时统计每个资源的流量情况，并在超出设置阈值时进行流量限制（比如抛出流控异常）。</li><li><strong>分布式限流</strong>：通过与配置中心（如 Nacos、Zookeeper）结合，动态调整流量控制规则，实现跨服务的统一限流。</li></ul><h2 id="Sentinel-中怎么实现集群限流">Sentinel 中怎么实现集群限流?</h2><p>在 Sentinel 中实现集群限流，主要通过两个角色来完成：Token Server 和 Token Client。简单来说，Token Server 就是流量控制的“大脑”，它负责管理流量的请求，而 Token Client 则是“执行者”，每个服务实例都相当于是一个 Token Client，向 Token Server 请求流量的许可。</p><p>具体的过程是这样的：每当一个 Token Client 发起请求时，它会先向 Token Server 申请一个令牌。如果成功拿到令牌，Token Client 就可以继续处理该请求；如果没拿到令牌，那么就会被限流，可能会被拒绝请求或进入排队等候。</p><p>为了提高系统的可靠性，Sentinel 支持多个 Token Server。当一个 Token Server 出现故障时，系统会自动切换到其他可用的 Token Server，确保集群流量控制的不中断，增强系统的稳定性。</p><p>所以，简单来说，Sentinel 通过 Token Server 集中管理流量的请求，确保高并发情况下流量能够被有效控制，系统也能稳定运行。</p><h2 id="什么是微服务网关？为什么需要服务网关？">什么是微服务网关？为什么需要服务网关？</h2><p>微服务网关是分布式系统中的关键组件，<strong>它充当了系统的统一入口，能够有效地管理和路由不同的请求</strong>。你可以把它想象成地铁站的<strong>安检闸机</strong>，所有进入系统的请求都必须通过网关。它不仅完成了请求的转发，还承担了很多其他的功能。</p><p>首先，<strong>网关负责统一的请求路由</strong>。<strong>当请求通过网关时，它会自动判断请求应该被转发到哪个服务上</strong>。此外，网关还可以结合<strong>负载均衡算法</strong>，确保集群中每个服务器的负载是均衡的。</p><p>另外，<strong>网关还能够对流量进行控制</strong>，比如它可以和像 Sentinel 这样的工具结合，实现全局的流量控制。如果系统中某个微服务的 QPS 达到限制，网关就能在入口处统一限流，避免后端系统过载。</p><p>此外，<strong>网关还承担了身份认证的任务</strong>。如果有未登录的用户请求访问受限资源，网关可以拦截并要求重新登录。它还能防止一些非法攻击，比如拦截 SQL 注入、跨站请求伪造等常见的安全问题。</p><p>最后，<strong>网关还支持协议转换</strong>。比如前端发送的请求是 JSON 格式，但后端服务需要 GRPC 协议，网关可以将数据格式转换，从而保证不同协议之间的无缝对接。</p><blockquote><p>总的来说，微服务网关是微服务架构中的核心，它不仅统一了请求管理，还提升了系统的安全性、稳定性和可维护性。</p></blockquote><h2 id="Spring-Cloud-可以选择哪些-API-网关？">Spring Cloud 可以选择哪些 API 网关？</h2><p>在 Spring Cloud 中，选择 API 网关有好几种方案</p><ul><li>首先是 <strong>Spring Cloud Gateway</strong>，这是目前最推荐的选项，它基于 WebFlux 响应式编程框架，支持流量控制、路由转发、服务熔断等功能，非常适合与 Spring Cloud 的生态系统兼容，尤其在微服务架构下，它与 Nacos、Consul、OpenFeign 等微服务组件非常契合。</li><li>另外，<strong>Kong</strong> 是一个高性能的 API 网关，常用于云原生架构，能够与 Spring Cloud 集成，提供强大的路由、认证、流量控制等能力，非常适合大规模的 API 管理需求。</li><li><strong>Apache APISIX</strong> 也是一种开放源代码的网关，具有良好的性能，并且支持多种框架和语言，适用于需要高可扩展性和灵活性的项目。</li><li>如果我们提到 <strong>Envoy</strong>，它使用 C++ 开发，适用于需要高性能、高并发的场景，虽然开发起来相对较难，但它在微服务领域的应用很广泛，尤其适合大规模的服务网格环境。</li><li><strong>Nginx</strong> 作为大家熟悉的反向代理工具，也可以作为 API 网关来使用，常见于负载均衡、流量控制等，但对于更复杂的路由和管理需求来说，可能不如专用的网关灵活。</li><li>最后是 <strong>Zuul</strong>，这是 Spring Cloud 早期推荐的网关，尽管它已逐渐被 Spring Cloud Gateway 所替代，但依然可以执行基本的路由和负载均衡功能。</li></ul><p>常见的就Spring cloud GateWay和Nginx</p><h2 id="什么是-Spring-Cloud-Gateway？">什么是 Spring Cloud Gateway？</h2><p>Spring Cloud Gateway 是 <strong>Spring Cloud 中用于处理微服务请求的网关，提供了许多强大的功能</strong>。它基于 Spring WebFlux 和 Reactor，支持高并发且低延迟的请求处理，可以有效提升服务的性能。</p><p>简单来说，Spring Cloud Gateway 扮演了类似交通指挥员的角色。它帮助将来自客户端的请求路由到正确的微服务，同时还能处理流量控制、身份验证、协议转换等任务。它的工作原理就像是你进入地铁站，先通过安检闸机，再决定你去哪个站。</p><h3 id="主要功能：">主要功能：</h3><ol><li><strong>请求路由</strong>：根据路由规则把请求转发到正确的微服务。</li><li><strong>负载均衡</strong>：通过负载均衡算法，均衡各个微服务的请求量，避免服务器过载。</li><li><strong>流量控制</strong>：类似 Sentinel，它可以进行流量限流，保证系统的稳定性。</li><li><strong>身份认证</strong>：例如，网关可以验证用户是否登录，未登录的请求会被重定向到登录页面。</li><li><strong>协议转换</strong>：如果前端和后端使用不同的协议（如 JSON 和 GRPC），网关也可以进行协议的转换。</li><li><strong>系统监控</strong>：它可以监控请求的处理时间和访问量，用于分析系统的性能瓶颈。</li></ol><p>总的来说，Spring Cloud Gateway 不仅是请求转发的工具，它还提供了一个集中管理微服务流量的方式，使得微服务的调用更加规范和高效。</p><h2 id="你的项目为什么选-Spring-Cloud-Gateway作网关">你的项目为什么选 Spring Cloud Gateway作网关</h2><ul><li><p>一句话概括</p><ul><li><strong>我们需要一个“统一入口”来转发前端请求、做鉴权/限流/日志，最好还能跟微服务注册中心打通、动态路由、好扩展。Spring Cloud Gateway正好契合这些诉求。</strong></li></ul></li><li><p>在 GQ Video 里它具体做了什么</p><ul><li>统一入口：<a href="http://localhost:7071">http://localhost:7071</a></li><li>按前缀分发到内部服务（见网关配置）<ul><li>/web → 视频主站服务</li><li>/interact → 互动服务（评论/弹幕）</li><li>/file → 资源服务（上传/转码/文件读取）</li><li>/admin → 后台管理服务</li></ul></li><li>动态发现/配置：对接 Nacos，服务上下线/路由规则改动不需要重启。</li><li>统一过滤器：<ul><li>自定义全局过滤器 <code>GatewayGlobalRequestFilter</code> 做链路日志、公共头处理等；</li><li>管理端路由挂了 <code>AdminFilter</code>，做管理口子的额外校验；</li><li>统一 CORS、去前缀 <code>StripPrefix</code>，出错走统一 <code>GatewayExceptionHandler</code>。</li></ul></li><li>前端开发也更顺：Vite 直接把 <code>/api</code> 代理到 7071 网关，后端路由透明。</li></ul></li><li><p>为什么选 Spring Cloud Gateway（而不是直接 Nginx/Zuul/Kong）</p><ul><li><strong>和 Spring 生态天然融合</strong>：拿到请求上下文、轻松接入 Spring Security、Resilience4j，写业务级过滤器更顺手（Java 代码即配置）。</li><li>动态路由/灰度更容易：基于注册中心+谓词/过滤器模型，按路径、Header、权重做灰度/蓝绿都行。</li><li>性能与模型合适：基于 Reactor Netty，天然异步非阻塞，吞吐和资源占用比早期 Zuul 1（Servlet 阻塞模式）更友好。</li><li>可观测与治理能力：方便加统一日志、限流、熔断、重试、埋点；问题定位只盯一处入口。</li><li>和 Nginx 的分工：Nginx 适合边缘层 L4/L7 转发、静态资源；Gateway 适合“贴近业务”的网关（鉴权、灰度、风控、参数改写）；两者可以叠加用。</li></ul></li><li><p>给我们带来的直接收益</p><ul><li>前后端/多服务的“单一入口”，隐藏内网拓扑，降低耦合。</li><li>统一的安全与流控点，保护下游（后期加限流/熔断非常方便）。</li><li>动态与可灰度的路由管理，发版/回滚更稳。</li><li>开发效率高：路由、过滤器都在一处维护，Java 同栈改起来更快。</li></ul></li></ul><p>总结</p><ul><li><strong>我们选 Gateway，是为了把“路由+鉴权+流控+日志+灰度”这些通用能力统一放在网关层，并且与 Spring/Nacos 无缝协作；对 GQ Video 这种多微服务、前后端分离的项目，既省心，又能随着业务轻松演化。</strong></li></ul><h2 id="说说什么是-API-网关？它有什么作用？">说说什么是 API 网关？它有什么作用？</h2><p>API 网关<strong>是一个为客户端和后端微服务之间提供统一入口的组件</strong>。它的作用是接收客户端的请求，判断请求应该转发到哪个服务，并且在转发时可以进行一系列处理，比如流量控制、认证、限流、缓存、日志记录等。</p><h3 id="主要作用：">主要作用：</h3><ol><li><strong>简化客户端调用</strong>：通过 API 网关，客户端只需要和网关打交道，避免了直接和多个后端服务沟通。这样客户端不需要知道后端服务的具体信息，比如部署位置和接口，极大简化了调用流程。</li><li><strong>流量管理与负载均衡</strong>：API 网关可以实现负载均衡，帮助分散到多个服务器的请求，确保系统的高可用性。</li><li><strong>请求路由与转发</strong>：网关根据配置规则将客户端请求转发到不同的后端服务上，提升系统的扩展性。</li><li><strong>权限认证与安全控制</strong>：可以在 API 网关层面进行用户认证和权限控制，确保只有合适的用户可以访问特定的服务。</li><li><strong>流量限制</strong>：网关可以限制特定接口的访问量，避免单个接口超负荷请求造成整个系统的崩溃。</li><li><strong>日志与监控</strong>：API 网关也可以负责记录请求日志、处理错误监控等，帮助分析系统性能，快速定位问题。</li><li><strong>协议转换</strong>：它还能处理不同协议之间的转换，比如客户端发出的 JSON 请求可以被转换成后端微服务所需要的 GRPC 协议，提升服务之间的兼容性。</li></ol><p>简而言之，API 网关就像是一个“门卫”，它管理着客户端和微服务的所有交互，帮助确保系统的高效、安全和稳定运行 。</p><h2 id="什么是漏桶什么是令牌桶？">什么是漏桶什么是令牌桶？</h2><p>漏桶和令牌桶都是用于流量控制的算法，它们有一个相似点：都使用了一个“桶”来控制数据流入和流出，但它们的工作原理和适用场景有所不同。</p><h3 id="漏桶算法：">漏桶算法：</h3><p>漏桶算法像一个有漏孔的水桶，水以固定速率漏出，而不管水流入的速度有多快。举个例子，假设水桶每秒钟可以漏出1滴水，那么即使前几秒没有水流进桶里，第五秒来了5滴水，漏桶只能处理1滴，剩下的请求会被拒绝。因此，漏桶算法适合于需要限制数据的平均传输速率，并确保流量平稳的场景。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Lw2ljJTd_Snipaste_2025-11-16_17-41-12_mianshiya.png" alt="Snipaste_2025-11-16_17-41-12.png" width="60%" /></p>### 令牌桶算法：<p>令牌桶算法和漏桶类似，但令牌桶的“桶”并不漏水，它只会以固定速率往桶中放入令牌。每当有请求来时，它就会去桶里取令牌。如果令牌桶里有令牌，说明可以处理请求；如果没有令牌，则请求会被拒绝或者阻塞。令牌桶的优势在于它可以处理突发流量——如果前面没有请求，令牌会一直积累，直到请求流量大幅增加时，可以用这些积累的令牌一次性处理多个请求。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/P4QpwCjP_Snipaste_2025-11-16_17-41-44_mianshiya.png" alt="Snipaste_2025-11-16_17-41-44.png" width="60%" /></p><h3 id="总结：">总结：</h3><ul><li><strong>漏桶算法</strong>适合于平稳的数据流控制，确保流量按照固定速率进行传输，但无法处理突发流量。</li><li><strong>令牌桶算法</strong>则可以平滑地控制流量，并能应对突发流量，它在很多情况下比漏桶更为灵活和高效。</li></ul><blockquote><p>你可以把漏桶想象成一个水龙头，每次只放出固定量的水；而令牌桶就像一个加油站，虽然每秒钟会加一定的油，但如果前面没人加油，油就会累积，到需要的时候一次性满足需求。</p></blockquote>]]></content>
    
    
    <summary type="html">我对SpringCloud的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="SpringCloud" scheme="https://itgeqian.github.io/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>雨云服务器Linux挂载磁盘</title>
    <link href="https://itgeqian.github.io/posts/62.html"/>
    <id>https://itgeqian.github.io/posts/62.html</id>
    <published>2025-10-12T02:09:03.000Z</published>
    <updated>2025-10-12T03:01:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>如果您在控制台新增了一块磁盘，您可以按照本小结挂载硬盘</p><h3 id="前置条件">前置条件</h3><p>如果您是RockyLinux9、CentOS7/8/9请先安装以下依赖</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CentOS7的源已失效，如果无法安装可以先尝试更换一个源</span></span><br><span class="line">yum <span class="keyword">install</span> nano</span><br></pre></td></tr></table></figure><h3 id="确认需要操作的磁盘">确认需要操作的磁盘</h3><p>使用 <code>fdisk -l</code>命令根据大小及其他信息确认需要操作的磁盘</p><blockquote><p>可以看到，本例子中新增的硬盘为sdb</p></blockquote><p><img src="https://cn-sy1.rains3.com/rainyun-assets/pic/2025/10/20251008-185815.png" alt="img"></p><h3 id="创建分区">创建分区</h3><p>输入命令</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sdx为您需要操作的分区，如本例子为sdb</span></span><br><span class="line">fdisk <span class="regexp">/dev/</span>sdx</span><br></pre></td></tr></table></figure><p>在fdisk中输入<strong>n</strong>，然后多次回车使用默认值，看到<code>Created a new partition 1 of type 'Linux' ....</code>后，输入<strong>w</strong>写入到分区表</p><p><img src="https://cn-sy1.rains3.com/rainyun-assets/pic/2025/10/20251008-190135.png" alt="img"></p><h3 id="格式化分区">格式化分区</h3><p>再次输入<code>fdisk -l</code>命令确认新创建的分区</p><blockquote><p>可以看到，本例子中新增的分区为sdb1</p></blockquote><p><img src="https://cn-sy1.rains3.com/rainyun-assets/pic/2025/10/20251008-190531.png" alt="img"></p><p>输入以下命令格式化磁盘为ext4</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sdxx为您看到的分区，如本例子为sdb1</span></span><br><span class="line">mkfs.ext4 <span class="regexp">/dev/</span>sdxx</span><br></pre></td></tr></table></figure><p><img src="https://cn-sy1.rains3.com/rainyun-assets/pic/2025/10/20251008-190619.png" alt="img"></p><h3 id="挂载磁盘">挂载磁盘</h3><p>创建一个空目录用作挂载磁盘</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 路径可以任意，但是需要为空目录，本例子为/mnt/disk-1</span></span><br><span class="line"><span class="built_in">mkdir</span> /mnt/disk-1</span><br></pre></td></tr></table></figure><p>由于挂载磁盘的sdx顺序可能会改变，如改变可能会导致系统无法启动，所以需要使用UUID挂载 输入以下命令获取blkid</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">blkid</span></span><br></pre></td></tr></table></figure><blockquote><p>可以看到，本例子中，磁盘的UUID为f5c1d999-19ec-457d-be82-c830094d9b70</p></blockquote><p><img src="https://cn-sy1.rains3.com/rainyun-assets/pic/2025/10/20251008-190916.png" alt="img"></p><p>最后输入<code>nano /etc/fstab</code>编辑fstab文件，在其中插入，插入完成后按<code>Ctrl+X</code>，然后输入<code>Y</code>并回车保存即可</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#注：UUID需要替换为您从blkid命令中获取的；/mnt/disk-1挂载路径也需要替换为您实际的</span></span><br><span class="line"><span class="attribute">UUID</span>=<span class="string">&quot;f5c1d999-19ec-457d-be82-c830094d9b70&quot;</span> /mnt/disk-<span class="number">1</span> ext4 defaults <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p><img src="https://cn-sy1.rains3.com/rainyun-assets/pic/2025/10/20251008-191505.png" alt="img"></p><h3 id="重启服务器">重启服务器</h3><p>重启服务器后，即可看到成功挂载</p>]]></content>
    
    
    <summary type="html">雨云服务器Linux挂载磁盘教程</summary>
    
    
    
    <category term="杂项" scheme="https://itgeqian.github.io/categories/%E6%9D%82%E9%A1%B9/"/>
    
    
    <category term="雨云服务器" scheme="https://itgeqian.github.io/tags/%E9%9B%A8%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>JVM面试题</title>
    <link href="https://itgeqian.github.io/posts/71.html"/>
    <id>https://itgeqian.github.io/posts/71.html</id>
    <published>2025-10-07T00:19:03.000Z</published>
    <updated>2025-10-20T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-JVM">GQ JVM</h1><h2 id="Java-中有哪些垃圾回收算法？">Java 中有哪些垃圾回收算法？</h2><p>我简单介绍一下常见的几种垃圾回收算法，其实大多数 GC 算法都是基于两个 “祖宗级” 的思想演变而来的：一个是 “标记 - 清除” 算法，一个是 “复制” 算法。</p><h3 id="1-标记-清除（Mark-Sweep）：">1. <strong>标记 - 清除</strong>（Mark-Sweep）：</h3><p>先是标记阶段，将所有存活的对象进行标记。 再是清除阶段，从内存中删除没有被标记也就是非存活对象，这种方式实现简单，只需要在第一阶段给每个对象维护标志位，第二阶段删除对象即可。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/KZ8DUT8F_1_mianshiya.png" alt="1.png" width="75%" /><p>但<strong>问题是容易产生内存碎片</strong>，比如清掉很多小块内存后，剩下的零碎空间可能凑不出一个新对象需要的空间。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/H1HzHoc6_2_mianshiya.png" alt="2.png" width="75%" /><h3 id="2-复制（Copying）算法：">2. <strong>复制</strong>（Copying）算法：</h3><p>它的想法是：准备两块内存区域（From 空间和 To 空间），<strong>每次只用一块（From 空间）</strong>，在GC阶段把存活的对象从当前区域复制到另一块区域（From-&gt;To），然后整体清空原来的区域。这样做虽然避免了内存碎片的问题，但缺点是只能用一半的空间，浪费比较大。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/1Bk7BeDf_3_mianshiya.png" alt="3.png" width="100%" /><h3 id="3-标记-整理（Mark-Compact）算法：">3. 标记 - 整理（Mark-Compact）算法：</h3><p>也是先是标记阶段，将所有存活的对象进行标记。再是整理阶段，会把所有存活对象往内存的一边移动，然后清理掉后面的一大片空闲内存。这样既解决了碎片问题，又保留了内存的连续性。不过移动对象的成本较高，效率会稍低。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/23JLXr9n_4_mianshiya.png" alt="4.png" width="100%" /><h3 id="4-分代垃圾回收（Generational-GC）：">4. 分代垃圾回收（Generational GC）：</h3><p>现代 JVM 一般都采用分代的方式，<strong>把堆内存分成 “年轻代” 和 “老年代”</strong>，不同代使用不同算法。</p><ul><li><strong>年轻代通常用 “复制” 算法，因为这里对象生命周期短、回收频繁</strong>；</li><li><strong>老年代则常用 “标记 - 清除” 或 “标记 - 整理”，因为对象通常存活时间较长，不适合频繁复制。</strong></li></ul><p>这个分代回收机制有个好处：<strong>程序中大部分对象都是朝生夕死，大部分新创建的对象很快就不再用，所以可以快速在年轻代清理掉，减少对整个堆的 Full GC 影响</strong>，从而<strong>提升应用的吞吐量</strong>和<strong>响应性能</strong>。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/waqcqgJI_5_mianshiya.png" alt="5.png" width="100%" /><p>总结：</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/OHSnDm05_6_mianshiya.png" alt="6.png" width="100%" /><h2 id="JVM-的-TLAB（Thread-Local-Allocation-Buffer）是什么？">JVM 的 TLAB（Thread-Local Allocation Buffer）是什么？</h2><p><strong>TLAB 是 JVM 为每个线程在堆中新生代 Eden 区分配的一小块私有内存，用来快速分配对象</strong>。</p><ul><li>每个线程优先在自己的 TLAB 中分配对象，避免了多线程竞争共享堆的同步开销。</li><li>如果 TLAB 用完，就会重新申请新的；</li><li>大对象会直接在 Eden 区分配。</li></ul><p>简单来说，TLAB 就是让对象分配更快、更安全的一种线程本地优化机制。</p><h2 id="Java-是如何实现跨平台的？">Java 是如何实现跨平台的？</h2><p>Java 实现跨平台的关键在于它的“<strong>编译一次，到处运行</strong>”的理念。简单来说，Java 源代码首先被编译成字节码文件（.class 文件），然后这些字节码文件通过 Java 虚拟机（JVM）在不同平台上进行解释和执行。JVM 是与平台相关的，每个操作系统或硬件平台都有一个特定的 JVM 实现。这样，无论在哪个平台上，只要有适配的 JVM，Java 程序就能运行。</p><p>总结</p><ol><li><p><strong>Java 编译成字节码（.class 文件），然后通过 JVM 在不同平台上执行。</strong></p></li><li><p><strong>每个操作系统或硬件平台都需要有特定的 JVM 实现。</strong></p></li><li><p><strong>JVM 让 Java 程序能够在任何平台上运行，而不需要重新编译。</strong></p></li></ol><h2 id="JVM-由哪些部分组成？">JVM 由哪些部分组成？</h2><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/0ThbrNql_10_mianshiya.png" alt="10.png" width="100%" /><ul><li>类加载子系统，负责加载、验证、解析、初始化class字节码文件。其核心就是类加载器。</li><li>运行时数据区，管理 JVM 使用到的内存。<ul><li>线程共享区<ul><li>堆：存放所有对象</li><li>方法区：存放类的元信息、常量池、静态变量</li></ul></li><li>线程私有区<ul><li>虚拟机栈：每个方法对应一个栈帧</li><li>本地方法栈：本地方法的栈</li><li>程序计数器：记录当前线程正在执行的字节码指令地址，确保线程切换后恢复到正确的这些位置</li></ul></li></ul></li><li>执行引擎，分为<ul><li>解释器 解释执行字节码指令；</li><li>即时编译器 优化代码执行性能；</li><li>垃圾回收器 将不再使用的对象进行回收。</li></ul></li><li>本地接口，保存了本地已经编译好的方法，使用 C/C++ 语言实现。</li></ul><p>然后我们再理解型的记忆上述几个组成部分：</p><ol><li>首先需要准备编译好的 Java 字节码文件（即class文件）。</li><li>然后需要先通过一定方式（类加载器）将 class 文件加载到内存中（运行时数据区）。</li><li>又因为字节码文件是 JVM 定义的一套指令集规范，底层操作系统无法直接执行。</li><li>因此需要特定的命令解释器（执行引擎）将字节码翻译成特定的操作系统指令集交给 CPU 去执行。</li><li>这个过程中会需要调用到一些不同语言为 Java 提供的接口（例如驱动、地图制作等），这就用到了本地方法接口（Native Interface）。</li></ol><h2 id="编译执行与解释执行的区别是什么？JVM-使用哪种方式？">编译执行与解释执行的区别是什么？JVM 使用哪种方式？</h2><p>编译执行：<br>定义：编译执行是将程序的<strong>源代码</strong>（如 Java 程序中的 .java 文件）<strong>在运行前由编译器转化为机器语言</strong>（通常是 .class 文件）。然后该机器代码直接在 CPU 上运行。</p><p>解释执行：<br>定义：<strong>解释执行是程序在运行时逐行由解释器将源代码转换为机器语言并执行</strong>。常见的解释型语言有 Python 和 Ruby。</p><h3 id="JVM-的方式：">JVM 的方式：</h3><p>JVM 使用的是<strong>混合模式</strong>，结合了编译执行和解释执行的优点。<strong>Java 在运行时使用 解释执行 将字节码转化为机器码，并且采用 JIT（即时编译器） 技术，在程序运行过程中，JVM 会将经常使用的代码片段编译成机器码，从而提高性能</strong>。这种方式在启动时使用解释执行，而在运行过程中逐渐将热点代码编译为机器码，提高执行效率。</p><p>总结</p><ul><li>编译执行 提供了更高的执行效率，但缺乏跨平台性。</li><li>解释执行 更具跨平台能力，但执行效率较低。</li><li><strong>JVM 结合了两者的优势，初期使用解释执行，之后通过 JIT 编译器将热点代码编译为机器码，提升效率</strong>。</li></ul><h2 id="JVM-的内存区域是如何划分的？">JVM 的内存区域是如何划分的？</h2><p>Java 虚拟机运行时数据区分为方法区、堆、虚拟机栈、本地方法栈、程序计数器。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/UEvvDb2b_11_mianshiya.png" alt="11.png" width="100%" /><h3 id="程序计数器">程序计数器</h3><p>程序计数器（Program Counter Register）也叫 PC 寄存器，<strong>每个线程会通过程序计数器记录当前线程要执行的的字节码指令的地址</strong>。<br>主要有两个作用：</p><ul><li><strong>程序计数器可以控制程序指令的进行</strong>，实现分支、跳转、异常等逻辑。</li></ul><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/okv9yxL4_12_mianshiya.png" alt="12.png" width="70%" /></p><ul><li><strong>多线程执行情况下，Java 虚拟机需要通过程序计数器记录 CPU 切换前解释执行到那一句指令并继续解释运行。</strong></li></ul><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/e0b8bCi9_13_mianshiya.png" alt="13.png" width="70%" /></p><p><strong>简单理解就是：它就像一个小导航器，记录着当前线程正在执行哪一条字节码指令。每个线程都有自己的程序计算器，线程切换时它能帮我们恢复现场。</strong></p><h3 id="虚拟机栈">虚拟机栈</h3><p><strong>Java 虚拟机栈采用栈的数据结构来管理方法调用中的基本数据</strong>，先进后出，每一个方法的调用使用一个栈帧来保存。每个线程都会包含一个自己的虚拟机栈，它的生命周期和线程相同。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/TZDXPOvR_14_mianshiya.png" alt="14.png" width="70%" /></p>栈帧主要包含三部分内容：<p>1、局部变量表，在方法执行过程中存放所有的局部变量。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/kkM7KzJL_15_mianshiya.png" alt="15.png" width="70%" /></p>2、操作数栈，虚拟机在执行指令过程中用来存放临时数据的一块区域。<p>如下图中，iadd 指令会将操作数栈上的两个数相加，为了实现 i+1。最终结果也会放到操作数上。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/wfmE3Xfa_16_mianshiya.png" alt="16.png" width="70%" /></p>3、帧数据，主要包含动态链接、方法出口、异常表等内容。<ul><li>动态链接：方法中要用到其他类的属性和方法，这些内容在字节码文件中是以编号保存的，运行过程中需要替换成内存中的地址，这个编号到内存地址的映射关系就保存在动态链接中。</li><li>方法出口：方法调用完需要弹出栈帧，回到上一个方法，程序计数器要切换到上一个方法的地址继续执行，方法出口保存的就是这个地址。</li><li>异常表：存放的是代码中异常的处理信息，包含了异常捕获的生效范围以及异常发生后跳转到的字节码指令位置。</li></ul><h3 id="本地方法栈">本地方法栈</h3><p>Java 虚拟机栈存储了 Java 方法调用时的栈帧，<strong>而本地方法栈存储的是 native 本地方法的栈帧。</strong></p><p>在 Hotspot 虚拟机中，Java 虚拟机栈和本地方法栈实现上使用了同一个栈空间。本地方法栈会在栈内存上生成一个栈帧，临时保存方法的参数同时方便出现异常时也把本地方法的栈信息打印出来。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/uvn65XV0_17_mianshiya.png" alt="17.png" width="120px" /></p><h3 id="堆">堆</h3><ul><li>一般 Java 程序中堆内存是空间最大的一块内存区域。<strong>创建出来的对象都存在于堆上</strong>。</li><li>栈上的局部变量表中，可以存放堆上对象的引用。静态变量也可以存放堆对象的引用，通过静态变量就可以实现对象在线程之间共享。</li><li>堆是垃圾回收最主要的部分，堆结构更详细的划分与垃圾回收器有关。</li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/1yF4Rxo8_18_mianshiya.png" alt="18.png" width="100%" /><h3 id="方法区">方法区</h3><p>方法区是 Java 虚拟机规范中提出来的一个虚拟机概念，<strong>在 HotSpot 不同版本中会用永久代或者元空间来实现</strong>。方法区主要存放的是基础信息，包含：</p><p>1、每一个加载的类的元信息（基础信息）。<br>2、运行时常量池，保存了字节码文件中的常量池内容，避免常量内容重复创建减少内存开销。<br>3、字符串常量池，存储字符串的常量。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/XEw09ADC_20_mianshiya.png" alt="20.png" width="100%" /><h3 id="面试简要回答">面试简要回答</h3><p>如果面试官问我：“你能说一下 JVM 的运行时数据区吗？”</p><p>答：当然可以。JVM 的运行时数据区，其实就是 JVM 在运行 Java 程序时会分配的一些内存区域，这些区域各自有不同的用途。整体上可以分成线程共享的和线程私有的两类。</p><p>线程共享的有两个：</p><ul><li><strong>堆（Heap）：</strong> 这是用来存储所有对象实例的地方，也是垃圾回收器的主要工作区域。对象被 new 出来之后都会放在这里。</li><li><strong>方法区（Method Area）：</strong> 这块区域里保存的是类的信息，比如类名、字段、方法、常量池这些。你可以理解成它更偏向“类”的元数据。</li></ul><p>线程私有的有三个：</p><ul><li><strong>程序计数器（PC Register）：</strong> 这就像一个小导航器，记录着当前线程正在执行哪一条字节码指令。每个线程都有自己的，线程切换时它能帮我们恢复现场。</li><li><strong>虚拟机栈（JVM Stack）：</strong> 每个线程也有自己的栈，它是方法调用的基础结构。每个方法执行时都会生成一个叫“栈帧”的东西，用来保存方法的局部变量、操作数、返回地址等。</li><li><strong>本地方法栈（Native Method Stack）：</strong> 它是专门用来支持 native 本地方法的，和 JVM 栈类似，只不过作用在本地方法上。</li></ul><p>另外还有一个特殊的区域叫 <strong>直接内存（Direct Memory）</strong>，它不是 JVM 管的，而是由操作系统直接管理的，常用于高性能 I/O，比如 NIO 中的 DirectByteBuffer。</p><p>所以总结下来就是：JVM 把内存分区做得很清楚，不同的区域负责不同的功能，有的线程共享，有的线程独占，目的就是为了更高效地管理对象和执行代码。</p><h2 id="JVM-方法区是否会出现内存溢出">JVM 方法区是否会出现内存溢出?</h2><h3 id="运行时数据区的哪些区域会出现内存溢出？">运行时数据区的哪些区域会出现内存溢出？</h3><p>内存溢出指的是<strong>内存中某一块区域的使用量超过了允许使用的最大值</strong>，从而使用内存时因空间不足而失败，虚拟机一般会抛出指定的错误。<br><strong>在 Java 虚拟机中，只有程序计数器不会出现内存溢出的情况，因为每个线程的程序计数器只保存一个固定长度的地址</strong>。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/BHPkPgIT_21_mianshiya.png" alt="21.png" width="100%" /><h3 id="堆内存溢出：">堆内存溢出：</h3><p><strong>堆内存溢出指的是在堆上分配的对象空间超过了堆的最大大小</strong>，从而导致的内存溢出。堆的最大大小使用 - Xmx 参数进行设置，如 - Xmx10m 代表最大堆内存大小为 10m。<br>溢出之后会抛出 OutOfMemoryError，并提示是 Java heap Space 导致的：</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/E3qwO46C_2_mianshiya.png" alt="2.png" width="100%" /><h3 id="栈内存溢出：">栈内存溢出：</h3><p><strong>栈内存溢出指的是所有栈帧空间的占用内存超过了最大值</strong>，最大值使用 - Xss 进行设置，比如 - Xss256k 代表所有栈帧占用内存大小加起来不能超过 256k。<br>溢出之后会抛出 StackOverflowError：</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/eAo3nyqE_3_mianshiya.png" alt="3.png" width="100%" />### 方法区内存溢出：**方法区内存溢出指的是方法区中存放的内容比如类的元信息超过了方法区内存的最大值**，JDK7 及之前版本方法区使用永久代（-XX:MaxPermSize = 值）来实现，JDK8 及之后使用元空间（-XX:MaxMetaspaceSize = 值）来实现。<p>元空间溢出：</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/xX8PAzL4_4_mianshiya.png" alt="4.png" width="100%" />永久代溢出：<img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/bY5cploi_5_mianshiya.png" alt="5.png" width="100%" /><h3 id="直接内存溢出：">直接内存溢出：</h3><p>直接内存溢出指的是申请的直接内存空间大小超过了最大值，使用 -XX:MaxDirectMemorySize = 值 设置最大值。</p><p>溢出之后会抛出 OutOfMemoryError：</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/LuT08D8b_6_mianshiya.png" alt="6.png" width="100%" /><h3 id="面试时简答：">面试时简答：</h3><p>回答：</p><p>在 JVM 中，内存溢出通常指的是某一块区域的内存超过了它的最大限制，导致无法分配内存，抛出相应的异常。常见的内存区域和对应的异常现象如下：</p><ol><li>堆内存溢出（OutOfMemoryError: Java heap space）</li></ol><ul><li><strong>原因</strong>：堆内存用于存储对象，如果应用创建了大量对象，超过了最大堆内存限制，就会导致堆内存溢出。</li><li><strong>现象</strong>：抛出 OutOfMemoryError: Java heap space 异常。</li></ul><ol start="2"><li>栈内存溢出（StackOverflowError）</li></ol><ul><li><strong>原因</strong>：每个线程都有自己的栈内存，如果递归调用过深，栈空间会被耗尽，导致栈内存溢出。</li><li><strong>现象</strong>：抛出 StackOverflowError 异常。</li></ul><ol start="3"><li>方法区内存溢出</li></ol><ul><li><strong>原因</strong>：JDK7及之前的版本使用永久代（PermGen）存储类的元数据，JDK8及之后使用元空间（Metaspace）。如果加载的类太多，或者类的元信息过多，可能会导致方法区溢出。</li><li><strong>现象</strong>：抛出 OutOfMemoryError，JDK7及之前提示 PermGen space，JDK8及之后提示 Metaspace。</li></ul><ol start="4"><li>直接内存溢出（OutOfMemoryError: Direct buffer memory）</li></ol><ul><li><strong>原因</strong>：Java 使用 NIO 进行 I/O 操作时，分配直接内存（通过 ByteBuffer.allocateDirect()），如果直接内存超过了最大限制，会发生溢出。</li><li><strong>现象</strong>：抛出 OutOfMemoryError: Direct buffer memory 异常。</li></ul><p>总结：</p><ul><li><strong>堆内存</strong>：溢出后抛出 OutOfMemoryError: Java heap space。</li><li><strong>栈内存</strong>：溢出后抛出 StackOverflowError。</li><li><strong>方法区</strong>：溢出后抛出 OutOfMemoryError，JDK7之前是 PermGen space，JDK8之后是 Metaspace。</li><li><strong>直接内存</strong>：溢出后抛出 OutOfMemoryError: Direct buffer memory。</li></ul><p>本题问的是JVM 方法区是否会出现内存溢出? 我们只需要回答方法区内存溢出的内容：</p><p>方法区会出现内存溢出，JDK7及之前的版本使用永久代（PermGen）存储类的元数据，JDK8及之后使用元空间（Metaspace）。如果加载的类太多，或者类的元信息过多，可能会导致方法区溢出。溢出后抛出 OutOfMemoryError，JDK7及之前提示 PermGen space，JDK8及之后提示 Metaspace。</p><h2 id="JVM-有那几种情况会产生-OOM（内存溢出）？">JVM 有那几种情况会产生 OOM（内存溢出）？</h2><p>回答：</p><p>在 JVM 中，内存溢出通常指的是某一块区域的内存超过了它的最大限制，导致无法分配内存，抛出相应的异常。常见的内存区域和对应的异常现象如下：</p><ol><li>堆内存溢出（OutOfMemoryError: Java heap space）</li></ol><ul><li><strong>原因</strong>：堆内存用于存储对象，如果应用创建了大量对象，超过了最大堆内存限制，就会导致堆内存溢出。</li><li><strong>现象</strong>：抛出 OutOfMemoryError: Java heap space 异常。</li></ul><ol start="2"><li>栈内存溢出（StackOverflowError）</li></ol><ul><li><strong>原因</strong>：每个线程都有自己的栈内存，如果递归调用过深，栈空间会被耗尽，导致栈内存溢出。</li><li><strong>现象</strong>：抛出 StackOverflowError 异常。</li></ul><ol start="3"><li>方法区内存溢出</li></ol><ul><li><strong>原因</strong>：JDK7及之前的版本使用永久代（PermGen）存储类的元数据，JDK8及之后使用元空间（Metaspace）。如果加载的类太多，或者类的元信息过多，可能会导致方法区溢出。</li><li><strong>现象</strong>：抛出 OutOfMemoryError，JDK7及之前提示 PermGen space，JDK8及之后提示 Metaspace。</li></ul><ol start="4"><li>直接内存溢出（OutOfMemoryError: Direct buffer memory）</li></ol><ul><li><strong>原因</strong>：Java 使用 NIO 进行 I/O 操作时，分配直接内存（通过 ByteBuffer.allocateDirect()），如果直接内存超过了最大限制，会发生溢出。</li><li><strong>现象</strong>：抛出 OutOfMemoryError: Direct buffer memory 异常。</li></ul><ol start="5"><li><strong>线程数过多导致的内存溢出（Unable to Create New Native Thread）</strong></li></ol><ul><li><strong>原因</strong>：每个线程都需要找空间和一定的操作系统资源。如果创建过多线程而超出操作系统的资源限制，可能无法再创建新的线程，导致 OOM。</li><li><strong>现象</strong>：抛出 <code>java.lang.OutOfMemoryError: Unable to create new native thread</code> 异常。</li><li><strong>解决方法</strong>：减少线程数，合理设置线程池的大小，避免无限制地创建线程。</li></ul><ol start="6"><li><strong>GC 执行耗时过长导致的 OOM（GC Overhead Limit Exceeded）</strong></li></ol><ul><li><strong>原因</strong>：当 JVM 在垃圾回收时花费的时间过多回收的内存不足以满足需求，JVM 会抛出 <code>GC Overhead Limit Exceeded</code> 错误，以避免长时间的垃圾回收循环。</li><li><strong>现象</strong>：抛出 <code>java.lang.OutOfMemoryError: GC overhead limit exceeded</code> 错误。</li><li><strong>解决方法</strong>：增加堆内存，优化内存管理，减少不必要的对象创建，或者调整垃圾回收策略。</li></ul><h3 id="总结：">总结：</h3><ul><li><strong>堆内存</strong>：溢出后抛出 OutOfMemoryError: Java heap space。</li><li><strong>栈内存</strong>：溢出后抛出 StackOverflowError。</li><li><strong>方法区</strong>：溢出后抛出 OutOfMemoryError，JDK7之前是 PermGen space，JDK8之后是 Metaspace。</li><li><strong>直接内存</strong>：溢出后抛出 OutOfMemoryError: Direct buffer memory。</li><li><strong>线程数过多</strong>：抛出 Unable to create new native thread。</li><li><strong>GC 执行耗时过长</strong>：抛出 GC Overhead Limit Exceeded。</li></ul><h2 id="Java-中堆和栈的区别是什么？">Java 中堆和栈的区别是什么？</h2><ol><li>堆（Heap）：</li></ol><ul><li><strong>用于存储对象实例和数组</strong>。每次使用 new 关键字创建对象时，JVM 都会在堆内存中分配空间。</li><li><strong>堆内存是动态分配的，大小不固定。</strong></li><li><strong>对象的生命周期由垃圾回收器管理</strong>，垃圾回收会定期检查不再被引用的对象，并回收其占用的内存。</li><li><strong>抛出异常：OutOfMrmoryError。</strong></li><li><strong>是线程共享的</strong>。</li></ul><ol start="2"><li>栈（Stack）：</li></ol><ul><li><strong>用于存储局部变量、方法调用和方法中的引用</strong>（例如，方法参数）。</li><li><strong>每个线程都会有自己的栈内存，存储方法调用的信息</strong>（例如返回地址、局部变量等）。</li><li><strong>对象的生命周期和方法调用一致，方法结束时就释放</strong></li><li><strong>栈内存是静态分配的，并且大小在编译时就确定</strong>。</li><li><strong>抛出异常：StackOverflowError</strong></li></ul><p>简单理解：</p><ul><li>堆：就像是一个存储大量数据的大仓库，<strong>里面存放着所有创建的对象</strong>。它的<strong>空间是动态分配</strong>的，<strong>垃圾回收机制会帮忙清理不再使用的空间</strong>。</li><li>栈：每个线程都有一个小仓库，<strong>里面存放的是方法调用时的局部数据和地址</strong>。这个仓库很小，<strong>方法一结束就会自动清空</strong>。</li></ul><h2 id="什么是-Java-中的直接内存（堆外内存）？">什么是 Java 中的直接内存（堆外内存）？</h2><p>直接内存并不在《Java 虚拟机规范》中存在，所以并<strong>不属于 Java 运行时的内存区域</strong>。在 JDK 1.4 中引入了 NIO 机制，<strong>由操作系统直接管理这部分内容</strong> ，是堆外内存，<strong>主要为了提升读写数据的性能</strong>。在网络编程框架如 Netty 中被大量使用。(Netty 使用了 Reactor 模型，主线程去负责链接，然后分发子任务给 Reactor 子线程)</p><p><strong>要创建直接内存上的数据，可以使用 ByteBuffer。</strong></p><ul><li>语法： ByteBuffer directBuffer = ByteBuffer.allocateDirect (size);</li></ul><p>与堆内存的区别：</p><ul><li>直接内存访问更快，减少了堆内存到直接内存之间的复制；</li><li>使用完需要用cleaner进行回收。jvm垃圾收集器不会进行回收。</li></ul><h2 id="什么是-Java-中的常量池？">什么是 Java 中的常量池？</h2><p>常量池（Constant Pool）是一个<strong>用于存储常量值的内存区域</strong>，主要用于<strong>提高性能和节省内存</strong>。常量池中有两种类型的常量：</p><ul><li>运行时常量池</li><li>字符串常量池</li></ul><ol><li><p><strong>运行时常量池</strong>：</p><ul><li>这是 <strong>JVM 在运行时通过 Class 文件加载的常量池</strong>，它<strong>包含类和方法中的常量信息</strong>，包括常量字符串、字段、方法引用等。加载到 JVM 后，运行时常量池会通过类的加载过程进入 Java 方法区，直到 JVM 退出。</li></ul></li><li><p><strong>字符串常量池</strong>：</p><ul><li>这是<strong>专门用于存储字符串常量的区域</strong>，<strong>位于 Java 堆内存中</strong>。通过字符串的 <code>intern()</code> 方法，字符串常量会被存入常量池中。这样如果遇到相同的字符串，JVM 就可以直接使用已经存在的字符串，而不是重新创建一个新的字符串对象，从而节省内存。</li></ul></li></ol><h3 id="常量池的作用：">常量池的作用：</h3><ul><li><strong>通过将常用的常量值（如字符串）存储在常量池中，避免重复创建相同的常量对象</strong>，从而提高性能和减少内存占用。</li></ul><h3 id="对比和优化：">对比和优化：</h3><ul><li>字符串常量池的实现让字符串在内存中的管理变得更高效。当在代码中使用类似 <code>String s = &quot;Hello&quot;;</code> 的方式时，JVM 会首先检查常量池中是否有 “Hello” 这个字符串。如果没有，则将它添加进去；如果已经有了，就直接引用已有的对象。</li></ul><p>总的来说，常量池不仅<strong>提升了 Java 应用的效率，还减少了内存的占用</strong>，<strong>特别是在大量使用常量字符串的场景中</strong>，优化显著。</p><h2 id="你了解-Java-的类加载器吗？">你了解 Java 的类加载器吗？</h2><h3 id="什么是类加载器">什么是类加载器</h3><p>它用于在运行时动态地将class字节码加载到内存中,以供JVM执行。</p><ul><li>启动类加载器 (Bootstrap ClassLoader)：<strong>这是最基本的类加载器，负责加载核心的 Java 类库</strong>，比如 rt.jar。它由 JVM 自身用 C++ 实现，因此不能直接在 Java 程序中访问。它是所有类加载器的父类加载器。</li><li>扩展类加载器 (Extension ClassLoader)：<strong>这个类加载器负责加载 lib/ext 目录下的类库</strong>，或者是由 java.ext.dirs 系统属性指定的路径下的类。它的主要任务是加载 Java 扩展的类库，比如一些第三方的库。</li><li>应用程序类加载器 (Application ClassLoader)：<strong>它负责加载应用程序的类路径下（classPath）的类</strong>（即 .class 文件）。通常我们直接使用 ClassLoader.getSystemClassLoader() 获取到的就是这个类加载器。它是用户自定义类加载器的默认父类加载器。</li><li>自定义类加载器(CustomizeClassLoader):自定义类继承ClassLoader,实现自定义类加载规则。</li></ul><h3 id="JDK-1-9-的变化">JDK 1.9 的变化</h3><p>在 JDK 1.9 中，类加载器发生了一些变化。<strong>原本的扩展类加载器被重命名为 平台类加载器</strong> (PlatformClassLoader)。<strong>这个新的类加载器主要加载 JDK 平台本身的类库</strong>，<strong>属于 Java 平台模块系统的非核心模块</strong>，而不是 java.* 系列类。平台类加载器的引入是为了配合 JDK 9 的模块化特性。</p><h3 id="类加载器之间的关系">类加载器之间的关系</h3><p>虽然有“双亲委派”的说法，<strong>但其实类加载器之间是通过组合关系来建立父子关系的</strong>。<strong>每个类加载器都有一个 parent 属性</strong>，表示它的父类加载器。当一个类加载器无法加载一个类时，它会委派给父类加载器去尝试加载。</p><h3 id="总结">总结</h3><ul><li><p>JDK 1.8 及之前：</p><ul><li>启动类加载器：加载核心 Java 类。</li><li>扩展类加载器：加载扩展库。</li><li>应用程序类加载器：加载用户类路径下的类。</li></ul></li><li><p>JDK 1.9 及以后：</p><ul><li>扩展类加载器被重命名为 平台类加载器，用于加载非核心模块，配合 Java 模块系统。</li></ul></li></ul><h2 id="什么是-Java-中的-JIT（Just-In-Time）">什么是 Java 中的 JIT（Just-In-Time）?</h2><p>JIT，全称 Just-In-Time，就是<strong>即时编译器</strong>。它的作用是——<strong>在程序运行时，把 Java 字节码动态编译成机器码，让代码执行得更快</strong>。</p><p>原理：</p><ol><li><strong>Java 一开始是解释执行的</strong>，也就是说，JVM 会一边解释字节码、一边执行，所以<strong>效率比较低</strong>。</li><li>但当 JVM 发现某些方法或代码块被频繁执行时，就会把它们<strong>标记为热点代码</strong>（Hotspot Code）</li><li>然后 JIT 编译器就会出手，<strong>把这段热点代码编译成机器码，并缓存起来</strong>。<strong>下次再执行的时候，直接运行机器码</strong>，不用再解释一遍，性能就接近 C++ 那种编译型语言了。</li></ol><h3 id="举个栗子">举个栗子</h3><p>比如有个循环执行上百万次，JVM 发现它很“热”，就会触发 JIT，把这段循环编译成本地机器指令。下次再跑这段循环时，几乎是“原生速度”在执行，快很多。</p><h3 id="JIT-编译优化做了什么？">JIT 编译优化做了什么？</h3><p>JIT <strong>不只是把代码编译成机器码，还会做很多优化</strong>，比如：</p><ul><li>方法内联（Inlining）：<strong>把小方法的代码直接展开，减少方法调用开销</strong>。</li><li>逃逸分析（Escape Analysis）：<strong>判断对象是否只在一个线程中使用，JIT编译器根据对象的逃逸状态采用不同的优化策略，以提高Java程序的性能和效率。</strong></li><li>循环展开（Loop Unrolling）：<strong>减少循环判断次数</strong>，加快执行速度。</li><li><strong>锁消除、标量替换</strong>：进一步减少多线程锁竞争，提高性能。</li></ul><p>这些优化都是在运行时动态完成的，因此 JIT 会越“跑越快”。</p><h3 id="热点代码识别方式：">热点代码识别方式：</h3><p>JIT 会通过两种方式识别热点：</p><ul><li>采样探测：周期性地检测哪些方法经常出现在栈顶；</li><li>计数器探测（HotSpot 采用）：统计方法被调用的次数或循环执行次数，超过阈值就触发编译。</li></ul><h3 id="JIT-编译器类型"><strong>JIT 编译器类型</strong></h3><p>JVM 里其实有两个 JIT 编译器：</p><ul><li>C1（Client）：启动快，适合客户端程序；</li><li>C2（Server）：优化更激进，适合服务器端应用。</li></ul><h3 id="JIT可能带来的问题：">JIT可能带来的问题：</h3><p>虽然 JIT 能显著提高性能，但它也有一些潜在的副作用：</p><ol><li>首次执行慢（编译开销）：<br>热点代码第一次被编译时需要消耗 CPU 时间，会导致程序初期性能波动。</li></ol><p>➤ 解决方案：可以通过“<strong>预热机制</strong>”提前让热点代码运行几次，<strong>让 JIT 提前触发</strong>；或者使用 AOT（Ahead-Of-Time）提前编译。</p><ol start="2"><li>内存占用增加：<br>编译后的机器码会被缓存到内存中，代码越多、占用越大。</li></ol><p>➤ 解决方案：通过 JVM 参数（比如 -XX:ReservedCodeCacheSize）<strong>限制代码缓存大小</strong>。</p><ol start="3"><li>编译与执行争用 CPU 资源：<br>JIT 编译本身也会消耗 CPU，可能在高并发场景下带来瞬时抖动。</li></ol><p>➤ 解决方案：使用分层编译（Tiered Compilation），让 C1 先做轻量编译，C2 后做深度优化，平衡性能与稳定性。</p><h3 id="小结">小结</h3><p>JIT 就是即时编译器，它在 Java 程序运行时，把热点代码动态编译成本地机器码执行。<br>这样程序能越跑越快，性能接近 C++。<br>但它也有缺点，比如首次编译会导致启动慢、占 CPU 和内存，还可能因为过度优化而回退。<br>通常我们通过预热或分层编译（Tiered Compilation）来平衡性能和稳定性。</p><h2 id="JIT-编译后的代码存在哪？">JIT 编译后的代码存在哪？</h2><p>JIT 编译后的机器码会被存放在 <strong>Code Cache（代码缓存区）</strong> 里。<br><strong>这个区域是 JVM 专门为即时编译器（JIT）准备的一块独立内存，用来存放编译生成的本地机器码。</strong></p><ul><li>需要注意的是，Code Cache <strong>不在堆内，也不在方法区（或元空间）里</strong>。</li><li>而 Code Cache 是另外一块独立的本地内存区域，JVM 会在里面缓存 JIT 编译后的机器码，方便后续直接执行。</li></ul><p>Code Cache 的大小和行为<strong>可以通过 JVM 参数来配置</strong>：</p><ul><li>-XX:InitialCodeCacheSize：设置初始大小</li><li>-XX:ReservedCodeCacheSize：设置最大容量</li><li>-XX:+PrintCodeCache：可以打印出当前 Code Cache 的使用信息</li></ul><h3 id="小结-2">小结</h3><p><strong>JIT 编译后的机器码会被放在 JVM 的 Code Cache 区，这是一块独立于堆和元空间的本地内存，用来缓存编译后的机器码，提高执行效率</strong></p><h2 id="什么是-Java-的-AOT（Ahead-Of-Time）？">什么是 Java 的 AOT（Ahead-Of-Time）？</h2><h3 id="什么是AOT">什么是AOT?</h3><p>AOT，全称 Ahead-Of-Time，就是<strong>提前编译</strong>。它和 JIT（即时编译）相反，JIT 是程序运行时才把字节码编译成机器码，<strong>而 AOT 是在程序运行之前，就提前把字节码编译成本地机器码</strong>。</p><h3 id="工作原理：">工作原理：</h3><p>AOT 在编译阶段就会对 Java 字节码进行静态分析，然后生成目标平台能直接执行的机器码，也就是所谓的 Native Image（本地镜像）。<br>这样程序启动时就不需要 JVM 再去解释或即时编译，可以直接运行在操作系统上，启动非常快。</p><h3 id="AOT-的优势：">AOT 的优势：</h3><ul><li>启动快：因为代码已经是<strong>机器码</strong>，不需要再运行时编译，特别适合快速启动的场景，比如云原生、Serverless、微服务。</li><li>内存占用更低：<strong>AOT 编译后的程序不再依赖完整 JVM</strong>，内存占用更少。</li><li><strong>冷启动性能好</strong>：省去了 JIT 的预热阶段，<strong>程序一启动就能达到高性能</strong>。</li></ul><h3 id="AOT-的缺点：">AOT 的缺点：</h3><ul><li><strong>缺乏运行时优化</strong>：JIT 可以根据程序运行时的热点信息动态优化，而 AOT 生成的代码是静态的，<strong>长时间运行的程序性能可能不如 JIT</strong>。</li><li><strong>跨平台性差</strong>：编译后的机器码是平台相关的，<strong>不能像字节码那样“一次编译，到处运行”</strong>。</li><li><strong>灵活性差</strong>：像反射、动态代理、类加载等运行时特性会受到限制，编译时必须都能确定（也就是所谓的“封闭性假设”）。</li></ul><p>使用场景：<br>AOT 一般<strong>用在对启动速度敏感的场景</strong>，比如：</p><ul><li>云原生 / Serverless 应用</li><li>容器化环境、微服务、嵌入式系统</li><li>启动频繁、生命周期短的任务型服务</li></ul><h3 id="常见-AOT-工具：">常见 AOT 工具：</h3><ul><li>GraalVM：目前最主流的 AOT 编译器，能把 Java 程序直接编译成本地可执行文件。</li><li>jaotc：Java 9 引入的官方 AOT 工具，但在生产中使用不多，更多是实验性质。</li></ul><h3 id="小结-3">小结</h3><p>AOT 就是提前编译（Ahead-Of-Time），在程序运行前就把 Java 字节码编译成本地机器码。<br>这样程序启动更快、占用更少，非常适合微服务、云原生、Serverless 这种对启动速度要求高的场景。<br>但它缺点是少了 JIT 的运行时优化，性能长期表现可能不如 JIT，灵活性也更差。<br>常见实现是 GraalVM 的 native image。</p><h2 id="你了解-Java-的逃逸分析吗？">你了解 Java 的逃逸分析吗？</h2><h3 id="什么是逃逸分析">什么是逃逸分析</h3><p>逃逸分析（Escape Analysis）是 JVM 的一种<strong>编译优化技术</strong>，主要用来<strong>判断一个对象是否会逃出当前方法或线程的作用范围</strong>。如果不会逃逸，JVM 就能对它做一系列性能优化，比如<strong>栈上分配、锁消除、标量替换</strong>等。</p><h3 id="核心原理">核心原理</h3><p>JVM 在 JIT 编译阶段，会静态分析对象的使用范围：</p><ul><li>如果<strong>对象只在当前方法内使用，不会被别的线程或外部引用到</strong>，就属于“<strong>不逃逸</strong>”；</li><li>如果<strong>对象作为参数传给别的方法，或被赋值给全局变量、返回给外部</strong>，那就是“<strong>发生了逃逸</strong>”。</li></ul><p>逃逸的本质，就是看<strong>一个对象的生命周期是否“跑出了”原来的作用域</strong>。</p><h3 id="根据逃逸范围分类：">根据逃逸范围分类：</h3><ul><li><strong>方法逃逸</strong>（Arg Escape）：对象被当作参数传递到别的方法；</li><li><strong>线程逃逸</strong>（Global Escape）：对象被多个线程共享，比如赋给静态变量；</li><li><strong>无逃逸</strong>（No Escape）：对象完全只在当前方法中使用。</li></ul><h3 id="JVM-根据逃逸情况会做的三种优化：">JVM 根据逃逸情况会做的三种优化：</h3><ul><li><strong>栈上分配</strong>：<ul><li>如果不逃逸，<strong>JVM 就能直接在栈上分配，而不是在堆上分配</strong>。这样分配速度快，还能减少 GC 压力。</li></ul></li><li>锁消除：<ul><li><strong>如果对象只在单线程内使用，那加的 synchronized 锁其实没意义，JVM 就能自动去掉</strong>。</li></ul></li><li>标量替换：<ul><li>如果对象不逃逸，JVM 可以<strong>把它的字段拆成独立的局部变量</strong>，甚至连对象本身都不创建。</li></ul></li></ul><h3 id="逃逸分析虽然很强，但也有一些问题：">逃逸分析虽然很强，但也有一些问题：</h3><ul><li>它本身是个复杂的分析过程，会<strong>增加编译开销</strong>；</li><li>在某些复杂逻辑中，<strong>分析结果可能不明显</strong>，导致<strong>优化收益不如消耗</strong>；</li><li><strong>所以实际中，逃逸分析对短小高频方法特别有用，但对复杂代码可能收益有限</strong>。</li></ul><h3 id="常见-JVM-参数（了解即可）">常见 JVM 参数（了解即可）</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+DoEscapeAnalysis</span>       <span class="comment"># 开启逃逸分析（默认开启）</span></span><br><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:-DoEscapeAnalysis</span>       <span class="comment"># 关闭逃逸分析</span></span><br><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+EliminateLocks</span>         <span class="comment"># 启用锁消除</span></span><br><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+EliminateAllocations</span>   <span class="comment"># 启用标量替换</span></span><br></pre></td></tr></table></figure><h3 id="小结-4">小结</h3><p>逃逸分析是 JVM 的一种优化技术，用来判断一个对象会不会‘逃出’当前方法或线程。<br>如果对象不会逃逸，JVM 就能做三种优化：<br>一是栈上分配，不用进堆，减少 GC；<br>二是锁消除，去掉没必要的同步；<br>三是标量替换，直接把对象拆成局部变量。<br>简单来说，它能让代码执行更快、内存占用更少，是 JIT 编译器很核心的优化手段。</p><h2 id="Java-中的强引用、软引用、弱引用和虚引用分别是什么？">Java 中的强引用、软引用、弱引用和虚引用分别是什么？</h2><p>在 Java 中，引用分为<strong>强引用、软引用、弱引用和虚引用</strong>四种类型。<br>它们的区别在于——<strong>GC（垃圾回收器）是否以及何时会回收对象</strong>。<br>简单说：强软弱虚，引用越往后，GC 越容易回收。</p><h3 id="强引用（Strong-Reference）">强引用（Strong Reference）</h3><p>这是最常见、也是 Java <strong>默认的引用方式</strong>。<br><strong>只要一个对象有强引用存在，GC 永远不会回收它</strong>，即使内存不足也会宁可抛出OutOfMemoryError。</p><h4 id="特点">特点</h4><ul><li>最普通的 new 出来的对象就是强引用；</li><li>只要引用还在，GC 不会动它。</li></ul><h4 id="举例：">举例：</h4><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span>[] arr = <span class="keyword">new</span> <span class="type">String</span>[]&#123;<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>&#125;;</span><br></pre></td></tr></table></figure><p>这就是典型的强引用。比如在 HashMap 里，键和值默认就是强引用。</p><h3 id="软引用（Soft-Reference）">软引用（Soft Reference）</h3><p>软引用是“<strong>可有可无</strong>”的引用，常用于<strong>缓存</strong>。<br><strong>当系统内存不足时，GC 会优先清理掉软引用指向的对象，以避免 OOM</strong>,内存足够时，不会去管他</p><h4 id="特点-2">特点</h4><ul><li>对象不会立即回收，只有在内存紧张时才清理；</li><li>常用于实现缓存机制，比如图片缓存、对象缓存。</li></ul><h4 id="举例：-2">举例：</h4><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SoftReference&lt;<span class="built_in">Object</span>&gt; softRef = <span class="keyword">new</span> SoftReference&lt;&gt;(<span class="keyword">new</span> <span class="built_in">Object</span>());</span><br></pre></td></tr></table></figure><p>Guava Cache 内部就使用了 SoftReference 来做内存友好的缓存</p><h3 id="弱引用（Weak-Reference）">弱引用（Weak Reference）</h3><p>弱引用比软引用更脆弱。<br><strong>只要 GC 运行，就会回收它，无论内存够不够</strong>。</p><h4 id="特点：">特点：</h4><ul><li>生命周期非常短；</li><li>常用于防止内存泄漏，比如 WeakHashMap、ThreadLocal。</li></ul><h4 id="举例：-3">举例：</h4><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WeakReference&lt;<span class="built_in">Object</span>&gt; weakRef = <span class="keyword">new</span> WeakReference&lt;&gt;(<span class="keyword">new</span> <span class="built_in">Object</span>());</span><br></pre></td></tr></table></figure><p>像 WeakHashMap 中的 key 就是弱引用，当 key 没被外部引用后，会被自动回收，Entry 也随之清除。</p><h3 id="虚引用（Phantom-Reference）">虚引用（Phantom Reference）</h3><p>虚引用最弱，<strong>几乎不影响对象生命周期</strong>。<br><strong>它存在的意义不是访问对象，而是用来“感知对象何时被回收”</strong>。</p><h4 id="特点：-2">特点：</h4><ul><li>不能通过虚引用获取对象；</li><li>通常配合 ReferenceQueue 使用，用于资源清理（比如文件句柄、DirectBuffer）。</li></ul><h4 id="举例：-4">举例：</h4><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PhantomReference&lt;<span class="built_in">Object</span>&gt; phantomRef =</span><br><span class="line">    <span class="keyword">new</span> PhantomReference&lt;&gt;(<span class="keyword">new</span> <span class="built_in">Object</span>(), <span class="keyword">new</span> ReferenceQueue&lt;&gt;());</span><br></pre></td></tr></table></figure><p>当对象被回收后，虚引用会被放入队列中，方便开发者执行资源释放逻辑。</p><h3 id="对比表格">对比表格</h3><table><thead><tr><th>引用类型</th><th>生命周期</th><th>何时被 GC 回收</th><th>典型用途</th></tr></thead><tbody><tr><td>强引用</td><td>最长</td><td>永不（除非引用断开）</td><td>普通对象引用</td></tr><tr><td>软引用</td><td>次长</td><td>内存不足时</td><td>缓存（如图片缓存）</td></tr><tr><td>弱引用</td><td>很短</td><td>一旦 GC 运行</td><td>防止内存泄漏（如 WeakHashMap）</td></tr><tr><td>虚引用</td><td>最短</td><td>几乎立即</td><td>跟踪回收状态、资源清理</td></tr></tbody></table><h3 id="小结-5">小结</h3><p>Java 里的引用分四种：强、软、弱、虚，强度依次减弱。<br>强引用是默认的，只要有它，对象就不会被回收；<br>软引用一般做缓存用，内存不够时才清理；<br>弱引用更弱，GC 一运行就回收，比如 WeakHashMap；<br>虚引用最弱，用来监听对象何时被回收，比如清理 DirectBuffer。<br>一句话总结：越往后越容易被回收。</p><h2 id="Java-中常见的垃圾收集器有哪些？">Java 中常见的垃圾收集器有哪些？</h2><p>在JVM中，垃圾回收器是实现垃圾回收算法的具体工具，主要分为处理年轻代和老年代的回收器。除了G1，其他回收器一般需要成对使用。常见的垃圾回收器主要包括以下几类：</p><ol><li><p><strong>Serial 和 Serial Old</strong>：这是<strong>最基础的串行垃圾回收器，单线程工作</strong>。它适合资源受限的客户端程序，虽然简单但在多核系统下效率不高。</p></li><li><p><strong>ParNew 和 CMS (Concurrent Mark Sweep)</strong> ：ParNew <strong>是 Serial 的多线程版本</strong>，<strong>CMS 关注的是减少系统停顿时间，它能在用户线程运行的同时并发进行垃圾回收</strong>。不过 CMS 会有“浮动垃圾”、内存碎片以及退化成Full GC的问题。</p></li><li><p><strong>Parallel Scavenge 和 Parallel Old (PS + PO)</strong> ：<strong>这是 JDK8 默认使用的回收器组合</strong>，采用<strong>多线程方式</strong>，追求高吞吐量，适合后台批处理任务等场景。但它的暂停时间较长，不太适合对响应时间要求高的业务。</p></li><li><p><strong>G1 (Garbage First)</strong> ：<strong>G1 是 JDK9 之后的默认回收器</strong>，<strong>它可以同时处理年轻代和老年代，采用分区+并发回收机制</strong>，能很好地控制最大停顿时间。适合大内存的服务端应用，比如堆内存 6G 以上的场景。</p></li><li><p><strong>Shenandoah</strong>：由 RedHat 开发，<strong>主打低停顿</strong>，连“整理”这一阶段都可以并发执行，因此无论堆大小如何，停顿时间都可以非常低。</p></li><li><p><strong>ZGC</strong>：是<strong>更进一步的低延迟回收器</strong>，号称 STW 停顿不会超过 1ms，而且支持从几百兆到 16TB 的堆内存扩展，适合超大内存和延迟非常敏感的系统。</p></li></ol><p>总结一句话：<br>JDK8 之前推荐用 CMS 或 PS+PO，JDK9 之后推荐 G1；如果对延迟非常敏感，可以选择 Shenandoah 或 ZGC。</p><p><strong>对比一下 G1、Shenandoah 和 ZGC 这三款垃圾回收器</strong></p><p>G1、Shenandoah 和 ZGC 都是现代 Java 的低延迟 GC 回收器。</p><ul><li>G1 将堆划分为 Region，通过并发标记和 STW 压缩来减少 full GC，适合通用场景；</li><li>Shenandoah 实现了并发压缩，通过转发表解决引用更新问题，可将 GC 停顿控制在毫秒级；</li><li>ZGC 采用 colored pointer 技术，实现了全并发、几乎全程无停顿的 GC，停顿时间低于 1ms，适用于延迟极敏感的大型系统。</li></ul><table><thead><tr><th>回收器</th><th>一句话记住它</th></tr></thead><tbody><tr><td>G1 GC</td><td><strong>区域化管理，目标是均衡停顿和吞吐</strong></td></tr><tr><td>Shenandoah</td><td><strong>并发压缩，目标是最小停顿（MS 级）</strong></td></tr><tr><td>ZGC</td><td><strong>染色指针，全并发回收，目标是亚毫秒级停顿</strong></td></tr></tbody></table><h2 id="Java-中如何判断对象是否是垃圾？不同实现方式有何区别？">Java 中如何判断对象是否是垃圾？不同实现方式有何区别？</h2><p>其实在 JVM 中，为了判断堆里的对象还能不能继续使用，主要用的是一种叫“可达性分析”的方法。</p><ul><li><p>早期也有一种方法叫“<strong>引用计数法</strong>”，就是每个对象维护一个<strong>计数器</strong>，<strong>每次被别的对象引用时加一，引用断了就减一。如果计数器变成 0，就说明没人再引用它了，可以回收了</strong>。这种方法实现简单、逻辑也直观，但有一个很大的问题：<strong>循环引用</strong>。<strong>比如对象 A 引用 B，B 也引用 A，虽然它们已经不再被程序其他地方引用，但它们互相指着对方，引用计数就永远不是 0</strong>，这样就会造成<strong>内存泄漏</strong>。</p></li><li><p>所以 Java 后来改用<strong>可达性分析算法</strong>（Reachability Analysis），这是一种从一组“<strong>GC Root</strong>”对象出发，看一个对象是不是还能被这些根对象“追踪”到的方式。<strong>如果一个对象从 GC Root 开始，一路沿着引用链可以走到，那说明它还在被用，就不能回收；反过来，如果走不到，就是“不可达”，可以回收</strong>。这种方法的好处是能很自然地处理掉循环引用的问题。</p></li></ul><blockquote><p>什么是GC Root</p></blockquote><p>GC Root 通常包括像：当前线程正在运行的方法栈、静态变量、类加载器、本地方法引用等。</p><h3 id="小结-6">小结</h3><p><strong>重点记住“引用计数有循环引用问题”、“可达性分析是 Java 的选择”这两个点就够了。</strong></p><h2 id="为什么-Java-的垃圾收集器将堆分为老年代和新生代？">为什么 Java 的垃圾收集器将堆分为老年代和新生代？</h2><p>Java 堆之所以要分为新生代（Young Generation）和老年代（Old Generation），<br><strong>核心目的是：优化 GC 性能。不同生命周期的对象放在一起回收效率太低，分代后可以“有针对性地清理”，大幅提升回收效率。</strong></p><h3 id="为什么要分代？">为什么要分代？</h3><p>在 Java 程序运行过程中，对象的生命周期差异很大，有的“朝生夕死”，有的会长期存在。</p><p>绝大多数对象存活时间很短：例如临时变量、方法中的局部对象，往往用一次就没了。<br>→ 这些短命对象集中放在新生代，用轻量的算法快速清理。</p><p>少数对象生命周期很长：比如缓存、线程池、单例等，长期存在。<br>→ 这类对象被晋升到老年代，使用更稳定的算法回收，避免频繁扫描。</p><ul><li>即：不同“寿命”的对象放在不同区域，<strong>GC 时就能有针对性地处理，提升整体性能</strong>。</li></ul><h3 id="堆的分代结构">堆的分代结构</h3><p>Java 堆（Heap）根据对象的生命周期分为三块：</p><ul><li>新生代（Young Generation）：存放新创建的对象；</li><li>老年代（Old Generation）：存放存活时间较长的对象；</li><li>永久代 / 元空间（Metaspace）：存放类元数据（方法、静态变量等）。</li></ul><h3 id="新生代结构">新生代结构</h3><p>新生代又细分为三块：</p><ul><li>Eden 区：新对象优先分配在这里；</li><li>Survivor0（S0）和 Survivor1（S1）：两个 Survivor 区轮流使用。</li></ul><p>GC 时，Eden 区中还活着的对象会被复制到一个 Survivor 区，<br>当对象在多次 GC 后仍然存活，就会晋升（Promote）到老年代。<br>新生代一般采用 复制算法（Copying GC），清理速度快、内存碎片少，适合短生命周期对象。</p><h3 id="老年代的作用">老年代的作用</h3><p>老年代用于存放长期存活或较大对象，GC 频率较低。<br><strong>通常采用 标记-清除（Mark-Sweep） 或 标记-整理（Mark-Compact） 算法。</strong><br>这类算法能最大限度地回收空间，但执行时间较长。</p><h3 id="小结：">小结：</h3><p>Java 把堆分成新生代和老年代是<strong>为了提升 GC 效率</strong>。<br><strong>因为大部分对象‘朝生夕死’，只活一会儿，就放在新生代，用轻量算法快速清理。</strong><br><strong>而少量长期存在的对象，比如缓存和单例，会晋升到老年代，用更稳定的标记清除算法处理。</strong><br>这样既减少扫描范围，又能让 GC 更高效。</p><h2 id="为什么-Java-8-移除了永久代（PermGen）并引入了元空间（Metaspace）？">为什么 Java 8 移除了永久代（PermGen）并引入了元空间（Metaspace）？</h2><p>Java 8 移除永久代（PermGen），引入元空间（Metaspace），<br>是为了解决<strong>PermGen 固定大小、易导致 OOM、GC 效率低等问题</strong>，让类元数据的存储更灵活高效。</p><h3 id="PermGen-的问题与局限">PermGen 的问题与局限</h3><p>永久代是 HotSpot 虚拟机在 Java 7 及之前版本中用于存储<strong>类的元信息（类名、方法、常量池等）</strong> 的一块 JVM 内存区域。<br>但这种设计存在不少缺：</p><ul><li><strong>固定大小，不可动态扩展</strong><ul><li>永久代的大小需要在 JVM 启动时固定设置（通过 -XX:MaxPermSize），如果类加载过多（如动态加载、反射、大量 JSP），很容易触发 OutOfMemoryError: PermGen space。</li></ul></li><li><strong>存储内容复杂，容易混乱</strong><ul><li>PermGen <strong>既保存类信息，又存储静态变量、常量池等数据</strong>，不仅容易造成空间竞争，还让 GC 难以优化。</li></ul></li><li>GC 效率低<ul><li><strong>永久代的数据大多是长期存在的类元信息</strong>，GC 很难高效回收，<strong>容易频繁触发 Full GC</strong>，尤其在应用频繁加载类或热部署时问题更明显。</li></ul></li></ul><p><strong>一句话总结 PermGen 的痛点：固定大小 + 内存受限 + GC 慢 + 容易 OOM。</strong></p><h3 id="Metaspace-的改进与优势">Metaspace 的改进与优势</h3><ol><li>使用本地内存（Native Memory）<br><strong>元空间不再使用 JVM 堆内存，而是使用本地内存</strong>。</li></ol><ul><li>理论上只受操作系统内存限制，更灵活、更不容易 OOM。</li></ul><ol start="2"><li>自动扩容</li></ol><ul><li>元空间可以根据类加载的实际需求<strong>自动增长大小</strong>，减少了手动设置内存的麻烦，同时降低了内存管理风险。</li></ul><ol start="3"><li><p>GC 效率更高<br><strong>元空间中的类元数据与堆分离，GC 在扫描堆对象时更轻量</strong>，同时降低 Full GC 频率，提高 JVM 性能。</p></li><li><p>跨平台与统一性<br>HotSpot 与 JRockit 在此之前实现不同，Java 8 将两者合并时选择了移除 PermGen，统一为 Metaspace。</p></li></ol><h3 id="如何调整元空间大小">如何调整元空间大小</h3><p>虽然元空间可动态增长，但仍可通过参数手动控制：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:MetaspaceSize=</span>128M       <span class="comment"># 元空间初始大小</span></span><br><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:MaxMetaspaceSize=</span>512M    <span class="comment"># 元空间最大上限</span></span><br></pre></td></tr></table></figure><h3 id="表格对比">表格对比</h3><table><thead><tr><th>对比项</th><th>永久代（PermGen）</th><th>元空间（Metaspace）</th></tr></thead><tbody><tr><td>存储位置</td><td>JVM 堆内存</td><td>本地内存（Native）</td></tr><tr><td>是否可扩展</td><td>否，大小固定</td><td>是，可根据需要自动扩展</td></tr><tr><td>常见问题</td><td>容易 OOM、GC 低效</td><td>更灵活，OOM 几率更低</td></tr><tr><td>JVM 版本</td><td>Java 7 及之前</td><td>Java 8 及之后</td></tr></tbody></table><h3 id="小结-7">小结</h3><p>Java 8 把永久代移除掉，换成元空间，<strong>主要是为了解决内存固定、OOM 和 GC 效率低的问题</strong>。<br>永久代的大小是固定的，类加载多了就容易溢出；<br>而元空间用的是<strong>本地内存</strong>，能根据需要<strong>自动扩展</strong>，管理更灵活，性能也更好。<br>同时它还降低了 Full GC 触发的概率，整体上让 JVM 的内存管理更稳定。</p><h2 id="为什么-Java-新生代被划分为-S0、S1-和-Eden-区？">为什么 Java 新生代被划分为 S0、S1 和 Eden 区？</h2><p>Java 把新生代划分为 Eden、S0（Survivor 0）和 S1（Survivor 1） 三个区，<br>核心目的是：<strong>提高内存利用率</strong>，配合复制算法实现高效的 Minor GC（年轻代垃圾回收）。</p><h3 id="为什么要分区？">为什么要分区？</h3><p>在 JVM 的新生代中，大多数对象“朝生夕死”，即生命周期很短。<br>JVM 使用 复制算法（Copying GC） 来高效清理这部分内存。<br>复制算法的基本思想是：</p><ul><li>每次只使用一半内存，当发生 GC 时，把存活的对象复制到另一半，然后一次性清理原区域。</li></ul><p>这个方法非常高效，但有个问题：<br>如果只用两块区域，一块存放对象，一块作为复制目标，那每次只有 50% 的内存被使用，<strong>利用率太低</strong>。<br>于是，Java 采用了“三分法”：<strong>Eden + Survivor0（S0）+ Survivor1（S1）</strong>，在保证复制安全的前提下，<strong>把内存利用率从 50% 提高到了 90%</strong>。</p><h3 id="分区结构与比例">分区结构与比例</h3><p>默认情况下，新生代的比例为：Eden : S0 : S1 = 8 : 1 : 1<br>也就是说：</p><ul><li>Eden 占新生代的约 80%；</li><li>两个 Survivor 区各占约 10%。</li><li>内存利用率 = 90%，因为只有一个 Survivor 是备用区。</li></ul><h3 id="GC时的工作流程">GC时的工作流程</h3><ol><li>新对象首先分配在 Eden 区。</li><li>当 Eden 区满时触发 Minor GC：</li></ol><ul><li>JVM 会把 Eden + 正在使用的 Survivor 区 中还存活的对象复制到另一个空闲的 Survivor 区。</li><li>Eden 和旧 Survivor 区会被清空。</li></ul><ol start="3"><li>两个 Survivor 区轮流使用（S0↔S1），达到“翻转”效果。</li><li>当对象在 Survivor 区经历多次 GC 后仍然存活，会晋升到 老年代（Old Gen）。</li></ol><p>整个过程称为 <strong>复制-清空-切换</strong>（Copy-Clear-Swap），保证了：</p><ul><li>快速分配（因为 Eden 连续分配，指针移动即可）；</li><li>无内存碎片（复制算法本身保证连续性）；</li><li>高内存利用率（90% 使用率）。</li></ul><h3 id="如果-Survivor-放不下怎么办？">如果 Survivor 放不下怎么办？</h3><p><strong>当 Survivor 空间不足时，幸存的对象会直接晋升到老年代</strong>。<br>这就是所谓的“<strong>提前晋升</strong>（Premature Promotion）”，<br>频繁出现会导致 老年代压力增加、触发 Full GC，所以 Survivor 的合理大小非常重要。</p><h3 id="小结-8">小结</h3><p>新生代分成 Eden、S0 和 S1，是<strong>为了配合复制算法优化内存利用率</strong>。<br>对象先放在 Eden，GC 时把活着的对象复制到另一个 Survivor 区，两个 Survivor 轮流用。<br>这样只需要一块备用空间，就能让内存利用率达到 90%，同时避免内存碎片。<br>简单说，就是为了让年轻代的 GC 又快又省空间。</p><h2 id="什么是三色标记算法？">什么是三色标记算法？</h2><p>三色标记算法是 JVM 并发垃圾回收中用来区分对象状态的算法。<br>它把对象分成三种颜色：<strong>白色表示没访问过、可能是垃圾；灰色表示正在扫描；黑色表示已经扫描完成的活对象</strong>。<br>GC 从根对象开始，把引用的对象标记成灰色，然后逐步转黑，最后剩下的白色对象就会被清除。<br>具体流程：</p><ol><li>所有对象初始为白色。</li><li>根对象被标为灰色 → 遍历它的引用。</li><li>遍历时发现其他对象 → 标为灰色。</li><li>被完全扫描完的灰色 → 转为黑色。</li><li>最终白色的对象无人引用 → GC 清除。</li></ol><ul><li>这个过程循环往复，直到堆中只剩黑色对象。<br>这种方式<strong>可以让 GC 和应用线程同时工作，减少停顿时间</strong>，在 CMS 和 G1 收集器里都用了它。</li></ul><h3 id="三色标记中可能出现漏标问题和多标问题">三色标记中可能出现漏标问题和多标问题</h3><ul><li>漏标问题，就是说一个对象本来应该是黑色存活对象，但是没有被正确的标记上，导致被错误的垃圾回收掉了。</li><li>多标：就是这个对象原本应该被回收掉的白色对象，但是被错误的标记成了黑色的存活对象。从而导致这个对象没有被GC回收掉。<ul><li>多标的话，会产生<strong>浮动垃圾</strong>，这个问题一般都不太需要解决，因为这种垃圾一般都不会太多，另外在下一次GC的时候也都能被回收掉。</li></ul></li></ul><p>漏标问题解决方法：<br>具体的解决方式，在CMS和G1中也不太一样。<strong>CMS采用的是增量更新方案，G1则采用的是原始快照的方案。</strong></p><h2 id="Java-中的-young-GC、old-GC、full-GC-和-mixed-GC-的区别是什么？">Java 中的 young GC、old GC、full GC 和 mixed GC 的区别是什么？</h2><p>Java 中的 GC 根据回收范围不同，可以分为 Young GC（Minor GC）、Old GC（Major GC）、Full GC 和 Mixed GC。<br>它们的区别主要在于：<strong>回收区域不同、触发条件不同、执行代价不同</strong>。</p><h3 id="Young-GC（年轻代垃圾回收）又称Minor-GC-或-YGC">Young GC（年轻代垃圾回收）又称Minor GC 或 YGC</h3><ul><li>作用范围：<ul><li>只回收 新生代（Eden + Survivor0 + Survivor1） 的对象。</li></ul></li><li>触发条件：<ul><li>当 Eden 区空间满了，无法再为新对象分配内存时触发。</li></ul></li><li>执行特性：<ul><li>新生代对象“朝生夕死”，大多数是短命对象；</li><li>回收速度快，采用复制算法（Copying GC）；</li><li>回收频率高但耗时短。</li></ul></li></ul><p><strong>一句话总结：Young GC 就像清理临时文件，清得勤但快。</strong></p><h3 id="Old-GC（老年代垃圾回收）又称Major-GC-或-OGC">Old GC（老年代垃圾回收）又称Major GC 或 OGC</h3><ul><li>作用范围：<ul><li>只回收 老年代（Old Generation）。</li></ul></li><li>触发条件：<ul><li>老年代空间不足；</li><li>或新生代晋升的对象太多，挤爆老年代。</li></ul></li><li>执行特性：<ul><li>对象存活时间长，数量多；</li><li>通常使用 标记-清除（Mark-Sweep）或标记-整理（Mark-Compact）算法；</li><li>执行频率低，但时间更长。</li></ul></li></ul><p><strong>一句话总结：Old GC 是大扫除，执行慢，但必要时得做</strong>。</p><p>Full GC（全堆垃圾回收）</p><ul><li>作用范围：<ul><li>同时回收 新生代 + 老年代 + 方法区（Metaspace）。</li></ul></li><li>触发条件：<ul><li>老年代空间不足，且 old GC 后仍无法释放足够内存；</li><li>永久代或者元空间不足；</li><li>手动调用 System.gc()；</li><li>年轻代晋升到老年代失败。</li></ul></li><li>执行特性：<ul><li>会暂停所有应用线程（Stop-The-World）；</li><li>耗时最长，对系统性能影响最大；</li><li>通常需要尽量避免。<br><strong>一句话总结：Full GC 是“系统级停机维护”，代价最高，非不得已别触发。</strong></li></ul></li></ul><h3 id="Mixed-GC（混合垃圾回收）">Mixed GC（混合垃圾回收）</h3><ul><li>出现版本：<ul><li>仅存在于 G1（Garbage First）收集器 中。</li></ul></li><li>作用范围：<ul><li>同时回收 整个新生代 + 部分老年代（不是全老年代）。</li></ul></li><li>触发条件：<ul><li>G1 在执行一定次数的 Young GC 后，老年代占用比例达到阈值（默认约 45%）时触发。</li><li>执行特性：</li><li>回收效率高；</li><li>通过选取“回收收益高的 Region”进行混合回收；</li><li>可控制停顿时间，减少 全堆垃圾回收 频率。</li></ul></li></ul><p><strong>一句话总结：Mixed GC 是 G1 的“智能混合回收”，在性能与停顿之间做平衡。</strong></p><h3 id="总结表格">总结表格</h3><table><thead><tr><th>GC 类型</th><th>回收范围</th><th>触发条件</th><th>执行频率</th><th>影响程度</th></tr></thead><tbody><tr><td><strong>Young GC</strong></td><td>新生代</td><td>Eden 区满</td><td>高</td><td>低</td></tr><tr><td><strong>Old GC</strong></td><td>老年代</td><td>老年代满 / 晋升太多</td><td>中</td><td>中</td></tr><tr><td><strong>Full GC</strong></td><td>新生代 + 老年代 + 元空间</td><td>堆内存或元空间不足 / System.gc()</td><td>低</td><td>高</td></tr><tr><td><strong>Mixed GC</strong></td><td>新生代 + 部分老年代（G1）</td><td>G1 老年代占用率超阈值</td><td>中</td><td>中偏低</td></tr></tbody></table><h3 id="小结-9">小结</h3><p>Java 的 GC 主要分四种：</p><ul><li>Young GC 回收新生代，触发快、耗时短；</li><li>Old GC 回收老年代，频率低但耗时长；</li><li>Full GC 是全堆回收，最耗时，一般要尽量避免；</li><li>Mixed GC 是 G1 独有的，它会同时回收新生代和部分老年代，在性能和停顿时间之间取得平衡。</li></ul><h2 id="什么条件会触发-Java-的-young-GC？">什么条件会触发 Java 的 young GC？</h2><ul><li>当 Eden 区空间满了</li><li>无法再为新对象分配内存时</li><li>部分垃圾回收器在Full GC之前先youngGC</li></ul><h2 id="什么情况下会触发-Java-的-Full-GC？">什么情况下会触发 Java 的 Full GC？</h2><ul><li>老年代空间不足，且 old GC 后仍无法释放足够内存；</li><li>永久代或者元空间不足；</li><li>手动调用 System.gc()；</li><li>年轻代晋升到老年代失败。</li></ul><h2 id="什么是-Java-的-PLAB？">什么是 Java 的 PLAB？</h2><p>PLAB <strong>是 JVM 在垃圾回收时的一种优化机制</strong>，主要<strong>用在对象从新生代晋升到老年代的过程中</strong>。<br><strong>GC 是多线程执行的，为了避免多个线程同时去申请老年代空间而竞争，JVM 给每个 GC 线程分配了一块本地缓冲区，也就是 PLAB。</strong><br><strong>线程在晋升对象时直接在自己的 PLAB 中分配，速度更快，也避免了锁冲突。</strong></p><h3 id="TLAB-vs-PLAB">TLAB vs PLAB</h3><p>简单来说，<strong>TLAB 是运行时线程分配对象的缓冲区，加快对象创建。</strong>，<strong>PLAB 是 GC 时晋升对象的缓冲区，加快垃圾回收。</strong></p><table><thead><tr><th>对比项</th><th><strong>TLAB</strong></th><th><strong>PLAB</strong></th></tr></thead><tbody><tr><td>所属阶段</td><td>正常运行时</td><td>垃圾回收时</td></tr><tr><td>使用线程</td><td>应用线程（App Thread）</td><td>GC 工作线程</td></tr><tr><td>分配区域</td><td>新生代（Eden 区）</td><td>老年代（Old Generation）</td></tr><tr><td>作用目标</td><td>加速普通对象的创建</td><td>加速对象晋升的分配</td></tr><tr><td>优化点</td><td>避免线程同步</td><td>避免 GC 线程竞争</td></tr></tbody></table><h2 id="JVM-垃圾回收时产生的-concurrent-mode-failure-的原因是什么？">JVM 垃圾回收时产生的 concurrent mode failure 的原因是什么？</h2><p>Concurrent Mode Failure（并发模式失败） 是<strong>在使用 CMS 垃圾回收器 时的一种失败现象</strong>，<br><strong>它表示 CMS 在并发回收阶段没来得及回收出足够的老年代空间</strong>，<br><strong>导致新对象或晋升对象无法分配，从而 退化为 Full GC</strong>，造成明显的性能抖动。</p><p>可以总结为一句话：</p><ul><li>“CMS 回收太慢，程序分配太快，老年代撑不住了。”</li></ul><p>更细地说主要有以下几类情况：</p><ol><li>老年代空间不足</li></ol><ul><li>当 CMS 正在并发回收时，如果老年代中没有足够的可用空间分配新对象或晋升对象，就会触发 concurrent mode failure。</li></ul><ol start="2"><li>对象晋升过快（晋升风暴）</li></ol><ul><li>年轻代晋升对象太多、太频繁，老年代来不及回收，空间被迅速吃光。</li></ul><ol start="3"><li>长生命周期对象过多</li></ol><ul><li>应用中存在大量长期存活的对象（缓存、连接池等），占满老年代，回收压力持续存在。</li></ul><ol start="4"><li>CMS 触发太晚</li></ol><ul><li>CMS 默认在老年代使用率达到约 92% 才启动（由参数XX:CMSInitiatingOccupancyFraction 控制），启动太迟可能回收不及，从而失败。</li></ul><ol start="5"><li>参数配置不合理 / 碎片过多</li></ol><ul><li>老年代空间碎片化严重（CMS 是标记-清除算法），可用内存虽多但无法连续分配大对象。</li></ul><h3 id="CMS-的工作原理简述">CMS 的工作原理简述</h3><p>CMS 的工作流程分为四个阶段：</p><ol><li>初始标记（Initial Mark）：标记与 GC Roots 直接关联的对象。</li><li>并发标记（Concurrent Mark）：和应用线程并行，标记可达对象。</li><li>重新标记（Remark）：修正上一步漏标或错标的对象。</li><li>并发清除（Concurrent Sweep）：清理垃圾对象空间，与应用线程并发执行。</li></ol><p>在并发清除阶段应用线程仍在运行，如果这时分配需求过高或清理不及时，就容易触发 concurrent mode failure。</p><h3 id="常见的优化措施">常见的优化措施</h3><ol><li>提早触发 CMS 回收</li></ol><ul><li>通过降低参数 -XX:CMSInitiatingOccupancyFraction（例如 70），</li><li>让 CMS 更早开始回收，留出充足的缓冲时间。</li></ul><ol start="2"><li>增加老年代空间</li></ol><ul><li>通过调大 -Xmx 或调整 -XX:NewRatio，为老年代分配更多空间。</li></ul><ol start="3"><li>减少晋升压力</li></ol><ul><li>调大年轻代空间（减少对象晋升频率）；</li><li>优化对象生命周期，减少短命对象进入老年代。</li></ul><ol start="4"><li>降低碎片影响</li></ol><ul><li>开启 -XX:+UseCMSCompactAtFullCollection，在 Full GC 时整理碎片；</li><li>或使用更现代的收集器（如 G1）。</li></ul><ol start="5"><li>监控与调优</li></ol><ul><li>通过 jstat -gcutil、-XX:+PrintGCDetails 等参数观察 CMS 触发频率和老年代使用情况。</li></ul><h3 id="小结：-2">小结：</h3><p>Concurrent Mode Failure 是在<strong>使用 CMS 垃圾回收器时，老年代在并发回收阶段来不及回收出足够的空间</strong>，<strong>导致新对象或晋升对象无法分配，只能退化执行 Full GC 的情况</strong>。</p><ul><li>常见原因包括<strong>老年代空间太小、晋升太快、CMS 触发太晚或内存碎片严重</strong>。</li><li>优化可以通过<strong>提前触发 CMS、加大老年代空间、减少晋升频率或开启内存压缩</strong>来避免。</li></ul><h2 id="为什么-Java-中-CMS-垃圾收集器在发生-Concurrent-Mode-Failure-时的-Full-GC-是单线程的？">为什么 Java 中 CMS 垃圾收集器在发生 Concurrent Mode Failure 时的 Full GC 是单线程的？</h2><p>因为 CMS 在设计上<strong>只负责并发回收老年代</strong>，<strong>它的备用 Full GC 是由 Serial Old 收集器 执行的</strong>。<br>Serial Old 是单线程的，所以当 CMS 发生 Concurrent Mode Failure 时，JVM 会退化到单线程 Full GC。<br>这主要是历史原因：<strong>CMS 最初是为低延迟设计的，不追求并行性能</strong>，而后来开发资源又转向了 G1，因此没有为 CMS 的 Full GC 实现多线程版本。</p><h2 id="为什么-Java-中某些新生代和老年代的垃圾收集器不能组合使用？比如-ParNew-和-Parallel-Old">为什么 Java 中某些新生代和老年代的垃圾收集器不能组合使用？比如 ParNew 和 Parallel Old</h2><p><strong>不同的 GC 不能随意组合，是因为它们的底层框架和设计目标不同</strong>。<br>比如 ParNew 属于老的 GC 框架，而 Parallel Old 属于新的 Parallel 框架，<br>两者的数据结构、线程模型和内存管理逻辑都不兼容。</p><ul><li>就像汽车组装，ParNew 是日系引擎接口，Parallel Old 是美系变速箱接口，<br>连接口规格不同，插上去也跑不了。</li></ul><p>ParNew 只能和 CMS 或 Serial Old 搭配，而 Parallel Scavenge 只能和 Parallel Old 一起用。<br><strong>强行组合不仅会性能下降，还可能导致内存布局和晋升逻辑出错</strong>。</p><h2 id="JVM-新生代垃圾回收如何避免全堆扫描？">JVM 新生代垃圾回收如何避免全堆扫描？</h2><p>新生代 GC 之所以不会“误删”被老年代引用的新生代对象，<br>是因为 JVM 使用了 <strong>写屏障</strong>（Write Barrier） + <strong>卡表</strong>（Card Table） 两个机制来跟踪这种引用关系。<br><strong>这样在 Minor GC 时，只需扫描标记过的“脏卡”，而不是整个老年代。</strong></p><h3 id="为什么会有“跨代引用”问题？">为什么会有“跨代引用”问题？</h3><p>当 JVM 做 Minor GC（回收新生代）时，只扫描新生代对象。但如果有一个<strong>老年代对象 A 引用了新生代对象 B</strong>，而 GC 只扫描新生代范围，就可能<strong>误以为 B 没被引用，错误回收</strong>。</p><h3 id="解决方案：卡表（Card-Table）-写屏障（Write-Barrier）">解决方案：卡表（Card Table）+ 写屏障（Write Barrier）</h3><p>JVM 为了解决这个问题，引入了两个关键机制</p><ol><li>写屏障（Write Barrier）</li></ol><ul><li>是在“引用写入操作”时触发的一段特殊逻辑。</li><li>当老年代对象要引用一个新生代对象时，写屏障机制会自动记录这次跨代引用。</li><li>类似 Spring AOP 的“切面”，在赋值语句时自动插入监控逻辑。<br>例如：</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">oldObj.field</span> = youngObj<span class="comment">; </span></span><br></pre></td></tr></table></figure><p>执行这行代码时，写屏障会被触发，<br>告诉 JVM：“兄弟，这个老年代对象引用了一个新生代对象。”</p><ol start="2"><li>卡表机制（Card Table）</li></ol><ul><li>JVM 将老年代的内存划分成许多小区域（称为卡页，Card）， 每个卡页一般对应 <strong>512 字节</strong>。</li><li>当某个卡页内的对象引用了新生代对象，JVM 会把该卡页对应的卡表项标记为“<strong>脏卡</strong>（Dirty Card）”。</li></ul><p>所以：</p><ul><li>“卡表”其实是一个字节数组；</li><li>0 表示“干净”（没跨代引用），非 0 表示“脏”（存在跨代引用）。</li></ul><h3 id="Minor-GC-时的工作流程">Minor GC 时的工作流程</h3><p>当触发 Minor GC 时：</p><ol><li>扫描卡表，找到所有标记为“脏卡”的老年代区域。</li><li>只扫描这些脏卡中的对象，检查是否引用了新生代对象。</li><li>把这些被引用的新生代对象标记为存活对象，<br>确保它们不会被错误回收。</li></ol><p>因此：</p><blockquote><p>JVM 不需要扫描整个老年代，只需关注少量脏卡，大大提高了 GC 效率，同时避免了“误删对象”的风险。</p></blockquote><table><thead><tr><th>机制</th><th>作用</th></tr></thead><tbody><tr><td><strong>写屏障</strong></td><td>拦截引用写操作，检测跨代引用发生的时刻</td></tr><tr><td><strong>卡表</strong></td><td>记录老年代哪些内存区域存在跨代引用</td></tr><tr><td><strong>Minor GC 时扫描脏卡</strong></td><td>保证被老年代引用的新生代对象不会被错误回收</td></tr></tbody></table><p>优点：</p><ul><li>避免全堆扫描</li><li>减少 GC 停顿时间</li><li>确保引用正确性</li></ul><h3 id="小结-10">小结</h3><p>新生代 GC 之所以不会误删被老年代引用的对象，是因为 JVM 在对象赋值时会触发 <strong>写屏障</strong>机制，自动记录老年代引用新生代的情况。</p><p>JVM 会把这些内存区域在 <strong>卡表</strong> 中标记为‘脏卡’，下次 Minor GC 时只需扫描这些脏卡，就能找到所有跨代引用，避免错误回收并提高效率。</p><h2 id="Java-的-CMS-垃圾回收器和-G1-垃圾回收器在记忆集的维护上有什么不同？">Java 的 CMS 垃圾回收器和 G1 垃圾回收器在记忆集的维护上有什么不同？</h2><p>CMS 和 G1 都需要记住跨代引用（防止老年代引用新生代对象被误回收），<br>但它们在“记忆集”的实现方式和粒度上完全不同：</p><ul><li><strong>CMS 用卡表（Card Table）实现，粒度粗，结构简单</strong>；</li><li><strong>G1 用记忆集（Remembered Set, RSet），粒度细到 Region 级，更精确但更复杂</strong>。</li></ul><p>CMS 的记忆集机制<br>CMS 使用 卡表（Card Table） 来记录跨代引用，<br>其实它就是一种“简化版的记忆集”，实现思路如下：</p><ol><li><p>原理：<br>当老年代对象引用了新生代对象时，触发 <strong>写屏障</strong>（Write Barrier）。<br>JVM 会将老年代中对应的卡页（Card）标记为“<strong>脏卡</strong>（Dirty Card）”。</p></li><li><p>数据结构：</p></li></ol><ul><li>每个卡页对应约 512 字节的老年代内存；</li><li>卡表中一个字节标记一个卡页是否含有跨代引用。</li></ul><ol start="3"><li><p>GC 时行为：<br>Minor GC 扫描卡表中被标记为“脏卡”的部分，<br>只扫描这些区域，而不是整个老年代，从而避免全堆扫描。</p></li><li><p>特点总结：<br>优点 实现简单，开销小；<br>缺点 粒度粗，一张“脏卡”里可能包含多个无关对象，精度不高。</p></li></ol><h3 id="G1-的记忆集机制">G1 的记忆集机制</h3><p>G1 的设计更复杂，它采用真正意义上的<strong>多层记忆集</strong>（Remembered Set, RSet）。</p><ol><li>原理：</li></ol><ul><li>G1 把堆划分为多个小的 Region（一般几 MB）。</li><li>每个 Region 都有自己的记忆集，用来记录“哪些其他 Region 中的对象引用了我”。</li><li>当某个对象在不同 Region 间发生引用时，写屏障会更新对应的 RSet。</li></ul><ol start="2"><li>数据结构：</li></ol><ul><li>每个 RSet 里维护的是一组“卡表条目（Card Table Entry）”，它指向引用该 Region 的其他 Region 的具体卡页。</li><li>这是一种“Region 粒度”的多对多关系映射。</li></ul><ol start="3"><li>GC 时行为：</li></ol><ul><li>G1 只扫描与目标 Region 的 RSet 有关联的 Region，这样可以做到非常精确的增量式回收。</li></ul><ol start="4"><li>特点总结：</li></ol><ul><li>优点：<ul><li>粒度细、定位精准；</li><li>支持 Region 之间的并发回收；</li></ul></li><li>缺点：<ul><li>维护成本更高，内存与 CPU 开销更大。</li></ul></li></ul><h3 id="对比总结">对比总结</h3><table><thead><tr><th>对比项</th><th>CMS</th><th>G1</th></tr></thead><tbody><tr><td><strong>实现形式</strong></td><td>卡表（Card Table）</td><td>记忆集（Remembered Set）</td></tr><tr><td><strong>跟踪范围</strong></td><td>老年代 → 新生代</td><td>Region ↔ Region（任意方向）</td></tr><tr><td><strong>粒度</strong></td><td>卡页（约 512B）</td><td>Region 内卡页级（更细）</td></tr><tr><td><strong>精确度</strong></td><td>粗略</td><td>精确</td></tr><tr><td><strong>维护开销</strong></td><td>低</td><td>高</td></tr><tr><td><strong>优势</strong></td><td>简单、低延迟</td><td>可控回收、分区化并发效率高</td></tr></tbody></table><h3 id="小结-11">小结</h3><p>CMS 用卡表来实现记忆集，只记录老年代引用新生代的情况，通过写屏障把对应区域标记为‘脏卡’，GC 时扫描这些脏卡即可，结构简单但粒度较粗。<br>而 G1 的记忆集是以 Region 为粒度的，每个 Region 都维护一个自己的 RSet，记录哪些其他 Region 有引用它，粒度更细更精准，<br>适合 G1 这种分区化、并发回收的设计，只是维护成本更高。</p><h2 id="为什么-G1-垃圾收集器不维护年轻代到老年代的记忆集？">为什么 G1 垃圾收集器不维护年轻代到老年代的记忆集？</h2><p>G1 不维护年轻代到老年代的记忆集，因为年轻代每次 GC 都是整区回收，<br>所有年轻代 Region 都会被扫描，根本不需要额外记录年轻代引用老年代的对象。<br>而老年代引用年轻代的情况才需要维护记忆集，否则年轻代 GC 时可能误删对象。</p><h2 id="Java-中的-CMS-和-G1-垃圾收集器如何维持并发的正确性？">Java 中的 CMS 和 G1 垃圾收集器如何维持并发的正确性？</h2><p>CMS 和 G1 在并发标记时都会遇到“引用关系可能变化”的问题，<br>为保证标记的正确性：</p><ul><li><strong>CMS 使用「增量更新（Incremental Update）」机制</strong>；</li><li><strong>G1 使用「SATB（Snapshot At The Beginning）」机制</strong>。</li></ul><p>这两种机制的目的，都是在“应用线程继续运行、对象引用不断变化”时，<br>仍能保证 GC 标记结果的正确性。</p><h3 id="为什么需要并发正确性机制？">为什么需要并发正确性机制？</h3><p>在并发标记阶段，应用线程（Mutator）仍在运行，<br>对象之间的引用关系会持续变化，比如：</p><ul><li>对象 A 删除了对 B 的引用</li><li>对象 C 新增了对 D 的引用</li></ul><p>这会导致标记线程和应用线程看到的“对象图”不一致，<br>如果不处理，就可能：</p><ul><li>误删仍被引用的对象（错误回收）</li><li>或保留已经无用的对象（浮动垃圾）</li></ul><p>所以 CMS 和 G1 都必须用特殊机制来记录这些变化。</p><h3 id="CMS：增量更新（Incremental-Update）">CMS：增量更新（Incremental Update）</h3><h4 id="机制原理">机制原理</h4><p>当一个“已标记的黑色对象”向“未标记的白色对象”建立引用时，CMS 会立刻把这个白色对象标记成灰色（表示后续还要扫描它）。</p><p>这相当于：</p><ul><li>“黑指白时，不让它漏标”</li></ul><h4 id="核心思想：补充新增的引用关系。也就是说，只要有新的引用产生，CMS-会通过写屏障立即更新标记状态。">核心思想：补充新增的引用关系。<strong>也就是说，只要有新的引用产生，CMS 会通过写屏障立即更新标记状态。</strong></h4><h4 id="实现方式">实现方式</h4><ul><li>CMS 使用 写屏障（Write Barrier） 拦截引用更新操作。</li><li>当检测到黑对象引用白对象时，就把白对象加入重新扫描队列。</li><li>在 remark 阶段会重新检查这些对象，确保不会漏标。</li></ul><h4 id="优缺点">优缺点</h4><ul><li>优点 能保证标记阶段的完整性；</li><li>缺点 但容易产生“浮动垃圾”——即在 GC 标记后新创建但未扫描的对象。</li></ul><h3 id="G1：SATB（Snapshot-At-The-Beginning）">G1：SATB（Snapshot At The Beginning）</h3><h4 id="机制原理-2">机制原理</h4><p>SATB（Snapshot At The Beginning） 的思路是：<br>“在并发标记开始那一刻，拍下堆的快照，哪怕引用关系之后改变，也以快照时的状态为准。”<br>也就是说：</p><ul><li>标记开始时认为“当时存活的对象都是活的”；</li><li>即使之后引用被删除，也不会立刻当作垃圾。</li></ul><h4 id="核心思想：保留旧的引用关系，防止误删对象。">核心思想：保留旧的引用关系，防止误删对象。</h4><h4 id="实现方式-2">实现方式</h4><ul><li>在写屏障中，当对象引用被删除时，会把“被删除的旧引用”记录下来。</li><li>后续 GC 扫描这些记录，确保被删除的对象仍被视为“存活”。</li></ul><h4 id="G1-的实现细节">G1 的实现细节</h4><p>G1 在每个 Region 里维护两个指针：</p><ul><li>prevTAMS（上一次标记的起点）</li><li>nextTAMS（本次标记的起点）</li></ul><p>在标记开始时，prevTAMS 到 Top 之间的对象被认为是存活的，<br>相当于捕捉了堆的一份“快照”。</p><h4 id="优缺点-2">优缺点</h4><ul><li>优点标记更精确，避免误删；</li><li>缺点可能暂时保留一些“实际上已无用”的对象（也就是浮动垃圾）。</li></ul><table><thead><tr><th>对比项</th><th>CMS（增量更新）</th><th>G1（SATB）</th></tr></thead><tbody><tr><td>核心思路</td><td>更新新引用关系</td><td>保留旧引用关系</td></tr><tr><td>触发时机</td><td>新引用创建时</td><td>引用删除时</td></tr><tr><td>写屏障作用</td><td>记录新增引用</td><td>记录被删除引用</td></tr><tr><td>优点</td><td>不漏标新引用</td><td>不误删旧对象</td></tr><tr><td>缺点</td><td>会留下浮动垃圾</td><td>也会保留浮动垃圾，但控制更好</td></tr></tbody></table><h3 id="小结-12">小结</h3><p>在并发标记阶段，对象引用关系可能不断变化。<br>为了保证标记结果的正确性，<strong>CMS 用的是 增量更新</strong>，它会在引用新增时立刻标记新对象，防止漏标。<br>而 <strong>G1 用的是 SATB</strong>（快照在最初），在标记开始时拍个快照，认为当时活着的对象都是存活的，<br>即使引用被删除也不会误删。<br>简单来说，<strong>CMS 记录新增的引用，G1 记录被删的引用</strong>，<br><strong>两者目的都是保证并发标记阶段的正确性</strong>。</p><h2 id="Java-G1-相对于-CMS-有哪些进步的地方">Java G1 相对于 CMS 有哪些进步的地方?</h2><p>G1 是 CMS 的“下一代垃圾回收器”，<br>它在 <strong>内存布局、回收算法、停顿控制</strong> 和 <strong>大对象优化</strong> 等方面都有明显进步，<br>目标是：更可控、更高效、更适合多核和大内存环境。</p><h3 id="从内存管理机制来看">从内存管理机制来看</h3><p>CMS 是传统的“分区制”，而 G1 把堆打碎成很多小块（Region），动态调整哪些块回收哪些保留，内存使用更灵活，也更容易做并行优化。</p><h3 id="从回收算法来看">从回收算法来看</h3><p>CMS <strong>标记-清除算法</strong> 清完垃圾后容易留下碎片，就像地板上扫完灰但还乱，<br>而 G1 <strong>标记-整理算法</strong> 会顺便把对象挤一挤，像打包箱子那样整齐，所以几乎不会出现碎片问题。</p><h3 id="从停顿时间来看">从停顿时间来看</h3><p><strong>CMS 的停顿不可控</strong>，有时候很短，有时候就卡几秒。<br>而 G1 可以<strong>设定“停顿目标”</strong>，GC 会自动规划任务，尽量让回收既高效又平稳。</p><h3 id="从大对象与跨代引用优化来看">从大对象与跨代引用优化来看</h3><p>CMS 对大对象处理比较笨，可能直接塞进老年代，<strong>容易导致 老年代空间紧张、甚至 Full GC</strong><br>而 G1 是<strong>分块管理</strong>的，<strong>大对象单独放一个 Region</strong>，管理起来更灵活，不容易挤爆老年代。</p><h3 id="额外补充">额外补充</h3><ul><li><strong>G1 不仅负责老年代，也能回收新生代</strong>，是一个 统一的垃圾收集器（不像 CMS 还要配合 ParNew）。</li><li>G1 的<strong>并行和并发设计更现代</strong>，在多核、大内存服务器上表现更稳定。</li></ul><h3 id="小结-13">小结</h3><p>G1 相比 CMS 的最大进步有四点：<br>第一，G1 把堆划成很多小块（Region），内存更灵活不易碎片化；<br>第二，CMS 用标记清除，而 G1 用标记整理，几乎不会有内存碎片；<br>第三，G1 可以设置停顿目标，GC 会自动调度，用户体验更平滑；<br>最后，G1 对大对象和跨代引用处理更智能，也不需要搭配 ParNew，整体更适合大内存和多核环境。</p><h2 id="什么是-Java-中的-logging-write-barrier？">什么是 Java 中的 logging write barrier？</h2><p>Logging Write Barrier（日志写屏障） 是一种<strong>在 Java GC 中用来记录对象引用变化的写屏障机制</strong>。<br><strong>它能让垃圾收集器在应用线程继续运行时，依然感知哪些引用被修改或删除，<br>从而保证并发标记的正确性</strong>（特别是 G1 的 SATB 和记忆集维护）。</p><h3 id="先理解写屏障（Write-Barrier）">先理解写屏障（Write Barrier）</h3><p>写屏障其实是一段 <strong>由 JVM 在引用赋值操作时插入的小代码</strong>。<br>当对象的引用字段发生改变（比如 a.field = b）时，写屏障就会被触发，执行一些额外逻辑。</p><p>常见的两种类型是：</p><ul><li><strong>Pre-Write Barrier（写前屏障）：在引用被覆盖前触发（记录旧值）</strong></li><li><strong>Post-Write Barrier（写后屏障）：在引用写入后触发（记录新值）</strong></li></ul><h3 id="Logging-Write-Barrier-是什么">Logging Write Barrier 是什么</h3><p>Logging Write Barrier 本质上属于 “Post-Write Barrier” 的一种实现形式。<br>它的核心思想是：</p><ul><li>“<strong>每当引用变化时，把变化记录（log）下来，而不是立刻处理</strong>。”</li></ul><p>这些变化日志（log entries）会被放入专用队列（如 SATBMarkQueue），<br>等到合适时机再由 GC 线程批量处理。</p><p>这样做的好处是：</p><ul><li>避免频繁打断应用线程</li><li>降低同步开销</li><li>保证并发标记时引用关系的正确性</li></ul><h3 id="Logging-Write-Barrier-的工作原理">Logging Write Barrier 的工作原理</h3><p>在 G1 的 SATB 模式下，当对象引用被覆盖（即旧引用要被删掉）时：</p><ol><li>触发写前屏障（Pre-Write Barrier）</li><li>JVM 检查当前是否处于并发标记阶段（mark_queue_set().is_active()）</li><li>如果是，就把“旧引用对象”入队到 SATBMarkQueue</li><li>后续由 GC 线程异步扫描这些队列，确保被删除的对象仍能被正确标记</li></ol><p>换句话说：<br><strong>即使应用线程删除了某个对象引用，GC 也能通过日志知道“它原来是被引用过的”，<br>从而避免错误回收。</strong></p><h3 id="在不同-GC-中的用途">在不同 GC 中的用途</h3><table><thead><tr><th>垃圾收集器</th><th>写屏障用途</th><th>说明</th></tr></thead><tbody><tr><td><strong>G1 GC</strong></td><td>记录对象引用变化，用于 <strong>SATB 快照机制</strong> 和 <strong>记忆集（RSet）更新</strong></td><td>确保跨 Region 引用关系正确</td></tr><tr><td><strong>CMS GC</strong></td><td>用于 <strong>增量更新（Incremental Update）</strong>，标记新增引用</td><td>防止漏标新引用对象</td></tr><tr><td><strong>Shenandoah / ZGC</strong></td><td>用于 <strong>读屏障（Read Barrier）</strong>，配合指针重定位</td><td>保证并发压缩时引用有效性</td></tr></tbody></table><h3 id="Logging-Write-Barrier-的意义">Logging Write Barrier 的意义</h3><p>它解决了两个问题：<br>1.GC 与应用线程并发运行时，如何同步引用变化？</p><ul><li>通过日志异步记录，避免扫描全堆。</li></ul><p>2.如何保证标记结果不出错？</p><ul><li>在 SATB 中保存旧引用，防止误删对象；<br>在增量更新中记录新引用，防止漏标对象。</li></ul><p>小结<br>Logging Write Barrier 是 GC 用来记录对象引用变化的机制，它会在引用写入时，把旧或新的引用信息记录下来放入日志队列，比如 SATBMarkQueue。<br>这样垃圾收集器在并发标记时，就能知道哪些对象引用被修改或删除，避免误删或漏标。<br><strong>像 G1 用它来维护 SATB 快照和记忆集，CMS 用它来做增量更新</strong>，既保证正确性，又减少同步开销。</p><h2 id="Java-的-G1-垃圾回收流程是怎样的？">Java 的 G1 垃圾回收流程是怎样的？</h2><p>G1 垃圾回收器的整个流程可以分为两个大阶段：</p><ul><li>并发标记（Concurrent Marking）</li><li>对象拷贝与整理（Evacuation）<br>其中标记阶段又包含 <strong>初始标记 → 并发标记 → 最终标记 → 清理</strong>四个子步骤。</li></ul><p><strong>简单说，G1 先“找出该回收的垃圾”，再“把存活的对象搬走”，实现高效、可控的 GC</strong>。</p><h3 id="一、初始标记（Initial-Mark，STW）">一、初始标记（Initial Mark，STW）</h3><ul><li>首先会暂停所有用户线程（Stop The World）；</li><li>从 GC Root 出发，标记第一层直接可达的对象；</li><li>因为只标记少量对象，停顿时间非常短；</li><li>这一步属于 SATB（Snapshot At The Beginning） 的起点阶段。</li></ul><p>这一步就像拍一张快照，先把根对象能直接触及的那一层标记起来，速度很快，停顿也短。</p><h3 id="二、并发标记（Concurrent-Mark）">二、并发标记（Concurrent Mark）</h3><ul><li>与应用线程并发进行，不会完全停顿；</li><li>从前面标记到的灰色对象开始，继续追踪并标记它们引用到的对象；</li><li>会标记出整个堆中所有可达的对象；</li><li>由于应用线程此时还在运行，引用关系可能变化，G1 使用 SATB 技术 保证正确性（在标记开始时拍快照，后续引用变化用日志记录）。</li></ul><p>这阶段是“大规模扫图”，GC 和程序一起跑；如果应用代码在过程中修改了引用，G1 用 SATB 机制保证不会漏标对象。</p><h3 id="三、最终标记（Final-Remark，STW）">三、最终标记（Final Remark，STW）</h3><ul><li>再次短暂停顿应用线程；</li><li>扫描并处理并发阶段残留的 SATB 队列，</li><li>把新创建或删除的引用关系补充上；</li><li>确保标记阶段的结果完全准确。</li></ul><p>这一步相当于“复核”，GC 停下来把并发阶段遗留的小细节都补上，保证标记结果没问题。</p><h3 id="四、清理阶段（Cleanup，STW）">四、清理阶段（Cleanup，STW）</h3><ul><li>检查各个 Region 的存活对象数量；</li><li>对没有存活对象的 Region 进行释放；</li><li>更新统计信息，为下一次回收做准备。</li></ul><p>就像打扫完屋子后清点一下哪些房间是空的，空房间就直接回收释放。</p><h3 id="五、对象拷贝-转移（Evacuation，STW）">五、对象拷贝 / 转移（Evacuation，STW）</h3><ul><li>这一阶段也是 STW（停顿的）；</li><li>根据前面标记的结果，挑选一批“垃圾多、收益高”的 Region 作为回收目标集合（CSet，Collection Set）；</li><li>把这些 Region 里的存活对象复制到新的 Region 中；</li><li>同时更新引用关系和卡表（Card Table）；</li><li>完成后释放原有的 Region 空间。</li></ul><p>最后这一步是“搬家”——GC 把活着的对象搬到新区域，把旧区的垃圾一起清掉，这样堆空间就重新整理干净了。</p><h3 id="G1-的并发调优参数">G1 的并发调优参数</h3><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td><code>-XX:MaxGCPauseMillis=&lt;n&gt;</code></td><td>设置最大停顿时间目标（比如 200ms），G1 会自动调整每次回收的工作量来满足这个目标。</td></tr><tr><td><code>-XX:G1HeapRegionSize=&lt;size&gt;</code></td><td>控制 Region 大小（默认 1MB~32MB），影响内存划分与扫描效率。</td></tr><tr><td><code>-XX:InitiatingHeapOccupancyPercent=&lt;p&gt;</code></td><td>设置老年代触发并发标记的阈值（默认 45%）。</td></tr><tr><td><code>-XX:G1MixedGCCountTarget=&lt;n&gt;</code></td><td>控制 mixed GC 阶段一次混合回收多少个 Region。</td></tr></tbody></table><p>小结：<br>G1 的垃圾回收过程分为五步：<br>先是 初始标记，快速标记 GC Roots 可达对象；<br>然后 并发标记，和程序一起运行，用 SATB 机制保证引用变化不出错；<br>接着 最终标记，补上并发阶段遗漏的部分；<br>之后是 清理，回收空 Region；<br>最后是 对象转移，把活的对象搬到新区域、释放旧区空间。<br>整个过程既保证高吞吐量，又能控制停顿时间，非常适合大内存场景。</p><blockquote><p>SATB<br>SATB 主要为了解决并发标记阶段可能产生的对象引用变化问题，SATB 宁可多标也不漏标，多标的大不了下一轮 GC 时再被回收（浮动垃圾），但漏标却会影响到程序的正常运行。</p></blockquote><h2 id="Java-的-CMS-垃圾回收流程是怎样的？">Java 的 CMS 垃圾回收流程是怎样的？</h2><p>CMS 是一种以<strong>最小化停顿时间为目标</strong>的<strong>老年代垃圾收集器</strong>。<br>它通过“并发标记”和“并发清理”来减少 STW（Stop The World）时间，<br>整体流程可以分为 <strong>初始标记 → 并发标记 → 预清理 → 重新标记 → 并发清理 → 并发重置</strong> 六个主要阶段</p><h3 id="一、初始标记（Initial-Mark，STW）-2">一、初始标记（Initial Mark，STW）</h3><ul><li>暂停所有用户线程（STW）。</li><li>从 GC Roots 出发，标记直接可达的对象。</li><li>只扫描第一层引用，因此非常快。</li></ul><p>初始标记就是先从 GC Roots 开始，快速打个底，把能直接关联到的对象标记出来，这一步虽然是停顿的，但时间很短。</p><h3 id="二、并发标记（Concurrent-Marking）">二、并发标记（Concurrent Marking）</h3><ul><li>与应用线程并发执行，不会完全停顿。</li><li>从初始标记的对象开始，遍历整个对象图，找出所有可达对象。</li><li>这一阶段的标记可能会受应用线程继续运行影响（对象引用可能被修改）。</li></ul><p>接下来进入并发标记阶段，GC 和应用线程一起跑，后台遍历堆里的对象图，把所有活对象都标出来。</p><h3 id="三、预清理（Concurrent-Preclean）">三、预清理（Concurrent Preclean）</h3><ul><li>仍是并发执行。</li><li>CMS 会处理在并发标记过程中，由于用户线程继续运行而新产生的引用变化。</li><li>这一步的目的是尽量减少后续“重新标记”阶段的工作量。</li></ul><p>因为标记过程中程序还在运行，可能又改了些引用，所以这一步会提前把新变化的引用先处理掉，让后面停顿更短。</p><h3 id="四、重新标记（Remark，STW）">四、重新标记（Remark，STW）</h3><ul><li>再次进入停顿（STW）。</li><li>扫描并修正并发阶段遗漏的标记信息，确保标记结果的准确性。</li><li>通常会用 多线程并行 来加速。</li></ul><p>这一步是“复核”阶段，GC 再次短暂停顿应用线程，把之前并发标记时漏掉的活对象都补标一下。</p><h3 id="五、并发清理（Concurrent-Sweep）">五、并发清理（Concurrent Sweep）</h3><ul><li>开始真正清理垃圾对象，释放内存。</li><li>清理过程与用户线程并发执行，不会停顿。</li><li>因为 CMS 使用的是 标记-清除算法，所以不会做内存整理（会留下碎片）。</li></ul><p>然后进入并发清理阶段，GC 在后台把标记为垃圾的对象清掉，这时程序照常运行。<br>不过 CMS 只是清理不会压缩，所以容易产生碎片。</p><h3 id="六、并发重置（Concurrent-Reset）">六、并发重置（Concurrent Reset）</h3><ul><li>清理完成后，CMS 会重置内部数据结构（如标记位图），为下一次 GC 做准备。</li><li>同样是并发执行，不会造成停顿。</li></ul><p>最后一步是收尾，清空标记信息，重置状态，为下一次回收做好准备。</p><h3 id="CMS-的两个典型问题">CMS 的两个典型问题</h3><ul><li>浮动垃圾（Floating Garbage）<ul><li>因为清理阶段是并发的，可能在清理期间又产生新的垃圾，这部分垃圾只能留到下次回收。</li></ul></li><li>内存碎片（Fragmentation）<ul><li>CMS 使用“标记-清除算法”，不会整理堆空间，久而久之会产生碎片，导致Promotion Failed（对象无法晋升到老年代）。</li></ul></li></ul><p>优化方式：</p><ul><li>-XX:+UseCMSCompactAtFullCollection → Full GC 时进行压缩。</li><li>-XX:CMSFullGCsBeforeCompaction → 每多少次 Full GC 后压缩一次。</li><li>-XX:CMSInitiatingOccupancyFraction=<n> → 调低触发阈值，提前启动回收，防止碎片过多。</li></ul><p>CMS 的缺点主要有两个：一个是清理时程序还在跑，会有浮动垃圾；<br>另一个是因为不压缩内存，会产生碎片，可能导致晋升失败。<br>可以通过参数配置，让它在 Full GC 时顺便压缩一下来解决。</p><h3 id="小结：-3">小结：</h3><p>CMS 的垃圾回收过程分六步：<br>先是<strong>初始标记，快速标记 GC Roots 直接关联的对象</strong>；<br>接着<strong>并发标记，后台扫描整个对象图</strong>；<br>然后<strong>预清理，处理新引用</strong>；<br>再进入<strong>重新标记阶段，短暂停顿修正遗漏</strong>；<br>接着<strong>并发清理，真正删除垃圾对象</strong>；<br>最后<strong>并发重置，为下次 GC 做准备</strong>。<br>它的优点是<strong>停顿时间短</strong>，缺点是容易有<strong>浮动垃圾</strong>和<strong>内存碎片</strong></p><h2 id="你了解-Java-的-ZGC（Z-Garbage-Collector）吗？">你了解 Java 的 ZGC（Z Garbage Collector）吗？</h2><p>ZGC（Z Garbage Collector）是 Java 中的一款<strong>超低延迟、高可扩展性垃圾收集器</strong>，<br>它的目标是：<strong>让 GC 停顿时间不超过 1ms，无论堆多大</strong>（可达 16TB）。<br>非常适合<strong>对响应时间要求极高的场景</strong>，比如金融交易系统、在线游戏、实时计算等。</p><h3 id="ZGC-的核心特性">ZGC 的核心特性</h3><ul><li>低延迟：每次 Stop-The-World 停顿都小于 1ms。</li><li>高并发：几乎所有阶段都是与应用线程并发执行。</li><li>超大堆支持：支持从几百 MB 到 16TB 的堆内存。</li><li>无碎片问题：采用并发压缩算法，回收后堆空间整洁无碎片。</li></ul><p>ZGC 的目标就是让 GC 延迟小到可以忽略不计，不管你堆是 1G 还是 10TB，<br>都能在 1ms 内完成暂停，非常适合对延迟特别敏感的系统。</p><h3 id="ZGC-的核心原理">ZGC 的核心原理</h3><p>ZGC 之所以能实现低延迟，关键在于两项技术：</p><ol><li>读屏障（Load Barrier）</li></ol><ul><li>当线程读取对象引用时，会经过一层“读屏障”检查。</li><li>如果发现对象被移动过，屏障逻辑会自动更新引用地址，确保读到的是最新位置的对象。</li></ul><ol start="2"><li>着色指针（Colored Pointers）</li></ol><ul><li>ZGC 在 64 位指针中嵌入标记位（颜色位），用来记录对象的状态（是否标记、是否转移、是否重映射）。</li><li>不再需要额外的标记表，提高效率。</li></ul><p>G1 回收时对象转移必须停顿所有线程，而 ZGC 用<strong>读屏障 + 着色指针</strong>，让对象转移也能并发执行，这就是它能做到“超低停顿”的秘密。</p><h3 id="ZGC流程">ZGC流程</h3><p>ZGC 的垃圾回收流程分为多个阶段，几乎都是并发完成的。</p><ol><li>初始标记（STW）</li></ol><ul><li>标记 GC Roots（线程栈、静态变量等）直接可达对象。</li><li>时间极短（&lt;1ms）。</li></ul><ol start="2"><li>并发标记</li></ol><ul><li>遍历对象图，标记所有可达对象。</li><li>用户线程在访问对象时如果发现对象未标记，会“顺带”帮忙标记（协同机制）。</li></ul><ol start="3"><li>并发处理</li></ol><ul><li>决定哪些内存页（ZPage）需要转移。</li><li>建立“旧地址 → 新地址”的映射表。</li></ul><ol start="4"><li>转移阶段（开始 + 并发）</li></ol><ul><li>初始转移（STW）：转移 GC Roots 直接引用的对象。</li><li>并发转移：后台将其他对象复制到新内存页（ZPage），并更新映射关系。</li><li>用户线程访问对象时，会通过读屏障自动更新引用地址。</li></ul><ol start="5"><li><p>第二次 GC（补全未完成转移）<br>ZGC 使用“双标记位机制” （Marked0 / Marked1）<br>区分当前和上次 GC 状态，保证不会重复转移或漏转。</p></li><li><p>并发问题处理机制</p></li></ol><p>如果用户线程和 GC 线程同时尝试转移对象，ZGC 会通过映射表判断是否已存在转移结果，<br>若存在则放弃重复操作，避免冲突。</p><blockquote><p>ZGC 的流程可以概括为：<br>“标记活对象 → 建立映射关系 → 并发搬家 → 用户线程自动帮忙修正引用”。<br>整个过程几乎没有明显停顿。</p></blockquote><h3 id="ZGC与-G1-的区别">ZGC与 G1 的区别</h3><table><thead><tr><th>对比点</th><th>G1 GC</th><th>ZGC</th></tr></thead><tbody><tr><td>转移过程</td><td>必须 STW（停顿）</td><td>可并发进行</td></tr><tr><td>屏障类型</td><td>写屏障（Write Barrier）</td><td>读屏障（Load Barrier）</td></tr><tr><td>碎片问题</td><td>可能有碎片</td><td>并发压缩，无碎片</td></tr><tr><td>停顿时间</td><td>10ms ~ 100ms</td><td>&lt; 1ms</td></tr><tr><td>堆大小支持</td><td>几 GB ~ 几十 GB</td><td>可达 16TB</td></tr></tbody></table><blockquote><p>简单说，G1 是“低延迟”，ZGC 是“超低延迟”。<br>它几乎把 GC 的所有步骤都做成并发了。</p></blockquote><h3 id="小结-14">小结</h3><p>ZGC 是 Java 的一款超低延迟垃圾回收器，能做到 GC 停顿不超过 1ms，支持从几百 MB 到 16TB 的堆内存。</p><p>它的核心是读屏障（Load Barrier）和着色指针（Colored Pointer），让对象转移过程也能并发执行，不用再 STW。</p><p>整个流程包括初始标记、并发标记、并发处理、并发转移和重映射，几乎全程并发，特别适合实时、高响应系统。</p><h2 id="JVM-垃圾回收调优的主要目标是什么？">JVM 垃圾回收调优的主要目标是什么？</h2><p>JVM 垃圾回收调优的主要目标有两个：</p><ul><li>最短暂停时间（低延迟）</li><li>高吞吐量（高性能）</li></ul><p>这两者是 GC 调优的核心方向，但通常是此消彼长的，需要根据业务场景权衡取舍。</p><ul><li>最短暂停时间的目标就是<strong>让 GC 尽快干完活，别拖慢应用</strong>。比如我们希望每次 GC 只暂停几毫秒，让用户几乎感受不到卡顿。</li><li>高吞吐量的目标不是让 GC 更快结束，而是<strong>尽量少触发 GC</strong>，让 CPU 更多地去跑业务代码，而不是在收垃圾。</li></ul><h3 id="两者的权衡">两者的权衡</h3><ul><li>低延迟和高吞吐量往往难以兼得。<ul><li>比如：每次 GC 停顿 100ms、每秒 GC 5 次（响应好但频繁）；</li><li>或者每次 GC 停顿 200ms、每秒 GC 2 次（吞吐高但延迟更大）。</li></ul></li><li>所以，调优时必须明确你的应用更关注响应速度还是处理效率。</li></ul><blockquote><p>调优的时候要先想清楚目标。<strong>如果你是支付系统，就追求低延迟</strong>；<br><strong>如果是离线计算任务，就追求高吞吐</strong>。两者很难两全。</p></blockquote><h3 id="小结-15">小结</h3><p>JVM 垃圾回收调优的主要目标是两个：<br>一是减少 GC 停顿时间，提升系统的响应能力；<br>二是提高吞吐量，让程序在单位时间内处理更多业务。<br>一般低延迟系统更关注停顿时间，高并发或计算密集型系统更看重吞吐量，<br>两者通常需要平衡取舍。</p><h2 id="如何对-Java-的垃圾回收进行调优？">如何对 Java 的垃圾回收进行调优？</h2><p>Java 垃圾回收调优的核心目标是：</p><p><strong>尽量让对象在年轻代就被回收掉，减少进入老年代的对象，从而降低 Full GC 的频率。</strong></p><ul><li>目标一：<strong>降低 Full GC 次数</strong>，Full GC 的停顿时间长，对性能影响大。所以调优的关键是让尽可能多的对象在年轻代就被清理掉，让老年代空间保持充足，避免频繁 Full GC。</li><li>目标二：<strong>提升年轻代回收效率</strong>，尽量让短命对象“生得快，死得也快”，在 Young GC 阶段直接回收，<strong>减少对象晋升到老年代的概率</strong>。</li></ul><h3 id="常见调优方法">常见调优方法</h3><p>1.分析 GC 日志，找到瓶颈点<br>先别急着调参数，要先看 Young GC 和 Full GC 的触发频率、停顿时间、晋升速率、老年代使用量等关键指标。</p><p>2.调整年轻代与老年代的比例</p><ul><li>如果发现对象频繁晋升到老年代，就说明年轻代太小。</li><li>可以适当增大 -Xmn 或者调大 SurvivorRatio，让更多对象在年轻代被回收。<br>3.优化 Survivor 区大小</li><li>Survivor 太小会导致对象提前晋升老年代。</li><li>适当增大 Survivor 区，让短命对象在新生代多活几次 GC，被及时清理掉。</li></ul><p>4.避免频繁的 System.gc() 调用<br>有些第三方库可能会主动调用 System.gc() 导致频繁 Full GC。<br>可以通过参数 -XX:+DisableExplicitGC 禁用显式 GC 调用。</p><blockquote><p>具体调优要看 GC 日志，<br>如果 Young GC 后老年代涨得快，就说明晋升太多，要调大新生代或 Survivor；<br>如果频繁 Full GC，就要看看是不是老年代空间太小或者有内存泄漏。<br>另外别忘了关掉那些偷偷调 System.gc() 的库。</p></blockquote><p>举例</p><ul><li><p>情况一：Full GC 太频繁</p><ul><li>增大老年代空间；</li><li>优化 Survivor，减少晋升。</li></ul></li><li><p>情况二：Young GC 频繁且耗时</p><ul><li>调整 Eden 与 Survivor 比例；</li><li>调大新生代，让对象更集中回收。</li></ul></li><li><p>情况三：内存碎片或老年代膨胀</p><ul><li>考虑使用 G1 或 ZGC 这类具备压缩能力的收集器。</li></ul></li></ul><h3 id="小结-16">小结</h3><p>调优垃圾回收的关键是让短命对象尽快在年轻代被清理掉，<br>减少老年代的压力，从而降低 Full GC 的频率。<br>一般我们会通过分析 GC 日志，观察 Young GC 和 Full GC 的次数、<br>晋升速率和内存占用，再去调整年轻代、Survivor 大小或者禁用 System.gc()。<br>核心思路其实就一句话：<strong>尽量在新生代把对象回收掉</strong>。</p><h2 id="常用的-JVM-配置参数有哪些？">常用的 JVM 配置参数有哪些？</h2><table><thead><tr><th>类别</th><th>参数</th><th>作用说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>内存相关参数</strong></td><td><code>-Xms</code></td><td>设置初始堆内存大小</td><td><code>-Xms512m</code></td></tr><tr><td></td><td><code>-Xmx</code></td><td>设置最大堆内存大小</td><td><code>-Xmx2g</code></td></tr><tr><td></td><td><code>-Xmn</code></td><td>设置年轻代大小</td><td><code>-Xmn512m</code></td></tr><tr><td></td><td><code>-XX:NewRatio</code></td><td>设置年轻代与老年代的比例</td><td><code>-XX:NewRatio=2</code></td></tr><tr><td></td><td><code>-XX:SurvivorRatio</code></td><td>设置 Eden 区与 Survivor 区比例</td><td><code>-XX:SurvivorRatio=8</code></td></tr><tr><td></td><td><code>-XX:MetaspaceSize</code></td><td>元空间初始大小</td><td><code>-XX:MetaspaceSize=128m</code></td></tr><tr><td></td><td><code>-XX:MaxMetaspaceSize</code></td><td>元空间最大大小</td><td><code>-XX:MaxMetaspaceSize=512m</code></td></tr><tr><td><strong>GC 相关参数</strong></td><td><code>-XX:+UseG1GC</code></td><td>启用 G1 垃圾收集器</td><td>—</td></tr><tr><td></td><td><code>-XX:+UseConcMarkSweepGC</code></td><td>启用 CMS 垃圾收集器</td><td>—</td></tr><tr><td></td><td><code>-XX:+UseParallelGC</code></td><td>启用并行 GC</td><td>—</td></tr><tr><td></td><td><code>-XX:MaxGCPauseMillis</code></td><td>设置最大 GC 停顿时间目标</td><td><code>-XX:MaxGCPauseMillis=200</code></td></tr><tr><td></td><td><code>-XX:GCTimeRatio</code></td><td>设置 GC 时间与应用执行时间的比例</td><td><code>-XX:GCTimeRatio=9</code></td></tr><tr><td><strong>性能调优参数</strong></td><td><code>-XX:+AggressiveOpts</code></td><td>开启积极优化选项</td><td>—</td></tr><tr><td></td><td><code>-XX:+UseCompressedOops</code></td><td>启用压缩指针（节省内存）</td><td>—</td></tr><tr><td></td><td><code>-XX:+DoEscapeAnalysis</code></td><td>启用逃逸分析</td><td>—</td></tr><tr><td></td><td><code>-XX:+UseBiasedLocking</code></td><td>启用偏向锁，减少锁竞争</td><td>—</td></tr><tr><td><strong>调试与监控参数</strong></td><td><code>-XX:+HeapDumpOnOutOfMemoryError</code></td><td>OOM 时生成堆转储文件</td><td>—</td></tr><tr><td></td><td><code>-XX:HeapDumpPath</code></td><td>指定堆转储文件路径</td><td><code>-XX:HeapDumpPath=/tmp/heap.hprof</code></td></tr><tr><td></td><td><code>-XX:+PrintGC</code></td><td>打印 GC 基本信息</td><td>—</td></tr><tr><td></td><td><code>-XX:+PrintGCDetails</code></td><td>打印详细 GC 日志</td><td>—</td></tr><tr><td></td><td><code>-Xloggc</code></td><td>设置 GC 日志输出路径</td><td><code>-Xloggc:/var/log/gc.log</code></td></tr><tr><td><strong>其他常用参数</strong></td><td><code>-Dfile.encoding</code></td><td>设置文件编码格式</td><td><code>-Dfile.encoding=UTF-8</code></td></tr><tr><td></td><td><code>-server</code></td><td>启用服务器模式（默认在 64 位 JDK）</td><td>—</td></tr><tr><td></td><td><code>-client</code></td><td>启用客户端模式</td><td>—</td></tr><tr><td></td><td><code>-XX:MaxDirectMemorySize</code></td><td>设置直接内存大小（影响 NIO）</td><td><code>-XX:MaxDirectMemorySize=1g</code></td></tr></tbody></table><p>在实际项目中，常见的 JVM 启动配置一般会包含以下几类参数组合：</p><table><thead><tr><th>类型</th><th>常用配置</th></tr></thead><tbody><tr><td><strong>基础内存设置</strong></td><td><code>-Xms1g -Xmx2g -Xmn512m</code></td></tr><tr><td><strong>垃圾回收设置</strong></td><td><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=200</code></td></tr><tr><td><strong>性能优化</strong></td><td><code>-XX:+UseCompressedOops -XX:+DoEscapeAnalysis -XX:+UseBiasedLocking</code></td></tr><tr><td><strong>监控调试</strong></td><td><code>-XX:+PrintGCDetails -Xloggc:/logs/gc.log -XX:+HeapDumpOnOutOfMemoryError</code></td></tr><tr><td><strong>其他常用项</strong></td><td><code>-Dfile.encoding=UTF-8 -XX:MaxDirectMemorySize=512m</code></td></tr></tbody></table><blockquote><p>JVM 参数主要分五大类：<br>内存分配、GC 策略、性能优化、监控调试、系统配置。</p></blockquote><h2 id="你常用哪些工具来分析-JVM-性能？">你常用哪些工具来分析 JVM 性能？</h2><p>分析 JVM 性能常用的工具主要分为五类：<br><strong>基础信息工具、内存与 GC 工具、线程分析工具、可视化工具、第三方监控分析工具</strong>。</p><h3 id="基础信息工具">基础信息工具</h3><table><thead><tr><th>工具</th><th>作用</th></tr></thead><tbody><tr><td><strong>jps</strong></td><td>查看当前用户的 Java 进程，快速定位进程 PID。</td></tr><tr><td><strong>jinfo</strong></td><td>查看或修改 JVM 参数配置，适合排查参数设置问题。</td></tr></tbody></table><p>“我一般先用 jps 查进程号，再用 jinfo 看看 JVM 参数，比如堆大小、GC 策略这些。”</p><h3 id="内存与-GC-分析工具">内存与 GC 分析工具</h3><table><thead><tr><th>工具</th><th>作用</th></tr></thead><tbody><tr><td><strong>jmap</strong></td><td>导出堆快照 dump 文件，或直接查看堆内对象分布情况。</td></tr><tr><td><strong>jstat</strong></td><td>实时监控 GC、类加载、编译和内存使用等运行时指标。</td></tr></tbody></table><p>“我常用 jstat 监控 GC 频率，看是否有 Full GC 过多的问题；<br>如果怀疑内存泄漏，就用 jmap dump 出堆文件，再用 MAT 分析。”</p><h3 id="线程和锁分析工具">线程和锁分析工具</h3><table><thead><tr><th>工具</th><th>作用</th></tr></thead><tbody><tr><td><strong>jstack</strong></td><td>抓取线程堆栈信息，用来分析死锁、线程阻塞、高 CPU 占用等问题。</td></tr></tbody></table><p>“应用 CPU 飙高或者响应慢时，我会先 jstack 看看是不是线程死锁或者有线程在 spin。”</p><h3 id="可视化工具">可视化工具</h3><table><thead><tr><th>工具</th><th>作用</th></tr></thead><tbody><tr><td><strong>jhat</strong></td><td>简单的堆快照分析工具（功能较弱，推荐用 MAT 或 VisualVM）。</td></tr><tr><td><strong>jconsole</strong></td><td>JDK 自带图形化监控工具，可查看内存、GC、线程和 CPU。</td></tr><tr><td><strong>VisualVM</strong></td><td>功能强大的可视化工具，支持实时监控、GC 统计、CPU 采样、dump 文件分析等。</td></tr></tbody></table><p>“我平时调优时喜欢用 VisualVM，能直观看到堆和 GC 的变化，还能采样分析 CPU。”</p><h3 id="第三方高级工具">第三方高级工具</h3><table><thead><tr><th>工具</th><th>作用</th></tr></thead><tbody><tr><td><strong>Arthas</strong></td><td>阿里开源的 Java 诊断神器，支持在线排查、查看类加载、监控方法调用和内存实时情况。</td></tr><tr><td><strong>MAT（Memory Analyzer Tool）</strong></td><td>深度分析堆转储文件，定位内存泄漏和大对象引用链。</td></tr></tbody></table><p>“如果是线上问题，我一般直接上 Arthas，远程 attach 进程实时看。<br>如果是内存泄漏，就导出 dump 文件用 MAT 深挖引用链。”</p><h3 id="常见问题与工具选择建议">常见问题与工具选择建议</h3><table><thead><tr><th>问题类型</th><th>推荐工具</th></tr></thead><tbody><tr><td><strong>内存溢出（OOM）</strong></td><td><code>jmap</code> + <code>MAT</code></td></tr><tr><td><strong>内存泄漏</strong></td><td><code>jstat</code> + <code>jmap</code> + <code>MAT</code></td></tr><tr><td><strong>GC 频繁</strong></td><td><code>GC 日志</code> + <code>jstat</code></td></tr><tr><td><strong>线程死锁</strong></td><td><code>jstack</code></td></tr><tr><td><strong>CPU 飙高</strong></td><td><code>top</code> / <code>ps</code> + <code>jstack</code></td></tr><tr><td><strong>长期监控</strong></td><td><code>Prometheus</code> + <code>Grafana</code></td></tr></tbody></table><h3 id="小结-17">小结</h3><p>我平时分析 JVM 性能问题主要分几类工具：<br>jps、jinfo 这种看基础信息的；<br>jmap、jstat 看内存和 GC；<br>jstack 查线程死锁或 CPU 问题；<br>可视化我用 VisualVM 或 jconsole；<br>线上排查就用 Arthas，离线分析用 MAT。<br>一般套路是：先 jps 定进程，再 jstat 看 GC，再根据问题用 jstack 或 jmap 定位。</p><h2 id="如何在-Java-中进行内存泄漏分析？">如何在 Java 中进行内存泄漏分析？</h2><p>面试官：“你知道如何解决内存泄漏问题吗？”</p><p>答：内存泄漏其实是指在 Java 中，有些对象在用完之后，虽然不再需要，但是它们还是被某些地方引用着，导致垃圾回收器无法回收这些对象，最终可能会导致内存溢出。</p><p>解决这个问题的步骤一般包括几个方面：</p><ol><li><p>发现问题：</p><ul><li>首先，你可以通过监控内存的使用情况来发现问题。正常情况下，内存会随着程序的运行起伏，<br>Minor GC 后内存会回落，但如果你看到内存持续增长，手动执行 FULL GC 后内存依然不下降，那就有可能是内存泄漏了。</li></ul></li><li><p>诊断问题：</p><ul><li>一旦怀疑是内存泄漏，你可以生成堆内存快照。这可以通过 JVM 参数来自动做，像是加上<br>-XX: +HeapDumpOnOutOfMemoryError，这样如果发生 OOM 错误时就会自动生成一个堆快照文件。或者你可以手动导出，比如用 jmap 或者 <strong>Arthas</strong> 来获取内存快照，这样就能看到哪些对象还没被回收。</li></ul></li><li><p>定位问题：</p><ul><li>接着，你可以使用 <strong>MAT（Memory Analyzer Tool）</strong> 来分析这些堆快照，看看是不是某些对象占用了大量的内存，导致其他对象无法被回收。</li></ul></li><li><p>修复问题：</p><ul><li>修复的时候，首先要看看问题是出在哪。比如代码中如果有不必要的引用，可以手动清理；如果是并发问题，可能是因为设置的堆内存太小或者设计不当，这时候可以通过调整内存参数或优化设计来解决。</li></ul></li><li><p>工具的使用：</p><ul><li>常用的工具有 JDK 自带的 jps （查看进程）和 jmap （生成内存快照），以及第三方工具像 <strong>VisualVM</strong> 和 <strong>Arthas</strong>，它们都能帮助我们监控和分析内存使用情况。</li></ul></li></ol><p>总的来说，内存泄漏是一个比较常见的问题，但只要我们通过监控、生成堆快照并分析，能够及时发现并修复它。</p><h2 id="Java-里的对象在虚拟机里面是怎么存储的？">Java 里的对象在虚拟机里面是怎么存储的？</h2><p>在 Java 中，对象是存放在 <strong>堆内存</strong> 中的，而对象在堆中的布局主要由三部分组成：<br><strong>对象头（Header）+ 实例数据（Instance Data）+ 对齐填充（Padding）</strong>。</p><h3 id="对象的整体结构">对象的整体结构</h3><p>对象在内存中的基本组成如下：</p><table><thead><tr><th>组成部分</th><th>说明</th><th>示例</th></tr></thead><tbody><tr><td><strong>对象头（Object Header）</strong></td><td>存放对象的元数据和运行时信息</td><td>Mark Word、Klass Pointer、数组长度</td></tr><tr><td><strong>实例数据（Instance Data）</strong></td><td>存放对象的实际字段（成员变量）</td><td>如 <code>int id</code>、<code>String name</code></td></tr><tr><td><strong>对齐填充（Padding）</strong></td><td>用于保证 8 字节对齐的内存要求</td><td>根据对象大小自动补齐</td></tr></tbody></table><h3 id="对象头（Header）详解">对象头（Header）详解</h3><p>对象头是 JVM 用来描述对象自身信息的区域，主要包含三部分内容：</p><ol><li>Mark Word（标记字段）</li></ol><ul><li>存储对象运行时数据，比如：hashCode、GC 分代年龄、锁状态标志（无锁、偏向锁、轻量级锁、重量级锁）等。</li><li>是一个会随着对象状态变化的多功能字段。</li></ul><ol start="2"><li>Klass Pointer（类型指针）</li></ol><ul><li>指向对象所属类的元数据，用于确定该对象的类型。</li></ul><ol start="3"><li>数组长度（仅数组对象有）</li></ol><ul><li>如果是数组对象，这里会额外存储数组长度信息。</li></ul><blockquote><p>简单理解：“对象头其实就是对象的身份证，里面记着它的 hashCode、锁状态、GC 信息，还有它是哪种类创建的。”</p></blockquote><h3 id="实例数据（Instance-Data）">实例数据（Instance Data）</h3><ul><li>存储对象的实际字段数据，比如成员变量。</li><li>JVM 会根据字段类型和继承层次进行内存重排，让对象结构更加紧凑。</li></ul><blockquote><p>简单理解：“这一块就是真正保存业务数据的地方，比如一个 User 对象，它的 id、name 都在这里。”</p></blockquote><h3 id="对齐填充（Padding）">对齐填充（Padding）</h3><ul><li>JVM 为了提高内存访问效率，要求对象大小是 8 字节的倍数。</li><li>如果对象实际大小不足，JVM 会自动添加填充字节。</li></ul><blockquote><p>简单理解：“对齐填充就像打补丁，为了让对象大小对齐到 8 字节边界。”</p></blockquote><p>存储位置</p><ul><li>普通对象：一般分配在<strong>堆</strong>（Heap）中。</li><li>年轻代（Young Generation）：新对象分配在 <strong>Eden</strong> 区，经过多次 GC 后可能晋升到老年代。</li><li>老年代（Old Generation）：<strong>存放生命周期较长的对象</strong>，比如缓存对象或静态实例。</li></ul><h3 id="Mark-Word-示例（64-位）">Mark Word 示例（64 位）</h3><table><thead><tr><th>位数</th><th>内容</th><th>含义</th></tr></thead><tbody><tr><td>54bit</td><td>哈希码（hashCode）/ GC 年龄 / 锁信息</td><td>动态变化字段</td></tr><tr><td>2bit</td><td>锁状态标志</td><td>00 无锁 / 01 偏向锁 / 10 轻量级锁 / 11 重量级锁</td></tr><tr><td>其他</td><td>线程 ID、GC 标志等</td><td>取决于锁类型</td></tr></tbody></table><p>“Mark Word 就像对象的‘运行日志’，JVM 会不断更新这里的锁状态和 GC 信息。”</p><h3 id="小结-18">小结</h3><p>在 JVM 里，对象是存放在堆中的，它的内存结构主要分三块：<br>第一是对象头，里面有 Mark Word（存 hashCode、锁信息、GC 年龄等）和类指针；<br>第二是实例数据，也就是对象真正的字段内容；<br>第三是对齐填充，用来保证 8 字节对齐。<br>数组对象会多一项数组长度字段。整体来看，对象头就像身份证，实例数据是内容，而填充只是凑整。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/1GHPIgAF_0_mianshiya.png" alt="0.png" width="100%" /><h2 id="说说-Java-的执行流程">说说 Java 的执行流程?</h2><p>Java的执行流程：</p><ol><li>源代码：编写.java文件</li><li>编译：使用javac编译器生成.class字节码文件。</li><li>类加载：JVM的类加载器加载.class文件到内存中。</li><li>解释执行：JVM将字节码转为机器码执行。</li><li>JIT编译：JVM根据需要将热点代码编译为机器码。</li><li>运行：执行main方法中的逻辑。</li><li>垃圾回收：JVM管理内存，并回收不再使用的对象。</li><li>程序结束：main方法结束，JVM清理资源，推出程序。</li></ol><h2 id="线上-CPU-飙高如何排查？">线上 CPU 飙高如何排查？</h2><blockquote><p>线上 CPU 飙高其实是一个非常常见、但排查流程非常固定的问题。我一般会按照 <strong>“定位进程 → 定位线程 → 定位代码 → 修复问题”</strong> 这套方法走。</p></blockquote><h4 id="①-定位哪个进程占用-CPU"><strong>① 定位哪个进程占用 CPU</strong></h4><p>第一步用：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">top</span></span><br></pre></td></tr></table></figure><p>看到哪个进程 CPU 最高，比如 Java 进程占了 180%+，就说明是应用本身的问题。</p><h4 id="②-定位哪个线程占用-CPU"><strong>② 定位哪个线程占用 CPU</strong></h4><p>继续用：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp <span class="tag">&lt;<span class="name">进程ID</span>&gt;</span></span><br></pre></td></tr></table></figure><p>找到 CPU 占用最高的线程，比如线程号 4519。</p><p>然后将线程号转成 16 进制：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">printf</span> <span class="string">&quot;<span class="variable">%x</span>\n&quot;</span> <span class="number">4519</span></span><br></pre></td></tr></table></figure><h4 id="③-打印线程栈，定位到底是哪段代码造成的"><strong>③ 打印线程栈，定位到底是哪段代码造成的</strong></h4><p>用 jstack 或 Arthas：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">jstack</span> &lt;pid&gt; | grep -A <span class="number">200</span> &lt;<span class="number">16</span>进制线程号&gt;</span><br></pre></td></tr></table></figure><p>再查看堆栈最顶层，看代码卡在哪个方法。</p><h4 id="④-修复-CPU-热点代码"><strong>④ 修复 CPU 热点代码</strong></h4><ul><li><strong>把高频创建的对象提前到应用启动时初始化一次</strong><br>（如：Sequence、Validator）</li><li>避免不必要的反射、正则、序列号获取</li><li>检查是否有死循环、大量 JSON 解析、大对象创建等</li></ul><h3 id="小结-19">小结</h3><blockquote><p>CPU 飙高我一般按固定流程排查：先找进程、再找线程、最后定位到具体代码。</p></blockquote><ol><li><p><strong>定位高 CPU 进程</strong><br>用 <code>top</code> 看是哪个进程占满 CPU。</p></li><li><p><strong>定位高 CPU 线程</strong><br><code>top -Hp &lt;pid&gt;</code> 找出最耗 CPU 的线程号。</p></li><li><p><strong>定位具体代码</strong><br>把线程号转成 16 进制：<br><code>printf &quot;%x\n&quot; &lt;tid&gt;</code><br>再用：<br><code>jstack &lt;pid&gt; | grep -A 200 &lt;16进制tid&gt;</code><br>或 Arthas <code>thread -n 3</code>，直接找到热点方法。</p></li><li><p><strong>根据堆栈优化代码</strong><br>多数根因都是：频繁创建对象、正则/反射过多、DB/IO 阻塞、死循环等。</p></li></ol><p><strong>一句话总结：</strong></p><blockquote><p><strong>top 找进程 → top -Hp 找线程 → jstack/Arthas 找热点方法 → 优化代码</strong>，这是排查 CPU 飙高最标准、最高效的流程。</p></blockquote><h2 id="怎么分析-JVM-当前的内存占用情况？OOM-后怎么分析？">怎么分析 JVM 当前的内存占用情况？OOM 后怎么分析？</h2><h2 id="怎么分析-JVM-当前的内存占用情况？OOM-之后怎么分析？">怎么分析 JVM 当前的内存占用情况？OOM 之后怎么分析？</h2><blockquote><p>我一般会分两步：<strong>先看实时内存情况</strong>，再分析 <strong>OOM dump 文件</strong> 去定位根因。</p></blockquote><h3 id="一、如何分析-JVM-当前的内存占用情况？">一、如何分析 JVM 当前的内存占用情况？</h3><p>主要用自带工具：</p><h4 id="1）jstat-——-看-JVM-内存实时情况"><strong>1）jstat —— 看 JVM 内存实时情况</strong></h4><p><code>jstat -gc &lt;pid&gt;</code><br>可以看到：</p><ul><li>Eden、Survivor、Old 区的使用情况</li><li>GC 次数和耗时<br>方便判断是不是某块内存持续上涨、GC 频繁等问题。</li></ul><h4 id="2）jmap-——-查看堆的详细结构"><strong>2）jmap —— 查看堆的详细结构</strong></h4><p><code>jmap -heap &lt;pid&gt;</code> 查看：</p><ul><li>堆大小配置</li><li>当前各区占用情况</li><li>GC 类别</li></ul><p><code>jmap -histo &lt;pid&gt;</code> 可以看到：</p><ul><li>哪些类实例最多、占用最大<br>用来判断是否有往堆里塞大量对象的风险。</li></ul><h3 id="二、OOM-后怎么分析？">二、OOM 后怎么分析？</h3><p>OOM 时最关键的是 <strong>拿到 heap dump 文件</strong>。</p><h3 id="1）开启自动-dump"><strong>1）开启自动 dump</strong></h3><p>在启动参数加：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:+HeapDumpOnOutOfMemoryError</span> </span><br><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:HeapDumpPath=/tmp/heapdump</span>.hprof</span><br></pre></td></tr></table></figure><p>发生 OOM 时 JVM 会自动生成 <code>.hprof</code> 文件。</p><h3 id="2）用专业工具分析-dump"><strong>2）用专业工具分析 dump</strong></h3><p>常用工具：</p><ul><li><strong>MAT（Eclipse Memory Analyzer）</strong></li><li><strong>VisualVM</strong></li><li><strong>GCeasy</strong></li><li><strong>YourKit</strong></li></ul><p>这些工具可以告诉你：</p><ul><li>哪些对象占了最多内存</li><li>哪些对象存在强引用链无法被清理</li><li>是否存在缓存未清理、连接未关闭、集合无限膨胀等问题<br>最后定位到具体代码并修复。</li></ul><h3 id="小结-20">小结</h3><blockquote><p>分析 JVM 内存我主要用两类工具：<strong>在线看实时内存</strong> + <strong>OOM 后看 dump 文件</strong>。</p></blockquote><p><strong>① 在线分析（实时内存占用）</strong></p><ul><li><code>jstat -gc &lt;pid&gt;</code> 看 Eden、Survivor、Old 区的使用情况和 GC 情况。</li><li><code>jmap -heap &lt;pid&gt;</code> 看堆大小、配置、当前占用情况。</li><li><code>jmap -histo &lt;pid&gt;</code> 找占内存最多的类。</li></ul><p><strong>② OOM 之后怎么分析</strong></p><ul><li>启动参数加上：<br><code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heap.hprof</code><br>OOM 时自动生成 dump。</li><li>用 <strong>MAT / VisualVM / GCeasy</strong> 打开 dump，找占用最大的对象、引用链，定位内存泄漏或对象膨胀的代码。</li></ul><p><strong>一句话总结：</strong></p><blockquote><p>在线靠 jstat/jmap 看趋势，OOM 靠 dump 文件找大对象和引用链，这两步就能定位大部分 JVM 内存问题。</p></blockquote>]]></content>
    
    
    <summary type="html">我对JVM的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="JVM" scheme="https://itgeqian.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch相关面试题</title>
    <link href="https://itgeqian.github.io/posts/78.html"/>
    <id>https://itgeqian.github.io/posts/78.html</id>
    <published>2025-10-07T00:19:03.000Z</published>
    <updated>2025-10-20T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-ElasticSearch">GQ ElasticSearch</h1><h2 id="什么是-Elasticsearch？它有哪些优势和应用场景？">什么是 Elasticsearch？它有哪些优势和应用场景？</h2><p>Elasticsearch 是一个基于 Lucene 构建的开源<strong>分布式搜索引擎</strong>，它特别<strong>擅长处理大规模数据并提供快速搜索能力</strong>。<strong>它通过建立索引加速检索，适用于全文搜索、日志分析、数据分析等场景</strong>。</p><p>优势：</p><ul><li><strong>速度快</strong>：因为基于 Lucene 构建，它的查询非常高效，尤其擅长处理大量数据，且支持实时搜索。</li><li><strong>扩展性强</strong>：它是分布式的，可以通过增加节点来扩展处理能力，适合大规模数据和高查询需求。</li><li><strong>多种搜索方式</strong>：不仅支持全文搜索，还支持模糊查询、地理位置查询等多种查询方式。</li><li><strong>实时分析</strong>：支持<strong>实时数据查询和分析</strong>，非常适合需要快速反馈的应用场景。</li><li>REST API：<strong>提供强大的 REST API</strong>，方便与其他系统进行集成。</li></ul><p>应用场景：</p><ol><li><p>搜索引擎：<strong>例如电商网站用它来快速检索商品</strong>，<strong>或是新闻网站的内容搜索</strong>。</p></li><li><p><strong>日志分析</strong>：与 Logstash 和 Kibana 配合使用（ELK），进行大规模的日志数据分析。</p></li><li><p><strong>实时监控</strong>：用于实时监控系统性能、数据变化等，帮助企业及时发现问题。</p></li><li><p><strong>数据分析</strong>：数据科学家和分析师可以使用 Elasticsearch 进行数据分析，获得业务洞察。</p></li></ol><p>与 MySQL 的区别：</p><ul><li><p><strong>数据存储结构</strong>：Elasticsearch <strong>使用 JSON 文档存储数据</strong>，而 MySQL 使用表格结构。Elasticsearch 更适合处理非结构化数据。</p></li><li><p><strong>查询方式</strong>：Elasticsearch 使用灵活的 Query DSL 查询语言，而 MySQL 使用 SQL。</p></li><li><p><strong>全文搜索能力</strong>：Elasticsearch 的全文搜索能力更强，而 MySQL 的全文搜索功能相对较弱。</p></li></ul><h2 id="如何使用-Elasticsearch-实现高亮显示搜索结果？">如何使用 Elasticsearch 实现高亮显示搜索结果？</h2><p>要在 Elasticsearch 中实现高亮显示搜索结果，你可以使用 Elasticsearch 的 <code>highlighter</code> 功能。具体步骤如下：</p><ol><li><strong>准备数据</strong>：首先，确保需要搜索的数据已经被索引到 Elasticsearch 中。</li><li><strong>构建查询请求</strong>：在查询请求中，加入 <code>highlight</code> 配置，指定需要高亮显示的字段和高亮显示的样式。</li><li><strong>解析响应结果</strong>：从 Elasticsearch 返回的查询结果中提取出高亮显示的部分，并展示给用户。</li></ol><p><strong>示例代码</strong>：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST /your_index/_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;elastic&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;highlight&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>在这个请求中，我们在 <code>content</code> 字段中搜索 <code>&quot;elastic&quot;</code>，并且在响应结果中高亮显示包含该词的部分。</p><p>总结一下，高亮显示的基本步骤就是：你需要在查询中指定要高亮显示的字段，并在返回的结果中提取出高亮部分，展示给用户，方便他们看到关键字出现的位置。</p><h3 id="我看到你的项目用到了ES做高亮显示能具体说说你是怎么做的吗？">我看到你的项目用到了ES做高亮显示能具体说说你是怎么做的吗？</h3><ul><li>我们的高亮是用 ES 自带的 Highlighter 做的，场景是“视频搜索”。索引里主要搜两个字段：标题 <code>videoName</code> 和标签 <code>tags</code>。</li><li>查询的时候我在 DSL 里同时做两件事：一是 <code>multi_match</code> 搜这两个字段，二是加上 <code>highlight</code> 配置，指定高亮字段是 <code>videoName</code>，并设置前后缀标签，比如 <code>&lt;span class='highlight'&gt;</code> 和 <code>&lt;/span&gt;</code>。</li><li>ES 返回结果后，我从 <code>hit.getHighlightFields()</code> 里把高亮片段取出来，如果这个命中有高亮，就用它覆盖原来的标题，这样前端直接展示就是带 <code>&lt;span class='highlight'&gt;关键词&lt;/span&gt;</code> 的字符串；前端只要给 <code>.highlight</code> 一个样式（比如黄色背景）就行。</li><li>没有高亮的情况我就用原文回退，保证结果不空；排序这边除了相关性，还会叠加播放量等权重做二次排序。</li><li>一句话总结：查询时让 ES 标注命中的关键词，返回时把高亮片段替换掉原字段，前端简单加个 CSS，用户就能一眼看到关键词出现的位置。</li></ul><h2 id="什么是-Elasticsearch-中的倒排索引？它有什么作用？">什么是 Elasticsearch 中的倒排索引？它有什么作用？</h2><p>在Elasticsearch中，<strong>倒排索引</strong>是一种常用的数据结构，主要用于快速查找包含某个词汇的文档。与传统的正向索引结构不同，正向索引是根据文档建立的，记录每个文档包含的词汇。而倒排索引则是根据词汇建立的，记录每个词汇在哪些文档中出现，并且记录该词汇在文档中的位置。</p><p>具体来说，倒排索引的结构大致如下：</p><ol><li>每个词汇（Term）会关联到一个或多个文档ID，并记录词汇在这些文档中的位置。</li><li>当用户输入一个查询关键字时，系统可以通过倒排索引快速找到包含该词汇的所有文档，再通过文档ID快速访问到相应的文档内容。</li></ol><h3 id="倒排索引的优点：">倒排索引的优点：</h3><ul><li><strong>快速查找</strong>：可以高效地定位包含特定词汇的文档。</li><li><strong>支持复杂查询</strong>：例如支持词组搜索、通配符搜索等。</li><li><strong>数据分析</strong>：倒排索引不仅能加速查询，还非常适合用于数据分析和统计，常用于搜索引擎、日志分析和推荐系统等领域。</li></ul><h3 id="倒排索引的构建过程：">倒排索引的构建过程：</h3><ol><li><strong>分词</strong>：首先将文档中的内容分解为一个个单词或词项（Term），例如“深入理解Java核心技术”等文本，经过分词后会得到“深入”、“理解”、“Java”等词汇。</li><li><strong>生成倒排表</strong>：将分词得到的词汇与文档ID进行关联，形成倒排表，记录每个词汇在哪些文档中出现。例如，“Java”词汇可能出现在文档1、2、3中。</li></ol><p>通过这种方式，倒排索引能有效加速搜索引擎的检索速度，并且支持更复杂的查询功能。</p><h2 id="如何通过-Elasticsearch-实现分布式事务？">如何通过 Elasticsearch 实现分布式事务？</h2><p>Elasticsearch <strong>本身并不直接支持分布式事务，因为它是一个主要用于全文搜索和分析的分布式搜索引擎，而非传统的关系型数据库</strong>，它并不提供像 ACID（原子性、一致性、隔离性、持久性）那样的强事务支持。</p><p>但是，Elasticsearch 提供了一些<strong>保证单个文档操作原子性的机制</strong>，也就是说，它能够确保对单个文档的操作（如创建、更新、删除）要么完全成功，要么完全失败，但它并<strong>不保证多个文档或跨多个操作的一致性</strong>。</p><h3 id="为了实现分布式事务，可以考虑以下方法：">为了实现分布式事务，可以考虑以下方法：</h3><ol><li><p><strong>借用消息队列</strong>：可以使用 Kafka、RabbitMQ 等消息队列来确保不同系统间的消息能够有序、可靠地传输。例如，在一个分布式事务中，操作成功后可以通过消息队列通知其他系统进行相应的操作。</p></li><li><p><strong>双写架构</strong>：通过 Elasticsearch 和关系型数据库的双写来保证事务一致性。具体来说，在一个事务处理中，可以先在关系数据库中写入数据，再将数据同步到 Elasticsearch。</p></li><li><p><strong>分布式事务协议</strong>：可以采用 Two-Phase Commit（2PC）或 Saga 模式来保证事务的最终一致性。2PC 协议可以确保多个参与方在事务的两阶段中一致地提交或回滚，而 Saga 模式则将大事务分解为多个小事务，每个小事务都有补偿操作，从而避免系统异常时无法回滚的情况。</p></li></ol><blockquote><p>小结<br>总结：Elasticsearch 不直接支持传统的 ACID 事务，但可以通过消息队列、双写架构和分布式事务协议（如 2PC 或 Saga）来保证分布式环境中的数据一致性。</p></blockquote>]]></content>
    
    
    <summary type="html">我对ElasticSearch的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="ElasticSearch" scheme="https://itgeqian.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot相关面试题</title>
    <link href="https://itgeqian.github.io/posts/76.html"/>
    <id>https://itgeqian.github.io/posts/76.html</id>
    <published>2025-10-07T00:19:03.000Z</published>
    <updated>2025-10-20T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-SpringBoot">GQ SpringBoot</h1><h2 id="说说-Springboot-的启动流程">说说 Springboot 的启动流程</h2><h3 id="一句话总览">一句话总览</h3><blockquote><p><strong>main → SpringApplication.run → 准备环境 → 创建并准备 ApplicationContext → 加载并注册 Bean 定义（含自动装配）→ 刷新容器（创建单例、启动内置服务器）→ 调用 Runner → 发布就绪事件</strong>。<br>途中会伴随一串生命周期事件，失败会发失败事件。</p></blockquote><h3 id="分步骤说">分步骤说</h3><ol><li><p><strong>入口 &amp; 构建 SpringApplication</strong></p><ul><li>从 <code>main()</code> 调 <code>SpringApplication.run()</code> 开始。</li><li>构造 <code>SpringApplication</code> 时会<strong>推断应用类型</strong>（Servlet/Reactive/None），加载 <code>ApplicationListener</code>、<code>ApplicationContextInitializer</code> 等（Boot 2.x 从 <code>spring.factories</code>，Boot 3.x 从 <code>META-INF/spring/*.imports</code>）。</li></ul></li><li><p><strong>准备 Environment（environmentPrepared）</strong></p><ul><li>创建并配置 <code>ConfigurableEnvironment</code>，<strong>读取配置</strong>（<code>application.yml/properties</code>、命令行、环境变量等），<strong>确定激活的 profile</strong>。</li><li>这一阶段会发布 <code>ApplicationEnvironmentPreparedEvent</code>，并<strong>打印 Banner</strong>。</li></ul></li><li><p><strong>创建 &amp; 准备 ApplicationContext（contextPrepared）</strong></p><ul><li>根据应用类型创建相应的 <code>ApplicationContext</code>（如 <code>ServletWebServerApplicationContext</code>）。</li><li>设置基础属性（资源加载器、BeanName 生成器等），然后<strong>调用所有 <code>ApplicationContextInitializer</code></strong> 对上下文做预初始化。</li></ul></li><li><p><strong>加载 Bean 定义 &amp; 自动装配（contextLoaded）</strong></p><ul><li><code>BeanDefinitionLoader</code> 把启动类及其扫描包里的组件注册进容器。</li><li>进入<strong>工厂后置处理</strong>：触发 <code>BeanFactoryPostProcessor</code>（特别是 <code>ConfigurationClassPostProcessor</code>），解析 <code>@Configuration/@ComponentScan/@Import</code>。</li><li><strong>关键：<code>@EnableAutoConfiguration</code></strong>（来自 <code>@SpringBootApplication</code> 复合注解）会通过 <code>AutoConfigurationImportSelector</code><br>从 <strong><code>META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports</code></strong>（或旧版的 <code>spring.factories</code>）读取<strong>自动配置类</strong>并注册 → 这就是“开箱即用”的来源（图右下红框部分）。</li></ul></li><li><p><strong>刷新容器 refresh（started）</strong></p><ul><li><p>标准的 <code>context.refresh()</code>：</p><ul><li>注册 <code>BeanPostProcessor</code>；</li><li>初始化 <code>MessageSource</code>、<code>ApplicationEventMulticaster</code>；</li><li><strong>onRefresh</strong>：如果是 Web 应用，<strong>创建并启动内嵌服务器</strong>（Tomcat/Jetty/Undertow）；</li><li>注册监听器；</li><li><strong>finishBeanFactoryInitialization</strong>：实例化所有<strong>单例 Bean</strong>，触发依赖注入、<code>@PostConstruct</code>、<code>InitializingBean</code> 等生命周期回调；</li><li><strong>finishRefresh</strong>：发布 <code>ContextRefreshedEvent</code>。</li></ul></li><li><p>到这里容器“可用了”，会发布 <code>ApplicationStartedEvent</code>。</p></li></ul></li><li><p><strong>调用 Runner（ready）</strong></p><ul><li>如果你定义了 <strong><code>ApplicationRunner</code>/<code>CommandLineRunner</code></strong>，此时会被调用，做业务启动收尾初始化。</li><li>一切正常后发布 <code>ApplicationReadyEvent</code>，表示服务<strong>已就绪</strong>；若中途异常，则发布 <code>ApplicationFailedEvent</code>。</li></ul></li><li><p><strong>运行阶段（running）</strong></p><ul><li>Web 容器已启动、端口已监听，Bean 都是单例常驻，应用进入稳定运行期。之后所有的请求、定时任务、消息消费等都在这阶段工作。</li></ul></li></ol><h3 id="事件与分层的直观对照">事件与分层的直观对照</h3><ul><li><strong>引导</strong>：<code>starting → environmentPrepared</code>（准备环境）</li><li><strong>启动</strong>：<code>contextPrepared → contextLoaded → started → ready</code>（容器准备、加载、刷新、就绪）</li><li><strong>运行</strong>：<code>running</code>（对外提供服务）<br>每一阶段都有相应 <code>ApplicationEvent</code> 广播，方便你在合适的时机做扩展。</li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/lCmYb6bZ_image_mianshiya.png" alt="image.png" width="100%" /><h3 id="精炼版">精炼版</h3><p>Spring Boot 启动从 <code>SpringApplication.run</code> 开始：先<strong>准备 Environment</strong> 读取配置和 profile，然后<strong>创建合适的 ApplicationContext</strong> 并应用 Initializer,对上下文做预初始化，接着<strong>加载 Bean 定义</strong>并通过 <code>@EnableAutoConfiguration</code> 把自动配置从 <code>*.imports/spring.factories</code> 导入；之后 <strong><code>refresh()</code></strong>：注册后置处理器、创建单例 Bean、Web 应用会<strong>启动内嵌 Tomcat</strong>；容器刷完再执行 <strong><code>Runner</code></strong>，最后发布 <strong><code>ApplicationReadyEvent</code></strong>，应用就绪对外提供服务。中途有一系列生命周期事件，方便做扩展，失败会发布失败事件。</p><blockquote><p>追问“自动配置怎么生效/怎么排错”：<br>记住 <strong><code>@EnableAutoConfiguration</code> + <code>AutoConfiguration.imports</code></strong>，配合 <code>debug=true</code> 或 <code>--debug</code> 能看到 <strong>Auto-Configuration Report</strong>，按条件装配（<code>@Conditional*</code>）判断哪些生效、哪些没生效，定位问题很快。</p></blockquote><h2 id="什么是-Spring-Boot？">什么是 Spring Boot？</h2><p>Spring Boot 是一个<strong>简化 Spring 应用开发的框架</strong>，它的目标是<strong>减少配置、降低开发复杂度</strong>，让我们能更快地构建、测试和部署 Spring 应用。</p><p>它通过几项核心特性来做到这一点：<br>1 <strong>自动化配置</strong> : 根据依赖自动帮你配置 Spring 环境，省去繁琐的 XML。<br>2 <strong>内嵌服务器</strong> : 自带 Tomcat 或 Jetty，直接运行，无需外部容器。<br>3 <strong>快速开发</strong> : 提供开箱即用的项目结构和依赖管理。<br>4 <strong>独立运行</strong> :应用可以打包成一个可执行的 Jar，一行命令就能启动。</p><blockquote><p>Spring Boot 就是帮我们“更快启动、更少配置、即开即用”的 Spring 框架。</p></blockquote><h2 id="Spring-Boot-的核心特性有哪些？">Spring Boot 的核心特性有哪些？</h2><p>1 自动化配置 : 根据依赖自动帮你配置 Spring 环境，省去繁琐的 XML。<br>2 内嵌服务器 : 自带 Tomcat 或 Jetty，直接运行，无需外部容器。<br>3 快速开发 : 提供开箱即用的项目结构和依赖管理。<br>4 独立运行 :应用可以打包成一个可执行的 Jar，一行命令就能启动。</p><h2 id="Spring-Boot-中-application-properties-和-application-yml-的区别是什么？">Spring Boot 中 application.properties 和 application.yml 的区别是什么？</h2><p>书写格式不一样。 优先级：application.properties &gt; application.yml</p><h2 id="Spring-Boot-打成的-jar-和普通的-jar-有什么区别">Spring Boot 打成的 jar 和普通的 jar 有什么区别 ?</h2><p>SpringBoot 打成的Jar 包，不仅包含应用程序的源代码和依赖库，还包含程序运行的配置、脚本以及服务依赖，只需要有个jdk就可以运行这个jar包了。</p><p>而普通jar需要启动tomcat才能运行这个jar包</p><h2 id="Spring-Boot-是否可以使用-XML-配置-？">Spring Boot 是否可以使用 XML 配置 ？</h2><p>支持，可以用@ImportResource注解导入XML文件</p><h2 id="SpringBoot-默认同时可以处理的最大连接数是多少？">SpringBoot 默认同时可以处理的最大连接数是多少？</h2><p>最大连接数=默认最大连接数+默认等待数 = 8192+100 最大请求数 线程池配置默认核心线程是10 最大是200</p><h2 id="如何理解-Spring-Boot-中的-starter？">如何理解 Spring Boot 中的 starter？</h2><h3 id="什么是-Spring-Boot-的-Starter？">什么是 Spring Boot 的 Starter？</h3><ul><li><strong>一句话</strong>：Starter 就是一组“<strong>开箱即用的依赖集合</strong>”。它把某个功能模块所需的常用依赖、默认配置、自动配置类打包好，<strong>你只需在 <code>pom.xml</code> 里引一个 starter 依赖</strong>，Spring Boot 在启动时就会按需装配对应的 Bean，避免你手写大量配置。</li><li><strong>好处</strong>：少依赖、少配置、少样板代码；按条件装配、默认即用、可覆盖可禁用。</li></ul><h3 id="自动生效的大致流程（看到-Starter-时，Spring-Boot-做了什么）">自动生效的大致流程（看到 Starter 时，Spring Boot 做了什么）</h3><ol><li><p>你在 <code>pom.xml</code> 引入了某个 <code>spring-boot-starter-xxx</code>。</p></li><li><p>这个 starter 里会依赖一个 <strong>自动配置模块</strong>（通常形如 <code>xxx-autoconfigure</code>）。</p></li><li><p>自动配置模块里通过 <strong><code>@EnableAutoConfiguration</code></strong> 机制，配合：</p><ul><li>Spring Boot 2.x：<code>META-INF/spring.factories</code> 列出自动配置类；</li><li><strong>Spring Boot 3.x</strong>：改为 <code>META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports</code>；<br>由框架在启动时加载这些 <strong><code>*AutoConfiguration</code></strong> 类。</li></ul></li><li><p>自动配置类里使用大量 <strong>条件注解</strong>（<code>@ConditionalOnClass</code>、<code>@ConditionalOnMissingBean</code>、<code>@ConditionalOnProperty</code>……）<strong>按需注册 Bean</strong>。</p></li><li><p>配置属性通过 <code>@ConfigurationProperties</code> 与你的 <code>application.properties/yaml</code> <strong>自动绑定</strong>，默认值可用，想调再覆写。</p></li></ol><blockquote><p>看图可以把它想象成：<strong>导入 starter → 发现 &amp; 激活自动配置类 → 读取配置属性 → 条件成立就注册 Bean → 场景就绪</strong>。</p></blockquote><h3 id="该怎么使用（开发者视角）">该怎么使用（开发者视角）</h3><ul><li>需要 Web？<code>spring-boot-starter-web</code></li><li>需要 JPA？<code>spring-boot-starter-data-jpa</code></li><li>需要缓存？<code>spring-boot-starter-cache</code></li><li>需要监控？<code>spring-boot-starter-actuator</code></li></ul><blockquote><p><strong>默认即可跑</strong>，想自定义再在 <code>application.yml/properties</code> 覆盖配置或提供自定义 Bean。</p></blockquote><h3 id="如何禁用-定制">如何禁用/定制</h3><ul><li>局部禁用：<code>application.yml</code> 中设置 <code>spring.autoconfigure.exclude=xxx.AutoConfiguration</code></li><li>全局禁用：<code>@SpringBootApplication(exclude = XxxAutoConfiguration.class)</code></li><li>覆盖默认：自己提供同名/同类型 Bean（配合 <code>@ConditionalOnMissingBean</code>，你的 Bean 会生效，默认的不会再装配）</li></ul><h3 id="自定义一个-Starter（简化流程版）">自定义一个 Starter（简化流程版）</h3><ol><li><p><strong>创建 <code>xxx-spring-boot-starter</code></strong>（只写依赖坐标，不含自动配置逻辑）。</p></li><li><p><strong>创建 <code>xxx-spring-boot-autoconfigure</code></strong>：</p><ul><li>写业务组件与 <code>@ConfigurationProperties</code>；</li><li>写 <code>XxxAutoConfiguration</code>（使用条件注解注册 Bean）；</li><li><strong>Spring Boot 2.x</strong>：在 <code>META-INF/spring.factories</code> 中声明自动配置类；<br><strong>Spring Boot 3.x</strong>：在 <code>META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports</code> 中声明。</li></ul></li><li><p>starter 依赖自动配置模块；业务项目只需引入 starter 即可生效。</p></li></ol><h3 id="一句话比喻">一句话比喻</h3><blockquote><p><strong>Starter 就像“功能套餐”</strong>：你点了 Web 套餐，服务员（Spring Boot）就把 MVC、默认 JSON、内嵌容器、基本配置都端上来；默认能吃，想加料/换口味自己配就行。</p></blockquote><h2 id="Spring-Boot-如何处理跨域请求（CORS）？">Spring Boot 如何处理跨域请求（CORS）？</h2><h3 id="问：Spring-Boot-怎么处理跨域（CORS）？">问：Spring Boot 怎么处理跨域（CORS）？</h3><p><strong>核心点</strong>：跨域要让浏览器的<strong>预检请求（OPTIONS）</strong> 和后续请求都能“过关”，并且在响应头里带上允许跨域的配置。Spring Boot 有三种常用做法：</p><hr><h3 id="1-局部开启：在-Controller-方法上加-CrossOrigin">1) 局部开启：在 Controller/方法上加 <code>@CrossOrigin</code></h3><ul><li><p>适合<strong>某几个接口</strong>临时放开跨域。</p></li><li><p>用法简单：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@CrossOrigin(origins = &quot;https://example.com&quot;, allowCredentials = &quot;true&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DemoController</span> &#123; ... &#125;</span><br></pre></td></tr></table></figure></li><li><p>可以精确控制 <code>origins / methods / headers / maxAge / allowCredentials</code> 等。</p></li></ul><hr><h3 id="2-全局开启：实现-WebMvcConfigurer-addCorsMappings">2) 全局开启：实现 <code>WebMvcConfigurer#addCorsMappings</code></h3><ul><li><p>适合<strong>整个应用统一管理</strong>跨域策略。</p></li><li><p>推荐做法（轻量、无侵入）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebMvcCorsConfig</span> <span class="keyword">implements</span> <span class="title class_">WebMvcConfigurer</span> &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addCorsMappings</span><span class="params">(CorsRegistry registry)</span> &#123;</span><br><span class="line">    registry.addMapping(<span class="string">&quot;/**&quot;</span>)</span><br><span class="line">            .allowedOrigins(<span class="string">&quot;https://example.com&quot;</span>)</span><br><span class="line">            .allowedMethods(<span class="string">&quot;GET&quot;</span>,<span class="string">&quot;POST&quot;</span>,<span class="string">&quot;PUT&quot;</span>,<span class="string">&quot;DELETE&quot;</span>)</span><br><span class="line">            .allowedHeaders(<span class="string">&quot;*&quot;</span>)</span><br><span class="line">            .allowCredentials(<span class="literal">true</span>)</span><br><span class="line">            .maxAge(<span class="number">3600</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>注意：Spring Security 开启时要同步 <code>http.cors()</code>（否则被安全链挡住）。</p></li></ul><hr><h3 id="3-过滤器方式：注册-CorsFilter-Bean">3) 过滤器方式：注册 <code>CorsFilter</code> Bean</h3><ul><li><p>走 <strong>Filter 链</strong>，在 <strong>进入 Spring MVC 之前</strong> 统一处理跨域。</p></li><li><p>适合你想在 <strong>MVC 之外的过滤器</strong> 场景里也放行跨域（如静态资源、某些网关场景）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> CorsFilter <span class="title function_">corsFilter</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">UrlBasedCorsConfigurationSource</span> <span class="variable">source</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UrlBasedCorsConfigurationSource</span>();</span><br><span class="line">  <span class="type">CorsConfiguration</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CorsConfiguration</span>();</span><br><span class="line">  config.addAllowedOrigin(<span class="string">&quot;https://example.com&quot;</span>);</span><br><span class="line">  config.addAllowedHeader(<span class="string">&quot;*&quot;</span>);</span><br><span class="line">  config.addAllowedMethod(<span class="string">&quot;*&quot;</span>);</span><br><span class="line">  config.setAllowCredentials(<span class="literal">true</span>);</span><br><span class="line">  source.registerCorsConfiguration(<span class="string">&quot;/**&quot;</span>, config);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">CorsFilter</span>(source);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="addCorsMappings-vs-CorsFilter：什么时候用哪个？">addCorsMappings vs CorsFilter：什么时候用哪个？</h3><ul><li><strong><code>addCorsMappings</code>（WebMvcConfigurer）</strong>：在 <strong>Spring MVC</strong> 层处理，<strong>进入 <code>DispatcherServlet</code> 之后</strong>才生效。</li><li><strong><code>CorsFilter</code></strong>：在 <strong>Filter 链</strong>中最先执行，<strong>进入 MVC 之前</strong>就把跨域处理好了。</li><li><strong>实践选择</strong>：能用 <strong>全局配置（addCorsMappings）</strong> 就用它；如果你有<strong>自定义 Filter/网关</strong>等 MVC 之外的场景需要跨域，就用 <strong>CorsFilter</strong>。</li></ul><hr><h3 id="常见坑-排查思路">常见坑 &amp; 排查思路</h3><ol><li><p><strong>预检请求被拦截</strong></p><ul><li>现象：OPTIONS 直接 401/403/404。</li><li>处理：确保拦截器/安全过滤器对 <strong>OPTIONS</strong> 放行；Spring Security 里加 <code>http.cors()</code>。</li></ul></li><li><p><strong><code>allowCredentials(true)</code> 与 <code>*</code> 冲突</strong></p><ul><li>有 <code>allowCredentials(true)</code> 时 <strong>不能</strong> 用 <code>allowedOrigins(&quot;*&quot;)</code>，要写具体域名。</li></ul></li><li><p><strong>顺序问题</strong></p><ul><li>如果你加了自定义 <code>Filter/Interceptor</code> 做鉴权，务必让 <strong>跨域先处理</strong>，否则浏览器拿不到允许跨域的响应头。</li></ul></li><li><p><strong>Spring Security</strong></p><ul><li><p>开启全局 CORS 后，还要在 Security 里：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http.cors().and().csrf().disable();</span><br></pre></td></tr></table></figure></li><li><p>否则安全链会先把请求挡住。</p></li></ul></li></ol><hr><h3 id="一句话总结">一句话总结</h3><blockquote><p>Spring Boot 处理跨域的最佳实践是：<strong>全局用 <code>addCorsMappings</code> 统一配置</strong>，安全框架里启用 <code>http.cors()</code>；若需要在 MVC 之外生效，再上 <strong><code>CorsFilter</code></strong>。记得放行 <strong>OPTIONS</strong>，并处理好 <strong>allowCredentials 与 * 的冲突</strong>。</p></blockquote><h2 id="SpringBoot-中如何实现定时任务">SpringBoot 中如何实现定时任务 ?</h2><p>单体：启动类加@EnableSchedual注解，定义定时任务类在任务上使用@Schedualed注解。</p><p>分布式：xxl-job</p><h2 id="Spring-Boot-3-x-与-2-x-版本有哪些主要的改进和区别？">Spring Boot 3.x 与 2.x 版本有哪些主要的改进和区别？</h2><p>1、从javaee迁移到Jakarta<br>2、JDK<strong>最低支持17</strong><br>3、微服务下 <strong>启动更快</strong>，毫秒级别</p><h2 id="SpringBoot（Spring）中为什么不推荐使用-Autowired-？">SpringBoot（Spring）中为什么不推荐使用 @Autowired ？</h2><hr><h3 id="为什么-Spring-Spring-Boot-不推荐使用-Autowired？"><strong>为什么 Spring / Spring Boot 不推荐使用 <code>@Autowired</code>？</strong></h3><p>其实 Spring 官方并不是“禁止” <code>@Autowired</code>，只是不推荐 <strong>字段注入（Field Injection）</strong> 的用法，推荐使用 <strong>构造器注入（Constructor Injection）</strong>。</p><p>原因主要有以下几点，一条条展开说：</p><hr><h3 id="1-不利于单元测试（强烈原因）">1 不利于单元测试（强烈原因）</h3><p>字段注入的时候：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> UserService userService;</span><br></pre></td></tr></table></figure><p>要写单元测试时，你无法直接构造对象，因为没有无参构造器 + 没有办法给字段赋值，只能靠 Spring 容器启动，非常麻烦。</p><p>而构造器注入：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">UserController</span><span class="params">(UserService userService)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.userService = userService;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>单元测试时可以直接 new<br>也可以 mock，完全不需要启动 Spring 容器。</p><p>这是 Spring 官方最推荐构造器注入的核心原因。</p><hr><h3 id="2-字段注入会隐藏依赖关系，不利于维护">2 字段注入会隐藏依赖关系，不利于维护</h3><p>字段注入时：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> OrderService orderService;</span><br></pre></td></tr></table></figure><p>看起来简单，但你根本看不出一个类到底依赖了哪些组件。</p><p>构造器注入就很清晰：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">MyService</span><span class="params">(AService a, BService b, CService c)</span> &#123; ... &#125;</span><br></pre></td></tr></table></figure><p>依赖一眼可见<br>构造方法参数过多的时候，你还能反思是否违反“单一职责”</p><hr><h3 id="3-字段注入容易造成循环依赖难排查">3 字段注入容易造成循环依赖难排查</h3><p>字段注入的生命周期顺序不受你控制，Spring 会在对象创建后再进行注入，所以：</p><ul><li>容易产生循环依赖</li><li>报错信息也不直观</li><li>排查起来非常痛苦</li></ul><p>构造器注入则更明确，Spring 会在构建对象前检查依赖关系，一旦循环依赖直接报错。</p><hr><h3 id="4-不利于不可变对象设计（违背-OOP-最佳实践）">4 不利于不可变对象设计（违背 OOP 最佳实践）</h3><p>字段注入要求：</p><ul><li>字段必须是非 final</li><li>必须允许被修改（反射注入）</li></ul><p>这违背了“依赖尽量不可变、对象设计尽量稳定”的理念。</p><p>构造器注入可以让字段使用 final：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> UserService userService;</span><br></pre></td></tr></table></figure><p>线程安全<br>更符合面向对象设计</p><hr><h3 id="5-Autowired-不是标准，-Resource-更标准">5 @Autowired 不是标准，@Resource 更标准</h3><ul><li><code>@Autowired</code> 是 Spring 自己的</li><li><code>@Resource</code> 是 JSR-250 标准（Java 标准规范）</li></ul><p>如果以后换成其他 IoC 框架：</p><ul><li><code>@Resource</code> 大部分都能用</li><li><code>@Autowired</code> 不一定兼容</li></ul><p>不过这里 <strong>大部分面试官不太关注这一点，但可以当加分项说明</strong>。</p><hr><h3 id="总结">总结</h3><p>我们不推荐字段注入的 @Autowired，而是推荐构造器注入。主要原因有四个：<br>1）可测试性差：字段注入必须依赖 Spring 容器，单元测试不好写；构造器注入能直接 new 或 mock。<br>2）依赖不透明：字段注入隐藏依赖，构造器注入一眼能看出类依赖了什么。<br>3）风险更高：字段注入更容易引发循环依赖且不易排查，构造器注入在创建阶段就能发现问题。<br>4）不利于不可变设计：字段注入不能用 final，构造器注入可以保证依赖不可变、线程更安全。<br>如果一定要用字段注入，也建议用标准的 @Resource，但整体最佳实践是构造器注入。</p><h2 id="说说-MyBatis-的缓存机制？">说说 MyBatis 的缓存机制？</h2><blockquote><p>MyBatis 里面有两级缓存：<strong>一级缓存</strong>和<strong>二级缓存</strong>。一级缓存默认开启，二级缓存需要手动配置。</p></blockquote><h3 id="一级缓存（SqlSession-级别）">一级缓存（SqlSession 级别）</h3><blockquote><p>可以理解成“当前会话里的一个临时缓存区”。</p></blockquote><ul><li><p>作用范围：<strong>同一个 SqlSession 内</strong>有效。只要你在同一个 SqlSession 中重复查相同数据，MyBatis 不会再查数据库，而是直接从缓存返回<br>→ 文档中称一级缓存为会话级缓存 </p></li><li><p>生命周期：跟 SqlSession 一致。</p></li><li><p>什么时候失效？</p><ul><li>执行增删改操作（insert/update/delete）</li><li>手动清缓存（clearCache）</li><li>SqlSession 关闭 / commit / rollback<br>→ 文档也明确提到这些会导致一级缓存清空 </li></ul></li></ul><p><strong>一句话总结</strong></p><blockquote><p>一级缓存是 SqlSession 级别的、默认开启的“最近查询结果”缓存，只在当前会话里有效。</p></blockquote><h3 id="二级缓存（Mapper-映射级别）">二级缓存（Mapper 映射级别）</h3><blockquote><p>可以理解成“mapper 级别的共享缓存”，跨多个 SqlSession 都能用。</p></blockquote><ul><li><p>作用范围：<strong>同一个 Mapper（命名空间）内的所有 SqlSession 共享</strong><br>→ 文档称其为命名空间级缓存，作用范围比一级缓存大 </p></li><li><p>需要手动开启，在 mapper.xml 中加：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">cache</span>/&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>生命周期：和 SqlSessionFactory 一致。</p></li><li><p>何时失效？</p><ul><li>对应 Mapper 执行任何增删改操作<br>→ 文档明确指出更新、插入、删除会让缓存失效 </li></ul></li></ul><p><strong>一句话总结</strong></p><blockquote><p>二级缓存是 Mapper 级的跨会话缓存，需要手动开启，可以让不同 SqlSession 共享查询结果。</p></blockquote><h3 id="总结：">总结：</h3><blockquote><p>MyBatis 有一级、二级两个缓存。<br>一级缓存默认开启，是 SqlSession 级别的，只在当前会话里生效，重复查询不会再查数据库。执行增删改、提交事务或清缓存时会失效。<br>二级缓存需要显式开启，是基于 Mapper 的缓存，可以被多个 SqlSession 共享。新增、修改、删除数据会让对应 Mapper 的二级缓存失效。<br>两级缓存一起配合，提升了查询性能，但缓存一致性依然由 MyBatis 自动维护。</p></blockquote><h1 id="MyBatis">MyBatis</h1><h2 id="说说MyBatis的缓存机制">说说MyBatis的缓存机制</h2><h3 id="说说-MyBatis-的缓存机制？-2">说说 MyBatis 的缓存机制？</h3><blockquote><p>MyBatis 里面有两级缓存：<strong>一级缓存</strong>和<strong>二级缓存</strong>。一级缓存默认开启，二级缓存需要手动配置。</p></blockquote><h3 id="一级缓存（SqlSession-级别）-2">一级缓存（SqlSession 级别）</h3><blockquote><p>可以理解成“当前会话里的一个临时缓存区”。</p></blockquote><ul><li><p>作用范围：<strong>同一个 SqlSession 内</strong>有效。只要你在同一个 SqlSession 中重复查相同数据，MyBatis 不会再查数据库，而是直接从缓存返回<br>→ 文档中称一级缓存为会话级缓存 </p></li><li><p>生命周期：跟 SqlSession 一致。</p></li><li><p>什么时候失效？</p><ul><li>执行增删改操作（insert/update/delete）</li><li>手动清缓存（clearCache）</li><li>SqlSession 关闭 / commit / rollback<br>→ 文档也明确提到这些会导致一级缓存清空 </li></ul></li></ul><p><strong>一句话总结</strong></p><blockquote><p>一级缓存是 SqlSession 级别的、默认开启的“最近查询结果”缓存，只在当前会话里有效。</p></blockquote><h3 id="二级缓存（Mapper-映射级别）-2">二级缓存（Mapper 映射级别）</h3><blockquote><p>可以理解成“mapper 级别的共享缓存”，跨多个 SqlSession 都能用。</p></blockquote><ul><li><p>作用范围：<strong>同一个 Mapper（命名空间）内的所有 SqlSession 共享</strong><br>→ 文档称其为命名空间级缓存，作用范围比一级缓存大 </p></li><li><p>需要手动开启，在 mapper.xml 中加：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">cache</span>/&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>生命周期：和 SqlSessionFactory 一致。</p></li><li><p>何时失效？</p><ul><li>对应 Mapper 执行任何增删改操作<br>→ 文档明确指出更新、插入、删除会让缓存失效 </li></ul></li></ul><p><strong>一句话总结</strong></p><blockquote><p>二级缓存是 Mapper 级的跨会话缓存，需要手动开启，可以让不同 SqlSession 共享查询结果。</p></blockquote><h3 id="总结：-2">总结：</h3><blockquote><p>MyBatis 有一级、二级两个缓存。<br>一级缓存默认开启，是 SqlSession 级别的，只在当前会话里生效，重复查询不会再查数据库。执行增删改、提交事务或清缓存时会失效。<br>二级缓存需要显式开启，是基于 Mapper 的缓存，可以被多个 SqlSession 共享。新增、修改、删除数据会让对应 Mapper 的二级缓存失效。<br>两级缓存一起配合，提升了查询性能，但缓存一致性依然由 MyBatis 自动维护。</p></blockquote><h2 id="MyBatis-中-和-的区别是什么？">MyBatis 中 #{} 和 ${} 的区别是什么？</h2><p>在 MyBatis 里，#{} 和 ${} 都是用来传参的，但它们的处理方式完全不一样。</p><h3 id="：预编译，占位符（安全、推荐使用）">{}：预编译，占位符（安全、推荐使用）</h3><blockquote><p>#{} 更像 JDBC 里的 PreparedStatement，占位符会先变成 “?”，然后 MyBatis 再安全地把参数绑定进去。</p></blockquote><ul><li>#{} 会在预处理阶段使用 ? 代替参数,能防止 SQL 注入（因为不会直接拼接 SQL）</li><li>传值时自动加引号、自动类型转换</li></ul><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM <span class="keyword">user</span> <span class="title">WHERE</span> id = <span class="comment">#&#123;id&#125;</span></span><br></pre></td></tr></table></figure><h3 id="：字符串拼接（不安全，需要谨慎）">${}：字符串拼接（不安全，需要谨慎）</h3><blockquote><p>${} 是直接把参数原样拼到 SQL 里，相当于字符串替换。</p></blockquote><ul><li>更像简单的字符串拼接</li><li>存在 SQL 注入风险（文档明确提到）</li><li>一般用户输入不能直接使用它</li></ul><p>示例：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> $&#123;tableName&#125;</span><br></pre></td></tr></table></figure><h4 id="那什么时候必须用-？">那什么时候必须用 ${}？</h4><p><strong>主要用于不能使用占位符的场景</strong>，比如数据库对象名、关键字动态拼接。<br>动态排序<br><code>ORDER BY $&#123;column&#125; $&#123;order&#125;</code><br>动态表名<br><code>SELECT * FROM $&#123;tableName&#125;</code><br>这类位置如果用 #{} 会报错，因为 SQL 关键字或字段名不能当作值绑定。(某些场景必须用 ${}（如 order by、group by 字段）)</p><h3 id="小结">小结</h3><blockquote><p>MyBatis 中 <strong>#{} 是安全的占位符</strong>，相当于 PreparedStatement，会把参数先替换成 “?” 再绑定，因此能 <strong>防止 SQL 注入</strong>，绝大多数场景都推荐用 #{}。</p><p><strong>${} 是字符串拼接</strong>，会把参数直接拼到 SQL 里，可能带来 <strong>SQL 注入风险</strong>，所以一般不用，只有在 <strong>动态表名、排序字段、group by / order by 字段</strong> 这些不能作为参数绑定的位置，才必须用 ${}。</p><p>一句话：<strong># 安全传值，$ 字符串拼接；能用 # 一律用 #，必须动态 SQL 的地方才用 $。</strong></p></blockquote><h2 id="什么是-MyBatis-Plus？它有什么作用？它和-MyBatis-有哪些区别？">什么是 MyBatis-Plus？它有什么作用？它和 MyBatis 有哪些区别？</h2><h3 id="什么是-MyBatis-Plus？它有什么作用？和-MyBatis-有什么区别？">什么是 MyBatis-Plus？它有什么作用？和 MyBatis 有什么区别？</h3><blockquote><p><strong>MyBatis-Plus 本质上是 MyBatis 的增强框架</strong>，它不改变 MyBatis 的核心，只是在原有基础上做增强，让开发更简单、高效。</p></blockquote><h3 id="1-MyBatis-是什么？">1. MyBatis 是什么？</h3><p>MyBatis 是一个半 ORM 框架，核心是 <strong>手写 SQL + 映射关系</strong>，开发者要写 SQL、写 XML、写 Mapper 方法，灵活但工作量大。</p><h3 id="2-MyBatis-Plus-是什么？">2. MyBatis-Plus 是什么？</h3><blockquote><p>文档中说得很清楚：MyBatis-Plus 就像 “MyBatis 的加强版弟弟”，对 MyBatis 做 <strong>二次封装，不做改变，只做增强</strong> 。</p></blockquote><p>它主要解决 MyBatis 写 SQL 多、CRUD 重复度高的问题，让开发更轻松。</p><h3 id="3-MyBatis-Plus-的作用（优势）">3. MyBatis-Plus 的作用（优势）</h3><p>总结为三大类：</p><h3 id="①-内置通用-CRUD（无需写-SQL）"><strong>① 内置通用 CRUD（无需写 SQL）</strong></h3><p>只要让 Mapper 继承 BaseMapper，就自动获得增删改查：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">UserMapper</span> <span class="keyword">extends</span> <span class="title class_">BaseMapper</span>&lt;User&gt; &#123;&#125;</span><br></pre></td></tr></table></figure><p>不用写 XML，直接能用。</p><h3 id="②-内置很多实用功能"><strong>② 内置很多实用功能</strong></h3><ul><li><strong>分页插件</strong>（不用自己写 LIMIT 语句）</li><li><strong>条件构造器</strong>（LambdaQueryWrapper，让代码更优雅）</li><li><strong>性能分析、SQL 注入器</strong>等扩展能力</li></ul><h3 id="③-自动代码生成器"><strong>③ 自动代码生成器</strong></h3><p>根据数据库表自动生成：</p><ul><li>Entity</li><li>Mapper / XML</li><li>Service<br>大幅减少重复劳动。</li></ul><h3 id="4-MyBatis-Plus-vs-MyBatis（核心区别）">4. MyBatis-Plus vs MyBatis（核心区别）</h3><table><thead><tr><th>对比点</th><th>MyBatis</th><th>MyBatis-Plus</th></tr></thead><tbody><tr><td>CRUD</td><td>手写 SQL</td><td>内置通用 CRUD</td></tr><tr><td>分页</td><td>手写分页 SQL</td><td>自带分页插件</td></tr><tr><td>代码量</td><td>多</td><td>少</td></tr><tr><td>上手难度</td><td>SQL 灵活但繁琐</td><td>更简单，更少样板代码</td></tr><tr><td>本质</td><td>半 ORM</td><td>MyBatis 的增强工具</td></tr></tbody></table><p>一句话总结：</p><blockquote><p><strong>MyBatis 需要你自己写 SQL；MyBatis-Plus 帮你自动写一大部分，让你把精力放在业务逻辑上。</strong></p></blockquote><h3 id="面试一句话总结">面试一句话总结</h3><blockquote><p><strong>MyBatis-Plus 是 MyBatis 的增强框架，提供通用 CRUD、分页、自动生成代码、Lambda 条件构造器等功能，大幅减少 SQL 和模板代码。相比 MyBatis，更省代码、更高效率，但底层还是 MyBatis，不会改变原有机制。</strong></p></blockquote><h2 id="Spring-AOP默认用的是什么动态代理，两者的区别？">Spring AOP默认用的是什么动态代理，两者的区别？</h2><p>Spring默认使用的是JDK动态代理，SpringBoot2.x版本默认改为CGLIB动态代理了。</p><ul><li>JDK动态代理需要基于接口实现，通过反射生成代理类</li><li>CGLIB动态代理基于类继承实现，通过字节码生成技术，生成目标类的子类，来实现对目标方法的代理</li></ul>]]></content>
    
    
    <summary type="html">我对SpringBoot的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="SpringBoot" scheme="https://itgeqian.github.io/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>Redis相关面试题</title>
    <link href="https://itgeqian.github.io/posts/73.html"/>
    <id>https://itgeqian.github.io/posts/73.html</id>
    <published>2025-10-07T00:19:03.000Z</published>
    <updated>2025-10-09T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-Redis">GQ Redis</h1><h2 id="Redis-主从复制的实现原理是什么？">Redis 主从复制的实现原理是什么？</h2><p>主从复制就是，将一个主节点上的数据全部复制到其他的从节点上，以保持主从节点的数据一致。</p><h3 id="为什么需要主从复制？">为什么需要主从复制？</h3><ul><li>支持负载均衡：为了减轻Redis的压力使用了读写分离的形式，也就是主节点写，从节点读，这样就必须要保证主从节点数据保持一致</li><li>提供故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；</li><li>主从复制是 Redis 高可用的基础，也是哨兵和集群实施的基础。</li></ul><h3 id="两种同步复制方式">两种同步复制方式</h3><h4 id="全量同步">全量同步</h4><p>全量同步是 Redis 主从同步中最关键的基础流程，尤其是在 <strong>第一次建立主从关系</strong>时。</p><blockquote><p>这里有一个问题，master 如何得知 salve 是否是第一次来同步呢？</p></blockquote><p>有几个概念，可以作为判断依据：</p><p>Replication Id：简称 <strong>replid</strong>，是数据集的标记，<strong>replid 一致则是同一数据集</strong>。每个 master 都有唯一的 replid，slave 则会继承 master 节点的 replid（<strong>根据 replid 是否一致来判断是不是第一次同步：如果是第一次同步，主从节点的 replid 不同，如果是断开重连，主从节点的 replid 相同</strong>）</p><p>offset：偏移量，随着记录在 repl_baklog 中的数据增多而逐渐增大。slave 完成同步时也会记录当前同步的 offset。<strong>如果 slave 的 offset 小于 master 的 offset，说明 slave 数据落后于 master，需要更新。</strong></p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Rhi1RFXC_image_mianshiya.png" alt="image.png" width="100%" />主从建立连接后，从节点会向主节点发送同步请求，其中包括：<ul><li>自己当前的 replication id（replid）</li><li>当前的 offset</li></ul><p>主节点据此判断<strong>是否可以进行增量同步</strong>。如果以下任一情况满足，就会触发全量同步：</p><ul><li><strong>主从 replid 不一致</strong> → 意味着这是一个新的 slave，必须进行全量同步。</li><li><strong>从节点 offset 太旧，主节点 backlog 已无法满足增量需求</strong> → 只能全量同步。</li></ul><h5 id="全量同步完整流程描述：">全量同步完整流程描述：</h5><p><strong>第一阶段</strong>：<strong>建立连接，协商同步</strong></p><ul><li>slave 节点请求增量同步</li><li>master 节点判断 replid，发现不一致，拒绝增量同步，或者一致但是offset太旧无法增量同步。</li></ul><p><strong>第二阶段：主库同步数据到从库</strong></p><ul><li>master 将完整内存数据生成 RDB快照，发送 RDB 到 slave</li><li>slave 清空本地数据，加载 master 的 RDB</li></ul><p><strong>第三阶段：master发送新写指令到从库</strong></p><ul><li>master 将 RDB 期间的命令记录在 repl_baklog，并持续将 log 中的命令发送给 slave</li><li>slave 执行接收到的命令，保持与 master 之间的同步</li></ul><h4 id="增量同步">增量同步</h4><p>增量同步是<strong>只会把主从库网络断联期间主库收到的命令同步交给从库</strong></p><blockquote><p>为什么需要增量同步？<br>全量同步需要先做 RDB，然后将 RDB 文件通过网络传输给 slave，成本太高了。因此除了第一次做全量同步，其它大多数时候 slave 与 master 都是做增量同步。</p></blockquote><p>master 怎么知道 slave 与自己的数据差异在哪里呢？</p><p>这就要说到全量同步时的 <strong>repl_baklog</strong> 文件了。这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从 0 开始读写</strong>，这样数组头部的数据就会被覆盖。<br>repl_baklog 中会记录 Redis 处理过的命令及 offset，包括 master 当前的 offset，和 slave 已经拷贝到的 offset，<strong>slave 与 master 的 offset 之间的差异，就是 salve 需要增量拷贝的数据了。</strong></p><ul><li>需要注意的是：如果 slave 出现网络阻塞，导致 master 的 offset 远远超过了 slave 的 offset：</li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/GKaBZyiL_1_mianshiya.png" alt="1.png" width="100%" /><ul><li>如果 master 继续写入新数据，master 的 offset 就会覆盖 repl_baklog 中旧的数据，直到将 slave 现在的 offset 也覆盖：</li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/zg8J4w4P_2_mianshiya.png" alt="2.png" width="100%" />棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果 slave 恢复，需要同步，却发现自己的 offset 都没有了，无法完成增量同步了。只能做全量同步。（这就是我们上面说的：从节点 offset 太旧，主节点 backlog 已无法满足增量需求，只能被迫做全量更新）<blockquote><p>小结： 模拟增量同步的几个场景</p></blockquote><p>场景 1：正常增量同步</p><ul><li>slave 掉线一小会儿，master 继续接收写入，repl_backlog 记录新命令。</li><li>slave 恢复连接，发来自己的 offset。</li><li>master 在 repl_backlog 中找到这部分数据，推送给 slave。</li><li>增量同步成功完成。</li></ul><p>场景 2：repl_backlog 写满了</p><ul><li>随着主节点不停接收新写入，repl_backlog 也在持续写入。</li><li>因为是固定大小的环形数组，旧数据会被新数据覆盖。</li><li>如果覆盖的数据包含 slave 尚未同步的 offset，那么 slave 想要增量同步时找不到数据。</li><li>增量同步失败，只能重新做 全量同步。</li></ul><h2 id="Redis-集群的实现原理是什么？">Redis 集群的实现原理是什么？</h2><h3 id="什么是Redis集群">什么是Redis集群</h3><p>Redis 集群是<strong>通过多个 Redis 实例组成的一个分布式集群</strong>，它<strong>可以通过分片</strong>（sharding）机制将数据分布到多个节点上，确保数据的高可用性和负载均衡。</p><h3 id="工作原理：">工作原理：</h3><ul><li>主从节点： Redis 集群由多个 master 节点和多个 slave 节点组成。<strong>每个 master 节点存储数据，而 slave 节点负责复制对应主节点的数据</strong>，提供数据冗余和故障恢复。</li><li>数据路由： <strong>客户端请求会通过哈希槽机制找到对应的主节点。每个 Redis 节点管理 16384 个哈希槽，每个键值（key）通过哈希计算后定位到某个哈希槽，进而找到数据存储的节点</strong>。</li><li><strong>故障转移</strong>： 如果<strong>某个主节点不可用，Redis 会自动将对应的从节点提升为新的主节点，保证集群的高可用性</strong>。</li></ul><h3 id="数据分片：">数据分片：</h3><p>Redis 集群使用哈希槽（Hash Slot）将数据分配到多个节点。每个节点负责一部分哈希槽的管理，数据通过计算哈希值映射到这些槽中，从而实现数据的分片存储。</p><p>总结：</p><ul><li><p>Redis 集群通过<strong>哈希槽机制实现了数据分片</strong>，确保数据的分布均衡。</p></li><li><p>集群具有<strong>高可用性</strong>，<strong>自动处理节点故障</strong>，确保服务不中断。</p></li><li><p>客户端通过<strong>哈希槽</strong>查询数据，能够<strong>快速定位到存储节点</strong>。</p></li></ul><h2 id="Redis-通常应用于哪些场景？">Redis 通常应用于哪些场景？</h2><p>Redis 是一个高性能的内存数据库，除了做缓存，它在很多高并发业务中都能用上。常见的使用场景主要有这几类：</p><h3 id="缓存（最经典、最常见）">缓存（最经典、最常见）</h3><p>Redis 最大的用途就是做缓存，用来<strong>加速数据读取、减轻数据库压力</strong>。比如用户信息、热点数据、页面渲染结果都可以先放到 Redis 里</p><blockquote><p>用户登录后，把用户资料放进 Redis，后续请求直接查缓存，不用每次打数据库。</p></blockquote><h3 id="分布式系统组件">分布式系统组件</h3><p>Redis 还能作为分布式架构的“中间件”来用，包括：</p><ul><li>分布式 Session：<ul><li>多台服务共享一个 Redis，所有用户登录状态都存在里面，解决 Session 不同步问题。</li></ul></li><li>分布式锁：<ul><li>通过 SETNX 或 RedLock 实现多实例间的互斥访问，比如防止重复下单。</li></ul></li><li>分布式限流：<ul><li>用计数器或 Lua 脚本来控制接口调用频率，实现限流保护。</li></ul></li></ul><blockquote><p>简单说，Redis 不止能缓存数据，还能帮我们在分布式系统里做‘协调员’。</p></blockquote><h3 id="实时系统与排行榜">实时系统与排行榜</h3><p>Redis 支持高并发的读写，非常适合实时数据场景，比如网站统计、在线用户数、排行榜等。<br>比如：排行榜常用 Redis 的 Sorted Set（有序集合）来实现：</p><ul><li>ZADD 添加用户和分数；</li><li>ZREVRANGE 查询前 N 名；</li><li>ZINCRBY 更新分数。</li></ul><blockquote><p>想要实时榜单或统计接口量，用 Redis 分分钟搞定。</p></blockquote><h3 id="消息队列">消息队列</h3><p>Redis 自带的 List 或 Pub/Sub 功能可以做轻量级的消息队列，用来异步解耦任务。</p><blockquote><p>用 LPUSH + BRPOP 实现简单任务队列，比如下单异步发消息、发送通知等。</p></blockquote><h3 id="计数器与统计">计数器与统计</h3><p>Redis 的自增操作原子性很强，非常适合做计数器。<br>比如：</p><ul><li>统计网站访问量；</li><li>点赞、收藏、评论计数；</li><li>接口限流统计。</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">INCR</span> page:view:<span class="number">1001</span>   # 访问量 +<span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="其他用处">其他用处</h3><p>除了上面这些，Redis 还经常用于：</p><ul><li>Bitmap：实现签到、活跃天数统计；</li><li>Geo：计算用户地理位置、附近的人；</li><li>HyperLogLog：做 UV（去重计数）；</li><li>分布式 ID 生成器；</li><li>时间轴、商品标签、用户关注关系等结构型数据。</li></ul><h3 id="小结">小结</h3><p>Redis 不仅是缓存工具，更是高性能的中间件组件。<br>它能做<strong>缓存、分布式锁、消息队列、排行榜、计数器、签到、地理位置计算</strong>等各种场景，几乎是互联网项目里必备的一环。</p><h2 id="Redis-为什么这么快？">Redis 为什么这么快？</h2><blockquote><p>Redis 之所以快，主要有五个原因：</p></blockquote><p>第一，<strong>基于内存存储</strong>。<br><strong>Redis 的数据都在内存里，内存访问比磁盘快几个数量级</strong>（RAM 延迟纳秒级，SSD 是微秒级），这决定了它的高读写速度。</p><p>第二，<strong>单线程 + IO 多路复用</strong>。<br>Redis 用<strong>单线程</strong>执行命令，<strong>避免线程切换开销</strong>；同时用 <strong>I/O 多路复用（epoll）模型</strong>，<strong>一个线程能同时处理上万连接，效率非常高</strong>。</p><p>第三，<strong>高效的数据结构</strong>。<br>内部结构比如<strong>哈希表、跳表、压缩列表</strong>（ziplist / listpack）等，<strong>都经过高度优化</strong>，大部分操作能在 <strong>O(1) 或 O(logN)</strong> 内完成。</p><p>第四，<strong>Redis 6.0 引入多线程 I/O</strong>。<br><strong>虽然核心命令仍是单线程执行，但网络读写、解包等可多线程并发处理，进一步提升吞吐。</strong></p><p>总结一句话：Redis 快的本质，是“内存 + 单线程 + I/O多路复用 + 高效数据结构 + 多线程I/O” 共同作用的结果。</p><h3 id="面试速答">面试速答:</h3><p>Redis 快主要因为：</p><ul><li>数据都在内存里，速度比磁盘快很多；</li><li>单线程避免切换开销，用 I/O 多路复用提升并发；</li><li>内部数据结构高度优化，操作复杂度低；</li><li>Redis 6 开始网络 I/O 多线程化，性能更高。</li></ul><p>简单说就是：内存存储 + 高效结构 + I/O 多路复用 + 轻量线程模型。</p><h3 id="面试官可能追问的延展">面试官可能追问的延展</h3><p>问：Redis 单线程为什么还能这么快？<br>答：<strong>因为主要耗时在 I/O，不在 CPU，单线程配合多路复用反而最优</strong>。</p><p>问：Redis 什么时候用到多线程？<br>答：Redis 6.0 开始多线程处理网络读写（accept、read/write），核心命令执行仍是单线程。</p><p>问：和 Memcached 的性能差异？<br>答：Redis 除了内存快，还优化了数据结构（ZSet、Hash 等）和持久化机制（RDB、AOF）。</p><p>问：<strong>什么是I/O 多路复用？</strong><br>答：I/O 多路复用就是：<strong>用一个线程同时监视很多连接的可读/可写事件（如 epoll/kqueue），哪个就绪就处理哪个。</strong><br>它的好处是少线程、少上下文切换、能支撑成千上万连接，所以像 Redis 用“单线程 + 多路复用 + 事件循环”就能跑很快。</p><h2 id="为什么-Redis-设计为单线程？6-0-版本为何引入多线程？">为什么 Redis 设计为单线程？6.0 版本为何引入多线程？</h2><h3 id="为什么-Redis-设计成单线程？"><strong>为什么 Redis 设计成单线程？</strong></h3><p>第一，<strong>Redis 是内存数据库，速度瓶颈不在 CPU</strong>。<br>它主要做内存操作和网络通信，CPU 根本不是重点，<strong>用多线程反而会增加线程切换的开销</strong>。</p><p>第二，<strong>单线程简单又稳定</strong>。<br>一个线程顺序执行所有命令，<strong>不需要加锁、也不会死锁</strong>，<strong>所有命令天然是原子操作</strong>，出问题也好排查。</p><p>第三，<strong>配合 I/O 多路复用就够快了</strong>。<br><strong>Redis 用 epoll 这类机制，一个线程就能同时处理成千上万个请求，所以根本不需要多线程</strong>。</p><h3 id="那-6-0-为何又引入多线程？">那 6.0 为何又引入多线程？</h3><p>因为<strong>网络 I/O 开始成为瓶颈了</strong>，比如<strong>并发多、带宽高、传大数据的时候</strong>。<br>所以 Redis 6.0 把<strong>网络读写</strong>这些活交给多个线程来做，提高了吞吐量。<br>但注意：真正执行命令的部分还是单线程，保证逻辑简单、结果可预测。</p><h3 id="一句话总结：">一句话总结：</h3><p>Redis 单线程是为了简单高效，6.0 加多线程是为了让网络 I/O 更快，不会破坏原来的执行顺序。也就是说<strong>Redis 现在的做法是“多线程处理网络，单线程执行命令”，两头都兼顾。</strong></p><h3 id="面试速答：">面试速答：</h3><p>Redis 单线程是因为它<strong>主要操作内存，不靠 CPU，单线程又简单又快，还避免加锁问题</strong>。<br>到 6.0 后，<strong>为了加快网络读写，就把 I/O 改成多线程，但核心命令还是单线程执行</strong>。</p><h2 id="Redis-中常见的数据类型有哪些？">Redis 中常见的数据类型有哪些？</h2><p>Redis 的核心数据结构，常用的有 <strong>五大类 + 四个扩展</strong>。</p><h3 id="五大类：">五大类：</h3><ul><li>String：<strong>普通字符串</strong>，Redis 中最简单的数据类型<ul><li>使用场景： <strong>计数器、分布式锁标记、缓存单值</strong>；支持整型自增、二进制安全。</li></ul></li><li>Hash：键值对集合,内部使用哈希表实现<ul><li>使用场景：存对象字段（如用户信息），方便快速检索</li></ul></li><li>List：Redis 中的 List 类型与 Java 中的 LinkedList 类似，<strong>有序集合</strong>，可以看做是一个<strong>双向链表结构</strong>。既可以支持正向检索和也可以支持反向检索。<ul><li>使用场景：<strong>消息队列/任务队列</strong>（LPUSH/RPOP、BLPOP阻塞取），储存用户操作的<strong>历史记录</strong>，便于快速访问。</li></ul></li><li>Set：<strong>无序去重集合</strong>，内部使用<strong>哈希表</strong>实现。<ul><li>使用场景：<strong>兴趣标签、去重</strong>、集合运算（交并差）。</li></ul></li><li>Sorted Set（ZSet）：<strong>带 score 的有序集合</strong>，SortedSet 中的每一个元素都带有一个 score 属性，可以基于 score 属性对元素<strong>排序</strong>，底层的实现是一个<strong>跳表（SkipList）加 hash 表</strong><ul><li>使用场景：<strong>排行榜、按权重/时间排序</strong>，支持区间查询。</li></ul></li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/W36qUfI8_Snipaste_2025-10-31_12-38-57_mianshiya.png" alt="Snipaste_2025-10-31_12-38-57.png" width="100%" /><h3 id="扩展结构：">扩展结构：</h3><ul><li>Bitmap：用 bit 存布尔状态，签到/活跃统计，超省内存。</li><li>HyperLogLog：基数统计（去重后的数量）近似值，内存固定很小。</li><li>GEO：存经纬度，附近的人/店，范围查询。</li><li>Stream：日志/消息流，消费组支持，做轻量消息队列。</li></ul><p>选型思路：<strong>单值用 String；对象用 Hash；队列用 List/Stream；去重/集合运算用 Set；排序/排行榜用 ZSet；大规模去重计数用 HLL；签到这类布尔时间线用 Bitmap；地理位置就 GEO</strong>。<br>生产上注意<strong>过期策略、内存上限、热键与大 Value 拆分</strong>，以及必要时持久化（RDB/AOF）。</p><h3 id="补充：">补充：</h3><ul><li>ZSet 实现：跳表 + 字典；List 新版本用 quicklist；Hash 小对象是紧凑编码（listpack），大了转哈希表。</li><li>怎么选 List 还是 Stream？ 简单队列、吞吐不高用 List；要消费组/消息追溯就用 Stream。</li><li>基数统计为什么用 HLL？ 固定内存 12KB 左右，能做亿级近似去重计数，误差约 0.81%。</li></ul><h3 id="总结：">总结：</h3><p>Redis 常见 <strong>5 类</strong>：<strong>String、Hash、List、Set、Sorted Set</strong>；<br>再加 4 个扩展：<strong>Bitmap、HyperLogLog、GEO、Stream。</strong><br>对应场景：单值缓存/计数、对象字段、队列、去重集合、排行榜、布尔时间线、近似去重计数、地理围栏、消息流。</p><h2 id="Redis-中跳表的实现原理是什么？">Redis 中跳表的实现原理是什么？</h2><blockquote><p>什么是跳表？<br>跳表主要是通过多层链表来实现，底层链表保存所有元素，而每一层链表都是下一层的子集。</p></blockquote><ul><li>跳表 = 底层完整有序链表 + 若干层“稀疏索引链表”。上层是下层的子集，像高速路“快车道”，用来加速查找。</li></ul><blockquote><p>为什么用：</p></blockquote><p>能实现有序集合的<strong>按 score 进行排序、范围查询、按名次（rank）定位</strong>等操作，复杂度接近平衡树但实现更简单。</p><h3 id="查找（score-member）：">查找（score / member）：</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/0uBQk0pH_image_mianshiya.png" alt="image.png" width="100%" />简单来说就是——从上往下、从左往右找。先从最顶层开始，一路往右找；如果发现下一个节点比目标大，就往下一层走；一直重复“能右就右，不能右就下”，最后到最底层，要么找到目标，要么确定没有。查找效率大概是 O(log n)。<h3 id="插入">插入</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/HLbLLjHZ_image_mianshiya.png" alt="image.png" width="100%" /><p>先按查找的方式找到插入的位置，再把元素插到最底层的链表里。然后 Redis 会用“<strong>抛硬币</strong>”的方式决定要不要把这个元素升到更高一层，比如有 50% 的概率升一层，再 50% 升到下一层……<br>直到“硬币没过”或者到了最高层。这样可以保证整体层级比较平衡。</p><h3 id="删除">删除</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/juCjk4Ui_image_mianshiya.png" alt="image.png" width="613px" /><p>先按查找的方式找到目标元素在每一层的位置，把元素从最底层的链表里删掉，然后在各层都把它从链表里摘掉。<br>如果删完某一层没有节点了，这一层就自动消失。删除的复杂度也是 O(log n)。</p><h4 id="总结：-2">总结：</h4><p>跳表查找就是“能右就右，不能右就下”；插入像“抛硬币”决定高度；<br>删除就是“逐层摘链”；查、插、删平均都是 O(log n)，实现简单又快，是 Redis 有序集合的关键结构。</p><h3 id="Redis的跳表实现和普通跳表实现的区别点">Redis的跳表实现和普通跳表实现的区别点</h3><ul><li>多了一个回退指针（backward，指向底层前驱），且score可以重复</li><li>回退指针能让 Redis 跳表“会倒着走、能就地摘”，减少一次查找，反向遍历和删除/更新更快，非常符合 Redis ZSet 的使用场景。</li></ul><h2 id="Redis-的-hash-是什么？">Redis 的 hash 是什么？</h2><blockquote><p>什么是Redis的Hash？</p></blockquote><p>Redis中的hash是一种键值对集合,可以将多个字段和值存储在一个键中,方便管理一些关联数据。</p><ul><li>可以把它理解成“存在 Redis 里的小型字典/对象”：一个 key 对应很多 field→value。</li><li>适合把一个对象的多个属性放在一起存，比如：user:1001 =&gt; {name:Tom, age:18}。</li></ul><blockquote><p>底层实现（按大小自动切换）</p></blockquote><ul><li>小对象：用<strong>压缩列表</strong> 紧凑存储，省内存；</li><li>大对象：当hash类型<strong>元素个数小于512并且每个字段名和字段值的长度小于64个字节</strong>，切到 哈希表（dict），查改更快但占内存稍多。</li></ul><blockquote><p>什么时候用 Hash？</p></blockquote><ul><li>需要把<strong>同一个对象的多字段放一起</strong>、且<strong>字段较多但单个字段不大</strong>；</li><li>想节省内存、又希望对字段做 O(1) 的 CRUD；</li><li>做层级结构（比如用户、商品属性）比用很多独立 key 更好管理。</li></ul><blockquote><p>rehash（扩/缩容）怎么做？</p></blockquote><ul><li>采用渐进式 rehash：不是一次性迁移、而是分批在后续读写操作里慢慢搬，避免卡顿；</li><li>触发通常跟负载因子有关：<ul><li>过大（&gt;≈1，或更激进时 &gt;≈5）会扩容（一般按 2 倍）；</li><li>很小（&lt;≈0.1）会缩容（节省内存）；</li></ul></li><li>rehash 期间会同时维护两个表，新数据逐步迁走，对外读写不受影响。</li></ul><blockquote><p>总结：</p></blockquote><p>Redis Hash = 一个 key 里的“小字典”。小用 listpack 省内存，大用哈希表提性能；rehash 渐进式，扩缩容靠负载因子。最适合存对象型数据。</p><h2 id="Redis-支持事务吗？如何实现？">Redis 支持事务吗？如何实现？</h2><ul><li><strong>Redis 是支持事务的</strong>，但和 MySQL 的事务不一样。</li><li><strong>Redis 事务主要保证的是命令的原子性执行，而不支持回滚机制。</strong></li></ul><h3 id="Redis-事务的实现方式">Redis 事务的实现方式</h3><p>Redis 通过以下几个命令实现事务功能：</p><ul><li>MULTI：标记事务的开始，之后输入的命令都会被暂存到队列中；</li><li>EXEC：执行事务队列中的所有命令；</li><li>DISCARD：放弃事务，清空命令队列；</li><li>WATCH：监控一个或多个 key，用于实现乐观锁机制。</li></ul><p><strong>Redis 事务其实就是一组命令的批量执行</strong>，所有命令会先入队，等到执行 EXEC 的时候，一次性顺序执行完，保证中间不会被打断。</p><h3 id="Redis-事务的执行流程">Redis 事务的执行流程</h3><ol><li>开启事务：使用 MULTI 命令；</li><li>命令入队：事务中的每条命令先进入队列；</li><li>执行事务：调用 EXEC 批量执行命令；</li><li>放弃事务：如果中途要取消，可用 DISCARD；</li><li>并发控制：若用 WATCH 监控的 key 被其他客户端修改，EXEC 会直接取消执行，防止数据不一致。</li></ol><h3 id="Redis-事务与-MySQL-事务的区别">Redis 事务与 MySQL 事务的区别</h3><table><thead><tr><th>对比项</th><th>MySQL 事务</th><th>Redis 事务</th></tr></thead><tbody><tr><td><strong>一致性保证</strong></td><td>支持完整的 ACID 特性</td><td>只保证命令的原子性执行</td></tr><tr><td><strong>回滚机制</strong></td><td>发生错误可回滚</td><td>不支持回滚</td></tr><tr><td><strong>并发控制</strong></td><td>支持锁机制</td><td>用 <code>WATCH</code> 实现乐观锁</td></tr><tr><td><strong>隔离级别</strong></td><td>可调节（如 Read Committed 等）</td><td>不支持多级隔离设置</td></tr></tbody></table><p>“MySQL 的事务是严格的 ACID 模型，而 Redis 更像是一个命令队列批处理工具，执行时要么全成功，要么全失败，但不会回滚。”</p><blockquote><p>为什么 Redis 不支持回滚<br>从 Redis 2.6.5 开始，Redis 能在命令入队阶段检测语法错误，但如果执行阶段某条命令出错，Redis 不会回滚已执行的命令，而是继续执行后续命令。</p></blockquote><blockquote><p>举个例子：<br>如果事务中一条命令失败，比如某条 INCR 操作在非整数上执行失败，Redis 不会撤销之前的命令。<br>官方说明中明确写到：<br>“Errors happening after EXEC are not handled in a special way; all the other commands will still be executed even if some command fails.”</p></blockquote><h3 id="小结-2">小结</h3><ul><li>Redis 是支持事务的，但和 MySQL 不一样。Redis 的事务是通过 MULTI、EXEC、DISCARD、WATCH 这几个命令来实现的，<strong>本质上是命令的批量原子执行</strong>。</li><li>它能保证事务内的命令要么全部执行，要么全部丢弃，但执行过程中不会回滚，也没有多级隔离机制。</li><li>所以我们可以理解 Redis 的事务其实更像一个命令队列的批处理，而不是数据库那种严格意义上的 ACID 事务。</li></ul><h2 id="Redis-数据过期后的删除策略是什么？">Redis 数据过期后的删除策略是什么？</h2><p>Redis 的过期 KEY 处理有两种策略，分别是<strong>惰性删除和周期删除</strong>。</p><p><strong>惰性删除</strong>是指在每次用户访问某个 KEY 时，才会判断 KEY 的过期时间：如果过期则删除；如果未过期则忽略。</p><p><strong>周期删除</strong>有两种模式：</p><ul><li><p>SLOW 模式：<strong>通过一个定时任务</strong>，定期的抽样部分带有 TTL 的 KEY，判断其是否过期。<strong>默认情况下定时任务的执行频率是每秒 10 次，但每次执行不能超过 25 毫秒</strong>。如果执行抽样后发现时间还有剩余，并且过期 KEY 的比例较高，则会多次抽样。</p></li><li><p>FAST 模式：<strong>在 Redis 每次处理 NIO 事件之前，都会抽样部分带有 TTL 的 KEY</strong>，判断是否过期，因此执行频率较高。但是每次执行时长不能超过 1ms，如果时间充足并且过期 KEY 比例过高，也会多次抽样</p></li></ul><blockquote><p>Redis 如何判断 KEY 是否过期呢？</p></blockquote><p>答：Redis内部有两个哈希表，一个用来存放key和value，另一个专门记录key的过期时间。每次判断是否过期的时候，它就去那个记录过期时间的哈希表查一下这个key有没有过期</p><h2 id="Redis-中有哪些内存淘汰策略？">Redis 中有哪些内存淘汰策略？</h2><p>Redis 支持 8 种不同的内存淘汰策略：</p><p>noeviction： 不淘汰任何 key，但是内存满时不允许写入新数据，默认就是这种策略。<br>volatile-ttl： 对设置了 TTL 的 key，比较 key 的剩余 TTL 值，TTL 越小越先被淘汰<br>allkeys-random：对全体 key ，随机进行淘汰。也就是直接从 db-&gt;dict 中随机挑选<br>volatile-random：对设置了 TTL 的 key,随机进行淘汰。也就是从 db-&gt;expires 中随机挑选。<br>allkeys-lru： 对全体 key，基于 LRU 算法进行淘汰<br>volatile-lru： 对设置了 TTL 的 key，基于 LRU 算法进行淘汰<br>allkeys-lfu： 对全体 key，基于 LFU 算法进行淘汰<br>volatile-lfu： 对设置了 TTL 的 key，基于 LFU 算法进行淘汰</p><table><thead><tr><th>策略名</th><th>描述</th></tr></thead><tbody><tr><td><code>noeviction</code></td><td>不淘汰，内存满时直接报错，默认策略</td></tr><tr><td><code>volatile-ttl</code></td><td>仅淘汰设置了 TTL 的 key，优先淘汰 TTL 最小的</td></tr><tr><td><code>allkeys-random</code></td><td>所有 key 中随机淘汰</td></tr><tr><td><code>volatile-random</code></td><td>TTL key 中随机淘汰</td></tr><tr><td><code>allkeys-lru</code></td><td>所有 key 中淘汰最久未使用的（近似 LRU）</td></tr><tr><td><code>volatile-lru</code></td><td>TTL key 中淘汰最久未使用的</td></tr><tr><td><code>allkeys-lfu</code></td><td>所有 key 中淘汰访问频率最低的（近似 LFU）</td></tr><tr><td><code>volatile-lfu</code></td><td>TTL key 中淘汰访问频率最低的</td></tr></tbody></table><h3 id="聊聊LRU和LFU：">聊聊LRU和LFU：</h3><p>LRU 是“<strong>最近最久未使用</strong>”，它记录每个 key 最近一次被访问的时间，然后从中挑最长时间没用的删掉。</p><p>但 Redis 的 LRU 是个近似算法，它会抽样一批 key，然后在里面选一个最久没用的来删。</p><p>LFU 是“<strong>最不常使用</strong>”，不是看最近一次用，而是看<strong>访问频率</strong>。它会记录每个 key 的访问次数，这样可以把访问频率低的删掉。不过因为内存有限，它其实记录的是一个“逻辑次数”，会做一些概率加减，最大值是 255，而且每分钟会自动衰减一次，这样就能反映出一个 key 的“热度”了。</p><h3 id="小结-3">小结</h3><p>Redis 内存满了之后会通过内存淘汰机制来释放内存。它支持 8 种策略，比如 LRU、LFU、随机等，区别在于是对所有 key 还是仅限设置了 TTL 的 key。Redis 不是对所有 key 做全量排序，而是通过抽样 + 候选池的方式来快速选出要淘汰的 key，效率很高。</p><p>如果业务对内存敏感，推荐使用 allkeys-lfu，这能最大程度上保留热门数据，清理冷门数据，比较适合高频访问的场景。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/JpwSFDxN_Untitled-diagram-_-Mermaid-Chart-2025-08-06-093450-294x1024_mianshiya.png" alt="Untitled-diagram-_-Mermaid-Chart-2025-08-06-093450-294x1024.png" width="294px" /><h2 id="Redis-的-Lua-脚本功能是什么？如何使用？">Redis 的 Lua 脚本功能是什么？如何使用？</h2><ul><li>功能：允许用户在redis服务端执行lua脚本，实现<strong>原子性操作</strong>和复杂的功能逻辑。</li><li>怎么用：通过redis.call调用redis命令，也有if，else这种逻辑可以用</li><li>原理：因为Redis会将Lua脚本封装成一个单独的事务，而这个单独的事务会在Redis客户端运行时，由Redis服务器自行处理并完成整个事务，如果在这个进程中有其他客户端请求的时候，Redis将会把它暂存起来，等到 Lua 脚本处理完毕后，才会再把被暂存的请求恢复。</li></ul><h2 id="Redis-的-Pipeline-功能是什么？">Redis 的 Pipeline 功能是什么？</h2><p>Redis 的 Pipeline（管道） 功能<strong>允许客户端在一次网络请求中批量发送多个命令</strong>，<br><strong>从而减少网络往返次数（RTT），大幅提升吞吐量</strong>。</p><ul><li>简单说，Pipeline 就像寄快递时打包多个包裹一次寄出，节省了很多来回跑的时间。</li></ul><p>Pipeline 与事务的区别</p><table><thead><tr><th>对比项</th><th>Pipeline</th><th>Redis 事务（MULTI/EXEC）</th></tr></thead><tbody><tr><td><strong>是否保证原子性</strong></td><td>❌ 不保证</td><td>✅ 保证</td></tr><tr><td><strong>执行方式</strong></td><td>批量发送命令，提高吞吐量</td><td>命令入队后一次性原子执行</td></tr><tr><td><strong>失败处理</strong></td><td>某条命令失败不影响其他命令</td><td>执行错误会影响整个事务结果</td></tr></tbody></table><ul><li>Pipeline <strong>只是网络层面的优化，并不是事务</strong>。命令之间相互独立，即使一条失败，其他命令照样执行。</li></ul><h3 id="小结-4">小结</h3><p>Redis 的 Pipeline 是一个<strong>批量命令机制</strong>，让客户端一次性发多个命令给服务器，从而减少网络延迟，提高吞吐量。<br>它不保证原子性，也不是事务，<strong>只是性能优化</strong>。<br>一般我们会控制每次打包的命令数，比如不超过 1 万条，太多可能导致内存压力。<br><strong>如果需要保证命令的原子性，那就得用 Lua 脚本或者 Redis 事务</strong>。</p><h2 id="Redis-中的-Big-Key-问题是什么？如何解决？">Redis 中的 Big Key 问题是什么？如何解决？</h2><h3 id="什么是big-key">什么是big key</h3><p>在 Redis 中，<strong>Big Key 是指占用大量内存的键</strong>，<strong>Big Key 不仅仅是键的值很大，还包括对应的 value 占用大量内存的情况</strong>，常见的如 String、list、hash、set、zset 等数据类型的键。<strong>通常来说，这些数据类型包含的元素数量过多，或者字符串的值本身很大，都会被视为 Big Key</strong>。</p><h3 id="Big-Key-问题的危害">Big Key 问题的危害</h3><ul><li><strong>性能影响</strong>：Big Key 的值会占用大量内存，导致访问速度慢，从而影响 Redis 的整体性能。</li><li><strong>内存占用</strong>：大量 Big Key 会占满 Redis 的内存，导致无法存储其他数据，甚至可能造成 Redis 卡顿。</li><li><strong>内存分布不均</strong>：在 Redis 集群中，某些节点可能存储了 Big Key，这会导致多个节点之间的内存使用不均衡。</li><li><strong>备份和恢复困难</strong>：当通过 RDB 文件恢复数据时，Big Key 会导致恢复过程变得异常缓慢，甚至无法正常恢复。</li><li><strong>搜索困难</strong>：Big Key 的数据量大，查找时需要的时间长，且会影响查找效率。</li><li><strong>迁移困难</strong>：迁移 Big Key 也会消耗大量资源，可能会影响 Redis 数据一致性。</li><li><strong>过期执行耗时</strong>：当设置了过期时间的 Big Key 被删除时，删除过程会非常耗时。</li></ul><h3 id="如何解决-Big-Key-问题">如何解决 Big Key 问题</h3><p>以下是几种解决 Big Key 问题的方法：</p><h4 id="开发层面">开发层面</h4><ol><li><strong>数据压缩</strong>：针对存储数据的大小，可以进行压缩来减少内存占用。</li><li><strong>拆分大 Key</strong>：将一个大 Key 拆分成多个小 Key，以减少单个 Key 的存储负担。</li><li><strong>使用合适的数据结构</strong>：对于存储大量数据的场景，使用 Hash 类型、Set 类型等数据结构来优化存储方式。</li></ol><h4 id="业务层面">业务层面</h4><ol><li><strong>删除低频使用的 Big Key</strong>：可以根据访问频率，对一些不常用的 Big Key 进行删除。</li><li><strong>合理设置缓存 TTL</strong>：通过设置合适的过期时间，避免过期的缓存不及时删除。</li><li><strong>清理不必要的字段和信息</strong>：可以去掉一些不必要的数据或信息，减小内存占用。</li></ol><h4 id="数据分布层面">数据分布层面</h4><ol><li><strong>使用 Redis 集群</strong>：通过 Redis 集群对数据进行分片，将 Big Key 分布到不同的节点上，从而提高查询和写入的性能。</li></ol><h4 id="辅助工具–（识别big-key）">辅助工具–（识别big key）</h4><ul><li><strong>redis-cli</strong> 工具：可以使用 <code>redis-cli --bigkeys</code> 来扫描 Redis 数据库，找出所有的大 Key。</li></ul><h2 id="如何解决-Redis-中的热点-key-问题？">如何解决 Redis 中的热点 key 问题？</h2><h3 id="什么是热key问题？">什么是热key问题？</h3><p>热 key 问题指的是在某个瞬间，大量请求集中访问 Redis 里的<strong>同一个固定 key</strong>，这会造成缓存击穿，使得请求都直接涌向数据库，最终拖垮缓存服务和数据库服务，进而影响应用服务的正常运行。</p><p>像<code>热点新闻、热点评论、明星直播</code>这类读多写少的场景，很容易出现热点 key 问题。虽然 Redis 的查询性能比数据库高很多，但它也有性能上限，单节点查询性能一般在 2 万 QPS，所以对单个固定 key 的查询不能超过这个数值。</p><h3 id="怎么解决热key问题？">怎么解决热key问题？</h3><p><strong>对于热key的处理，主要在于事前预测和事中解决。</strong></p><ul><li>事前预测：这通常是通过经验预测，即在促销活动或者已知的热点事件前，提前识别出可能成为热key的key，例如“双11秒杀商品”。<ul><li>然而这种方式并不完美，因为某些突发的热点事件（比如明星官宣）是无法提前预测的。</li></ul></li><li>事中解决：</li></ul><ol><li><strong>多级缓存</strong>：</li></ol><ul><li><strong>将数据缓存在多个层级的缓存</strong>中（例如，浏览器缓存、CDN缓存、Redis缓存等），减少直接访问后端数据库的次数，从而缓解系统压力。</li><li>缓存策略包括使用<strong>CDN、客户端本地缓存</strong>等。</li></ul><ol start="2"><li><strong>热key备份</strong>：</li></ol><ul><li>除了在单一的缓存服务器上进行缓存外，<strong>还可以将热点数据分发到多个缓存集群中</strong>。如果一个集群承载过重，其他集群可接管流量，保证系统的高可用性。</li></ul><ol start="3"><li><strong>热key拆分</strong>：</li></ol><ul><li>将<strong>一个热key拆分为多个子key，并且将这些子key分散到不同的缓存节点上</strong>。例如，将“热搜商品”拆分成多个子key存储到Redis集群的不同节点，这样多个请求就能分散到不同节点，从而避免了单点压力。</li></ul><h3 id="热key的识别方法">热key的识别方法</h3><ul><li><p><strong>经验预测</strong>：基于历史数据和业务经验预测可能成为热key的key。</p></li><li><p><strong>实时监控</strong>：通过<strong>实时监控并收集key的访问频率</strong>，使用Redis本身的热点key发现功能（<strong>如redis-cli中的–hotkeys选项</strong>）来动态识别。</p></li></ul><h3 id="多热算热，给个标准？">多热算热，给个标准？</h3><p>JD有一个框架叫做hotkey，他就是专门做热key检测的，<strong>他的热key定义是在单位时间内访问超过设定的阈值频次就是热key</strong>，<strong>这个阈值需要业务自己设定，并不断的调整和优化。</strong></p><p>热key的定义，通常以其接收到的Key被请求频率来判定，例如：</p><ul><li>QPS集中在特定的Key：Redis实例的总QPS为10,000，而其中一个Key的每秒访问量达到了7,000。那么这个key就算热key了。</li><li>带宽使用率集中在特定的Key：对一个拥有1000个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。</li><li>CPU使用时间占比集中在特定的Key：对一个拥有10000个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求。</li></ul><h2 id="Redis-的持久化机制有哪些？">Redis 的持久化机制有哪些？</h2><h3 id="为什么需要持久化">为什么需要持久化</h3><p>Redis 是一个<strong>基于内存</strong>的数据库，所有数据存储在内存中。如果 Redis 服务发生了宕机，内存中的数据会全部丢失。因此Redis提供了持久化机制，将数据保存在磁盘中，以便在服务重启的时候恢复数据。</p><p>目前Redis提供了三种持久化机制</p><h3 id="RDB-持久化机制">RDB 持久化机制</h3><p>RDB（Redis Database） 是通过生成内存快照，将数据保存为二进制文件（dump.rdb）的方式实现持久化。它记录了某一时刻的数据状态，可用于灾难恢复和快速重启。</p><p><strong>RDB的优点是：快照文件小、恢复速度快，适合做备份和灾难恢复。</strong></p><p><strong>RDB的缺点是：定期更新可能会丢数据</strong></p><h3 id="AOF">AOF</h3><p>AOF（Append Only File） 是通过将每个写操作<strong>追加到日志文件</strong>（appendonly.aof）的末尾实现持久化的方式。当Redis 重启时可以通过重放日志文件中的命令来恢复数据。</p><p>但是如果Redis刚刚执行完一个写命令，还没来得及写AOF文件就宕机了，那么这个命令和相应的数据就会丢失了。但是他也比RDB要更加靠谱一些。</p><p><strong>AOF的优点是：可以实现更高的数据可靠性、支持更细粒度的数据恢复，适合做数据存档和数据备份。</strong></p><p><strong>AOF的缺点是：文件大占用空间更多，每次写操作都需要写磁盘导致负载较高</strong></p><h3 id="RDB与AOF比较">RDB与AOF比较</h3><table><thead><tr><th><strong>特性</strong></th><th><strong>RDB</strong></th><th><strong>AOF</strong></th></tr></thead><tbody><tr><td>数据可靠性</td><td>可能会丢失最后一次快照之后的数据</td><td>保证最后一次写操作之前的数据不会丢失</td></tr><tr><td>性能</td><td>读写性能较高，适合做数据恢复</td><td>写性能较高，适合做数据存档</td></tr><tr><td>存储空间占用</td><td>快照文件较小，占用空间较少</td><td>AOF文件较大，占用空间较多</td></tr><tr><td>恢复时间</td><td>从快照文件中恢复数据较快</td><td>从AOF文件中恢复数据较慢</td></tr></tbody></table><h3 id="混合持久化">混合持久化</h3><p>混合持久化 是 Redis 4.0 引入的一种机制，结合了 RDB 和 AOF 的优点：</p><ul><li>RDB 用于快速保存大部分数据。</li><li>AOF 用于记录两次快照之间的增量数据。</li></ul><p>通过 aof-user-rdb-preamble 配置开启混合持久化，<strong>在开启混合持久化的情况下，AOF 重写时会把 Redis 的持久化数据，以 RDB 的格式写入到 AOF 文件的开头，之后的数据再以 AOF 的格式化追加到文件的末尾。</strong></p><p>这样的优势就是，混合持久化结合了 RDB 和 AOF 持久化的优点，<strong>开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险</strong>。</p><h3 id="扩展知识">扩展知识</h3><h4 id="Redis能完全保证数据不丢失吗？">Redis能完全保证数据不丢失吗？</h4><p>不能，因为Redis是基于<strong>内存存储</strong>的，当Redis进程异常退出或服务器断电等情况发生时，内存中的数据可能会丢失。</p><p>为了防止数据丢失，Redis提供了RDB和AOF的持久化机制，Redis可以将数据从内存保存到磁盘中，以便在Redis进程异常退出或服务器断电等情况下，通过从磁盘中加载数据来恢复数据。</p><p><strong>但是，持久化机制也不是绝对可靠的</strong>，归根结底Redis还是个缓存，他并不是完全给你做持久化用的，所以还是要有自己的持久化方式，比如双写到数据库。</p><p>因此，为了最大程度地保障数据安全，建议采用多种手段来提高数据可靠性，如定期备份数据、使用主从复制机制、使用集群模式等。</p><h3 id="AOF的三种写回策略">AOF的三种写回策略</h3><p>AOF有三种数据写回策略，分别是Always，Everysec和No。</p><ul><li><strong>Always</strong>，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li><li><strong>Everysec</strong>，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li><li><strong>No</strong>，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li></ul><p>“同步写回”可靠性肯定是最高的，但是它在每一个写命令后都有一个落盘操作，而且还是同步的，这和直接写磁盘类型的数据库有啥区别？</p><p>&quot;操作系统控制的写回&quot;这种是最不靠谱的，谁知道操作系统啥时候帮你做持久化，万一没来及持久化就宕机了，不就gg了。</p><p>&quot;每秒写回&quot;是在二者之间折中了一下，异步的每秒把数据写会到磁盘上，最大程度的提升效率和降低风险。</p><h3 id="Always也不能保证不丢">Always也不能保证不丢</h3><p>即使是在always策略下，也不能保证100%不丢失数据的，主要出于以下原因：</p><ol><li><p><strong>磁盘和系统故障</strong>：如果在写入操作和同步到磁盘之间发生硬件故障或系统崩溃，可能会丢失最近的写操作。</p></li><li><p><strong>操作系统缓冲区</strong>：即使Redis请求立即将数据同步到磁盘，操作系统的I/O缓冲区可能会导致实际写入磁盘的操作延迟发生。如果在写入缓冲区之后，没写磁盘前，机器挂了，那么数据就丢了。</p></li></ol><blockquote><p>操作系统缓冲区，通常指的是操作系统用于管理数据输入输出（I/O）的一种内存区域。当程序进行文件写入操作时，数据通常首先被写入到这个缓冲区，而不是直接写入到硬盘。</p></blockquote><ol start="3"><li><strong>磁盘写入延迟</strong>：磁盘的写入并非实时完成，特别是在涉及到机械硬盘时，写入延迟主要由磁盘旋转速度（RPM）和寻道时间决定。如果在这这个延迟过程中，机器挂了，那么数据也就丢了。</li></ol><h3 id="Redis-7-0-MP-AOF（Multi-Part-Append-Only-File）">Redis 7.0 MP-AOF（Multi-Part Append Only File）</h3><p>7.0 之前的 AOF 重写有三大问题：</p><ul><li>内存开销：aof_buf 和 aof_rewrite_buf 中大部分内容是重复的。</li><li>CPU 开销：主进程需要花费 CPU 时间往 aof_rewrite_buf 写入数据，并向子进程发送aof_rewrite_buf 中的数据。子进程需要消耗 CPU 时间将aof_rewrite_buf 写入新 AOF 文件。</li><li>磁盘开销：aof_buf数据会写到当前的 AOF 文件，aof_rewrite_buf数据写到新的 AOF 文件，一份数据需要写两次磁盘。</li></ul><p>针对以上问题 Redis 7.0 引入了 MP-AOF（Multi-Part Append Only File）机制。简单来说就是将一个 AOF 文件拆分成了多个文件：</p><ul><li>一个基础文件（base file），代表数据的初始快照</li><li>增量文件（incremental files），记录自基础文件创建以来的所有写操作，可以有多个</li><li>基础文件和增量文件都会存放在一个单独的目录中，并由一个清单文件（manifest file）进行统一跟踪和管理</li></ul><h2 id="Redis-在生成-RDB-文件时如何处理请求？">Redis 在生成 RDB 文件时如何处理请求？</h2><p>Redis 在生成 RDB 文件时，是通过 fork 子进程 的方式来做的。主进程继续处理客户端请求，而由子进程负责把数据写到 RDB 文件里，这样就不会影响线上正常读写。</p><h3 id="原理说明">原理说明</h3><p>生成 RDB 的时候，Redis 主进程会执行 bgsave 命令，<br>它会 fork 出一个子进程来完成快照。</p><p>fork 的时候不会复制整块内存，而是<strong>主进程和子进程共享相同的内存页</strong>（共享物理页），<br>这就是<strong>写时复制</strong>（Copy On Write, COW） 技术。</p><h3 id="那如果此时有写操作怎么办？">那如果此时有写操作怎么办？</h3><p>如果主进程在这时收到写命令，比如要修改某个 key 的数据，它就会把要修改的那一页内存复制一份，主进程在副本上修改数据，而子进程仍然指向旧的数据页。</p><p>这样一来：</p><ul><li>子进程看到的是<strong>老的数据（旧快照）</strong>，可以安心生成 RDB；</li><li>主进程修改的是<strong>新数据</strong>，不会互相影响。</li></ul><p>这就保证了：<strong>RDB 快照是数据生成那一刻的状态，主进程还能照常提供服务</strong>。</p><blockquote><p>就像 Redis 在拍一张‘全量照片’，拍照的是子进程，而主进程还能继续‘工作’。<br>要是拍照过程中有人动了东西，主进程就复制一份新的给自己改，<br>照片里留下的还是当时的状态，不会乱。</p></blockquote><h3 id="小结-5">小结</h3><p>Redis 在生成 RDB 时通过 fork 子进程配合写时复制技术，让子进程负责快照、主进程继续处理请求，既保证数据一致性，又不影响正常服务。</p><h2 id="Redis-的哨兵机制是什么？">Redis 的哨兵机制是什么？</h2><h3 id="Sentinel-哨兵-的三个作用是什么？">Sentinel(哨兵) 的三个作用是什么？</h3><p>哨兵机制主要有三个作用:</p><ul><li>第一个是<strong>监控 Redis 节点的运行状态</strong>，每秒发送 ping 判断节点是否正常;</li><li>第二个是<strong>故障恢复</strong>，当<strong>主节点宕机时，它可以自动完成主从切换</strong>;</li><li>第三个是<strong>通知机制</strong>，<strong>当主从发生变化时会通过 API 通知其他服务，比如客户端或中间件</strong>，帮助它们更新连接信息。</li></ul><h3 id="Sentinel-如何判断一个-redis-实例是否健康？">Sentinel 如何判断一个 redis 实例是否健康？</h3><ul><li>每隔 1 秒发送一次 ping 命令，如果超过一定时间没有相向则认为是主观下线（sdown）</li><li>如果大多数 sentinel 都认为实例主观下线，则判定服务客观下线（odown）</li></ul><h3 id="故障转移步骤有哪些？">故障转移步骤有哪些？</h3><p>故障转移一共分 4 步：</p><ol><li><p>“首先，<strong>从所有哨兵中选出一个 leader</strong>，<strong>只有 leader 有权限发起故障转移</strong>；”</p></li><li><p>“然后 <strong>leader 会从所有从节点中选择一个作为新的主节点</strong>，执行 <strong>SLAVEOF NO ONE</strong>；”</p></li><li><p>“再让其他的 slave 执行 <strong>SLAVEOF 新主节点</strong>，重新组成主从结构；”</p></li><li><p>“最后，<strong>修改之前主节点的配置，让它重新变为新的主节点的从节点</strong>。”</p></li></ol><h3 id="sentinel-选举-leader-的依据是什么？">sentinel 选举 leader 的依据是什么？</h3><ul><li>票数超过 sentinel 节点数量 1 半</li><li>票数超过 quorum （法定人数）数量，例如quorum 值为2代表着（三个哨兵，2 个认为主观下线就是客观下线）</li><li>一般情况下最先发起 failover 的节点会当选</li></ul><h3 id="sentinel-从-slave-中选取-master-的依据是什么？">sentinel 从 slave 中选取 master 的依据是什么？</h3><p>sentinel 会综合考虑多个因素来挑选新的主节点，优先级如下：</p><ol><li><p>“先看这个从节点与原主节点断开时间是否过长，<strong>太久的会被排除</strong>；”</p></li><li><p>“再看 slave 节点的 <code>slave-priority</code> 值，<strong>数值小的优先</strong>，值为 0 则不参与选举；”</p></li><li><p>“如果优先级一样，就比谁的 <code>offset</code> 更大，<strong>数据更全的优先</strong>；”</p></li><li><p>“最后如果还一样，就比 <code>run_id</code> ，<strong>谁小谁胜出</strong>。”</p></li></ol><h2 id="Redis-集群会出现脑裂问题吗？">Redis 集群会出现脑裂问题吗？</h2><p>Redis 集群确实可能出现“脑裂（Split-Brain）”问题，<br>通常是由于 <strong>网络分区或主节点故障恢复不及时</strong> 导致系统中出现<strong>两个主节点同时对外提供服务，从而造成数据不一致或数据丢失</strong>。</p><h3 id="什么是脑裂">什么是脑裂</h3><p>脑裂（Split-Brain）指的是<strong>在一个分布式系统中，同时出现多个主节点</strong>（Master），每个节点都以为自己是“主脑”，开始独立对外提供服务。</p><ul><li>脑裂就像一个团队同时有两个领导，都在下命令，最后每个人的任务都乱套了。<br>在 Redis 中，这种情况常见于以下两种场景</li></ul><ol><li>网络分区</li></ol><ul><li>比如主节点和从节点、哨兵之间的通信被隔断；</li><li>哨兵无法联系上 Master，以为它挂了，就会重新选出新的 Master；</li><li>此时原 Master 其实还在运行，两个 Master 同时对外服务。</li></ul><ol start="2"><li>主节点短暂故障后恢复</li></ol><ul><li>Master 因故障暂时下线，哨兵选出新的主节点；</li><li>原来的 Master 恢复后没有及时变为从节点，而是继续接收写入请求。<br>结果就是：<strong>两个主节点同时接受写操作</strong>。</li></ul><h3 id="脑裂的危害">脑裂的危害</h3><table><thead><tr><th>问题类型</th><th>描述</th></tr></thead><tbody><tr><td><strong>数据不一致</strong></td><td>两个主节点分别写入不同的数据，导致集群状态不一致。</td></tr><tr><td><strong>数据丢失</strong></td><td>原主节点恢复后会被重新同步，新数据被清空。</td></tr><tr><td><strong>重复写入</strong></td><td>合并数据时可能造成相同命令重复执行。</td></tr></tbody></table><ul><li>最严重的情况是<strong>数据丢失</strong>，因为新的主节点会让原主节点执行全量同步，而同步前会清空旧数据。</li></ul><h3 id="Redis-如何避免脑裂">Redis 如何避免脑裂</h3><p>Redis 提供了两个关键参数用于防止脑裂：</p><table><thead><tr><th>参数名</th><th>含义</th></tr></thead><tbody><tr><td><strong>min-slaves-to-write</strong></td><td>主节点要求最少有多少从节点处于正常复制状态才能写入。</td></tr><tr><td><strong>min-slaves-max-lag</strong></td><td>主从之间允许的最大复制延迟时间（秒）。</td></tr></tbody></table><ul><li>这两个条件必须同时满足，主节点才允许写入。</li><li>如果从节点延迟过大或掉线，就会拒绝写入，从而防止旧 Master 继续接收请求。</li><li>比如我设置 min-slaves-to-write=1，min-slaves-max-lag=10，如果 Master 宕机超过 10 秒，它和从节点的延迟太大，就会自动停止写入，避免旧主节点在网络恢复后继续接收写操作。</li></ul><h3 id="能彻底解决脑裂吗？">能彻底解决脑裂吗？</h3><p><strong>Redis 无法完全避免脑裂</strong>。</p><p>因为主从切换、网络恢复、延迟检测等都是时间敏感操作，在一些极端场景（比如主节点刚恢复但新主还没完全接管），<strong>仍然可能出现短暂的双主情况</strong>。</p><h3 id="小结-6">小结</h3><ul><li>Redis 集群是有可能出现脑裂问题的，比如网络分区或主节点恢复不及时时，可能会出现两个 Master 同时写数据。</li><li>这样会导致数据不一致甚至丢失。</li><li>Redis 可以通过配置 min-slaves-to-write 和 min-slaves-max-lag 来降低风险，它们能让旧 Master 在检测到延迟或断连时拒绝写入，从而避免错误写操作。</li><li>但因为分布式延迟是不可避免的，Redis 只能尽量规避，不能彻底解决脑裂。</li></ul><h2 id="Redis-中如何实现分布式锁？">Redis 中如何实现分布式锁？</h2><p>背景：小徐是一个程序员，他开发了一个秒杀功能，但出现了超卖问题。</p><ul><li>超卖问题的出现：多线程并发环境下，如果同时对一个共享资源进行读写，数据会出现错乱的问题</li></ul><p>这一次他加了一个同步锁 synchronized，这次终于不会超卖了，那我们都知道当多线程并发情况下我们加了同步锁，在同一时刻保证只有一个线程能拿到锁，其他进程进来会进行一个互斥，需要排队等待需要等持有锁线程处理完释放锁</p><p>但是随着用户量越来越多小徐发现服务器压力越来越大，性能达到了瓶颈，于是小徐通过nginx进行了负载均衡，他将服务器进行了水平扩展，通过nginx进行了分布式集群部署，但是测试时吞吐量确实上来了，但是秒杀功能又出现了超卖问题，经过发现原来是同步锁的问题，<strong>因为同步锁它是JVM级别的，它只能锁住单个进程，但是经过分布式部署之后呢，每台服务器在并发的情况下只能锁住一个线程</strong></p><p>所以要解决这个问题我们就要用到分布式锁，分布式锁，顾名思义，<strong>分布式锁就是分布式场景下的锁，比如多台不同服务器上的进程，去竞争同一项资源，就是分布式锁。</strong></p><p>主流的分布式锁的解决方案有Redis和zookeeper</p><p>这里我们主要讲解Redis的分布式锁</p><h3 id="1-我们先实现一个最简单的分布式锁">1.我们先实现一个最简单的分布式锁</h3><p>直接用Redis的setnx命令，这个命令的语法是：setnx key value如果key不存在，则会将key设置为value，并返回1；如果key存在，不会有任务影响，返回0。</p><p>基于这个特性，我们就可以用setnx实现加锁的目的：通过setnx加锁，加锁之后其他服务无法加锁，用完之后，再通过delete解锁。</p><p>但是一定要加过期时间，<strong>因为如果用户在请求的过程中，服务器挂了，那么其他的服务器正常请求时，就会出现一个阻塞的情况</strong>，因为其他服务器的线程通过setnx进行上锁的时候，发现这个键里面一直有值，就会永远不会上锁成功，之前挂掉的服务器它一直持有锁从而造成了一个死锁的现象，所以此时我们要加上一个过期时间进行兜底，经过这个时间后锁就会自动释放，从而不影响其他服务器的正常请求</p><h3 id="二个问题的解决（锁续期与锁误删）以及Lua脚本">二个问题的解决（锁续期与锁误删）以及Lua脚本</h3><p>虽然业务的扩展，我们又发现了问题，<strong>当业务（线程1）的处理时间超过了这把锁的过期时间时，此时业务还没有处理完，锁就释放掉了</strong>，其他的线程（线程2）就会趁虚而入，线程1处理完业务后，回来释放锁，此时释放的就是线程2的锁，而其他的线程此时又会趁虚而入，以此类推。<strong>总结下来就是有两个问题：</strong></p><ul><li><strong>锁过期时线程还在处理业务当中</strong></li><li><strong>存在线程1释放掉线程2的锁，即锁误删现象</strong>（<strong>分布式锁需要满足谁申请谁释放原则，不能释放别人的锁，也就是说，分布式锁，是要有归属的</strong>。）</li></ul><p>我们先来解决第一个问题-锁过期时线程还在处理业务当中怎么办呢</p><ul><li>我们可以加长锁的一个过期时间，并且我们还需要考虑到如果我加长的这个时间还是不够怎么办呢，我们增加一个兜底的方案，在业务代码当中我们添加一个子线程，每10秒去确认主线程是不是在线，如果在线则将过期时间重置，也就是将锁续期</li></ul><p>我们再来解决第二个问题-锁误删现象怎么解决</p><ul><li>就是我们给锁增加一个唯一ID（UUID），这样就能保证每一把锁的它的KEY是绑定的自己的那一个线程，从而业务执行完毕后会先检查锁是不是自己的，最后进行释放。就不会释放其他线程的锁</li></ul><h4 id="Lua脚本">Lua脚本</h4><p>也就是说我们完整的流程是竞争者获取锁执行任务，执行完毕后检查锁是不是自己的，最后进行释放。但是执行完毕后，检查锁，再释放，这些操作如何保证它是原子化的操作呢？Redis还有个特性，专门整合原子操作，就是Lua脚本。</p><p>Lua脚本可以保证原子性，因为Redis会将Lua脚本封装成一个单独的事务，而这个单独的事务会在Redis客户端运行时，由Redis服务器自行处理并完成整个事务，如果在这个进程中有其他客户端请求的时候，Redis将会把它暂存起来，等到 Lua 脚本处理完毕后，才会再把被暂存的请求恢复。</p><p>但是我们发现如果我们自己实现锁误删和锁续期这些代码非常的麻烦，还要保证它的一个健壮性，所以Redis有没有提供相关的组件来完成这些功能呢，有的兄弟有的，这就是Redisson</p><h3 id="Redisson原理">Redisson原理</h3><p>Redis提供了一个Redisson完成我们刚刚说到的功能，实现起来也非常的简单，只要添加Redisson相关的一个依赖，把Redisson的客户端自动装配起来通过lock.lock（）就可以实现Redisson的分布式锁</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Xe3mXKZI_image-20251103140343453_mianshiya.png" alt="image-20251103140343453.png" width="100%" /><p>我们来说说Redisson的原理是什么，同样的多个线程请求同一资源，当然只有一个线程才能获取这把锁，比如线程1获取到了这把锁，它的key呢就如我们刚刚所说，它用的是UUID+线程ID合并起来保证我们的key和当前线程绑定在一起，这样就不会出现锁误删的问题，当线程1获取锁成功去处理业务的时候，它内部会有一个看门狗机制，它呢会每隔10秒看一下当前线程是否还持有锁，如果持有的话就延长生存时间，从而给这把锁续命。如果我们实现了Redis的集群呢，它就会选择Redis当中的某一个集群</p><p>那如果没有获取到锁的话，线程就会不停的自旋尝试获取锁只到超时为止</p><p>以上就是Redisson的实现原理</p><h4 id="红锁的实现">红锁的实现</h4><p>在Redis中如果使用了主从集群的一个模式，因为Redis采用的是AP模式，也就是<strong>它只能保证这个高可用和高性能，但是不能保证高一致性</strong>，当我们设置一个锁的时候它其实只会往一个节点去设置一个锁，设置完了就会立马告诉你设置成功，然后内部进行主从同步，<strong>如果我们把这个key设置到了主节点，我们主从同步的时候正好主节点挂了，从节点并没有同步到这把锁</strong>，<strong>导致新的主节点也没有同步过来锁信息，客户端可能重新获取新的主节点的锁，出现了多客户端同时持锁，导致数据不一致的问题</strong>。（<strong>主从异步复制+主从切换可能出现“旧主没释放锁，新主也没这把锁”的锁丢失/多客户端同时持锁问题。</strong>）这个时候应该怎么做呢</p><p>其实Redis也提供了相应的解决方法，那就是红锁RedLock，Redlock 是 Redis 官方提出的分布式锁算法，<strong>通过在N个（通常为5）相互独立的 master 上同时加锁，并且拿到多数派的锁(≥ N/2+1) 才算成功</strong>，来提升锁的安全性和可用性。<strong>如果没有RedLock就如我们刚刚所说，我们往一个主节点去设置一个锁，设置完了就会立马响应设置成功，而不去管从节点是否完成了同步，我们使用了RedLock，它要保证你提供的多数派节点（5个主节点，其中要5/2+1,即4个）都存储完毕了，它才会给你响应设置完成，来提升锁的安全性和可用性</strong></p><h2 id="分布式锁在未完成逻辑前过期怎么办？">分布式锁在未完成逻辑前过期怎么办？</h2><p>它内部会有一个看门狗机制，它呢会每隔10秒看一下当前线程是否还持有锁，如果持有的话就延长生存时间30s，从而给这把锁续命</p><h2 id="Redis-的-Red-Lock-是什么？你了解吗？">Redis 的 Red Lock 是什么？你了解吗？</h2><p>red lock是一种分布式锁的实现方案。解决分布式锁中主从同步的问题。<br>在Redis中如果使用了主从集群的一个模式，因为Redis采用的是AP模式，也就是<strong>它只能保证这个高可用和高性能，但是不能保证高一致性</strong>，当我们设置一个锁的时候它其实只会往一个节点去设置一个锁，设置完了就会立马告诉你设置成功，然后内部进行主从同步，<strong>如果我们把这个key设置到了主节点，我们主从同步的时候正好主节点挂了，从节点并没有同步到这把锁</strong>，<strong>导致新的主节点也没有同步过来锁信息，客户端可能重新获取新的主节点的锁，出现了多客户端同时持锁，导致数据不一致的问题</strong>。（主从异步复制+主从切换可能出现“旧主没释放锁，新主也没这把锁”的锁丢失/多客户端同时持锁问题。）这个时候应该怎么做呢</p><p>其实Redis也提供了相应的解决方法，那就是红锁RedLock，Redlock 是 Redis 官方提出的分布式锁算法，<strong>通过在N个（通常为5）相互独立的 master 上同时加锁，并且拿到多数派的锁(≥ N/2+1) 才算成功</strong>，以此来提升锁的安全性和可用性。<strong>如果没有RedLock就如我们刚刚所说，我们往一个主节点去设置一个锁，设置完了就会立马响应设置成功，而不去管从节点是否完成了同步，我们使用了RedLock，它要保证你提供的多数派节点（5个主节点，其中要5/2+1,即4个）都存储完毕了，它才会给你响应设置完成，来提升锁的安全性和可用性</strong></p><h2 id="Redis-实现分布式锁时可能遇到的问题有哪些？">Redis 实现分布式锁时可能遇到的问题有哪些？</h2><h3 id="问题一和问题二-锁过期问题和锁误删问题">问题一和问题二 锁过期问题和锁误删问题</h3><p><strong>当业务（线程1）的处理时间超过了这把锁的过期时间时，此时业务还没有处理完，锁就释放掉了</strong>，其他的线程（线程2）就会趁虚而入，线程1处理完业务后，回来释放锁，此时释放的就是线程2的锁，而其他的线程此时又会趁虚而入，以此类推。<strong>总结下来就是有两个问题：</strong></p><ul><li><strong>锁过期时线程还在处理业务当中</strong></li><li><strong>存在线程1释放掉线程2的锁，即锁误删现象</strong>（<strong>分布式锁需要满足谁申请谁释放原则，不能释放别人的锁，也就是说，分布式锁，是要有归属的</strong>。）</li></ul><p>我们先来解决第一个问题-锁过期时线程还在处理业务当中怎么办呢</p><ul><li>我们可以加长锁的一个过期时间，并且我们还需要考虑到如果我加长的这个时间还是不够怎么办呢，我们增加一个兜底的方案，在业务代码当中我们添加一个子线程，每10秒去确认主线程是不是在线，如果在线则将过期时间重置，也就是将锁续期</li></ul><p>我们再来解决第二个问题-锁误删现象怎么解决</p><ul><li>就是我们给锁增加一个唯一ID（UUID），这样就能保证每一把锁的它的KEY是绑定的自己的那一个线程，从而业务执行完毕后会先检查锁是不是自己的，最后进行释放。就不会释放其他线程的锁</li></ul><h3 id="问题三-主从问题不同步问题">问题三 主从问题不同步问题</h3><p>在Redis中如果使用了<strong>主从集群</strong>的一个模式，因为Redis采用的是AP模式，也就是<strong>它只能保证这个高可用和高性能，但是不能保证高一致性</strong>，当我们设置一个锁的时候它其实只会往一个节点去设置一个锁，设置完了就会立马告诉你设置成功，然后内部进行主从同步，<strong>如果我们把这个key设置到了主节点，我们主从同步的时候正好主节点挂了，从节点并没有同步到这把锁，导致新的主节点也没有同步过来锁信息，客户端可能重新获取新的主节点的锁，出现了多客户端同时持锁，导致数据不一致的问题</strong>。（主从异步复制+主从切换可能出现“旧主没释放锁，新主也没这把锁”的锁丢失/多客户端同时持锁问题。）这个时候应该怎么做呢</p><p>其实Redis也提供了相应的解决方法，那就是红锁RedLock，Redlock 是 Redis 官方提出的分布式锁算法，<strong>通过在N个（通常为5）相互独立的 master 上同时加锁，并且拿到多数派的锁(≥ N/2+1) 才算成功</strong>，来提升锁的安全性和可用性。<strong>如果没有RedLock就如我们刚刚所说，我们往一个主节点去设置一个锁，设置完了就会立马响应设置成功，而不去管从节点是否完成了同步，我们使用了RedLock，它要保证你提供的多数派节点（5个主节点，其中要5/2+1,即4个）都存储完毕了，它才会给你响应设置完成，来提升锁的安全性和可用性</strong></p><h3 id="问题四-单点故障问题">问题四 单点故障问题</h3><p>在使用单节点Redis实现分布式锁时，如果这个Redis实例挂掉，那么所有使用这个实例的客户端都会出现无法获取锁的情况。</p><p>解决方案就是引入<strong>集群模式</strong>，通过<strong>哨兵</strong>检测redis实例挂掉的情况，提升整个集群的可用性。</p><h2 id="Redis-中的缓存击穿、缓存穿透和缓存雪崩是什么？">Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？</h2><h3 id="缓存击穿（Hot-Key-Breakdown）">缓存击穿（Hot Key Breakdown）</h3><ul><li>现象：<strong>一个热点 key 正好过期</strong>（或被删）瞬间，大量并发同时打到数据库，数据库瞬时压力飙升，可能导致数据库崩溃。</li><li><strong>触发点：集中在单个热点 key 且恰好失效</strong>。</li><li><strong>解决方案</strong>：<ul><li>查询前先对 key <strong>加分布式锁/互斥</strong>，确保同一时间只有一个请求可以去数据库查询并更新缓存</li><li><strong>热点 key 不过期</strong></li><li>Redis 中<strong>存逻辑过期时间，过期后先返回旧值</strong>，后台异步刷新，避免并发“一起回源”。</li></ul></li></ul><h3 id="缓存穿透（Cache-Penetration）">缓存穿透（Cache Penetration）</h3><ul><li>现象：<strong>请求一个不存在的数据</strong>（恶意 id、非法参数等），Redis 没有，数据库也没有，每次都直接把请求打到 数据库，造成数据库负担加重。</li><li><strong>触发点：大量不存在 key 的查询。</strong></li><li><strong>解决方案</strong><ul><li><strong>缓存空值</strong>：DB 查不到也把“空结果”缓存一小会（短 TTL），避免反复打 DB。</li><li><strong>布隆过滤器</strong>：提前把可能存在的 key 放到 Bloom Filter，不在集合里的直接拦截。</li><li><strong>黑名单/防刷</strong>：拦截异常访问。</li><li><strong>参数校验/鉴权/限流</strong>：源头减少无效/恶意请求。</li></ul></li></ul><h3 id="缓存雪崩（Cache-Avalanche）">缓存雪崩（Cache Avalanche）</h3><ul><li>现象：<strong>大量 key 在同一时刻集中失效</strong>（或缓存节点整体不可用），大批请求直击数据库，造成系统整体“雪崩”。</li><li><strong>触发点：批量同时过期、缓存宕机/集群故障。</strong></li><li><strong>解决方案</strong><ul><li><strong>错峰过期（TTL 加随机值）</strong>：避免同一时间点集中过期。</li><li><strong>预热与分批加载</strong>：大促/新版本上线前<strong>把核心数据预热进缓存</strong>；大批 key 分段加载。</li><li><strong>降级/限流/熔断</strong>：保护 DB 与核心链路，必要时<strong>返回兜底数据</strong>。</li><li><strong>多级缓存 + 读写隔离</strong>：本地/边缘缓存兜底，减少直击 DB。</li></ul></li></ul><h3 id="总结：-3">总结：</h3><ul><li><strong>缓存击穿</strong>：是指<strong>单个热点 key</strong> 在失效瞬间被大量请求“打穿”，直接冲到数据库。<ul><li>解决方案包括：<strong>互斥锁/分布式锁</strong> 确保只有一个线程重建缓存；<strong>逻辑过期+异步刷新</strong> 保证旧值可返回、后台慢更新；以及 <strong>热点 key 不过期</strong>或使用多级缓存 来分担压力。</li></ul></li><li><strong>缓存穿透</strong>：是指请求<strong>访问不存在的数据</strong>，缓存和数据库都没有，导致每次都查数据库。<ul><li>解决方案包括：<strong>布隆过滤器</strong> 拦截无效 key；<strong>缓存空值</strong> 防止反复请求 DB；同时可配合 <strong>黑名单机制、参数校验或限流策略</strong>，从源头阻断恶意流量。</li></ul></li><li><strong>缓存雪崩</strong>：是指<strong>大量 key 同时失效</strong> 或 <strong>缓存节点宕机</strong>，引发海量请求瞬间打爆数据库。<ul><li>解决方案包括：<strong>错峰过期</strong>（<strong>TTL 加随机值</strong>） 防止集中失效；<strong>预热与分批加载</strong> 提前写入热点数据；配合 <strong>降级/熔断/限流机制</strong> 保护数据库；并通过 <strong>多级缓存架构</strong>（<strong>本地+Redis</strong>） 减少直击 DB 的压力。</li></ul></li></ul><h2 id="Redis-中如何保证缓存与数据库的数据一致性？">Redis 中如何保证缓存与数据库的数据一致性？</h2><p>缓存和数据库的同步可以通过以下几种方式：</p><p><s>1）先更新缓存，再更新数据库</s></p><p><s>2） 先更新数据库存，再更新缓存</s></p><p><s>3） 先删除缓存，再更新数据库，后续等查询把数据库的数据回种到缓存中</s></p><p>以上三种不推荐，以下是业内3种比较常见的具体方案：</p><p>1）先更新数据库，再删除缓存，后续等查询把数据库的数据回种到缓存中</p><p>2）缓存双删策略。更新数据库之前，删除一次缓存；更新完数据库后，再进行一次延迟删除</p><p>3）使用 Binlog 异步更新缓存，监听数据库的 Binlog 变化，通过异步方式更新 Redis 缓存</p><p>补充：</p><blockquote><p>为什么优先选择删缓存而不是更新</p></blockquote><p>删除缓存相对于更新缓存来说，操作更简单，出错几率更低，且能更好地保证数据一致性。尽管可能会出现缓存击穿，但可以通过加锁等措施解决。所以，建议优先选择删除缓存。</p><blockquote><h3 id="先写数据库还是先删缓存？">先写数据库还是先删缓存？</h3></blockquote><h4 id="1-先删缓存：">1. <strong>先删缓存</strong>：</h4><ul><li><p><strong>优点</strong>：</p><ul><li>如果删除缓存成功，但数据库更新失败，这种情况是可以接受的。缓存被清空但不会出现脏数据，只需要重试更新数据库即可。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li>这种方式可能会放大&quot;读写并发&quot;导致的数据不一致问题。因为删除缓存后，读线程无法命中缓存，直接去查询数据库。如果在此过程中数据库被更新，但缓存未及时更新，就会导致缓存被错误的数据覆盖，从而产生数据不一致。</li><li>虽然这种情况发生的概率比较低（因为数据库查询速度快），但如果恰好发生，就会导致缓存中的数据始终错误，影响后续的查询结果。</li></ul></li></ul><h4 id="2-先写数据库：">2. <strong>先写数据库</strong>：</h4><ul><li><p><strong>优点</strong>：</p><ul><li>先写数据库可以确保数据的可靠性和一致性，特别是数据库作为持久层存储，先写数据库能保证数据在持久层中的更新，即使缓存删除失败，也不会丢失数据。</li><li>删除缓存失败的概率较低，只有在网络问题或缓存服务器宕机时才会失败。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li>如果先更新数据库再删除缓存，可能会导致数据一致性问题：数据库已更新，但缓存未删除，导致缓存中的数据仍为旧值，造成缓存与数据库的不一致。</li></ul></li></ul><h4 id="3-解决方案：延迟双删：">3. <strong>解决方案：延迟双删</strong>：</h4><ul><li>为了避免旧数据回写缓存，可以先删除缓存，更新数据库后再延迟删除缓存。延迟删除可以通过消息队列、定时任务等方式实现。</li><li><strong>缺点</strong>：延迟时间不易确定，且在延迟过程中可能出现脏数据，无法保证强一致性。</li></ul><h4 id="总结：-4">总结：</h4><ul><li>如果需要优先保证<strong>数据一致性</strong>，可以选择<strong>先更新数据库后删缓存</strong>。</li><li>如果考虑到<strong>并发问题</strong>和<strong>缓存击穿</strong>，可以选择<strong>先删缓存后写数据库</strong>，但需要注意可能引发的<strong>数据不一致问题</strong>。</li></ul><h4 id="场景：">场景：</h4><p>小业务量、低并发：可以选择<strong>先更新数据库后删除缓存</strong>，因为这种方式简单易行，适用于较低并发的场景。</p><p>大业务量、高并发：建议选择<strong>先删除缓存</strong>，并引入<strong>延迟双删、分布式锁等机制</strong>，以降低并发问题。这种方式较为复杂，但能更好地保证数据一致性。</p><blockquote><p>优化方案 Binlog 异步更新缓存：</p></blockquote><p><strong>异步删除缓存</strong>：使用数据库的binlog或基于异步消息的订阅机制来异步删除缓存。这样，先更新数据库后，发送异步消息，再由监听器删除缓存，保证数据库与缓存一致性。</p><p><strong>无需延迟双删</strong>：因为通过binlog监听机制可以可靠地重试删除缓存操作，相比写代码删除缓存更稳定。</p><blockquote><p>完美方案：</p></blockquote><ol><li>先删除缓存</li><li>更新数据库</li><li>监听binlog异步删除缓存</li></ol><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/vSy45rqY_image_mianshiya.png" alt="image.png" width="100%" /><h3 id="面试总结：">面试总结：</h3><p>在Redis中保证缓存和数据库的数据一致性主要面临“缓存击穿”、“缓存穿透”和“缓存雪崩”等问题。为了避免这些问题，常见的做法是使用“删除缓存”而不是“更新缓存”，因为删除缓存能减少并发带来的数据不一致性问题，同时也避免了更新缓存时可能出现的复杂操作和错误。</p><p>在选择“先写数据库还是先删缓存”时，通常推荐先删除缓存。这是因为，如果先删除缓存再更新数据库，万一更新数据库失败，也不会有脏数据的问题，只需重试即可。不过，先删缓存会引发“读写并发”的问题，尤其是缓存删除后，可能会发生缓存中的数据被读线程以“旧数据”覆盖的情况，从而造成数据不一致。</p><p>为了更好的处理这个问题，可以使用“延迟双删”策略，或者引入“binlog异步更新缓存”的方案。通过监听数据库的binlog，确保在数据库变更后，缓存能异步更新或删除。</p><p>如果面对高并发的业务场景，建议使用先删除缓存再更新数据库的方式，并配合binlog的异步监听机制来确保缓存和数据库的最终一致性。这种方法虽然较复杂，但能有效保证数据一致性和系统的高可用性。</p><h2 id="Redis-String-类型的底层实现是什么？（SDS）">Redis String 类型的底层实现是什么？（SDS）</h2><blockquote><p>什么是SDS</p><p>Redis 的 String 类型底层主要是通过 <strong>SDS</strong>（Simple Dynamic String，简单动态字符串）结构实现的，<strong>它是 Redis 自己封装的一种字符串结构，用来代替 C 语言中的 char</strong>*。<br>为什么要用 SDS：</p></blockquote><p>C 的字符串有两个问题：</p><ul><li>第一，取字符串长度要遍历 \0，效率低；</li><li>第二，容易因为扩容或拼接导致缓冲区溢出。</li></ul><p>SDS 通过在结构体中<strong>记录字符串的 长度（len） 和 分配空间（alloc）</strong>，就解决了这些问题。</p><blockquote><p>SDS 的结构设计亮点：</p></blockquote><p>SDS 头部包含 len、alloc、flags 三个字段，buf 存真正的字符数据，并且末尾仍然保留 \0，保持对 C API 的兼容。<br>它有几个版本，比如 sdshdr5/8/16/32/64，根据字符串长度选择不同大小的头部，用来优化内存占用。</p><blockquote><p>SDS 的核心优势：</p></blockquote><ul><li>O(1) 获取长度：直接读 len 字段；</li><li>自动扩容 + 预分配机制，避免多次 realloc；</li><li>惰性释放，减少内存碎片；</li><li>二进制安全，任意字节都能存；</li><li>兼容 C 字符串，保留 \0。</li></ul><blockquote><p>扩展：String 的三种编码方式：</p></blockquote><p>Redis 的 String 类型底层不止 SDS，还会根据数据类型采用三种编码：</p><ul><li>int：保存整数，最节省内存；</li><li>embstr：短字符串（一般 ≤44B），redisObject 和 SDS 一起分配；</li><li>raw：较长或可变字符串，单独分配 SDS。</li></ul><p>编码会根据内容和操作自动切换，比如 embstr 修改后会变成 raw。</p><p>所以总结一下：<br><strong>Redis 的 String 底层是 SDS 动态字符串结构</strong>，相比 C 字符串，它支持动态扩容、O(1) 获取长度、二进制安全，解决了内存管理和性能问题；<br>同时配合 <strong>int、embstr、raw 三种编码</strong>，在性能和内存之间做了最优平衡。</p><h2 id="如何使用-Redis-快速实现排行榜？">如何使用 Redis 快速实现排行榜？</h2><p>实现排行榜，用 Redis 最顺手的就是 <strong>ZSet（有序集合）</strong>，因为它天生支持“分数 + 排序”。</p><ul><li>使用ZADD命令实现用户和分数插入</li><li>使用ZRANK获取某个用户的排名</li><li>使用ZREVRANGE按分数从高到低返回指定区间内的成员列表</li><li>使用ZINCRBY实现分数的修改</li></ul><p>在 xx项目 里，我用 Redis 的有序集合（ZSet）做排行榜，思路很简单：我这边一条榜单就是一个 ZSet，</p><ul><li>member 存视频 ID，</li><li>score 存播放量或热度值。</li></ul><p>比如：</p><ul><li>日榜：rank:video:play:2025-11-09</li><li>周榜：rank:video:week:2025-W45</li><li>总榜：rank:video:all</li></ul><h3 id="我怎么写入（实时更新分数）">我怎么写入（实时更新分数）</h3><p>前端产生“播放、点赞、评论、收藏”事件后，<br>我先把这些事件写进 Redis 队列（或者 RocketMQ）做<strong>削峰</strong>，<br>然后后台消费者去执行 <strong>ZINCRBY</strong>对应的加分操作。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ZINCRBY</span> rank:video:play:<span class="number">2025</span>-<span class="number">11</span>-<span class="number">09</span> <span class="number">1</span> &lt;videoId&gt;</span><br><span class="line"><span class="attribute">ZINCRBY</span> rank:video:hot:<span class="number">2025</span>-<span class="number">11</span>-<span class="number">09</span> &lt;加权分&gt; &lt;videoId&gt;</span><br></pre></td></tr></table></figure><ul><li><p>播放一次加 1；</p></li><li><p>热度榜是个加权计算（播放=1、点赞=3、评论=2、收藏=4…）。</p><ul><li>前端产生“播放/点赞/投币/评论”这些事件后，我先进 Redis 队列（List），后台MQ消费（削峰），然后对对应榜单执行 <code>ZINCRBY</code>：<ul><li>播放一次：<code>ZINCRBY rank:video:play:2025-11-09 1 &lt;videoId&gt;</code></li><li>热度分：<code>ZINCRBY rank:video:hot:2025-11-09 &lt;加权分&gt; &lt;videoId&gt;</code></li></ul></li></ul></li><li><p>为了减少 Redis 的网络往返，我用 pipeline 或 Lua 脚本 <strong>批量执行自增</strong>。</p></li><li><p>日榜会 设个 TTL（比如 1 天自动过期），周榜、总榜我用定时任务或 ZUNIONSTORE 聚合。</p></li></ul><h3 id="我怎么查（接口轻量）">我怎么查（接口轻量）</h3><p>查询很简单：</p><ul><li><p><strong>Top N 排行榜</strong>：<br><code>ZREVRANGE key 0 9 WITHSCORES</code><br>拿到 videoId 后再批量查详情（封面、标题等）。</p></li><li><p><strong>某个视频的排名</strong>：<br>ZREVRANK key videoId，结果从 0 开始我会 +1。</p></li></ul><p>切榜维度只要换 key，比如从日榜切到周榜，一次查询毫秒级就能出结果。</p><h3 id="小结-7">小结</h3><p>我用 ZSet 做排行榜：写入用 ZINCRBY 实时加分，查询用 ZREVRANGE/ZREVRANK 秒级出榜；榜单按时间拆 key 管理（天/周/总榜），再配合队列削峰、定时回写持久化，<br>整体又快又稳，还能灵活扩展权重逻辑，支持各种‘热度榜’玩法。</p><h2 id="如何使用-Redis-快速实现布隆过滤器？">如何使用 Redis 快速实现布隆过滤器？</h2><p>布隆过滤器是一种用来<strong>快速判断某个数据是否存在</strong>的概率型结构，要用它来<strong>防止缓存穿透</strong>。</p><h3 id="原理">原理</h3><p>它的核心是一个<strong>超大的 bit 数组</strong>，初始全是 0。<br>每次我们往过滤器里加一个元素时，会通过 <strong>多个哈希函数</strong> 算出几个位置，把对应的 bit 置为 1。</p><p>之后如果要判断某个元素是否存在：</p><ul><li>只要有一个 bit 位是 0，那它肯定不存在；</li><li>如果全是 1，那就“可能存在”。</li></ul><p>（因为有哈希碰撞，所以布隆过滤器会有一定误判率，但可以控制到很低）</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/09myonfA_image_mianshiya.png" alt="image.png" width="100%" /><h3 id="工作流程">工作流程</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/h6B1sP3t_image_mianshiya.png" alt="image.png" width="100%" />1️ 客户端发请求，Redis 先查缓存：<ul><li>命中 → 直接返回；</li><li>未命中 → 去看布隆过滤器。</li></ul><p>2️ 如果布隆过滤器判断“不存在”，那就直接拒绝访问数据库（防止穿透）。</p><p>3️ 如果“可能存在”，才会去查数据库，然后把结果重新写回缓存。</p><h3 id="Redis-实现布隆过滤器的两种方式">Redis 实现布隆过滤器的两种方式</h3><p>方式一：用 Bitmap 位图 自己实现</p><ul><li>用<code> SETBIT / GETBIT</code> 操作，自己维护 bit 数组；</li><li>用多个 hash 函数计算对应位置；</li><li>每次新增元素就把对应 bit 置 1；</li><li>判断时检测那几个位置是不是都为 1。</li></ul><p>适合想轻量实现、或者布隆过滤器逻辑特别简单的场景。</p><p>方式二：用 RedisBloom 模块<br>Redis 官方提供了一个插件模块 RedisBloom，线上项目一般直接用 RedisBloom，因为它比自己写 Bitmap 省很多维护成本。</p><h3 id="小结-8">小结</h3><p>布隆过滤器通过哈希+位图判断元素‘可能存在’，结合 Redis 实现特别高效。<br>在项目里用它放在缓存层前面：请求先查 Redis，再看布隆过滤器。不存在就直接拒绝，存在才放行查库。<br>这样能防止恶意请求穿透数据库，也能显著减轻后端压力。</p><h2 id="Redis-字符串类型的最大值大小是多少？">Redis 字符串类型的最大值大小是多少？</h2><p>最大512MB，但是不建议存储大于2MB的在字符串</p><h2 id="Redis-性能瓶颈时如何处理？">Redis 性能瓶颈时如何处理？</h2><p>我们要<strong>先搞清楚瓶颈在哪，然后再扩容、分流、再设计</strong>。</p><p><strong>能加机器就扩容，撑不住就主从 / 集群横向扩，最后再加多级缓存和限流降级。</strong></p><h2 id="如何在-Redis-中实现队列和栈数据结构？">如何在 Redis 中实现队列和栈数据结构？</h2><h3 id="实现队列（FIFO，先进先出）：">实现队列（FIFO，先进先出）：</h3><p>Redis 中，可以使用 LPUSH 命令向队列的左侧添加元素，使用 RPOP 命令从队列的右侧弹出元素。确保最先加入的元素最先被移除。</p><h3 id="实现栈（LIFO，后进先出）：">实现栈（LIFO，后进先出）：</h3><p>Redis 中，可以使用 LPUSH 命令向栈的左侧推入元素，使用 LPOP 命令从栈的左侧移除元素。确保最后加入的元素最先被移除。</p><ul><li>队列 = List 的「一头进、一头出」：LPUSH + RPOP（或反之），需要阻塞就用 BLPOP/BRPOP。</li><li>栈 = List 的「一头进、一头出，但在同一头」：LPUSH + LPOP。</li><li>要优先级，就用 ZSet 把“分数 = 优先级”，配合 ZADD + ZPOPMIN/ZREVRANGE。</li></ul><h2 id="Redis-中的-Ziplist-和-Quicklist-数据结构的特点是什么？">Redis 中的 Ziplist 和 Quicklist 数据结构的特点是什么？</h2><p>Ziplist（压缩列表）<br>就是一种“<strong>紧凑型、连续内存结构</strong>”，它把所有元素都顺序挨着放在一块连续内存中。</p><ul><li>优点是<strong>非常节省空间</strong>，适合小数据量、少修改的场景，比如小哈希、小列表。</li><li>缺点每个元素前面都要记录上一个元素的大小，如果插入或删除一个元素，就会涉及到后续元素的连锁更新，<strong>成本高</strong>。所以 Ziplist 不适合频繁插入、删除的情况。</li></ul><blockquote><p>Ziplist 更轻量、更节省内存，但不灵活。</p></blockquote><h3 id="Quicklist（快速列表）">Quicklist（快速列表）</h3><p>Redis 后面为了优化 List 的性能，引入了 Quicklist。它其实是一个“<strong>双向链表 + Ziplist</strong>的结合体”。</p><p>每个链表节点里，不再直接放一个元素，而是放一个小的 Ziplist。<br>这样既能保持链表的灵活性（插删快），又能利用 Ziplist 的紧凑存储节省内存。</p><p>Quicklist 从 Redis 3.2 开始就是 List 的默认底层实现。</p><h3 id="小结-9">小结</h3><blockquote><p>Ziplist 是“小而省”的代表，适合小量、少变的数据；<br>Quicklist 是“灵活高效”的代表，用链表包着多个 Ziplist，既能省内存，又能快速插删。</p></blockquote><h2 id="Redis-事务与关系型数据库事务的主要区别是什么？">Redis 事务与关系型数据库事务的主要区别是什么？</h2><ul><li>Redis 支持事务,Redis中的事务主要保证的是多个命令执行的原子性,即所有的命令在一个原子操作中执行,不会被打断。而不是MYSQL中的ACID</li><li>Redis中的事务是不支持回滚的</li></ul><h2 id="Redis-Cluster-模式与-Sentinel-模式的区别是什么？">Redis Cluster 模式与 Sentinel 模式的区别是什么？</h2><p>cluster提供了<strong>数据分片的功能</strong>，适合大数据量场景<br>sentinel没有数据分片功能，适合<strong>主从高可用</strong>，读写分离场景</p><h2 id="说说-Redisson-分布式锁的原理">说说 Redisson 分布式锁的原理?</h2><p>多个线程请求同一资源，只有一个线程才能获取这把锁</p><ul><li>redission通过lua脚本封装多个redis的命令来实现加锁和获取锁的原子性操作。</li><li>redission用的是UUID+线程ID合并起来保证我们的key和当前线程绑定在一起，这样就不会出现X线程1释放掉了线程2的锁这样的“锁误删”问题</li><li>redission内部会有一个看门狗机制，它会每隔10秒看一下当前线程是否还持有锁，如果持有的话就延长生存时间，从而给这把锁续命。</li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/0uH6dSZD_Snipaste_2025-11-09_18-55-15_mianshiya.png" alt="Snipaste_2025-11-09_18-55-15.png" width="100%" /><h2 id="Redis-Zset-的实现原理是什么？">Redis Zset 的实现原理是什么？</h2><blockquote><p>ZSet 是啥？</p></blockquote><p>ZSet 是一个带分数的有序集合：每个成员一个 score，按分数排序，还要保证成员唯一。</p><blockquote><p>底层怎么实现？</p></blockquote><ul><li>跳表（skiplist）：<ul><li>是一个多层索引的链表,主要是通过多层链表来实现,底层链表保存所有元素,而每一层链表都是下一层的子集。</li><li>按 score 排好序，做范围/排名查询很快，插入/删除/查找都是 O(log N)。</li></ul></li><li>哈希表（dict）：用于存储member -&gt; score 的映射，提供快速查找O(1)</li></ul><p>小数据优化：当有序集合的元素个数小于 128 ，并且每个元素的值小于 64 字节时，用<strong>压缩列表</strong>（ziplist）存，更省内存；超出阈值就用 跳表 + dict（字典）。</p><blockquote><p>为什么要跳表 + 哈希表？</p></blockquote><ul><li>跳表解决<strong>按分数进行有序的、范围的/排行的</strong>这类查询；</li><li>哈希表解决<strong>按成员秒查/改分数</strong>；</li><li>两者结合，查某个成员 O(1)，插入/删除/范围查 O(log N)，同时还能分页/TopN。</li></ul><blockquote><p>典型场景：</p></blockquote><p>排行榜、Feed 排序、延时队列、区间检索（如按分数查一段范围的人）。</p><blockquote><p>总结：</p></blockquote><p>ZSet = 跳表（排序与范围）+ 哈希表（按成员 O(1) 定位），小集合用压缩结构省内存；增删改 O(logN)、按成员查 O(1)、范围 O(logN+M)，特别适合做排行榜/区间查询。</p><h2 id="为什么-Redis-Zset-用跳表实现而不是红黑树？B-树？">为什么 Redis Zset 用跳表实现而不是红黑树？B+树？</h2><p>Redis 里 Zset（有序集合）用的是<strong>跳表 + 哈希表</strong> 组合实现的，而不是红黑树或者 B+ 树，主要是从实现复杂度、性能和使用场景几个方面考虑的。</p><h3 id="为什么不用红黑树？">为什么不用红黑树？</h3><ol><li>跳表实现更简单，维护成本低</li></ol><p>红黑树虽然查找快，但每次插入、删除都要做复杂的平衡操作；<br>跳表只用随机化层级，维护成本小得多。</p><ol start="2"><li>跳表更适合范围查询<br>Zset 很多操作都是<strong>范围查询</strong>，跳表可以直接顺序往后扫，非常高效。</li><li>跳表结构更灵活，扩展性好<br>小数据层少一点，大数据层多一点，不像红黑树那样固定死结构。</li></ol><h3 id="为什么不用-B-树？">为什么不用 B+ 树？</h3><p>B+ 树虽然在磁盘数据库（比如 MySQL）里很强，但 Redis 是<strong>纯内存型数据库</strong>。</p><ol><li><p>B+ 树节点太大，指针太多<br>B+ 树为<strong>磁盘优化设计</strong>，一个节点会存很多 key 和指针。<br>而 Redis 跳表节点只存一个 key 和几个指针（前进、回退），<br>在内存中结构更轻、更紧凑，缓存命中率高。</p></li><li><p>B+ 树更适合磁盘存储，不适合内存操作</p></li></ol><p>B+ 树是为减少磁盘 I/O 而设计的；<br>Redis 是内存操作，随机访问不再是瓶颈，所以没必要用 B+ 树这种“大块结构”。</p><h3 id="跳表更契合-Redis-的实现逻辑">跳表更契合 Redis 的实现逻辑</h3><p>在 Redis 的 Zset 里：</p><ul><li>Hash 用来根据成员快速查分数；</li><li>SkipList 用来按分数排序、做范围查询。</li></ul><p>这俩结构组合起来，既能快速定位，又能高效排序。<br>跳表比平衡树更自然地满足这种“双需求”场景。</p><h3 id="小结-10">小结</h3><p>Redis 之所以选跳表，不是因为红黑树或 B+ 树不行，而是因为跳表结构更简单、性能稳定、支持范围查询、内存利用率高，并且和哈希表组合（Hash + SkipList）能完美满足 Zset 的需求。</p><h2 id="Redisson-看门狗（watch-dog）机制了解吗？">Redisson 看门狗（watch dog）机制了解吗？</h2><ul><li>Redisson中的看门狗机制(watchdog)主要用来避免业务逻辑还未执行完毕,Redis中的锁就因为过了超时时间而释放了</li><li>它通过定期向Redis发送命令更新锁的过期时间来实现自动续期,默认每10s发送一次请求,每次续期30s。</li><li>当客户端主动释放锁时,Redisson会取消看门狗刷新操作。如果客户端宕机了,定时任务自然也就无法执行了,此时等超时时间到了,锁也会自动释放。</li></ul><h2 id="你在项目中使用的-Redis-客户端是什么？">你在项目中使用的 Redis 客户端是什么？</h2><p>我这个项目用的是Lettuce</p><ul><li>用的是 Spring Data Redis 默认的 Lettuce（Boot 2.x 起默认）。</li><li>为什么选它<ul><li>和 Spring 无缝集成，开箱即用，用 <code>RedisTemplate</code> 就能搞定缓存、验证码、token、队列、在线人数等场景。</li><li>基于 Netty，线程安全、单连接多路复用，适合我们这种并发量不小的读写；相比老的 Jedis 不需要连接池，资源占用更稳。</li><li>天然支持哨兵/集群、异步/Reactive，用起来省心，线上故障重连也更友好。</li></ul></li><li>没选 Jedis/Redisson 的原因<ul><li>Jedis 更适合简单/单线程场景，我们需要高并发和异步能力。</li><li>Redisson偏“分布式对象/锁”套件，我们当前主要是KV/自增/过期事件这类操作，Lettuce + Spring Data Redis 已够用；若后续重度用分布式锁/延迟队列，再引 Redisson 不迟。</li></ul></li></ul><h2 id="如果发现-Redis-内存溢出了？你会怎么做？请给出排查思路和解决方案">如果发现 Redis 内存溢出了？你会怎么做？请给出排查思路和解决方案</h2><p>如果线上 Redis 内存溢出，我的第一反应是：<strong>先扩容，保证业务不受影响；然后再排查根因，做长期优化</strong>。</p><h3 id="一、第一步：止血（确保服务正常）">一、第一步：止血（确保服务正常）</h3><p>如果错误提示是 used memory &gt; maxmemory，说明 Redis 达到最大内存限制，继续写入被拒绝。</p><p>所以第一时间我会：</p><ul><li>扩容 Redis 实例内存 或</li><li>增加新的 Redis 节点分担压力</li><li>先保证线上业务不挂，再排查根因。</li></ul><h3 id="二、第二步：排查-Redis-内存为什么涨满？">二、第二步：排查 Redis 内存为什么涨满？</h3><p>常见的几种情况</p><ol><li>数据量太多</li></ol><ul><li>存入 Redis 的 key/数据本身太大，超过内存容量。</li></ul><ol start="2"><li>大量 key 没有设置过期时间</li></ol><ul><li>数据长期堆积不释放，导致内存持续增长。</li></ul><ol start="3"><li>大对象 / 大型数据结构滥用</li></ol><ul><li>比如 hash、list、set 里塞了大量内容，占用极大空间。</li></ul><ol start="4"><li>持久化策略影响</li></ol><ul><li>RDB fork 时会额外占一份内存（写时复制机制），高峰容易炸。</li></ul><ol start="5"><li>业务代码误用 Redis 当数据库</li></ol><ul><li>比如把日志、明细表全写进 Redis。</li></ul><h3 id="第三步：解决方案（短期-长期）">第三步：解决方案（短期 + 长期）</h3><p>（1）<strong>短期优化</strong></p><ul><li><p><strong>启用合适的淘汰策略</strong><br>如 allkeys-lru、volatile-lru，让 Redis 自动删除不常用 key。</p></li><li><p><strong>为 key 设置合理的 TTL</strong><br>避免无过期数据永远占内存。</p></li></ul><p>（2）<strong>长期优化</strong></p><ul><li><p><strong>优化数据结构设计</strong></p><ul><li>大 hash 拆分成小 hash，减少单个结构的内存占用。</li></ul></li><li><p><strong>水平扩展 Redis</strong></p><ul><li>分库分槽，将数据打散到多个 Redis 节点降低单机压力。</li></ul></li><li><p><strong>优化持久化策略</strong></p><ul><li>减少 RDB 在高峰期触发并导致额外内存开销。</li></ul></li></ul><p>下面是 <strong>30 秒极速口语版</strong>，面试时直接说就能拿高分👇</p><h3 id="小结-11">小结</h3><blockquote><p>如果发现 Redis 内存溢出，我的第一反应是<strong>先扩容保证业务不挂</strong>，然后再排查原因。</p></blockquote><p>常见根因主要有三类：</p><ol><li><strong>数据太多</strong>：写入的数据量超出 Redis 内存限制。</li><li><strong>无过期时间</strong>：大量 key 没 TTL，越积越多。</li><li><strong>大对象滥用</strong>：比如一个 hash、list、set 塞几十万条数据。</li></ol><p>解决也很简单：</p><ul><li><strong>开启合适的淘汰策略</strong>（allkeys-lru 等）</li><li><strong>给 key 设置合理 TTL</strong></li><li><strong>拆分大对象，优化数据结构</strong></li><li><strong>必要时做 Redis 水平扩容</strong>（分片/集群）</li><li><strong>优化 RDB/AOF 配置，避免高峰期 fork 占用额外内存</strong></li></ul><p><strong>一句话总结：</strong></p><blockquote><p>先扩容止血，再找无 TTL、大对象、数据堆积等根因；最后通过淘汰策略、TTL、拆分数据结构和扩容彻底解决。</p></blockquote>]]></content>
    
    
    <summary type="html">我对Redis的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="Redis" scheme="https://itgeqian.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>javase+集合相关面试题</title>
    <link href="https://itgeqian.github.io/posts/77.html"/>
    <id>https://itgeqian.github.io/posts/77.html</id>
    <published>2025-10-07T00:19:03.000Z</published>
    <updated>2025-10-20T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ八股-Java基础-集合">GQ八股-Java基础+集合</h1><h2 id="java基础">java基础</h2><h3 id="Java中的序列化和反序列化是什么？"><strong>Java中的序列化和反序列化是什么？</strong></h3><p><strong>序列化</strong>：指将一个对象转化为字节流的过程，通常用于存储或者通过网络传输。<code>ObjectOutputStream</code>用于将对象序列化。</p><p><strong>反序列化</strong>：指将字节流还原为原始对象的过程，使用<code>ObjectInputStream</code>来实现。</p><p><strong>关键要求</strong>：</p><ol><li><strong>Serializable接口</strong>：类必须实现<code>Serializable</code>接口，才能被序列化。</li><li><strong>transient关键字</strong>：标记为<code>transient</code>的字段会被序列化时忽略。</li><li><strong>serialVersionUID</strong>：每个类应定义<code>serialVersionUID</code>，用于验证序列化和反序列化版本一致性。</li><li><strong>性能与安全</strong>：序列化可能导致性能下降，同时反序列化存在安全风险（例如反序列化攻击），因此需要对输入数据进行验证。</li><li><strong>静态变量</strong>：静态变量不会被序列化，因为它们与实例无关。</li></ol><p>总结：序列化和反序列化为Java对象的存储和传输提供了便利，但需要关注性能和安全性问题。</p><h3 id="Exception-和-Error-的区别">Exception 和 Error 的区别</h3><p>Exception 和 Error 都是 Throwable 的子类，<br>区别在于：</p><ul><li><strong>Exception</strong> 表示程序可以处理的异常，比如业务逻辑错误、文件找不到等。</li><li><strong>Error</strong> 表示系统层面的严重错误，比如内存溢出（OutOfMemoryError）或栈溢出（StackOverflowError），程序一般无法恢复。</li></ul><p>Exception 又分为两类：</p><ul><li><strong>Checked Exception</strong>（受检异常）：编译期必须处理，比如 IOException；</li><li><strong>Unchecked Exception</strong>（运行时异常）：运行期才抛出，比如 NullPointerException。</li></ul><p>通常我们只捕获 Exception，不处理 Error。</p><p><img src="./../AppData/Roaming/Typora/typora-user-images/image-20251024211600928.png" alt="image-20251024211600928"></p><p>如果面试官追问</p><p><strong>Q：那为什么 Error 不推荐捕获？</strong></p><blockquote><p>因为 Error 通常由 JVM 抛出，代表系统层问题，程序恢复不了，捕获也没意义。比如堆内存溢出时，就算 catch 了也无法分配对象继续运行。</p></blockquote><p><strong>Q：Exception 和 RuntimeException 的关系呢？</strong></p><blockquote><p>RuntimeException 是 Exception 的子类，它代表运行时异常，不需要强制 try-catch，比如空指针、数组越界。</p></blockquote><h3 id="Java的优势">Java的优势</h3><ol><li><strong>跨平台性</strong><br>Java的“写一次，运行多平台”特性通过JVM（Java虚拟机）实现，保证了Java程序能够在不同操作系统上运行，不需要针对每个系统重新编译。</li><li><strong>垃圾回收</strong><br>Java提供了自动垃圾回收功能（GC），可以管理内存的分配与回收，减轻了开发者的负担，且不需要手动释放内存，避免了内存泄漏问题。</li><li><strong>生态系统</strong><br>Java有强大的生态支持，包括丰富的第三方库、工具、框架和资源，使开发更加高效，适用的领域广泛。</li><li><strong>面向对象</strong><br>Java采用面向对象的编程模型，支持继承、多态、封装等特性，代码易于维护和扩展，提升了开发效率和系统的可维护性。</li></ol><p>这些特点使Java成为了一个高度可移植、可靠并且在企业级开发中广泛应用的语言。</p><p><img src="./../AppData/Roaming/Typora/typora-user-images/image-20251024211934460.png" alt="image-20251024211934460"></p><h3 id="java中的多态特性">java中的多态特性</h3><p>Java 多态特性：</p><p>Java 的多态是指同一方法在不同的对象上执行时，表现出不同的行为。它是面向对象编程的核心特性之一，通过方法重载和方法重写来实现。主要有两种类型：</p><ol><li><strong>编译时多态（方法重载）</strong>：<ul><li>同一个类中，可以定义多个同名的方法，但是它们的参数列表（参数的数量、类型或顺序）必须不同。</li><li>这种多态性是在编译阶段决定的，编译器会根据方法的参数类型来决定调用哪个版本的重载方法。</li></ul></li><li><strong>运行时多态（方法重写）</strong>：<ul><li>子类继承父类，并可以重写父类的方法，运行时决定具体调用哪个类的方法。</li><li>这种多态性发生在程序运行时，当父类引用指向子类对象时，实际执行的是子类的重写方法。</li></ul></li></ol><p>多态的优点：</p><ul><li><strong>代码的可扩展性</strong>：可以编写更灵活的代码，减少重复代码。</li><li><strong>解耦</strong>：通过接口或继承来解耦代码，易于修改和维护。</li></ul><p>面试中简洁回答：</p><p>Java 多态是指同一个方法调用，在不同的对象上会产生不同的执行效果。它主要分为编译时多态（方法重载）和运行时多态（方法重写）。编译时多态通过方法的参数差异来决定调用哪个方法，而运行时多态通过子类重写父类的方法来决定实际调用的版本。</p><h3 id="java中的参数传递是按值还是按引用">java中的参数传递是按值还是按引用</h3><p>在Java中，方法参数的传递是基于“值传递”机制的，但这里有一些细节需要注意：</p><ul><li>对于<strong>基本数据类型</strong>（例如 <code>int</code>, <code>char</code>，<code>boolean</code>），参数传递的是<strong>值的副本</strong>，因此修改副本不会影响原始变量。</li><li>对于<strong>引用数据类型</strong>（如类的实例），传递的是<strong>对象的引用</strong>，也就是对象的内存地址。在方法内部修改对象的属性会影响原始对象，但无法改变引用，使得引用指向另一个对象。</li></ul><p>总结来说，Java中方法参数的传递是<strong>值传递</strong>，但对于对象引用来说，实际上是传递引用的副本，所以能修改对象的内容，但不能修改引用本身。</p><h3 id="为什么java不支持多重继承">为什么java不支持多重继承</h3><p>Java不支持多重继承的主要原因是避免“钻石问题”，即当一个类继承了多个父类，并且这些父类有相同的方法或属性时，会导致冲突。为了防止这种复杂性，Java选择了单继承模型。通过接口（interface）提供了灵活的多继承方式，允许一个类实现多个接口，从而避免了传统多继承的缺点。</p><p><img src="./../AppData/Roaming/Typora/typora-user-images/image-20251024213752991.png" alt="image-20251024213752991"></p><h3 id="java面向对象编程与面向过程编程的区别是什么">java面向对象编程与面向过程编程的区别是什么</h3><img src="./../AppData/Roaming/Typora/typora-user-images/image-20251024214438789.png" alt="image-20251024214438789" style="zoom:150%;" /><p>在Java中，面向过程编程和面向对象编程的区别，主要体现在思维方式和代码组织方式上。</p><ol><li>面向过程编程（Procedure-Oriented Programming）<br>它以“过程”为核心，把程序看作一系列顺序执行的步骤，强调“先做什么、再做什么”。程序的基本单元是函数或过程，更关注执行的流程和算法逻辑，适合用来处理结构简单、流程清晰的任务。</li></ol><p>举个例子，我们要写一个“煮咖啡”的程序，面向过程的思路可能是：</p><ul><li><p>打开咖啡机；</p></li><li><p>加水；</p></li><li><p>加咖啡粉；</p></li><li><p>煮咖啡；</p></li><li><p>倒出咖啡。<br>整个过程就像一条流水线，关注的是步骤和执行顺序。</p></li></ul><ol start="2"><li>面向对象编程（Object-Oriented Programming, OOP）<br>它以“对象”为核心，将数据和操作数据的方法封装在一起，程序的基本单元是对象。OOP更注重封装、继承、多态等特性，强调代码的复用性、可扩展性和灵活性。</li></ol><p>如果用面向对象的方式来实现“煮咖啡”，我们会先抽象出对象，比如“人”和“咖啡机”。</p><ul><li><p>“人”负责发出“煮咖啡”的指令；</p></li><li><p>“咖啡机”对象内部封装了加水、加豆、加热等方法。</p></li><li><p>当人调用咖啡机的 makeCoffee() 方法时，内部会自动完成一系列步骤。这样，代码更清晰、更易维护，也便于后期扩展，比如增加“加奶”“打泡”等新功能。</p></li></ul><p>总结来说：</p><ul><li><p>面向过程关注“做事的步骤”，适合小型、简单的任务；</p></li><li><p>面向对象关注“谁来做这件事”，更适合复杂、可扩展的系统开发。</p></li></ul><p>Java作为典型的面向对象语言，正是通过“封装、继承、多态”这些特性，让开发者能够更高效地管理复杂业务逻辑。</p><ol start="3"><li>一句总结：</li></ol><p>“面向过程关注流程，面向对象关注对象。前者适合解决问题，后者适合构建系统。就像煮咖啡——面向过程一步步写流程，而面向对象则让‘咖啡机对象’自己完成整个动作。”</p><h3 id="Java-方法重载和方法重写之间的区别是什么？">Java 方法重载和方法重写之间的区别是什么？</h3><p>Java 里的 重载（Overload） 和 重写（Override） 最大区别在于：</p><ul><li>重载 **发生在同一个类中，方法名相同但参数不同（**类型、数量或顺序不同），和返回值无关，主要用于提高代码的灵活性，比如构造函数的重载。</li><li>而 重写 <strong>发生在父类和子类之间，子类对父类方法进行改写或扩展以实现多态</strong>。重写要求方法名、参数列表都相同，返回值类型相同或是其子类，访问修饰符权限不能更低。<br>此外，private、static、final 方法不能被重写。</li></ul><table><thead><tr><th style="text-align:left">对比项</th><th style="text-align:left"><strong>方法重载（Overload）</strong></th><th style="text-align:left"><strong>方法重写（Override）</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>定义</strong></td><td style="text-align:left">在<strong>同一个类中</strong>定义多个同名方法，参数列表不同</td><td style="text-align:left">在<strong>子类中重写父类的方法</strong>，以实现多态</td></tr><tr><td style="text-align:left"><strong>发生位置</strong></td><td style="text-align:left">同一个类中</td><td style="text-align:left">父类与子类之间</td></tr><tr><td style="text-align:left"><strong>参数列表</strong></td><td style="text-align:left">必须不同（类型、数量、顺序至少有一处不同）</td><td style="text-align:left">必须完全相同</td></tr><tr><td style="text-align:left"><strong>返回值类型</strong></td><td style="text-align:left">可以不同（但仅靠返回值不同不能构成重载）</td><td style="text-align:left">必须相同，或是父类返回值的子类（协变返回类型）</td></tr><tr><td style="text-align:left"><strong>访问修饰符</strong></td><td style="text-align:left">无限制</td><td style="text-align:left">子类重写方法的访问权限<strong>不能低于</strong>父类方法</td></tr><tr><td style="text-align:left"><strong>异常声明</strong></td><td style="text-align:left">可随意定义</td><td style="text-align:left">子类方法抛出的异常<strong>不能比父类更宽泛</strong></td></tr><tr><td style="text-align:left"><strong>static / final / private 方法</strong></td><td style="text-align:left">可以被重载</td><td style="text-align:left">不能被重写（static 是隐藏，final/private 无法重写）</td></tr><tr><td style="text-align:left"><strong>调用方式</strong></td><td style="text-align:left">由编译器在<strong>编译时确定</strong>（编译时多态）</td><td style="text-align:left">由 JVM 在<strong>运行时动态绑定</strong>（运行时多态）</td></tr><tr><td style="text-align:left"><strong>目的</strong></td><td style="text-align:left">提高代码灵活性和可读性（同一功能不同实现）</td><td style="text-align:left">实现多态性，让子类定制父类行为</td></tr><tr><td style="text-align:left"><strong>示例</strong></td><td style="text-align:left"><code>void print(int a)</code> vs <code>void print(String s)</code></td><td style="text-align:left">子类重写 <code>void eat()</code> 改变父类默认实现</td></tr></tbody></table><p>重载是编译时多态，同类中同名不同参；<br>重写是运行时多态，子类改写父类方法，方法名与参数都必须一致。</p><h3 id="什么是-Java-内部类？它有什么作用？">什么是 Java 内部类？它有什么作用？</h3><p>Java 内部类是<strong>定义在另一个类中的类</strong>，根据定义位置不同分为四种：<strong>成员内部类、静态内部类、局部内部类和匿名内部类</strong>。</p><ul><li>成员内部类可以访问外部类的所有成员，包括 private；</li><li>静态内部类只能访问外部类的静态成员；</li><li>局部内部类定义在方法中，只在方法内部可见；</li><li>匿名内部类没有类名，常用于接口回调或事件处理。</li></ul><table><thead><tr><th>类型</th><th>定义位置</th><th>可访问范围</th><th>是否有类名</th><th>常见用途</th></tr></thead><tbody><tr><td>成员内部类</td><td>外部类中，非静态位置</td><td>可访问外部类所有成员（含 private）</td><td>有</td><td>外部类与内部类强关联时使用</td></tr><tr><td>静态内部类</td><td>外部类中，static 修饰</td><td>只能访问外部类静态成员</td><td>有</td><td>辅助逻辑类，不依赖外部类实例</td></tr><tr><td>局部内部类</td><td>方法或代码块中定义</td><td>可访问 final 或 effectively final 的局部变量</td><td>有</td><td>临时逻辑封装</td></tr><tr><td>匿名内部类</td><td>无类名，直接定义实例</td><td>同局部类</td><td>无</td><td>简化接口实现或回调逻辑</td></tr></tbody></table><p>它的主要作用是提高封装性和代码内聚性，并且在只在一个地方使用的情况下可以简化代码结构。</p><p><strong>速答版</strong>：<br>Java 内部类就是定义在类内部的类，分为成员内部类、静态内部类、局部内部类和匿名内部类。<br>它能访问外部类的成员，提高封装性和内聚性，常用于回调、事件处理等场景。</p><h3 id="Java8-有哪些新特性？">Java8 有哪些新特性？</h3><p>Java 8 是一次非常重要的版本更新，引入了很多影响后续生态的特性。</p><ul><li><p>最核心的是 Lambda 表达式 和 函数式接口，让 Java 能以更简洁的方式实现函数式编程；</p></li><li><p>然后是 Stream API，可以用链式操作来处理集合，比如过滤、排序、映射这些操作，代码更优雅；</p></li><li><p>还新增了 接口的默认方法和静态方法，让接口在扩展时不破坏原有实现；</p></li><li><p>同时引入了 全新的日期时间 API（LocalDate、LocalTime、LocalDateTime），解决了老的 Date 不可变与线程安全问题；</p></li><li><p>在内存管理方面，用 元空间（Metaspace）替代了永久代（PermGen），解决了内存不足和 GC 效率低的问题；</p></li><li><p>此外还有 Optional 类 避免空指针，CompletableFuture 和 StampedLock 等并发增强类，以及 :: 方法引用语法。</p></li></ul><p>可以说 Java8 的这些改进让代码更简洁、更安全，也为后续的响应式编程打下了基础。</p><p><strong>速答版</strong>：<br>Java8 的主要新特性有 Lambda 表达式、Stream API、接口默认方法、新日期时间 API、Optional 类，以及用元空间替代永久代。这些特性让 Java 更简洁、更高效、更现代化。</p><h3 id="Java-中-String、StringBuffer-和-StringBuilder-的区别是什么？">Java 中 String、StringBuffer 和 StringBuilder 的区别是什么？</h3><p>String、StringBuffer、StringBuilder用于表示一串字符，即字符序列。StringJoiner是JDK8引入的一个String拼接工具</p><p>在 Java 中，String、StringBuffer 和 StringBuilder 的主要区别在于<strong>可变性</strong>、<strong>线程安全性</strong>和<strong>性能</strong>。</p><p>首先，String 是<strong>不可变</strong>的，底层用 final char[] 修饰，每次修改都会创建新的对象，所以<strong>适合字符串内容不频繁变化的场景</strong>，比如常量池或日志输出。</p><p>而 StringBuffer 和 StringBuilder 都是<strong>可变</strong>的，修改内容不会新建对象，底层通过 append() 来操作。</p><p>不同的是，<strong>StringBuffer 是线程安全的</strong>，因为内部方法使用了 synchronized，适合多线程环境下的字符串操作；<br>StringBuilder 则是非线程安全的，但没有同步锁，性能更高，适合单线程环境。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/3v9BoRnS_image_mianshiya.png" alt="image.png" width="100%" /><p>总结一句话：String 用于少变内容，StringBuffer 多线程改字符串，StringBuilder 单线程拼接最快。</p><p>速答版：</p><ul><li>String 不可变，线程安全；</li><li>StringBuffer 可变、线程安全、性能一般；</li><li>StringBuilder 可变、线程不安全，但性能最好。</li></ul><h3 id="Java-的-StringBuilder-是怎么实现的？">Java 的 StringBuilder 是怎么实现的？</h3><p>StringBuilder 的底层是通过一个 可变的 char 数组 来存储字符序列的。</p><p>和 String 不同的是，String 的底层也是 char[]，但被 final 修饰且是私有的，所以内容不可变；而 StringBuilder 没有这个限制。</p><p>当我们调用 append()、insert() 等方法时，StringBuilder 会 直接修改底层字符数组的内容，而不是像 String 那样创建新对象。</p><p>如果数组容量不够，会通过 Arrays.copyOf() 扩容，扩容规则是：新容量 = 旧容量 × 2 + 2，这样可以减少扩容次数、提升性能。</p><p>另外，它的所有方法没有加同步锁，所以是 线程不安全 的，但单线程下性能最好。</p><p>速答版：<br>StringBuilder 底层是可变的 char[]，通过 append 直接修改，不会创建新对象；容量不足时会按 2 倍加 2 扩容；线程不安全但性能最好。</p><h3 id="Java-中包装类型和基本类型的区别是什么？">Java 中包装类型和基本类型的区别是什么？</h3><p>在 Java 中，基本类型和包装类型的区别主要体现在 <strong>性能</strong>、<strong>存储</strong>、<strong>比较方式</strong>和<strong>默认值</strong> 这几个方面。</p><ul><li><p>首先，基本类型 不是对象，占用内存小、效率高，适合频繁使用的简单运算；<br>包装类型 是对象，会涉及堆内存分配和垃圾回收，性能相对低。</p></li><li><p>在比较时，基本类型用 == 比较数值，而包装类型的 == 比较的是地址，若要比较内容要用 equals()。</p></li><li><p>默认值也不同：基本类型如 int 默认是 0，boolean 默认 false，而包装类型的默认值是 null。</p></li><li><p>存储上，基本类型作为局部变量存在线程栈中，若是成员变量则在堆中；包装类型一定是对象，存在堆上。</p></li></ul><p>总结一句话：基本类型轻量高效，包装类型更灵活但开销更大。</p><p>速答版：<br>基本类型存数值、效率高、不占内存；包装类型是对象，占堆内存、支持泛型和 null。<br>比较上一个比值、一个比地址，默认值也不同：0 vs null。</p><p>附上对比表</p><table><thead><tr><th style="text-align:left">对比项</th><th style="text-align:left">基本类型（Primitive）</th><th style="text-align:left">包装类型（Wrapper）</th></tr></thead><tbody><tr><td style="text-align:left"><strong>定义位置</strong></td><td style="text-align:left">位于 JVM 基本数据类型体系（如 int、double）</td><td style="text-align:left">位于 <code>java.lang</code> 包下的类（如 Integer、Double）</td></tr><tr><td style="text-align:left"><strong>是否对象</strong></td><td style="text-align:left">❌ 不是对象</td><td style="text-align:left">✅ 是对象（继承自 Object）</td></tr><tr><td style="text-align:left"><strong>存储位置</strong></td><td style="text-align:left">局部变量在<strong>栈上</strong>，成员变量在<strong>堆上</strong></td><td style="text-align:left">永远在<strong>堆中</strong>（对象引用存于栈上）</td></tr><tr><td style="text-align:left"><strong>默认值</strong></td><td style="text-align:left">数值型为 <code>0</code>，布尔型为 <code>false</code></td><td style="text-align:left">全部为 <code>null</code></td></tr><tr><td style="text-align:left"><strong>比较方式</strong></td><td style="text-align:left"><code>==</code> 比较<strong>值</strong></td><td style="text-align:left"><code>==</code> 比较<strong>地址</strong>，<code>equals()</code> 比较<strong>值</strong></td></tr><tr><td style="text-align:left"><strong>性能表现</strong></td><td style="text-align:left">占用内存小、执行快</td><td style="text-align:left">占用内存大、执行慢（涉及 GC）</td></tr><tr><td style="text-align:left"><strong>用途场景</strong></td><td style="text-align:left">常用于数值计算、频繁运算</td><td style="text-align:left">适用于集合框架（如 List<Integer>）和需要对象的场景</td></tr><tr><td style="text-align:left"><strong>初始化方式</strong></td><td style="text-align:left">直接赋值（如 <code>int a = 1;</code>）</td><td style="text-align:left">需 new 或自动装箱（如 <code>Integer a = 1;</code>）</td></tr><tr><td style="text-align:left"><strong>可空性</strong></td><td style="text-align:left">❌ 不能为 null</td><td style="text-align:left">✅ 可为 null</td></tr><tr><td style="text-align:left"><strong>泛型支持</strong></td><td style="text-align:left">❌ 不支持泛型</td><td style="text-align:left">✅ 可用于泛型（例如 <code>List&lt;Integer&gt;</code>）</td></tr></tbody></table><h3 id="接口和抽象类有什么区别？">接口和抽象类有什么区别？</h3><h4 id="为什么-Java-要同时存在抽象类和接口？它们在设计思想上分别解决了什么问题？">为什么 Java 要同时存在抽象类和接口？它们在设计思想上分别解决了什么问题？</h4><p>我们从语法 + 思想 + 场景 三层逻辑来回答</p><h4 id="概念层（简述区别）">概念层（简述区别）</h4><p>抽象类是对事物共性的抽象，可以包含属性和方法；<br>接口是对行为规范的抽象，更关注对象能做什么。</p><h4 id="语法层（核心对比表）">语法层（核心对比表）</h4><table><thead><tr><th>对比点</th><th>抽象类（abstract class）</th><th>接口（interface）</th></tr></thead><tbody><tr><td>继承实现</td><td>单继承</td><td>多实现</td></tr><tr><td>成员内容</td><td>可有属性、构造方法、普通方法、抽象方法</td><td>仅能有常量和方法（JDK8 起可有默认方法、静态方法，JDK9 可有私有方法）</td></tr><tr><td>设计定位</td><td>模板：抽象出相同部分，提高复用</td><td>协议：定义行为规范，解耦调用方与实现方</td></tr><tr><td>访问修饰</td><td>可有各种修饰符</td><td>默认 public、static、final（常量）</td></tr><tr><td>场景</td><td>父类通用功能扩展</td><td>不同类的行为统一</td></tr></tbody></table><h4 id="思想层">思想层</h4><p>抽象类体现的是模板复用思想，<br>接口体现的是解耦和规范思想。</p><p>举个例子</p><p>比如我们有 Bird、Airplane、Superman 都能飞。</p><ul><li>它们的“飞”是一种行为能力，应该定义在接口 Flyable 中（规定必须实现 fly()）。</li><li>而“鸟类”有共同特征，比如翅膀、吃虫等，就应该抽象为一个抽象类 Bird，让子类继承它共享实现。</li></ul><p>所以接口是「能做什么」，抽象类是「是什么 + 怎么做」。</p><h4 id="一句话总结">一句话总结</h4><p>抽象类和接口最大的区别在于“<strong>目的</strong>”。</p><ul><li>抽象类是<strong>对类的共性抽象</strong>，可以包含属性和方法，强调复用；</li><li>接口是<strong>对行为的抽象</strong>，强调规范与解耦。</li></ul><blockquote><p>比如我们有 Bird、Airplane、Superman 都能飞。</p></blockquote><ul><li>它们的“飞”是一种行为能力，应该定义在接口 Flyable 中（规定必须实现 fly()）。</li><li>而“鸟类”有共同特征，比如翅膀、吃虫等，就应该抽象为一个抽象类 Bird，让子类继承它共享实现。</li></ul><p>所以接口只关注「能做什么」，抽象类则关注「是什么 + 怎么做」。</p><p>抽象类解决代码复用问题，接口解决多继承和行为统一问题。</p><p>一句话：<strong>抽象类是模板，接口是契约。</strong></p><h3 id="JDK-和-JRE-有什么区别？">JDK 和 JRE 有什么区别？</h3><p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/tmp_cc3668b18e6cb614fc647f0c0561ddc11d2a69f460fda751_mianshiya.jpg" width="80%" data-custom="id=abcd&amp;role=god"></p><p><br></p><h3 id="你使用过哪些-JDK-提供的工具？">你使用过哪些 JDK 提供的工具？</h3><table><thead><tr><th>分类</th><th>工具</th><th>功能简述</th></tr></thead><tbody><tr><td><strong>基础开发工具</strong></td><td><code>javac</code></td><td>Java 编译器，将 <code>.java</code> 源码编译为 <code>.class</code> 字节码</td></tr><tr><td></td><td><code>java</code></td><td>运行 Java 应用的命令，启动 JVM</td></tr><tr><td></td><td><code>javadoc</code></td><td>根据注释生成 API 文档</td></tr><tr><td></td><td><code>jar</code></td><td>打包/解压 JAR 文件</td></tr><tr><td></td><td><code>jdb</code></td><td>Java 调试工具，命令行调试、断点、变量查看</td></tr><tr><td><strong>性能监控与分析工具</strong></td><td><code>jps</code></td><td>查看当前正在运行的 Java 进程</td></tr><tr><td></td><td><code>jstack</code></td><td>查看线程堆栈，用于分析死锁和卡顿</td></tr><tr><td></td><td><code>jmap</code></td><td>导出内存映射（heap dump）文件，分析内存泄漏</td></tr><tr><td></td><td><code>jhat</code></td><td>堆分析工具，配合 <code>jmap</code> 使用</td></tr><tr><td></td><td><code>jstat</code></td><td>JVM 统计监控工具（GC 次数、加载类数等）</td></tr><tr><td></td><td><code>jconsole</code></td><td>图形化 JVM 监控工具</td></tr><tr><td></td><td><code>jvisualvm</code></td><td>综合性能分析工具（线程、GC、CPU 等）</td></tr><tr><td><strong>诊断与远程工具</strong></td><td><code>jinfo</code></td><td>查看和调整 JVM 参数</td></tr><tr><td></td><td><code>jstatd</code></td><td>远程 JVM 监控守护进程</td></tr></tbody></table><p><strong>但面试官想听到的不是“你会背”，而是“你会用”</strong><br>所以不要机械背诵工具清单，而要讲出你真的用过、解决过问题的场景。</p><p>我平时在开发和排查问题时用过一些 JDK 自带的工具。</p><ol><li>首先是开发类工具，比如 javac、java、jar、javadoc 这些是日常必用的。</li><li>其次是性能排查类工具：</li></ol><ul><li>我常用 jps 查看运行中的 Java 进程；</li><li>遇到线程死锁或 CPU 占用高时，会用 jstack 导出线程堆栈排查问题；</li><li>如果怀疑内存泄漏，会通过 jmap -dump 导出堆文件，然后用 jvisualvm 或 Eclipse MAT 分析；</li><li>GC 频繁或 Full GC 慢的时候，我会用 jstat -gc 实时观察垃圾回收情况。</li></ul><ol start="3"><li>最后是调优与监控类：<br>我也用过 jconsole 和 jvisualvm 做 JVM 性能监控，比如查看线程数量、内存占用、GC 情况等。</li></ol><h4 id="补充">补充</h4><p>如果被问：“那你更喜欢哪个工具？”</p><ul><li>可以说：jvisualvm 因为它图形化、集成度高、可以远程连接。</li></ul><p>如果被问：“这些工具和 Arthas、SkyWalking 有什么区别？”</p><ul><li>可以说：JDK 工具偏底层调试，而 Arthas / SkyWalking 更适合线上系统监控和诊断。</li></ul><h3 id="Java-中-hashCode-和-equals-方法是什么？它们与-操作符有什么区别？">Java 中 hashCode 和 equals 方法是什么？它们与 == 操作符有什么区别？</h3><p>在 Java 中：</p><ul><li>== 比较的是两个引用是否指向同一个对象；</li><li>equals() 用于比较对象的内容是否相等，很多类（比如 String、Integer）都重写了它；</li><li>hashCode() 用于计算对象的哈希值，在 HashMap、HashSet 等集合中定位元素。</li></ul><p>实际上，equals() 与 hashCode() 有一致性要求——如果两个对象相等，它们的哈希码必须相同，否则会导致哈希集合中无法正确识别重复元素。</p><p><strong>一句话总结</strong>：<br>== 比“是不是同一个对象”，equals 比“内容”，hashCode 用来“快速查找”。</p><h3 id="Java-中的-hashCode-和-equals-方法之间有什么关系？">Java 中的 hashCode 和 equals 方法之间有什么关系？</h3><ol><li>概念简述</li></ol><p>在 Java 中，equals() 和 hashCode() 是判断对象相等性的重要方法，<br>它们在基于哈希的数据结构（如 HashMap、HashSet）中共同决定了对象的存取行为。<br>2. 关系规则（必须背熟）<br>它们之间遵循一致性约定（Contract）：</p><ul><li>如果两个对象通过 equals() 相等，那么它们的 hashCode() 必须相等。</li><li>但如果 hashCode() 相等，equals() 不一定相等（可能是哈希冲突）。</li><li>同一个对象多次调用 hashCode()，在程序运行期间必须返回同一个值。</li></ul><p>一句话总结：equals 决定“逻辑相等”，hashCode 决定“存储位置”。</p><ol start="3"><li>为什么要重写 hashCode()</li></ol><p>如果我们只重写了 equals() 而没有重写 hashCode()，<br>那么即使两个对象在逻辑上相等，哈希集合（HashSet/HashMap）也会认为它们是两个不同对象。<br>这会导致：</p><ul><li>HashSet 出现重复数据；</li><li>HashMap 的 key 无法正确覆盖旧值；</li><li>contains()、remove() 等操作失败。</li></ul><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/biqQfeUz_image_mianshiya.png" alt="image.png" width="100%" />4. 总结一句话<ul><li>equals() 决定对象“是否相等”，</li><li>hashCode() 决定对象“放在哪”。</li></ul><p>两者必须一起重写，才能保证基于哈希的集合正确工作。</p><h4 id="面试时口语答题版">面试时口语答题版</h4><p>在 Java 中，equals() 和 hashCode() 是判断对象相等性的两个核心方法。<br>equals() 判断两个对象的内容是否相等，hashCode() 用于计算对象在哈希结构中的位置。<br>它们之间有一致性约定：如果两个对象 equals() 相等，它们的 hashCode() 必须相等，否则在 HashMap 或 HashSet 中会出现定位错误。</p><p>比如我们定义了自定义类做 HashSet 的 key，只重写 equals() 不重写 hashCode()，会导致集合中出现重复数据。<br>因此，重写 equals() 时必须同时重写 hashCode()，保证逻辑相等和哈希一致。</p><h3 id="什么是-Java-中的动态代理？">什么是 Java 中的动态代理？</h3><p>动态代理是 Java 提供的<strong>一种在运行时动态创建代理对象的机制</strong>。<br>它允许我们在不修改目标对象代码的情况下，对方法调用进行增强，比如添加日志、权限验证或事务控制。<br>Java 中主要有两种实现方式：一种是基于接口的 JDK 动态代理，另一种是基于继承的 CGLIB 动态代理。<br>JDK 代理通过 InvocationHandler 拦截方法调用；CGLIB 通过生成目标类的子类实现。<br>它的核心作用是让代码更灵活、更解耦，也是 Spring AOP 的基础。</p><p><strong>延伸</strong><br>问1：动态代理底层是怎么生成类的？<br>答：JDK 动态代理会在运行时使用 ProxyGenerator 生成 $Proxy0.class 字节码文件，然后由 ClassLoader 加载到内存中。</p><p>问2：Spring 是用哪种？<br>答：Spring AOP 优先使用 JDK 动态代理；如果目标类没有接口，则自动切换到 CGLIB。</p><h3 id="JDK-动态代理和-CGLIB-动态代理有什么区别？">JDK 动态代理和 CGLIB 动态代理有什么区别？</h3><p>JDK 动态代理是基于接口的实现，通过反射机制在运行时生成代理类，并通过 InvocationHandler 调用目标对象的方法。<br>它只能代理实现了接口的类。</p><p>CGLIB 动态代理是基于继承机制的，通过 ASM 字节码生成技术创建目标类的子类来实现代理，<br>因此可以代理没有接口的普通类，但不能代理被 final 修饰的类或方法。</p><p>在 Spring AOP 中，如果目标类实现了接口，会优先使用 JDK 动态代理，否则自动切换到 CGLIB。<br>性能上 JDK8 后两者几乎没有差别。</p><p>总结口诀</p><table><thead><tr><th>口诀</th><th>含义</th></tr></thead><tbody><tr><td>“接口用 JDK，类用 CGLIB”</td><td>代理对象类型区分</td></tr><tr><td>“继承受限 final，接口灵活无限”</td><td>限制区别</td></tr><tr><td>“JDK 反射调，CGLIB 生成类”</td><td>实现原理</td></tr><tr><td>“AOP 双轮驱动，版本无性能坑”</td><td>框架应用</td></tr></tbody></table><h3 id="Java-中的注解原理是什么？">Java 中的注解原理是什么？</h3><p>注解是 Java 提供的一种元数据机制，用于在代码中添加结构化信息。<br>它本质上是继承自 Annotation 接口的特殊接口，编译器会将注解信息写入字节码文件中。</p><p>在运行时，可以通过反射机制读取这些元数据，完成如依赖注入、配置映射等逻辑。</p><p>根据保留策略不同，注解分为编译期（SOURCE、CLASS）和运行期（RUNTIME）。<br>运行期注解是框架如 Spring、MyBatis 的核心机制。</p><p>总结口诀</p><table><thead><tr><th>口诀</th><th>含义</th></tr></thead><tbody><tr><td>“注解是标记，反射是钥匙”</td><td>反射是读取注解的关键</td></tr><tr><td>“保留到运行期，反射能识别”</td><td>只有 <code>RUNTIME</code> 才能反射读取</td></tr><tr><td>“编译做检查，运行做增强”</td><td>区分注解用途</td></tr><tr><td>“框架靠注解，灵魂是反射”</td><td>框架底层实现原理</td></tr></tbody></table><h3 id="你使用过-Java-的反射机制吗？如何应用反射？">你使用过 Java 的反射机制吗？如何应用反射？</h3><p>Java 的反射机制是指<strong>在运行时动态获取类的结构信息</strong>（包括属性、方法、构造器等），并能对对象进行<strong>动态创建、访问和修改</strong>的机制。</p><blockquote><p>它的核心类包括 Class、Method、Field、Constructor。</p></blockquote><ul><li><p>反射的最大优点是<strong>灵活性强，不需编译期确定类型</strong>，很多框架如 Spring、MyBatis、Junit 都依赖它实现依赖注入和动态代理。（<strong>框架三件套 = 反射 + 动态代理 + 注解</strong>。）</p></li><li><p>缺点是<strong>性能较低、安全性降低</strong>，但可以通过缓存 Method 对象或使用 MethodHandle 来优化性能。</p></li></ul><p><strong>小结</strong>：<br>Java 的反射机制是一种在运行时动态获取类信息并操作对象的机制，是 Spring、MyBatis 等框架的核心基础，但要注意性能与安全性问题。</p><p>补充： 反射常用操作代码示例：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// <span class="number">1.</span> 获取类对象的三种方式</span><br><span class="line"><span class="keyword">Class</span>&lt;?&gt; cls1 = <span class="keyword">Class</span>.forName(&quot;com.example.User&quot;);</span><br><span class="line"><span class="keyword">Class</span>&lt;?&gt; cls2 = <span class="keyword">User</span>.<span class="keyword">class</span>;</span><br><span class="line"><span class="keyword">Class</span>&lt;?&gt; cls3 = <span class="built_in">new</span> <span class="keyword">User</span>().getClass();</span><br><span class="line"></span><br><span class="line">// <span class="number">2.</span> 创建对象</span><br><span class="line"><span class="keyword">Object</span> obj = cls1.newInstance(); // 调用无参构造</span><br><span class="line"></span><br><span class="line">// <span class="number">3.</span> 获取并调用方法</span><br><span class="line"><span class="keyword">Method</span> <span class="keyword">method</span> = cls1.getMethod(&quot;setName&quot;, String.<span class="keyword">class</span>);</span><br><span class="line"><span class="keyword">method</span>.invoke(obj, &quot;Alice&quot;);</span><br><span class="line"></span><br><span class="line">// <span class="number">4.</span> 访问私有属性</span><br><span class="line">Field field = cls1.getDeclaredField(&quot;age&quot;);</span><br><span class="line">field.setAccessible(<span class="keyword">true</span>);  // 暴力反射</span><br><span class="line">field.<span class="keyword">set</span>(obj, <span class="number">25</span>);</span><br><span class="line"><span class="keyword">System</span>.<span class="keyword">out</span>.println(field.<span class="keyword">get</span>(obj)); // 输出 <span class="number">25</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="什么是-Java-中的不可变类？">什么是 Java 中的不可变类？</h3><p>不可变类（Immutable Class）是指对象一旦被创建，其状态（成员变量）就不能被修改的类。<br>一旦初始化完成，对象的属性在整个生命周期中都保持不变，例如 String、Integer、BigDecimal 等。<br>不可变类的核心特征：</p><table><thead><tr><th>特征</th><th>说明</th></tr></thead><tbody><tr><td>1️⃣ 类必须用 <code>final</code> 修饰</td><td>防止被继承后修改行为</td></tr><tr><td>2️⃣ 所有字段必须是 <code>private</code> 且 <code>final</code></td><td>防止外部直接修改属性</td></tr><tr><td>3️⃣ 不提供任何 setter 方法</td><td>确保状态一经初始化无法改变</td></tr><tr><td>4️⃣ 所有可变对象字段必须防御性复制</td><td>Getter 返回副本，防止外部修改原对象</td></tr><tr><td>5️⃣ 通过构造函数初始化全部属性</td><td>保证对象在创建时即处于完整状态</td></tr></tbody></table><h4 id="面试回答：">面试回答：</h4><p>不可变类是指<strong>对象在创建后，其状态就不能再被修改的类</strong>。<br>类通常被声明为 final，所有成员变量是 <strong>private final</strong>，并且<strong>没有 setter 方法</strong>。<br>如果类包含可变对象字段，需要通过防御性复制来保护内部状态不被外部修改。</p><p>不可变类的典型例子有 String、Integer、BigDecimal 等。<br>它们的优点是线程安全、可缓存、调试简单；<br>缺点是频繁修改会产生大量中间对象，浪费内存。</p><h3 id="什么是-Java-的-SPI（Service-Provider-Interface）机制？">什么是 Java 的 SPI（Service Provider Interface）机制？</h3><p>Java 的 SPI（Service Provider Interface）是一种服务发现机制，<br>用于在运行时动态加载接口的不同实现类，实现系统解耦与模块化扩展。</p><p>它的核心是通过接口定义规范，第三方在 META-INF/services 目录下注册实现类，<br>由 ServiceLoader 在运行时自动发现并加载这些类。</p><p>SPI 的典型应用是 JDBC、Dubbo、SLF4J 等。<br>优点是扩展性强、解耦好；缺点是性能较低且无法动态刷新。</p><ul><li><p>一句话总结：<br>Java SPI 是一种运行时加载第三方实现类的机制，<br>通过接口 + 配置文件 + ServiceLoader 实现解耦与可插拔扩展，<br>是 Java 框架（如 JDBC、Dubbo、Spring Boot Starter）底层的重要基础。</p></li><li><p>一句话概括了 SPI 和 API 的区别：<br>“API 是我提供接口和实现，SPI 是我提供接口，别人实现。”</p></li></ul><h3 id="Java-泛型的作用是什么？">Java 泛型的作用是什么？</h3><p>Java 泛型的作用主要有三点：<br>第一，类型安全，它可以在编译阶段检查类型，避免运行时 ClassCastException（类型转换异常）；<br>第二，代码重用，通过泛型类和泛型方法，可以让同一份代码适用于多种数据类型；<br>第三，消除显式类型转换，取出集合元素时不需要再手动强制类型转换，代码更简洁安全。</p><p>泛型只在编译期有效，编译后会进行“类型擦除/泛型擦除”，JVM 实际运行时使用的是原始类型（如 Object），所以泛型不会影响程序运行效率，只是提供编译期的安全检查。</p><h3 id="Java-泛型擦除是什么？">Java 泛型擦除是什么？</h3><h4 id="定义：">定义：</h4><p>泛型擦除（Type Erasure）是 Java 编译器在编译阶段执行的一种机制，<br>它会在生成字节码时移除所有泛型类型信息，<br>将类型参数替换为其限定类型（上界），<br>若无上界则替换为 Object，以保证运行时与非泛型代码的兼容性。</p><h4 id="作用：">作用：</h4><ul><li>保持向下兼容（与 Java 5 之前版本兼容）；</li><li>减少 JVM 的复杂性（运行时不需要泛型类型检查）；</li></ul><h4 id="影响：">影响：</h4><ul><li>运行时无法获取泛型实际类型（List<String> 和 List<Integer> 在运行时完全相同）；</li><li>无法直接创建泛型数组或进行泛型类型判断；</li><li>反射只能获取泛型声明信息，不能获取运行时真实类型。</li></ul><h3 id="什么是-Java-泛型的上下界限定符？">什么是 Java 泛型的上下界限定符？</h3><p>Java 泛型的上下界限定符用于约束泛型参数的取值范围。</p><ul><li>? extends T 表示泛型类型必须是 T 或 T 的子类，常用于“只读”场景，保证读取时类型安全。</li><li>? super T 表示泛型类型必须是 T 或 T 的父类，常用于“只写”场景，保证插入时类型安全。</li></ul><p>它们遵循 PECS 原则（Producer Extends, Consumer Super）：</p><ul><li>生产者用 extends，消费者用 super。</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="title class_">List</span>&lt;? <span class="keyword">extends</span> <span class="title class_">Number</span>&gt; list1 = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;<span class="title class_">Integer</span>&gt;(); <span class="comment">// 只能读</span></span><br><span class="line"><span class="title class_">List</span>&lt;? <span class="variable language_">super</span> <span class="title class_">Integer</span>&gt; list2 = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;<span class="title class_">Number</span>&gt;();   <span class="comment">// 只能写</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Java-中的深拷贝和浅拷贝有什么区别？">Java 中的深拷贝和浅拷贝有什么区别？</h3><p>在 Java 中，拷贝分为浅拷贝和深拷贝：</p><ul><li>浅拷贝 只复制对象的基本类型字段，对于引用类型字段只复制引用地址，新旧对象共享同一堆内实例，因此修改一个对象会影响另一个。</li><li>深拷贝 不仅复制对象本身，还会递归复制其引用对象，两个对象完全独立，互不影响。</li></ul><p>Java 默认的 clone() 方法是浅拷贝，如需深拷贝可通过手动实现 clone()、对象序列化或工具类来完成。</p><p>用一个例子可以更好的理解-身份证复印件 vs 克隆人 ：</p><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td><strong>浅拷贝</strong></td><td>复印了身份证。看起来信息一样（名字、地址相同），但你拿复印件去办事，所有操作其实都还是对“原人”生效。</td></tr><tr><td><strong>深拷贝</strong></td><td>造了一个“克隆人”，这个人和你一模一样（数据完全复制），但独立存在。他改发型、搬家都不会影响你。</td></tr></tbody></table><p>浅拷贝：两个人共用一个脑袋。<br>深拷贝：每个人有自己的脑袋。</p><h3 id="什么是-Java-的-Integer-缓存池？">什么是 Java 的 Integer 缓存池？</h3><p>Java 的 Integer 缓存池是为了节省内存和提升性能而设计的。<br>在 -128 ~ 127 范围内的 Integer 对象会被缓存并复用，<br>当自动装箱或调用 Integer.valueOf() 时，若值在此范围内，会直接返回缓存对象，而不是新建。<br>若使用 new Integer() 或超出该范围，则会创建新对象。<br>缓存池通过静态内部类 IntegerCache 实现，范围可通过 JVM 参数调整。</p><p>补充：<br>面试陷阱题</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Integer a <span class="operator">=</span> <span class="number">127</span><span class="comment">;</span></span><br><span class="line">Integer b <span class="operator">=</span> <span class="number">127</span><span class="comment">;</span></span><br><span class="line">Integer c <span class="operator">=</span> <span class="number">128</span><span class="comment">;</span></span><br><span class="line">Integer d <span class="operator">=</span> <span class="number">128</span><span class="comment">;</span></span><br><span class="line"></span><br><span class="line">System.out.println(a <span class="operator">=</span><span class="operator">=</span> b)<span class="comment">; // ✅ true</span></span><br><span class="line">System.out.println(c <span class="operator">=</span><span class="operator">=</span> d)<span class="comment">; // ❌ false</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>原因：</p><ul><li>127 在缓存范围内 → a、b 引用同一对象</li><li>128 超出缓存范围 → c、d 各自新建对象</li></ul><h3 id="Java-的类加载过程是怎样的？">Java 的类加载过程是怎样的？</h3><p>Java 类加载分为三个主要阶段：加载、链接和初始化。<br>其中“链接”又分为 验证、准备、解析 三个子阶段。</p><ul><li>加载阶段：把类字节码加载进内存，生成 Class 对象；</li><li>验证阶段：确保字节码符合 JVM 规范；</li><li>准备阶段：为静态变量分配内存并赋默认值；</li><li>解析阶段：把符号引用替换为直接引用；</li><li>初始化阶段：执行静态变量赋值与静态代码块逻辑。</li></ul><p>最终类就可以被 JVM 使用。</p><p>总结口诀（方便背诵）<br>加载 → 验证 → 准备 → 解析 → 初始化<br>简称：“<strong>加 验 准 解 初</strong>”</p><p>口诀记法：</p><p>加载类进内存，验证格式真；<br>准备分配值，解析换引用；<br>初始化执行码，一切都齐全。</p><h3 id="什么是-Java-的-BigDecimal？">什么是 Java 的 BigDecimal？</h3><p>BigDecimal 是 Java 提供的用于高精度小数计算的类，属于 java.math 包。<br>它能避免 float 和 double 的精度误差，常用于金融、结算等高精度场景。<br>BigDecimal 是不可变类，每次运算都会生成新的对象，提供加减乘除、比较、取整等方法，<br>并支持多种舍入模式（如四舍五入 HALF_UP）。<br>建议使用字符串构造方法以避免精度丢失。</p><h3 id="BigDecimal-为什么能保证精度不丢失">BigDecimal 为什么能保证精度不丢失?</h3><p>BigDecimal 之所以能保证精度不丢失，是因为它采用了 任意精度的<strong>整数表示法</strong>，<br>BigDecimal 通过将数值部分（intVal）和小数位数（scale）<strong>分开存储</strong>，<br>在计算时进行整数运算，最后通过 scale 调整小数点位置，避免了二进制浮点表示导致的精度丢失。</p><h3 id="使用-new-String-“abc”-语句在-Java-中会创建多少个对象？">使用 new String(“abc”) 语句在 Java 中会创建多少个对象？</h3><p>答：其实啊，new String(“abc”) 这句代码最多会创建两个对象，最少创建一个对象。<br>我这么解释你就懂了：<br>首先，Java 里有个字符串常量池（String Pool），JVM 在看到 “abc” 这个字面量的时候，会先去常量池里看看有没有 “abc” 这个字符串。</p><ul><li>如果已经有了，那就直接用，不再创建；</li><li>如果还没有，那 JVM 就会在常量池里先放一个 “abc”。</li></ul><p>接着呢，new String(“abc”) 这个操作，<br>一定会在<strong>堆内存</strong>（Heap)里再创建一个新的对象，这个新对象的内容就是拷贝常量池里的 “abc”。</p><p>所以最后的情况是：</p><ul><li>如果 “abc” 在常量池里早就存在了 → 只在堆中创建 1 个对象；</li><li>如果 “abc” 在常量池里是第一次出现 → 会创建 2 个对象（常量池 1 个 + 堆里 1 个）。</li></ul><p><strong>一句话总结</strong>：<br>new String(“abc”) 至少创建一个对象，最多两个。<br>常量池管字面量，堆内存管 new 出来的对象。</p><h3 id="Java-中-final、finally-和-finalize-各有什么区别？">Java 中 final、finally 和 finalize 各有什么区别？</h3><p>final -&gt;修饰符（防修改）：final 可以修饰类、方法、变量，意思是“不能再改了”。<br>finally -&gt;异常处理语句块（保证执行）:finally 一定会和 try-catch 一起出现，无论是否发生异常，finally 块里的代码都会执行。<br>finalize()  -&gt; 对象回收前的“遗言方法”（已过时):finalize() 是 Object 类的一个方法，当垃圾回收器（GC）准备回收对象时，会调用它来让对象“临终清理”。(不推荐使用，因为 JVM 不保证它什么时候执行，甚至可能根本不执行。)</p><h3 id="为什么在-Java-中编写代码时会遇到乱码问题？">为什么在 Java 中编写代码时会遇到乱码问题？</h3><p>其实 Java 出现乱码，最根本的原因就是——<strong>编码和解码方式不一致</strong>。</p><p>比如写文件的时候用 UTF-8，但读的时候用 GBK，那 JVM 就会把字节解释错，原本的中文就变成了乱码。</p><p>常见的情况有三种：</p><ol><li>默认编码不同（Windows 是 GBK，Linux 是 UTF-8）；</li><li>文件流读写没指定编码；</li><li>数据库字符集不统一。</li></ol><p>只要统一用 UTF-8 就行，编码、解码、数据库都保持一致就不会乱。</p><h3 id="为什么-JDK-9-中将-String-的-char-数组改为-byte-数组？">为什么 JDK 9 中将 String 的 char 数组改为 byte 数组？</h3><p>JDK 9 把 String 的底层从 char[] 换成了 byte[]</p><ul><li>因为char数组，每个字符占用2个字节，但实际上，大量字符串（比如英文、数字、符号）只需要 1 个字节。这就造成空间浪费。</li><li>改用了byte数组后，通过一个 coder 字段来标记编码方式（0 → LATIN1（单字节），1 → UTF-16（双字节）），JVM 会根据字符串内容自动选择合适的编码。</li></ul><p>这样英文只占 1 字节，中文用 2 字节，不但省了一半内存，还提升了性能</p><h3 id="如果一个线程在-Java-中被两次调用-start-方法，会发生什么？">如果一个线程在 Java 中被两次调用 start() 方法，会发生什么？</h3><ul><li>一个线程在 Java 中只能启动一次。调用 start() 后，线程状态会从“新建”（NEW）变成“就绪”(RUNNABLE)，再由 JVM 调度执行。</li><li>如果再次调用 start()，线程已经不是新建状态了，JVM 就会抛出IllegalThreadStateException，因为线程生命周期是单向的，不能重复启动。</li></ul><h3 id="栈和队列在-Java-中的区别是什么？">栈和队列在 Java 中的区别是什么？</h3><p>栈和队列的主要区别在于数据的进出顺序。<br>栈是后进先出（LIFO），像叠盘子，最后放上去的先拿走；<br>队列是先进先出（FIFO），像排队买票，先来的人先走。</p><p>在 Java 里，Stack 类实现了栈结构，现在更推荐用 Deque。<br>队列则由 Queue 接口实现，比如 LinkedList、PriorityQueue。</p><p>栈常用于函数调用、递归、表达式求值；<br>队列常用于任务调度、消息队列或广度优先搜索（BFS）。</p><table><thead><tr><th>数据结构</th><th>特点</th><th>常见场景</th></tr></thead><tbody><tr><td>栈（Stack）</td><td>后进先出 LIFO</td><td>函数调用栈、表达式求值、括号匹配、深度优先搜索（DFS）</td></tr><tr><td>队列（Queue）</td><td>先进先出 FIFO</td><td>任务调度、消息队列、数据流处理、广度优先搜索（BFS）</td></tr></tbody></table><h3 id="Java-的-Optional-类是什么？它有什么用？">Java 的 Optional 类是什么？它有什么用？</h3><p>Optional 是 Java 8 引入的一个容器类，用来表示一个可能为空的值。<br>它的主要作用是防止空指针异常，通过像 isPresent()、orElse()、ifPresent() 这样的 API，<br>让我们不用到处写 if (obj != null)，代码更清晰、更安全。</p><p>你可以理解成它是一个“带状态的盒子”，<br>盒子里可能有值，也可能是空的，但我们不用再直接碰 null。</p><h3 id="Java-的-I-O-流是什么？">Java 的 I/O 流是什么？</h3><p>Java 的 I/O 流其实就是用来读写数据的“通道”，<br>程序可以通过它从文件、网络等地方读取数据，或者把数据输出到文件、控制台。</p><p>它分为两大类：</p><ul><li>字节流（InputStream / OutputStream），处理二进制数据；</li><li>字符流（Reader / Writer），处理文本数据。</li></ul><p>举个例子：读图片就用字节流，读写文本就用字符流。<br>这样设计是为了让程序更灵活、更高效地操作不同类型的数据。</p><h3 id="Java-中的基本数据类型有哪些？">Java 中的基本数据类型有哪些？</h3><p>Java 一共有 8 种基本数据类型，用来存放最基础的数据，<br>它们不属于对象类型，也不存放在堆里，而是在栈中。</p><p>整数类型有 4 个：byte、short、int、long；<br>浮点类型 2 个：float、double；<br>字符类型是 char；<br>布尔类型是 boolean。</p><p>这些类型的设计是为了性能更高，不需要对象包装。</p><h3 id="什么是-Java-中的自动装箱和拆箱？">什么是 Java 中的自动装箱和拆箱？</h3><p>自动装箱和拆箱是 Java 编译器帮我们做的类型转换。<br>比如，当我们把 int 放进 List<Integer> 时，会自动变成 Integer —— 这就是装箱；<br>当我们从 List 取出来再参与运算时，它又会自动变回 int —— 这就是拆箱。</p><p>它是在 Java 5 引入的，主要是为了让代码更简洁。<br>底层其实就是调用 valueOf() 和 xxxValue() 方法。</p><p>不过要注意两点：<br>一是频繁装拆箱会影响性能，二是拆箱时如果是 null 会直接抛 NullPointerException。</p><h3 id="什么是-Java-中的迭代器（Iterator）？">什么是 Java 中的迭代器（Iterator）？</h3><h4 id="Iterator-是什么？">Iterator 是什么？</h4><p>Iterator 是 Java 集合框架中的一个接口，用于顺序遍历集合中的元素。<br>它提供了一种统一访问集合元素的方式，开发者不需要关心集合的底层实现。<br>常与 Collection 接口及其子类（如 List、Set）配合使用。</p><h4 id="核心方法">核心方法</h4><ul><li>boolean hasNext()：判断集合中是否还有下一个元素；</li><li>E next()：返回下一个元素，若没有则抛出 NoSuchElementException；</li><li>void remove()：删除最近一次通过 next() 返回的元素，仅在调用 next() 之后使用，否则抛出 IllegalStateException。</li></ul><h4 id="主要作用">主要作用</h4><ul><li>提供统一、简洁、安全的遍历方式，避免直接使用索引；</li><li>支持在遍历过程中删除元素；</li><li>for-each 语法实际上是基于 Iterator 实现的语法糖。</li></ul><h3 id="Java-运行时异常和编译时异常之间的区别是什么？">Java 运行时异常和编译时异常之间的区别是什么？</h3><p>Java 的异常分两类：编译时异常和运行时异常。<br>举例：</p><ul><li>编译时异常-&gt;FileNotFoundException、IOException</li><li>运行时异常-&gt;算数异常 (ArithmeticException)、空指针异常 (NullPointerException)、数组越界 (ArrayIndexOutOfBoundsException)</li></ul><p>二者的区别：</p><ul><li>编译时异常在编译阶段就会被检查，比如文件读写错误，必须用 try-catch 或 throws 处理，否则编译不过；</li><li>而运行时异常是程序运行时才抛出的，比如空指针或数组越界，编译器不会强制你处理。</li></ul><p>设计上是因为编译时异常多来自外部环境，而运行时异常多是代码逻辑错误。</p><h3 id="什么是-Java-中的继承机制？">什么是 Java 中的继承机制？</h3><p>Java 的继承是面向对象的三大特性之一，<br>它允许子类通过 extends 关键字继承父类的属性和方法，从而实现代码复用和功能扩展。<br>Java 只支持单继承，但支持接口的多继承。<br>优点是结构清晰、便于维护，缺点是耦合性高、灵活性差。</p><h3 id="什么是-Java-的封装特性？">什么是 Java 的封装特性？</h3><p>封装就是把对象的属性和方法包装在类里面，对外只提供访问接口，比如通过 getter/setter 控制访问权限。<br>这样做可以隐藏内部实现细节，保护数据安全，也让代码更容易维护和扩展。</p><h3 id="Java-中的访问修饰符有哪些？">Java 中的访问修饰符有哪些？</h3><p>Java 有四种访问修饰符：public、protected、default、private。<br>它们控制类和成员的访问范围。<br>private 最严格，只能在当前类访问；default 是包级访问；<br>protected 可以被同包或不同包的子类访问；public 最开放，任何地方都能访问。<br>代码示例：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">String</span> name;       <span class="comment">// 所有人可访问</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="type">int</span> age;        <span class="comment">// 同包或子类可访问</span></span><br><span class="line">    <span class="type">String</span> gender;            <span class="comment">// 默认访问，同包可访问</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> idCard;    <span class="comment">// 仅类内可访问</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Java-中静态方法和实例方法的区别是什么？">Java 中静态方法和实例方法的区别是什么？</h3><ul><li>静态方法用 static 定义，属于类本身，不需要创建对象就能调用，只能访问静态成员，常用于工具类或工厂方法。</li><li>实例方法属于对象，必须通过对象调用，可以访问类中所有成员，常用于操作对象属性或实现对象行为。</li></ul><p>总结一句话：<br>静态方法属于类，实例方法属于对象；<br>静态方法不依赖对象，只能访问静态成员；<br>实例方法依赖对象，可以访问一切成员。</p><h3 id="Java-中-for-循环与-foreach-循环的区别是什么？">Java 中 for 循环与 foreach 循环的区别是什么？</h3><p>for 循环比较灵活，可以通过索引访问、修改、删除元素，适合需要<strong>控制循环逻辑</strong>的场景；<br>foreach 是语法糖，用起来更简洁，但不能访问索引，也不能在遍历时修改集合内容，否则会报错。</p><p>总结一句话：<br>for 灵活、能控制；foreach 简洁、安全但不能改。</p><h3 id="什么是-Java-中的双亲委派模型？">什么是 Java 中的双亲委派模型？</h3><h3 id="什么是双亲委派机制？">什么是双亲委派机制？</h3><p>Java 的双亲委派机制是类加载的一种设计模式。<br>当类加载器收到加载请求时，它不会自己立刻加载，而是把请求交给父加载器，一层层向上委派，直到 Bootstrap 尝试加载。<br>如果上层加载器都加载不了，才由当前加载器执行加载。<br>这样做可以<strong>防止同一个类被重复加载</strong>，同时<strong>保证核心类的安全性</strong>，比如 java.lang.Object 永远由启动类加载器加载。</p><ul><li>一句话记忆：先找爸爸，爸爸找不到我再上！</li></ul><h4 id="工作流程">工作流程:</h4><p>1️ 当前类加载器接收到一个类加载请求；<br>2️ 它不会立刻加载，而是将请求交给父类加载器；<br>3️ 父类加载器再交给更上层的父类加载器；<br>4️ 一直到最顶层的 Bootstrap ClassLoader（启动类加载器）；<br>5️ 如果父加载器都无法完成加载，才由当前加载器执行加载。<br>即：<strong>自下而上委派，自上而下加载</strong></p><h4 id="三种主要类加载器"><strong>三种主要类加载器</strong></h4><table><thead><tr><th>类加载器</th><th>实现方式</th><th>加载内容</th><th>加载路径</th></tr></thead><tbody><tr><td><strong>Bootstrap ClassLoader</strong></td><td>C++ 实现（JVM 内部）</td><td>JRE 核心类库</td><td><code>&lt;JAVA_HOME&gt;/lib</code></td></tr><tr><td><strong>Extension ClassLoader</strong></td><td>Java 实现</td><td>扩展类库</td><td><code>&lt;JAVA_HOME&gt;/lib/ext</code></td></tr><tr><td><strong>Application ClassLoader</strong></td><td>Java 实现</td><td>用户类（classpath）</td><td><code>classpath</code> 路径</td></tr></tbody></table><pre><code>                    启动类加载器（Bootstrap ClassLoader）                            ↑                    扩展类加载器（ExtClassLoader）                            ↑                    应用类加载器（AppClassLoader）</code></pre><p>一般加载顺序是：应用类加载器 → 扩展类加载器 → 启动类加载器<br>子类 → 父类 → Bootstrap → 父类返回 → 子类加载</p><h4 id="设计目的">设计目的</h4><p>“为什么要设计双亲委派机制？”<br>1️ 防止类被重复加载<br>→ 同一个类只会被一个加载器加载，避免内存中出现多个副本。</p><p>2️ 保证核心类安全<br>→ 比如 java.lang.Object 永远由 Bootstrap 加载，<br>即使用户自定义同名类也不会被替代。</p><p>3️ 实现类隔离<br>→ 不同类加载器加载的类互相独立，互不干扰，方便模块化和沙箱机制。</p><h4 id="破坏双亲委派的场景">破坏双亲委派的场景</h4><p>实际开发中，有些框架“故意”打破双亲委派。</p><table><thead><tr><th>场景</th><th>说明</th></tr></thead><tbody><tr><td><strong>SPI 机制（Service Provider Interface）</strong></td><td>典型如 JDBC 的 <code>DriverManager</code>，需要由子加载器加载厂商实现类。</td></tr><tr><td><strong>Web 容器热加载机制（热部署）</strong></td><td>如 Tomcat / Spring Boot，为实现模块热替换，需要自定义类加载器。</td></tr><tr><td><strong>插件化框架</strong></td><td>比如 OSGi、Dubbo 插件系统，为实现模块隔离也会自定义加载逻辑。</td></tr></tbody></table><h4 id="面试简答">面试简答</h4><p>双亲委派机制是 Java 类加载器的一种设计模式。<br>当类加载器加载类时，不会自己先去加载，而是把请求交给父类加载器，<br>父类加载器再向上委派，直到最顶层的 Bootstrap ClassLoader。<br>如果父类无法加载，才由当前加载器执行加载。<br>这样可以避免类重复加载、保证核心类安全、实现类加载隔离。<br>常见的类加载器包括 Bootstrap、Extension 和 Application 三种。<br>在 SPI 或 Tomcat 热加载中，出于扩展性考虑会打破这一机制。</p><h3 id="Java-中-wait-和-sleep-的区别？">Java 中 wait() 和 sleep() 的区别？</h3><p>在 Java 中，wait() 和 sleep() 都能让线程暂停，但它们的作用和机制不同。</p><ul><li>wait() 属于 Object 类，必须在同步块中使用，会释放锁，通常配合 notify() 或 notifyAll() 实现线程通信。</li><li>sleep() 属于 Thread 类，不需要同步块，不会释放锁，只是让线程休眠指定时间后自动恢复。<br>简单来说：wait 用于线程通信，sleep 用于线程延时；wait 放锁，sleep 不放锁。</li></ul><h3 id="Java-Object-类中有什么方法，有什么作用？">Java Object 类中有什么方法，有什么作用？</h3><p>Java 的 Object 类是所有类的父类，它定义了一组通用方法，<br>主要包括对象比较（equals、hashCode）、对象拷贝（clone）、<br>对象字符串表示（toString）、反射（getClass）、<br>多线程协调（wait、notify、notifyAll）以及垃圾回收钩子（finalize）。<br>这些方法几乎构成了所有 Java 对象的基本行为。</p><h3 id="Java-中的字节码是什么？">Java 中的字节码是什么？</h3><ul><li>Java 字节码（Bytecode）是 Java 编译器将 .java 源文件编译后生成的中间表示形式，<strong>它位于 Java 源代码与 JVM 执行的机器码之间。</strong></li><li>存储在 .class 文件中。</li><li>它是平台无关的指令集，由JVM 解释器或 JIT 编译器将其翻译为机器码运行。</li><li>字节码是 Java 实现 “一次编译，到处运行” 的核心机制。</li></ul><h3 id="什么是-BIO、NIO、AIO？">什么是 BIO、NIO、AIO？</h3><p>在 Java 中：</p><ul><li>BIO（Blocking I/O）：是传统的同步阻塞模型，一个请求一个线程，调用方在 I/O 操作完成前会一直被阻塞。适合连接数少、逻辑简单的场景。</li><li>NIO（Non-blocking I/O）：是同步非阻塞模型，I/O 操作立即返回，通过轮询（Selector）检查状态，一个线程可处理多个连接，提高并发性能。</li><li>AIO（Asynchronous I/O）：是异步非阻塞模型，I/O 请求发出后由操作系统完成，完成后通过回调或事件通知应用层。适用于高并发高响应场景。</li></ul><p>🔹 用比喻：<br>BIO 是“自己一直盯着水烧开”；<br>NIO 是“自己时不时来看看水开没”；<br>AIO 是“请别人帮忙看，水开了他会通知你”。</p><h3 id="什么是-Channel？">什么是 Channel？</h3><p>在 Java NIO 中，Channel 是一个<strong>数据通道</strong>（Data Channel）， 用于在程序与 I/O 设备（文件、网络套接字等）之间进行数据的读写。 与传统的 I/O 流不同，Channel 是<strong>双向的、可读可写</strong>，并且支持<strong>非阻塞模式</strong>。</p><p>它通常与 Buffer 和 Selector 配合使用：</p><ul><li>Buffer 用于临时存储数据；</li><li>Selector 用于实现多路复用，从而用一个线程同时处理多个连接。</li></ul><p>常见的实现类包括：</p><ul><li>FileChannel（文件 I/O）</li><li>SocketChannel（TCP 客户端）</li><li>ServerSocketChannel（TCP 服务端）</li><li>DatagramChannel（UDP 通信）</li></ul><p>一句话总结：</p><p>Channel 就是 NIO 的“管道”，负责在程序与外部资源之间传输数据，是高效非阻塞 I/O 的核心。</p><h3 id="什么是-Selector？">什么是 Selector？</h3><p>Selector 是 Java NIO（New I/O） 中用于实现 <strong>I/O 多路复用</strong>（Multiplexing） 的核心组件。<br>它允许一个线程同时监听多个 Channel（通道）上的事件（如可读、可写、连接就绪等），<br>从而实现一个线程管理多个网络连接，大幅减少线程开销，提高系统并发性能。</p><p>工作原理：<br>Channel 向 Selector 注册感兴趣的事件（如 OP_READ、OP_WRITE 等），<br>Selector 通过 select() 方法检测哪些 Channel 就绪，然后再由程序去处理这些就绪事件。</p><p>类比理解<br>可以把 Selector 理解成一个“<strong>监控中心</strong>”：<br>它不停地查看哪些连接（Channel）有事要处理（比如有数据可读、有新连接等），<br>然后把这些“有事的连接”交给程序去处理。</p><p>所以 Selector 的核心优势就是——<strong>一个线程就能看管成百上千个连接</strong>，<br>不再像传统 BIO 一样一个连接就要一个线程。</p><h3 id="Float-经过一系列的操作后-加减乘除-，如何判断是否和另一个数相等呢？">Float 经过一系列的操作后(加减乘除)，如何判断是否和另一个数相等呢？</h3><p>在 Java 中，浮点数（float、double）不能直接用 == 比较是否相等，<br>因为二进制浮点数无法精确表示所有十进制小数，会产生精度误差。</p><p>常见解决方案有三种：</p><p>1.容差比较法：<br>Math.abs(a - b) &lt; epsilon，通过设置精度范围判断是否相等。</p><p>2.使用 BigDecimal：<br>用于高精度计算场景（如金融），比较时用 compareTo() 而不是 equals()。</p><p>3.整数化处理：<br>若业务允许（如金额以“分”为单位），可转为整数后再比较。</p><p>一句话总结：<br>不能直接用 == 比较浮点数，推荐使用“误差范围法”或 BigDecimal.compareTo()。</p><h3 id="PO、VO、BO、DTO、DAO、POJO-有什么区别？">PO、VO、BO、DTO、DAO、POJO 有什么区别？</h3><h4 id="PO、VO、BO、DTO、DAO、POJO-到底怎么区分？">PO、VO、BO、DTO、DAO、POJO 到底怎么区分？</h4><p>让我一句话概括它们：</p><blockquote><p><strong>PO 放数据库、VO 给前端看、DTO 用来传数据、BO 干业务逻辑、DAO 操作数据库、POJO 是最普通的 Java 类。</strong><br>——简单记：<strong>存储→PO、展示→VO、传输→DTO、业务→BO、访问数据库→DAO</strong></p></blockquote><h4 id="①-PO（持久化对象）——和数据库最贴近的对象">① PO（持久化对象）——和数据库最贴近的对象</h4><p><strong>PO 就是和数据库表一一对应的类。字段基本等于表字段。</strong></p><ul><li>主要目的是“读库/写库”</li><li>字段一般不会删减（不展示也得存）</li><li>不会加展示用字段（如 createTimeStr）</li></ul><p><strong>什么时候用？</strong><br>Service / Mapper 在与数据库交互时，取出来的就是 PO；最终转成其它对象再返回。</p><h4 id="②-VO（视图对象）——返回给前端-页面用的">② VO（视图对象）——返回给前端/页面用的</h4><p>你可以把 VO 理解为：</p><blockquote><p><strong>“为了让前端更好用而设计的对象”</strong></p></blockquote><ul><li>字段是展示友好的（如格式化时间、状态文案）</li><li>可以组合多个来源的数据</li><li>不带数据库字段，不暴露敏感信息</li></ul><p>项目里的 VO 例子</p><ul><li><code>ResponseVO</code>：统一响应结构</li><li><code>PaginationResultVO</code>：分页数据包装</li><li>有时会自定义业务 VO，例如组合多个来源的展示字段</li></ul><p>也就是说：<br><strong>Controller 返回值永远是 VO 或分页 VO，不直接给前端 PO。</strong></p><h4 id="③-DTO（数据传输对象）——用来传输数据的“契约”">③ DTO（数据传输对象）——用来传输数据的“契约”</h4><p>DTO 的核心点是：</p><blockquote><p><strong>”我不是给前端看的，也不是用来存数据库的，我就是用来传数据的。”</strong></p></blockquote><ul><li>可能作为 Controller 的入参（CreateDTO/UpdateDTO）</li><li>也可能作为 Service 之间的传输载体</li><li>字段按业务含义组织，不按展示/数据库组织</li></ul><p>项目中 的 DTO 例子</p><ul><li><code>TokenUserInfoDto</code>：用户登录态，会发到 Redis</li><li><code>UserCountInfoDto</code>：统计粉丝数/点赞数</li><li><code>VideoInfoEsDto</code>：搜索时传给 ES</li><li><code>VideoPlayInfoDto</code>：跨层使用的数据结构</li></ul><p>也就是说：<br><strong>DTO 是中立的数据模型，既不是前端展示，也不绑定表结构。</strong></p><h4 id="④-BO（业务对象）——处理业务逻辑用的">④ BO（业务对象）——处理业务逻辑用的</h4><p>BO 属于业务域内的模型：</p><ul><li>用来封装业务逻辑（如“订单结算结果”“视频发布结果”）</li><li>可以包含多个 PO/DTO/外部数据的组合</li><li>业务层专用，不对外暴露</li></ul><p>很多项目不显式写 BO，但概念上它就是“业务处理阶段的对象”。</p><h4 id="⑤-DAO（数据访问对象）——操作数据库">⑤ DAO（数据访问对象）——操作数据库</h4><p>DAO 就是：</p><ul><li>提供 <code>save/get/update/delete</code> 的接口</li><li>Service 层不会直接操作数据库，而是调 DAO</li></ul><p>在 MyBatis/Spring 项目里你看到的：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UserMapper.<span class="keyword">java</span></span><br><span class="line"><span class="keyword"></span>VideoInfoMapper.<span class="keyword">java</span></span><br></pre></td></tr></table></figure><p>其实就是 DAO，只不过现在大家叫 Mapper。</p><h4 id="⑥-POJO（普通-Java-对象）——最基础的类">⑥ POJO（普通 Java 对象）——最基础的类</h4><p>POJO 不是一个“职责角色”，只是指：</p><ul><li>最普通的 Java 类</li><li>没继承、没实现特殊接口</li></ul><p><strong>PO/VO/DTO/BO 这些其实都是 POJO 的“变种”。</strong></p><h4 id="把它们串起来">把它们串起来</h4><blockquote><p>在我们后端分层里，几个对象的职责非常明确：<br><strong>PO 是和数据库表对应的，用来持久化存储；<br>DTO 是输入输出的契约，是服务之间或前后端之间的数据载体；<br>VO 是返回给前端展示的对象，会做格式化/文案等处理；<br>BO 是业务处理阶段的对象，可以组合多个来源的数据；<br>DAO/Mapper 则负责具体的数据库 CRUD。<br>而它们本质上都是 POJO，只是职责不同。</strong></p></blockquote><h4 id="结合你的-项目-来讲">结合你的 <strong>项目</strong> 来讲</h4><p>你可以这样讲（非常推荐）：</p><blockquote><p>在我的 项目里，这些对象分得更明确：</p><ul><li><strong>VO</strong>：比如 <code>ResponseVO</code>、<code>PaginationResultVO</code>，都是返回给前端的展示类；有些接口会拼组多个来源的数据再封装成自定义 VO。</li><li><strong>DTO</strong>：比如 <code>TokenUserInfoDto</code>、<code>VideoInfoEsDto</code>，用于服务之间、缓存、搜索层的传输，不会直接暴露给前端。</li><li><strong>Query 对象</strong>：像 <code>VideoInfoPostQuery</code>、<code>UserInfoQuery</code>，用于分页/条件查询，是输入专用。</li><li><strong>PO</strong>：例如 <code>UserInfo</code> 这种实体类，只负责映射数据库，不直接返回给前端。</li></ul><p>因为分层清晰，所以 Controller 只处理 DTO/Query，Service 处理 PO 和业务逻辑，最终用 VO 返回前端，整个系统观察性和扩展性都很好。 </p></blockquote><h4 id="面试官最爱的问题：">面试官最爱的问题：</h4><p><strong>为什么要搞这么多对象？不能用一个对象走天下吗？</strong></p><blockquote><p>不能，因为不同阶段关心点不一样：</p><ul><li><strong>PO</strong>：字段多、和数据库强绑定，不适合暴露</li><li><strong>VO</strong>：展示字段往往需要组合/格式化</li><li><strong>DTO</strong>：输入输出的契约要稳定、可校验</li><li><strong>BO</strong>：业务逻辑可能需要多个数据源的组合</li></ul><p>如果混在一起，就会出现“数据丢了没人发现、数据库字段改动导致前端挂掉”等问题，项目越大越混乱。<br>分成多个对象其实是“职责隔离”，保证系统稳定可维护。</p></blockquote><h2 id="Java-集合面试题">Java 集合面试题</h2><h3 id="Java-中有哪些集合类？请简单介绍">Java 中有哪些集合类？请简单介绍</h3><p>Java 集合主要分为两大体系：</p><ul><li><p>Collection单列集合（存单值）包括：</p><ul><li><p>List（有序可重复，如 ArrayList、LinkedList）</p></li><li><p>Set（无序不重复，如 HashSet、TreeSet）</p></li><li><p>Queue（队列，如 PriorityQueue）</p></li></ul></li><li><p>Map双列集合（键值对存储）包括：</p><ul><li>HashMap、LinkedHashMap、TreeMap、Hashtable。</li></ul></li></ul><p>各集合底层一般是数组、链表、哈希表或红黑树，根据应用场景选择即可。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/1MBvCVsp_image_mianshiya.png" alt="image.png" width="100%" /><h3 id="数组和链表在-Java-中的区别是什么？">数组和链表在 Java 中的区别是什么？</h3><p>数组和链表的主要区别在于<strong>存储方式</strong>、<strong>访问效率</strong>、<strong>插入删除性能</strong>和<strong>空间利用率</strong>。</p><ul><li>数组在内存中是<strong>连续存储</strong>的，支持 O(1) 时间的随机访问，但插入删除需要移动元素，效率较低。</li><li>链表在内存中是<strong>非连续存储</strong>的，每个节点包含数据和指针，插入删除效率高 O(1)，但访问需要遍历 O(n)。</li><li>数组空间利用率高，但扩容麻烦；链表空间开销大，但结构灵活。</li></ul><p>适用场景：</p><ul><li>数组适合数据量固定、频繁访问的场景；</li><li>链表适合数据量不固定、频繁插入删除的场景。</li></ul><p>一句话总结：</p><p>“数组快在访问，慢在插删；链表快在插删，慢在访问。”</p><h3 id="Java-中的-List-接口有哪些实现类？">Java 中的 List 接口有哪些实现类？</h3><p>Java 中常见的 List 实现类有：<strong>ArrayList、LinkedList、Vector、Stack</strong> 和 <strong>CopyOnWriteArrayList</strong>。</p><ul><li><strong>ArrayList</strong>：基于动态数组实现，随机访问快，插入删除慢，线程不安全。</li><li><strong>LinkedList</strong>：基于双向链表实现，插入删除快，随机访问慢，也不是线程安全的。</li><li><strong>Vector</strong>：早期线程安全版本的 ArrayList，方法同步，性能较低。</li><li><strong>Stack</strong>：继承自 Vector，实现了先进后出（LIFO）的栈结构。</li><li><strong>CopyOnWriteArrayList</strong>：线程安全，读操作无锁，写操作会复制一份新数组，适合读多写少的并发场景。</li></ul><p>一句话总结：<br>“ArrayList 访问快，LinkedList 增删快，Vector 是同步老版本，CopyOnWriteArrayList 适合并发读多写少。”</p><h3 id="Java-中-ArrayList-和-LinkedList-有什么区别？">Java 中 ArrayList 和 LinkedList 有什么区别？</h3><p>ArrayList 和 LinkedList 都实现了 List 接口，区别主要在底层结构和性能上：</p><ul><li>ArrayList 基于<strong>动态数组</strong>实现，内存连续，随机访问快（O(1)），但插入删除慢（O(n)），适合读多写少场景；</li><li>LinkedList 基<strong>于双向链表</strong>实现，内存不连续，插入删除快（O(1)），访问慢（O(n)），适合频繁插删的场景；</li><li>二者都<strong>线程不安全</strong>，如需线程安全可用 CopyOnWriteArrayList。</li></ul><p>一句话总结：<br>“ArrayList 快在访问，慢在增删；LinkedList 快在增删，慢在访问。”</p><h3 id="Java-ArrayList-的扩容机制是什么？">Java ArrayList 的扩容机制是什么？</h3><p>在 Java 中，ArrayList 是基于<strong>动态数组</strong>实现的。<br>当元素数量超过当前数组的容量时，就会<strong>触发扩容机制</strong>。</p><p>默认情况下，ArrayList 的<strong>初始容量是 10</strong>。当发生扩容时，会创建一个<strong>新的数组</strong>，容量大约是旧容量的** 1.5 倍**，也就是通过 oldCapacity + (oldCapacity &gt;&gt; 1) 这个计算式来得到的。</p><p>然后，会把原来数组中的元素通过 Arrays.copyOf() 方法复制到新数组里。</p><p>扩容的过程是比较<strong>耗时</strong>的，因为涉及到<strong>内存分配和数据复制</strong>，<br>所以如果能<strong>提前指定容量</strong>，性能会更好。</p><p><strong>此外，ArrayList 没有负载因子（loadFactor），这是和 HashMap 不同的地方</strong>。</p><p>另外在 JDK 1.7 和 1.8 版本之间有个小区别：</p><ul><li>在 JDK 1.7 中，调用无参构造方法时会直接创建一个长度为 10 的数组；</li><li>而在 JDK 1.8 中，采用了懒加载机制，只有在第一次调用 add() 方法时才真正分配空间。</li></ul><p>一句话总结：<br>“ArrayList 的扩容机制就是——当容量不够时，自动按 1.5 倍增长，并复制旧数据到新数组中。”</p><h4 id="面试回答：-2">面试回答：</h4><p>ArrayList 底层是动态数组实现的，当元素数量超过当前容量时就会触发扩容。默认初始容量是 10，扩容时新容量是旧容量的 1.5 倍，实际上是通过 oldCapacity + (oldCapacity &gt;&gt; 1) 计算出来的。然后用 Arrays.copyOf() 把旧数组的内容复制到新数组里。</p><p>扩容过程会涉及内存分配和数据复制，性能相对较低，<br>所以在预知元素数量时最好在构造时指定初始容量。</p><p>ArrayList 没有负载因子，和 HashMap 不一样。</p><p>在 JDK 1.7 中是构造时分配数组，1.8 以后是懒加载，只有第一次 add() 才真正分配空间。</p><p>总结：<br>“ArrayList 的扩容机制 = 触发时自动按 1.5 倍新建数组 + 拷贝旧数据。”</p><h3 id="说说-Java-中-HashMap-的原理？">说说 Java 中 HashMap 的原理？</h3><p>HashMap 的底层是 <strong>数组 + 链表 + 红黑树</strong>  的结构。<br>1.当我们向 HashMap 中存入一个键值对时，会先根据 key 的 hashCode 计算哈希值，再定位到数组下标。<br>2.如果该位置为空，就直接插入；如果已有元素，就会比较 key：</p><ul><li>相同则覆盖 value；</li><li>不同则判断是链表还是红黑树结构。<ul><li>若为链表 → 遍历插入尾部</li><li>若为TreeNode → 插入红黑树；</li></ul></li></ul><p>3.插入后判断</p><ul><li>链表长度 &gt; 8 且 table 大小 ≥ 64 → 转红黑树；（在 JDK 1.8 以后，为了避免链表过长导致性能下降，当链表长度超过 8 且数组容量 ≥ 64 时，会自动转换为 红黑树 提升查询效率。）</li><li>若红黑树节点数小于6-&gt;转回链表</li><li>若 size 超过 threshold（阈值） → 扩容。（HashMap 默认初始容量是 16，负载因子是 0.75，当元素数量超过 capacity × loadFactor 时会触发扩容（容量 ×2）。</li></ul><p>不过要注意的是：<strong>HashMap 不是线程安全的</strong>，多线程环境下建议使用 ConcurrentHashMap。</p><h3 id="Java-中-HashMap-的扩容机制是怎样的？">Java 中 HashMap 的扩容机制是怎样的？</h3><p>HashMap的扩容机制<br>HashMap 在存储元素超过一定数量时会触发扩容，具体机制如下：</p><p>1.触发扩容<br>当 HashMap 中的元素数量超过 负载因子（默认是 0.75）与当前容量的乘积时，扩容操作就会触发。</p><p>2.扩容规则<br>扩容时，HashMap 的容量会 翻倍。例如，从 16 扩容到 32。<br>扩容后，新的数组大小为原来的一倍，因此元素将重新分配到新的数组中。</p><p>3.扩容时jdk7会重新计算每个元素的哈希值，jdk8时不会重新计算哈希值，jdk8是通过hash值与上老数组的容量 (hash &amp; oldCapacity )来判断hash值的最高位是不是1，如果是1，则扩容后元素存放的位置为<strong>旧数组下标+老数组的容量</strong>，如果是0，说明元素还是存放在原来的下标位置。</p><h3 id="为什么-HashMap-在-Java-中扩容时采用-2-的-n-次方倍？">为什么 HashMap 在 Java 中扩容时采用 2 的 n 次方倍？</h3><p>HashMap 采用 2 的 n 次方作为容量，是为了让哈希值分布更均匀、减少冲突，并通过位运算代替取模运算来提升索引效率。<br>同时在扩容时，只需判断哈希值新增一位的 0/1，即可快速确定新位置，避免重新计算哈希，提高扩容性能。</p><h3 id="为什么-Java-中-HashMap-的默认负载因子是-0-75？">为什么 Java 中 HashMap 的默认负载因子是 0.75？</h3><p>HashMap 的默认负载因子是 0.75，这个值是为了在<strong>时间复杂度</strong>和<strong>空间利用率</strong>之间取得一个合理的平衡。</p><ul><li>如果负载因子太小，比如 0.5，虽然哈希冲突少，查询快，</li><li>但会导致频繁扩容，浪费空间；</li><li>如果负载因子太大，比如 0.9，虽然空间利用率高，</li><li>但冲突多，查找效率会下降。<br>所以 0.75 是经过大量实践验证的经验值，既能保证较低的冲突概率，又能减少扩容次数。</li></ul><p>总结：<br>“0.75 是 HashMap 在空间利用率与查找效率之间的最优平衡点。”</p><h3 id="为什么-JDK-1-8-对-HashMap-进行了红黑树的改动？">为什么 JDK 1.8 对 HashMap 进行了红黑树的改动？</h3><p>在 JDK1.8 之前，HashMap 使用链表来解决哈希冲突。<br>当冲突比较严重时，链表会变得很长，查找、插入、删除的时间复杂度从 O(1) 退化为 O(n)。</p><p>为了避免性能急剧下降，从 JDK1.8 开始，当桶中元素数量超过 8 时，<br>并且数组长度大于 64，HashMap 会将链表转换为红黑树。<br>红黑树是一种自平衡二叉查找树，操作复杂度是 O(log n)，可以显著提升性能。</p><p>当元素数量减少到 6 以下时，红黑树又会退化回链表，以节省内存。</p><p>另外，之所以不直接使用红黑树，是因为树节点体积更大，占用更多内存。<br>因此，只有在冲突严重时才树化，是在<strong>性能与内存之间的平衡设计</strong>。</p><p>一句话总结：<br>“JDK1.8 引入红黑树是为了解决哈希冲突导致的性能退化问题，<br>将最坏时间复杂度从 O(n) 优化为 O(log n)，实现时间与空间的最佳折中。”</p><h3 id="JDK-1-8-对-HashMap-除了红黑树还进行了哪些改动？">JDK 1.8 对 HashMap 除了红黑树还进行了哪些改动？</h3><p>除了引入红黑树以外，JDK1.8 对 HashMap 还做了三项关键优化：</p><p>第一，<strong>优化了哈希函数</strong>。<br>通过 (h = key.hashCode() ^ (h &gt;&gt;&gt; 16)) 通过高 16 位与低 16 位异或，使高位信息参与索引计算，让哈希值分布更均匀，减少冲突。</p><p>第二，<strong>改进了扩容机制</strong>。<br>JDK1.7 每次扩容都要重新计算 hash 值，而 JDK1.8 直接通过 (hash &amp; oldCap) 旧容量（oldCap）的高位判断节点的新位置，无需重新计算 hash。</p><p>第三，<strong>插入方式从头插法改为尾插法</strong>。<br>头插法在多线程扩容时可能造成<strong>链表反转和死循环</strong>，改为尾插法后可以有效避免这一问题。</p><p>一句话总结：<br>“JDK1.8 的 HashMap 通过优化哈希函数、改进扩容机制、改为尾插法，在性能、稳定性和安全性上都比 JDK1.7 有显著提升。”</p><h3 id="使用-HashMap-时，有哪些提升性能的技巧？">使用 HashMap 时，有哪些提升性能的技巧？</h3><p>在使用 HashMap 时，主要可以从以下几个方面提升性能：</p><p>① <strong>预估初始容量，避免频繁扩容</strong><br>HashMap 扩容会触发 rehash，代价高；可以通过 new HashMap(expectedSize / 0.75f) 预设容量。</p><p>② <strong>合理调整负载因子（LoadFactor）</strong><br>默认 0.75 是空间与时间的平衡点，数据密集或读多写少的场景可略调低。</p><p>③<strong>确保 hashCode 分布均匀</strong><br>设计良好的 hashCode 可避免冲突，减少链表/红黑树退化，提高访问效率。</p><p>④ <strong>根据场景选用合适 Map 实现类</strong></p><ul><li>LinkedHashMap：保持插入顺序；</li><li>ConcurrentHashMap：高并发场景；</li><li>TreeMap：需要排序的场景。</li></ul><p>一句话总结：<br>提前规划容量、优化哈希函数、合理配置负载因子，才是 HashMap 高性能的关键。</p><h3 id="什么是-Hash-碰撞？怎么解决哈希碰撞？">什么是 Hash 碰撞？怎么解决哈希碰撞？</h3><p>Hash 碰撞是指不同的 key 通过哈希函数计算后得到相同的哈希值，从而映射到哈希表中的同一个槽位。</p><p>常见的解决方式包括：</p><p><strong>① 拉链法（链地址法）</strong>：<br>每个槽位对应一个链表或红黑树，所有哈希值相同的元素存在该链表中。<br>（Java 的 HashMap 就是采用这种方式）</p><p><strong>② 开放寻址法</strong>：<br>当发生碰撞时，继续在数组中寻找下一个空闲槽位（如线性探测、二次探测）。</p><p><strong>③ 再哈希法（双重哈希）</strong>：<br>使用多个哈希函数，在发生碰撞时重新计算新的索引位置。</p><p>🔹总结一句话：<br>“Hash 碰撞是不可避免的，关键在于通过合理的冲突解决策略（如拉链法+红黑树）保持高效性能。”</p><h3 id="Java-的-CopyOnWriteArrayList-和-Collections-synchronizedList-有什么区别？分别有什么优缺点？">Java 的 CopyOnWriteArrayList 和 Collections.synchronizedList 有什么区别？分别有什么优缺点？</h3><p>CopyOnWriteArrayList 和 Collections.synchronizedList 都是线程安全的 List 实现，但机制完全不同。</p><ul><li><strong>CopyOnWriteArrayList</strong> 采用“写时复制”策略，写操作会复制一个新数组再修改，读操作无锁，适合读多写少的并发场景。优点是读性能极高、迭代安全；缺点是写操作慢且内存占用高。</li><li><strong>Collections.synchronizedList</strong> 通过 synchronized 关键字为所有操作加锁，实现线程安全。优点是实现简单，写操作无额外内存开销；缺点是读写都加锁，性能较差，且迭代需手动同步。</li></ul><p>一句话总结：<br>读多写少用 CopyOnWriteArrayList，读写频繁用 Collections.synchronizedList（或直接用 ConcurrentHashMap、CopyOnWriteArraySet 等 JUC 类更优）。</p><h3 id="Java-中的-HashMap-和-Hashtable-有什么区别？">Java 中的 HashMap 和 Hashtable 有什么区别？</h3><p>在 Java 中，HashMap 和 Hashtable 的区别主要有四点：</p><p>第一，<strong>线程安全性不同</strong>：<br>HashMap 是非线程安全的，多线程环境下可能出现数据不一致；<br>而 Hashtable 是线程安全的，因为内部所有方法都加了 synchronized。</p><p>第二，<strong>性能不同</strong>：<br>由于没有同步锁，HashMap 在单线程环境下性能更好。<br>而 Hashtable 因为锁粒度太粗，性能偏低。</p><p>第三，<strong>对 null 的支持不同</strong>：<br>HashMap 允许一个 null 键和多个 null 值；<br>Hashtable 不允许任何 null 键或 null 值。</p><p>第四，<strong>迭代器机制不同</strong>：<br>HashMap 使用 fail-fast 的 Iterator，迭代时修改会抛出ConcurrentModificationException（并发修改异常）；<br>Hashtable 使用旧的 Enumeration，不会抛异常，但已经过时。</p><p>另外，HashMap 继承自 AbstractMap，Hashtable 继承自过时的 Dictionary 类。<br>一句话总结：<br>“HashMap 非线程安全、性能高；Hashtable 线程安全但过时，建议用 ConcurrentHashMap 替代。”</p><h3 id="ConcurrentHashMap-和-Hashtable-的区别是什么？">ConcurrentHashMap 和 Hashtable 的区别是什么？</h3><p>在 Java 中，ConcurrentHashMap 和 Hashtable 都是<strong>线程安全</strong>的哈希表实现，但它们在实现线程安全的方式上完全不同。</p><p>Hashtable 使用的是整表锁，即每次读写都要竞争同一把锁，所以并发性能比较低。</p><p>而 ConcurrentHashMap 在 <strong>JDK7 采用分段锁机制</strong>，<br><strong>在 JDK8 之后采用了 CAS + synchronized 的方式</strong>：<br>CAS 用于无锁写入，如果冲突严重再退化为锁定特定桶的头结点。</p><p>这样锁的粒度更细，可以让多个线程同时访问不同桶，从而大幅提高并发性能。</p><p>此外，ConcurrentHashMap 的底层结构也更优化，<br>它在高冲突时会将链表转换为红黑树，进一步提升查询效率。</p><p>一句话总结：<br>“Hashtable 锁整张表，而 ConcurrentHashMap 只锁冲突桶 + 使用 CAS，无锁读写，并发性能更高。”</p><h3 id="Java-中的-HashSet-和-HashMap-有什么区别？">Java 中的 HashSet 和 HashMap 有什么区别？</h3><ol><li><p>HashSet 不允许重复元素，只存储一个元素<br>HashSet 是一个不允许重复元素的集合。在 HashSet 中，存储的每个元素都是唯一的。当你尝试插入一个已经存在的元素时，插入操作会失败。</p></li><li><p>HashMap 存储键值对，键必须唯一，值可以重复<br>HashMap 是一个由键值对组成的集合。它的键（key）必须是唯一的，但值（value）可以重复。如果你尝试将一个已经存在的键对应的值更新为一个新的值，它会替换掉旧的值。</p></li><li><p>HashSet 底层基于 HashMap 实现，HashSet 存储的元素是存储在 HashMap 的键中，value 就是一个 Object 对象<br>HashSet 的底层是通过 HashMap 来实现的。在 HashSet 中，元素被存储为 HashMap 的键，而每个键的值（value）在 HashMap 中其实并不关心，它是一个常量对象，通常使用 Object 类型。</p></li></ol><h3 id="Java-中的-LinkedHashMap-是什么？">Java 中的 LinkedHashMap 是什么？</h3><p><strong>LinkedHashMap 是 HashMap 的子类</strong>，它在 HashMap 的基础上通过维护一个 <strong>双向链表</strong>，来记录键值对的 <strong>插入顺序</strong>或<strong>访问顺序</strong>。</p><p>默认情况下按插入顺序排序，如果在构造时将 accessOrder 设为 true，<br>则按最近访问顺序（LRU）排序。</p><p>它的查找、插入、删除操作依然是 O(1) 时间复杂度，并且允许键和值为 null。</p><p>常用于实现<strong>LRU 缓存</strong> 或需要保持插入顺序的场景。</p><h3 id="Java-中的-TreeMap-是什么？">Java 中的 TreeMap 是什么？</h3><p>TreeMap 是 Java 中实现 Map 接口的一种数据结构，<strong>它是基于红黑树的</strong>。红黑树是一种<strong>平衡的二叉查找树</strong>，它能确保在执行插入、删除和查找操作时，时间复杂度都能保持在 O(log n)。在 TreeMap 中，<strong>所有的键都会根据自然顺序或者我们提供的 Comparator 进行排序</strong>。</p><p>另外，<strong>TreeMap 不允许 null 作为键，因为 null 不能进行比较排序，但它允许存储 null 值</strong>。TreeMap 的一个特点是，<strong>它在实现上是一个有序的集合，能保证键值对始终按照升序排列</strong>。</p><h3 id="Java-中的-IdentityHashMap-是什么？">Java 中的 IdentityHashMap 是什么？</h3><p>IdentityHashMap 主要用在那些<strong>需要根据对象的内存地址来判断是否相等的场景</strong>，<strong>而不是判断两个对象的内容是否相同</strong>。简单来说，IdentityHashMap 会使用 <strong>==</strong> 来判断两个键是否相同，<strong>而不是像 HashMap 使用 equals() 方法来判断</strong>。它通常在一些特殊的情况下使用，比如<strong>缓存管理或者需要进行对象唯一性的场景</strong>。</p><p>此外，IdentityHashMap 和 HashMap 的存储方式也有所不同，它存储键的方式<strong>更注重引用</strong>而不是对象内容，因此它适用于某些特定的使用场景。</p><h3 id="Java-中的-WeakHashMap-是什么-？">Java 中的 WeakHashMap 是什么 ？</h3><ul><li><strong>WeakHashMap</strong> 是一种使用<strong>弱引用</strong>（Weak Reference）作为键（key）的哈希表实现。与普通的 HashMap 不同，WeakHashMap 会允许垃圾回收器去回收不再被其他对象引用的键。也就是说，当 WeakHashMap 中的键对象不再被其他任何地方引用时，该键值对会自动从 WeakHashMap 中移除。</li><li>通过这种机制，WeakHashMap 能够避免因对象持续存在于内存中而导致的<strong>内存泄漏</strong>问题。</li><li>WeakHashMap适用于<strong>需要对缓存对象进行动态管理</strong>的场景，<strong>它通过弱引用机制，确保对象可以在没有强引用时自动被垃圾回收。</strong></li></ul><h3 id="Java-中-ConcurrentHashMap-1-7-和-1-8-之间有哪些区别？">Java 中 ConcurrentHashMap 1.7 和 1.8 之间有哪些区别？</h3><h4 id="1-数据结构">1.数据结构</h4><p>JDK 1.7 ：ConcurrentHashMap 采用了<strong>Segment（分段锁）</strong>+ <strong>HashEntry（哈希表</strong>）来组成数据结构。</p><p>JDK 1.8 : ConcurrentHashMap 去掉了 Segment，使用<strong>数组+链表和红黑树的结构</strong>(与HashMap类似)。</p><h4 id="2-锁的类型与粒度">2.锁的类型与粒度</h4><p>JDK 1.7： 分段锁(Segment)继承了 ReentrantLock，每个 Segment 是独立的，因此可以支持更多的并发线程，<strong>默认情况下有 16 个 Segment</strong>。</p><p>JDK 1.8： 使用 <strong>synchronized 和 CAS</strong> 来保证线程安全，相比于 1.7 更细粒度的锁。</p><h4 id="3-扩容机制：">3. 扩容机制：</h4><p>JDK 1.7： 每个segment里单独进行自己的扩容。</p><p>JDK 1.8： JDK 1.8 的扩容机制引入了<strong>渐进式扩容</strong>，当我们的元素个数达到扩容阈值时，<strong>首先创建一个 2 倍大小的数组，然后后续每次有线程对当前数据结构进行操作（新增、修改等），都会帮忙迁移部分的数组槽位上的数据(使用tranferIndex进行标记)，直到旧数组的数据完全迁移到新数组为止</strong>。扩容过程更加高效，减少了锁的竞争。</p><h3 id="Java-中-ConcurrentHashMap-的-get-方法是否需要加锁？">Java 中 ConcurrentHashMap 的 get 方法是否需要加锁？</h3><p>在 Java 中的 ConcurrentHashMap 中，get() 方法<strong>不需要加锁</strong>。这个设计是<strong>为了提升性能，并减少锁的开销</strong>。</p><ul><li><p>get方法是读取数据操作，不对资源做处理，所以只要使用 <strong>volatile</strong> 关键字来确保每次读取操作都能获取到最新的数据即可。</p></li><li><p>具体来说，get() 方法是在数组节点上执行的，它通过 Unsafe 类的 getObjectVolatile() 方法来保证线程可见性，确保每次读取到的值是最新的。</p></li></ul><h3 id="为什么-Java-的-ConcurrentHashMap-不支持-key-或-value-为-null？">为什么 Java 的 ConcurrentHashMap 不支持 key 或 value 为 null？</h3><p>Java 中的 ConcurrentHashMap 不支持 key 或 value 为 null 主要是为了<strong>避免并发操作时出现不可预知的行为</strong>。比如，在多线程环境下执行 get(key) 时，<strong>如果 key 对应的值是 null，就无法判断这是因为 key 不存在，还是它的 value 就是 null。如果允许 null，那么就需要额外的代码来区分这些情况，增加了复杂度。</strong></p><p>此外，ConcurrentHashMap 的设计是为了避免歧义和并发问题。如果允许 null 作为 key 或 value，就会使得例如 get、put、containsKey 等操作更加复杂，可能<strong>导致频繁的状态检查或异常情况</strong>。</p><blockquote><p>hahsmap为什么可以？</p></blockquote><p>hashmap设计的初衷是单线程，它有containsKey方法可以判断key是否存在。<br>ConcurrentHashMap不能用containsKey, 因为多线程环境下也会有歧义。</p><h3 id="Java-中的-CopyOnWriteArrayList-是什么？">Java 中的 CopyOnWriteArrayList 是什么？</h3><p>CopyOnWriteArrayList 是 Java 提供的线程安全的动态数组实现。这个类通过“<strong>写时复制”</strong>（Copy on Write）机制来保证<strong>线程安全</strong>，<strong>在进行写操作时，会先复制一份数组副本，写操作仅在新的副本上进行，而不对原始数组进行修改。</strong></p><p>基本特性:</p><ul><li>线程安全：使用 CopyOnWrite 机制，读操作不会加锁，写操作在写副本时加锁，保证线程安全。</li><li>写操作开销大：每次写操作都需要复制整个数组，有一定的性能消耗，而且消耗内存。</li><li>读操作无锁：由于数组是每次写时才被复制，所以对于大量的读操作是无锁的，性能较高。</li></ul><p>适合场景：</p><p>适合<strong>读多写少</strong>的情况。常用于事件通知、事件监停器等场景，能有效减少同步开销，确保线程安全。</p><h3 id="你遇到过-ConcurrentModificationException-错误吗？它是如何产生的？">你遇到过 ConcurrentModificationException 错误吗？它是如何产生的？</h3><p><strong>ConcurrentModificationException</strong> 它通常出现在多线程环境中，当我们在遍历集合（如 ArrayList）时，<strong>如果在遍历的过程中修改了集合的结构（比如添加或删除元素），就会抛出这个异常</strong>。这个异常的产生是因为 Java 使用了 <strong>fail-fast 机制</strong>，它会在检测到结构性修改时立即抛出异常，防止继续执行后续操作，避免不一致的状态。</p><blockquote><p>举例：</p></blockquote><p>比如，如果你在使用 for-each 遍历 ArrayList 时，同时修改了集合的内容，就会触发这个异常。Java 集合类会在 next() 方法调用时检查是否有结构性修改，如果检测到有修改，它会抛出 ConcurrentModificationException。</p><blockquote><p>如何避免:</p></blockquote><p>“为了避免这个异常，通常我们可以使用 <strong>Iterator</strong> 来遍历集合，<strong>因为 Iterator 提供了 remove() 方法来安全地删除元素</strong>。此外，在多线程环境下，可以使用像 <strong>CopyOnWriteArrayList</strong> 这样的线程安全集合，或者使用 <strong>synchronized</strong> 来同步操作。”</p>]]></content>
    
    
    <summary type="html">我对java基础和集合类的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="javase+集合" scheme="https://itgeqian.github.io/tags/javase-%E9%9B%86%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>GQ Video项目部署</title>
    <link href="https://itgeqian.github.io/posts/2.html"/>
    <id>https://itgeqian.github.io/posts/2.html</id>
    <published>2025-10-06T10:19:03.000Z</published>
    <updated>2025-10-06T14:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>服务名称</th><th>英文名</th><th>端口号</th><th>版本号</th><th>服务类别</th></tr></thead><tbody><tr><td>数据库</td><td>mysql</td><td>3306</td><td>v8.26</td><td>环境依赖</td></tr><tr><td>搜索引擎</td><td>es</td><td>9201</td><td>3.1.9</td><td>环境依赖</td></tr><tr><td>缓存</td><td>Redis</td><td>6379</td><td>v8</td><td>环境依赖</td></tr><tr><td>消息队列</td><td>RocketMQ</td><td></td><td>2.3.0</td><td>环境依赖</td></tr><tr><td>注册中心</td><td>nacos</td><td>8848</td><td>v2.2.0</td><td>环境依赖</td></tr><tr><td>网关服务</td><td>easylive-cloud-gateway</td><td>7071</td><td>java8</td><td>项目</td></tr><tr><td>分布式事务</td><td>Seata</td><td>7091</td><td>2021.0.5.0</td><td>环境依赖</td></tr><tr><td>对象存储</td><td>Minio</td><td>9000</td><td>2024-09-13T20-26-02Z</td><td>环境依赖</td></tr><tr><td>管理端服务</td><td>easylive-cloud-admin</td><td>7070</td><td>java8</td><td>项目</td></tr><tr><td>用户端服务</td><td>easylive-cloud-web</td><td>7072</td><td>java8</td><td>项目</td></tr><tr><td>交互服务</td><td>easylive-cloud-interact</td><td>7073</td><td>java8</td><td>项目</td></tr><tr><td>资源服务</td><td>easylive-cloud-resource</td><td>7074</td><td>java8</td><td>项目</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h1 id="微服务项目部署指导">微服务项目部署指导</h1><p><em>Exported on 2025/10/6 at GMT+8 0:12:27 from Cursor (1.4.2)</em></p><hr><p><strong>User</strong></p><p>整个项目已经完结，请你仔细查看一下项目的结构，我现在想要把这个微服务项目部署到一个我已经准备好的4核4g的服务器上该如何部署，是选择用宝塔面板还是用docker compose部署呢，请你指引着我一步步完成部署@c:\Users\wanglei\Desktop\<a href="http://xn--i0yq5pe7ol9g.md">项目部署.md</a></p><hr><p><strong>Cursor</strong></p><p>我先快速查看各微服务的配置文件端口与外部依赖（Nacos、Redis、RocketMQ、Minio 等）的指向，确保 docker-compose 方案能一次性把依赖与服务都编排好。随后我会给出一步步部署清单与可直接使用的 compose 文件与构建命令。</p><p>我将先创建一个部署任务清单，随后直接给出推荐方案（Docker Compose）与可运行的命令、配置与文件模板。接下来我会把全部步骤一次性写全，便于你按部就班执行。</p><p>我先并行打开各微服务的配置文件，确认注册中心、配置名与端口设置，以便给出可直接可用的 docker-compose 参数和环境变量。接着我会确定采用 Docker Compose 的总体策略并开始给出脚本。</p><p>我已确认各服务的 <code>bootstrap.yml</code> 通过 Nacos 加载共享配置且默认指向 127.0.0.1:8848，容器化时需用环境变量覆盖为 nacos:8848。现在我先确定采用 Docker Compose 方案，并开始给出安装与编排文件。接下来把“安装 Docker/Compose”设为进行中。</p><p>我将并行打开各服务的 dev 配置文件，确认数据库、存储和消息队列的连接信息，以便在 docker-compose 中正确注入环境变量。</p><p>我将把“安装 Docker/Compose”完成并开始“创建目录结构与 .env 机密变量”，随后给出<code>.env</code>和<code>docker-compose.yml</code>模板与执行命令。接着我会继续推进依赖与应用编排等步骤，并同步勾选对应待办。</p><p>我已经确定采用 Docker Compose 部署，并开始输出目录结构、<code>.env</code> 与依赖编排模板，随后给出后端镜像构建与应用编排、前端与 Nginx 配置。接着我会把“创建目录结构与 .env”标记完成，并开启“依赖服务编排”和“应用编排”。</p><p>我已确认采用 Docker Compose 并核对了各微服务的 Nacos 配置与端口。现在我会直接给出一步步部署清单、必要命令与可用模板（.env、docker-compose、Dockerfile、Nginx），你可以按顺序执行。随后我会把清单项勾选完成。### 结论与建议</p><ul><li>建议使用 Docker Compose 部署。原因：<ul><li>多个基础依赖（MySQL/Redis/Nacos/RocketMQ/Minio/ES/Seata）与 5 个 SpringBoot 微服务需要统一编排、网络与持久化，更易复现与维护。</li><li>日志、重启策略、资源限制、备份与迁移都更容易标准化。</li></ul></li><li>4 核 4G 机器资源偏紧。建议先上线核心链路（MySQL、Redis、Nacos、Minio、网关与核心三服务），RocketMQ/ES/Seata如非强依赖可延后启用，或按需独立机器。</li></ul><h3 id="端口规划（来自你的部署文档）">端口规划（来自你的部署文档）</h3><ul><li>数据库 MySQL: 3306</li><li>Nacos: 8848</li><li>网关 <code>easylive-cloud-gateway</code>: 7071</li><li>管理端 <code>easylive-cloud-admin</code>: 7070</li><li>用户端 <code>easylive-cloud-web</code>: 7072</li><li>交互 <code>easylive-cloud-interact</code>: 7073</li><li>资源 <code>easylive-cloud-resource</code>: 7074</li><li>Redis: 6379</li><li>Minio: 9000(服务) + 9001(控制台)</li><li>RocketMQ/ES/Seata：按需启用（建议后置）</li></ul><p>下面步骤直接可执行，按顺序来。</p><h3 id="1-安装-Docker-Compose（以-Ubuntu-20-04-22-04-为例）">1) 安装 Docker &amp; Compose（以 Ubuntu 20.04/22.04 为例）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1) 基础依赖</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update -y</span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y ca-certificates curl gnupg lsb-release</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) Docker 仓库</span></span><br><span class="line"><span class="built_in">sudo</span> install -m 0755 -d /etc/apt/keyrings</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg \</span><br><span class="line"> | <span class="built_in">sudo</span> gpg --dearmor -o /etc/apt/keyrings/docker.gpg</span><br><span class="line"><span class="built_in">echo</span> \</span><br><span class="line">  <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.gpg] \</span></span><br><span class="line"><span class="string">  https://download.docker.com/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable&quot;</span> \</span><br><span class="line"> | <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"><span class="built_in">sudo</span> apt-get update -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 安装</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4) 免 sudo（重新登录生效）</span></span><br><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">$USER</span></span><br></pre></td></tr></table></figure><h3 id="2-目录结构与时区">2) 目录结构与时区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /opt/easylive/&#123;mysql/data,mysql/init,redis,data,nacos,data,minio/data,nginx/conf.d,frontend/&#123;web,admin&#125;,logs&#125;</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /opt/easylive/&#123;gateway,admin,web,interact,resource&#125;/config</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /opt/easylive/&#123;rocketmq/&#123;namesrv,broker&#125;,es/data,seata&#125;</span><br><span class="line"><span class="built_in">sudo</span> timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure><h3 id="3-env（放到-opt-easylive-env）">3) .env（放到 /opt/easylive/.env）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">TZ=Asia/Shanghai</span><br><span class="line"></span><br><span class="line"><span class="comment"># MySQL</span></span><br><span class="line">MYSQL_ROOT_PASSWORD=YourStrongRootPass!</span><br><span class="line">MYSQL_DATABASE=easylive</span><br><span class="line"></span><br><span class="line"><span class="comment"># Nacos</span></span><br><span class="line">NACOS_VERSION=v2.2.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Minio</span></span><br><span class="line">MINIO_ROOT_USER=admin</span><br><span class="line">MINIO_ROOT_PASSWORD=YourStrongMinioPass!</span><br><span class="line"></span><br><span class="line"><span class="comment"># Java 内存建议（4G 机器尽量克制）</span></span><br><span class="line">JAVA_XMS=256m</span><br><span class="line">JAVA_XMX=512m</span><br></pre></td></tr></table></figure><h3 id="4-docker-compose-yml（放到-opt-easylive-docker-compose-yml）">4) docker-compose.yml（放到 /opt/easylive/docker-compose.yml）</h3><p>为节省内存，RocketMQ/ES/Seata 先注释，核心链路先跑通。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3.9&quot;</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">easylive</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">easylive-net:</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">mysql-data:</span></span><br><span class="line">  <span class="attr">redis-data:</span></span><br><span class="line">  <span class="attr">nacos-data:</span></span><br><span class="line">  <span class="attr">minio-data:</span></span><br><span class="line">  <span class="attr">es-data:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">mysql:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql:8.0</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--default-authentication-plugin=mysql_native_password</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--character-set-server=utf8mb4</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--collation-server=utf8mb4_unicode_ci</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_ROOT_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_DATABASE=$&#123;MYSQL_DATABASE&#125;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;3306:3306&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql-data:/var/lib/mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./mysql/init:/docker-entrypoint-initdb.d</span></span><br><span class="line">    <span class="attr">healthcheck:</span></span><br><span class="line">      <span class="attr">test:</span> [<span class="string">&quot;CMD-SHELL&quot;</span>,<span class="string">&quot;mysqladmin ping -uroot -p$&#123;MYSQL_ROOT_PASSWORD&#125; | grep &#x27;mysqld is alive&#x27;&quot;</span>]</span><br><span class="line">      <span class="attr">interval:</span> <span class="string">10s</span></span><br><span class="line">      <span class="attr">timeout:</span> <span class="string">5s</span></span><br><span class="line">      <span class="attr">retries:</span> <span class="number">30</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">redis:6.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">command:</span> [ <span class="string">&quot;redis-server&quot;</span>, <span class="string">&quot;--appendonly&quot;</span>, <span class="string">&quot;yes&quot;</span> ]</span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;6379:6379&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">redis-data:/data</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">nacos:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nacos/nacos-server:$&#123;NACOS_VERSION&#125;</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">nacos</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MODE=standalone</span></span><br><span class="line">      <span class="comment"># 使用 MySQL 做持久化（推荐）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PLATFORM=mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_HOST=mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_DB_NAME=nacos_config</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_PORT=3306</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_USER=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="comment"># JVM 缩小</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JVM_XMS=256m</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JVM_XMX=512m</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JVM_XMN=256m</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="attr">mysql:</span></span><br><span class="line">        <span class="attr">condition:</span> <span class="string">service_healthy</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8848:8848&quot;</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">minio:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">minio/minio:RELEASE.2024-09-13T20-26-02Z</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">minio</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MINIO_ROOT_USER=$&#123;MINIO_ROOT_USER&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MINIO_ROOT_PASSWORD=$&#123;MINIO_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">server</span> <span class="string">/data</span> <span class="string">--console-address</span> <span class="string">&quot;:9001&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">minio-data:/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9000:9000&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9001:9001&quot;</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 如无强依赖，先不启动下列服务，稳定后再启用</span></span><br><span class="line">  <span class="comment"># rocketmq-namesrv:</span></span><br><span class="line">  <span class="comment">#   image: apache/rocketmq:5.2.0</span></span><br><span class="line">  <span class="comment">#   container_name: rmq-namesrv</span></span><br><span class="line">  <span class="comment">#   ports: [&quot;9876:9876&quot;]</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#     - JAVA_OPT_EXT=-Xms256m -Xmx512m</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># rocketmq-broker:</span></span><br><span class="line">  <span class="comment">#   image: apache/rocketmq:5.2.0</span></span><br><span class="line">  <span class="comment">#   container_name: rmq-broker</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - NAMESRV_ADDR=rmq-namesrv:9876</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#     - JAVA_OPT_EXT=-Xms256m -Xmx512m</span></span><br><span class="line">  <span class="comment">#   depends_on: [rocketmq-namesrv]</span></span><br><span class="line">  <span class="comment">#   ports: [&quot;10911:10911&quot;,&quot;10909:10909&quot;,&quot;10912:10912&quot;]</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># es:</span></span><br><span class="line">  <span class="comment">#   image: docker.elastic.co/elasticsearch/elasticsearch:7.17.22</span></span><br><span class="line">  <span class="comment">#   container_name: es</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - discovery.type=single-node</span></span><br><span class="line">  <span class="comment">#     - xpack.security.enabled=false</span></span><br><span class="line">  <span class="comment">#     - ES_JAVA_OPTS=-Xms512m -Xmx512m</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#   ulimits:</span></span><br><span class="line">  <span class="comment">#     memlock:</span></span><br><span class="line">  <span class="comment">#       soft: -1</span></span><br><span class="line">  <span class="comment">#       hard: -1</span></span><br><span class="line">  <span class="comment">#   ports:</span></span><br><span class="line">  <span class="comment">#     - &quot;9201:9200&quot;</span></span><br><span class="line">  <span class="comment">#   volumes:</span></span><br><span class="line">  <span class="comment">#     - es-data:/usr/share/elasticsearch/data</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># seata:</span></span><br><span class="line">  <span class="comment">#   image: seataio/seata-server:1.6.1</span></span><br><span class="line">  <span class="comment">#   container_name: seata</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - SEATA_PORT=7091</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#   ports: [&quot;7091:7091&quot;]</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ------------------ 应用服务 ------------------</span></span><br><span class="line">  <span class="attr">gateway:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-gateway:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">gateway</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7071</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7071:7071&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">admin:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-admin:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">admin</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7070</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="comment"># 覆盖数据库与 Redis（如 Nacos 未配置完整）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7070:7070&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">web:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-web:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7072</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7072:7072&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">interact:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-interact:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">interact</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7073</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7073:7073&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">resource:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-resource:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">resource</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7074</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">      <span class="comment"># 如资源服务用到 Minio，请在 Nacos 配置或此处补充访问参数</span></span><br><span class="line">      <span class="comment"># - MINIO_ENDPOINT=http://minio:9000</span></span><br><span class="line">      <span class="comment"># - MINIO_ACCESS_KEY=$&#123;MINIO_ROOT_USER&#125;</span></span><br><span class="line">      <span class="comment"># - MINIO_SECRET_KEY=$&#123;MINIO_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="comment"># - MINIO_BUCKET=your-bucket</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>, <span class="string">minio</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7074:7074&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">nginx:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.25</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">gateway</span>]</span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;80:80&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./nginx/conf.d:/etc/nginx/conf.d</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./frontend/web:/usr/share/nginx/html</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./frontend/admin:/usr/share/nginx/html/admin</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br></pre></td></tr></table></figure><h3 id="5-后端服务镜像构建">5) 后端服务镜像构建</h3><p>建议每个服务放一个最简 Dockerfile（以 <code>easylive-cloud-gateway</code> 为例）：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 放在 easylive-server/easylive-cloud/easylive-cloud-gateway/Dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> eclipse-temurin:<span class="number">8</span>-jre</span><br><span class="line"><span class="keyword">ENV</span> TZ=Asia/Shanghai</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> target/*.jar app.jar</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">7071</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;java&quot;</span>,<span class="string">&quot;-Xms<span class="variable">$&#123;JAVA_XMS:-256m&#125;</span>&quot;</span>,<span class="string">&quot;-Xmx<span class="variable">$&#123;JAVA_XMX:-512m&#125;</span>&quot;</span>,<span class="string">&quot;-jar&quot;</span>,<span class="string">&quot;/app/app.jar&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>构建步骤（在你的仓库根目录执行；其他四个服务同理更换路径与镜像名/端口）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打包全部（跳过测试）</span></span><br><span class="line"><span class="built_in">cd</span> /path/to/easylive-springcloud/easylive-server</span><br><span class="line">./mvnw -v || mvn -v</span><br><span class="line">mvn -DskipTests clean package</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建镜像（五个服务）</span></span><br><span class="line">docker build -t easylive-cloud-gateway:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-gateway</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-admin:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-admin</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-web:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-web</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-interact:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-interact</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-resource:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-resource</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>端口通过 <code>SERVER_PORT</code> 覆盖为 7071/7070/7072/7073/7074，跟你的表一致。</li><li>Nacos 地址在容器间为 <code>nacos:8848</code>（已在 compose 中用环境变量覆盖）。</li><li>数据库/Redis 在容器间为 <code>mysql:3306</code>、<code>redis:6379</code>。</li></ul><h3 id="6-Nginx-反代与前端">6) Nginx 反代与前端</h3><p><code>/opt/easylive/nginx/conf.d/easylive.conf</code>：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">  <span class="attribute">server_name</span> _;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 用户端 Web 静态</span></span><br><span class="line">  <span class="attribute">root</span> /usr/share/nginx/html;</span><br><span class="line">  <span class="attribute">index</span> index.html;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 管理端静态（访问 /admin/）</span></span><br><span class="line">  <span class="section">location</span> /admin/ &#123;</span><br><span class="line">    <span class="attribute">alias</span> /usr/share/nginx/html/admin/;</span><br><span class="line">    <span class="attribute">try_files</span> <span class="variable">$uri</span> <span class="variable">$uri</span>/ /admin/index.html;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 反向代理到网关（和 gateway 的路由保持一致）</span></span><br><span class="line">  <span class="section">location</span> /web/       &#123; <span class="attribute">proxy_pass</span> http://gateway:7071/web/; &#125;</span><br><span class="line">  <span class="section">location</span> /interact/  &#123; <span class="attribute">proxy_pass</span> http://gateway:7071/interact/; &#125;</span><br><span class="line">  <span class="section">location</span> /user/      &#123; <span class="attribute">proxy_pass</span> http://gateway:7071/user/; &#125;</span><br><span class="line">  <span class="section">location</span> /file/      &#123; <span class="attribute">proxy_pass</span> http://gateway:7071/file/; &#125;</span><br><span class="line">  <span class="section">location</span> /adminapi/  &#123; <span class="attribute">proxy_pass</span> http://gateway:7071/admin/; &#125; <span class="comment"># 避免静态路径冲突，给管理端 API 换前缀</span></span><br><span class="line"></span><br><span class="line">  <span class="attribute">proxy_set_header</span> Host              <span class="variable">$host</span>;</span><br><span class="line">  <span class="attribute">proxy_set_header</span> X-Real-IP         <span class="variable">$remote_addr</span>;</span><br><span class="line">  <span class="attribute">proxy_set_header</span> X-Forwarded-For   <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">  <span class="attribute">proxy_set_header</span> X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>构建前端并拷贝静态资源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户端</span></span><br><span class="line"><span class="built_in">cd</span> /path/to/easylive-springcloud/easylive-front/easylive-front-web</span><br><span class="line">npm ci || npm install</span><br><span class="line">npm run build</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r dist/* /opt/easylive/frontend/web/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 管理端</span></span><br><span class="line"><span class="built_in">cd</span> /path/to/easylive-springcloud/easylive-front/easylive-front-admin</span><br><span class="line">npm ci || npm install</span><br><span class="line">npm run build</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /opt/easylive/frontend/admin</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -r dist/* /opt/easylive/frontend/admin/</span><br></pre></td></tr></table></figure><p>如前端请求网关的基地址可配置，建议改为相对路径并按上面 Nginx 反代规则访问。</p><h3 id="7-Minio-初始化（可选）">7) Minio 初始化（可选）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run --<span class="built_in">rm</span> --network easylive_easylive-net -it \</span><br><span class="line">  minio/mc sh -c <span class="string">&quot;</span></span><br><span class="line"><span class="string">mc alias set minio http://minio:9000 <span class="variable">$&#123;MINIO_ROOT_USER&#125;</span> <span class="variable">$&#123;MINIO_ROOT_PASSWORD&#125;</span> &amp;&amp; \</span></span><br><span class="line"><span class="string">mc mb -p minio/easylive &amp;&amp; \</span></span><br><span class="line"><span class="string">mc anonymous set download minio/easylive&quot;</span></span><br></pre></td></tr></table></figure><h3 id="8-Nacos-配置">8) Nacos 配置</h3><ul><li>访问 <code>http://服务器IP:8848/nacos</code>，默认无鉴权或按镜像默认设置。</li><li>为每个服务新增配置：<ul><li><code>easylive-cloud-admin-dev.yml</code></li><li><code>easylive-cloud-web-dev.yml</code></li><li><code>easylive-cloud-interact-dev.yml</code></li><li><code>easylive-cloud-resource-dev.yml</code></li><li>内容至少包含数据库与 Redis 连接（参考你仓库中 dev yml，将 host 从 127.0.0.1 改为 <code>mysql</code>、<code>redis</code>）：</li></ul></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure><ul><li>资源服务若使用 Minio，请在对应 yml 增加 Minio 配置项（按你项目属性命名），指向 <code>http://minio:9000</code>。</li></ul><h3 id="9-启动与验证">9) 启动与验证</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/easylive</span><br><span class="line">docker compose pull   <span class="comment"># 第一次可忽略</span></span><br><span class="line">docker compose up -d  <span class="comment"># 启动</span></span><br><span class="line">docker compose ps     <span class="comment"># 查看状态</span></span><br><span class="line">docker logs -f gateway</span><br><span class="line">docker logs -f admin</span><br><span class="line">docker logs -f web</span><br><span class="line">docker logs -f interact</span><br><span class="line">docker logs -f resource</span><br></pre></td></tr></table></figure><ul><li>浏览器访问：<ul><li>Nacos: <code>http://服务器IP:8848/nacos</code></li><li>Minio: <code>http://服务器IP:9001</code></li><li>前端: <code>http://服务器IP/</code>（用户端）与 <code>http://服务器IP/admin/</code>（管理端）</li></ul></li><li>后端连通性：网关 <code>http://服务器IP:7071</code> 下的 <code>/web/**</code>、<code>/interact/**</code>、<code>/user/**</code>、<code>/file/**</code>、<code>/admin/**</code>。</li></ul><h3 id="10-域名与-HTTPS（可选快速）">10) 域名与 HTTPS（可选快速）</h3><ul><li>用 Nginx + Certbot：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install -y certbot python3-certbot-nginx</span><br><span class="line"><span class="built_in">sudo</span> certbot --nginx -d your.domain.com -m your@email \</span><br><span class="line">  --agree-tos --no-eff-email --redirect</span><br></pre></td></tr></table></figure><ul><li>或用 Caddy（更简单，自动签发）：将 Nginx 换成 <code>caddy:2</code>，用 Caddyfile 一行反代网关和静态。</li></ul><h3 id="11-常见资源与优化建议">11) 常见资源与优化建议</h3><ul><li>4G 机器内存紧张：先不上 RocketMQ/ES/Seata，JVM 堆保持 <code>-Xms256m -Xmx512m</code>；Nacos JVM 也已收敛。</li><li>MySQL/ES/Minio 数据请使用卷持久化（compose 已配置）。</li><li>日志落盘到容器 stdout，建议再配 ELK/Vector 后续接入。</li></ul><p>你现在可以按以上顺序执行；如果遇到端口/内存/配置问题，发我报错我继续帮你排查。</p><ul><li>我已经完成部署方案选择与全部步骤指引，包含 <code>.env</code>、<code>docker-compose.yml</code>、后端 Dockerfile、Nginx 反代与初始化要点。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 1) 基础依赖</span><br><span class="line">sudo apt-get update -y</span><br><span class="line">sudo apt-get install -y ca-certificates curl gnupg lsb-release</span><br><span class="line"></span><br><span class="line"># 2) Docker 仓库</span><br><span class="line">sudo install -m 0755 -d /etc/apt/keyrings</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg \</span><br><span class="line"> | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg</span><br><span class="line">echo \</span><br><span class="line">  &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \</span><br><span class="line">  https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; \</span><br><span class="line"> | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line">sudo apt-get update -y</span><br><span class="line"></span><br><span class="line"># 3) 安装</span><br><span class="line">sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line"></span><br><span class="line"># 4) 免 sudo（重新登录生效）</span><br><span class="line">sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /opt/easylive/&#123;mysql/data,mysql/init,redis,data,nacos,data,minio/data,nginx/conf.d,frontend/&#123;web,admin&#125;,logs&#125;</span><br><span class="line">sudo mkdir -p /opt/easylive/&#123;gateway,admin,web,interact,resource&#125;/config</span><br><span class="line">sudo mkdir -p /opt/easylive/&#123;rocketmq/&#123;namesrv,broker&#125;,es/data,seata&#125;</span><br><span class="line">sudo timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">TZ=Asia/Shanghai</span><br><span class="line"></span><br><span class="line"># MySQL</span><br><span class="line">MYSQL_ROOT_PASSWORD=YourStrongRootPass!</span><br><span class="line">MYSQL_DATABASE=easylive</span><br><span class="line"></span><br><span class="line"># Nacos</span><br><span class="line">NACOS_VERSION=v2.2.0</span><br><span class="line"></span><br><span class="line"># Minio</span><br><span class="line">MINIO_ROOT_USER=admin</span><br><span class="line">MINIO_ROOT_PASSWORD=YourStrongMinioPass!</span><br><span class="line"></span><br><span class="line"># Java 内存建议（4G 机器尽量克制）</span><br><span class="line">JAVA_XMS=256m</span><br><span class="line">JAVA_XMX=512m</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&quot;3.9&quot;</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">easylive</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">easylive-net:</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">mysql-data:</span></span><br><span class="line">  <span class="attr">redis-data:</span></span><br><span class="line">  <span class="attr">nacos-data:</span></span><br><span class="line">  <span class="attr">minio-data:</span></span><br><span class="line">  <span class="attr">es-data:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">mysql:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql:8.0</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--default-authentication-plugin=mysql_native_password</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--character-set-server=utf8mb4</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">--collation-server=utf8mb4_unicode_ci</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_ROOT_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_DATABASE=$&#123;MYSQL_DATABASE&#125;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;3306:3306&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql-data:/var/lib/mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./mysql/init:/docker-entrypoint-initdb.d</span></span><br><span class="line">    <span class="attr">healthcheck:</span></span><br><span class="line">      <span class="attr">test:</span> [<span class="string">&quot;CMD-SHELL&quot;</span>,<span class="string">&quot;mysqladmin ping -uroot -p$&#123;MYSQL_ROOT_PASSWORD&#125; | grep &#x27;mysqld is alive&#x27;&quot;</span>]</span><br><span class="line">      <span class="attr">interval:</span> <span class="string">10s</span></span><br><span class="line">      <span class="attr">timeout:</span> <span class="string">5s</span></span><br><span class="line">      <span class="attr">retries:</span> <span class="number">30</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">redis:6.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">command:</span> [ <span class="string">&quot;redis-server&quot;</span>, <span class="string">&quot;--appendonly&quot;</span>, <span class="string">&quot;yes&quot;</span> ]</span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;6379:6379&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">redis-data:/data</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">nacos:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nacos/nacos-server:$&#123;NACOS_VERSION&#125;</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">nacos</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MODE=standalone</span></span><br><span class="line">      <span class="comment"># 使用 MySQL 做持久化（推荐）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PLATFORM=mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_HOST=mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_DB_NAME=nacos_config</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_PORT=3306</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_USER=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MYSQL_SERVICE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="comment"># JVM 缩小</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JVM_XMS=256m</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JVM_XMX=512m</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JVM_XMN=256m</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="attr">mysql:</span></span><br><span class="line">        <span class="attr">condition:</span> <span class="string">service_healthy</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8848:8848&quot;</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">minio:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">minio/minio:RELEASE.2024-09-13T20-26-02Z</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">minio</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MINIO_ROOT_USER=$&#123;MINIO_ROOT_USER&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">MINIO_ROOT_PASSWORD=$&#123;MINIO_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">server</span> <span class="string">/data</span> <span class="string">--console-address</span> <span class="string">&quot;:9001&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">minio-data:/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9000:9000&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9001:9001&quot;</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 如无强依赖，先不启动下列服务，稳定后再启用</span></span><br><span class="line">  <span class="comment"># rocketmq-namesrv:</span></span><br><span class="line">  <span class="comment">#   image: apache/rocketmq:5.2.0</span></span><br><span class="line">  <span class="comment">#   container_name: rmq-namesrv</span></span><br><span class="line">  <span class="comment">#   ports: [&quot;9876:9876&quot;]</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#     - JAVA_OPT_EXT=-Xms256m -Xmx512m</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># rocketmq-broker:</span></span><br><span class="line">  <span class="comment">#   image: apache/rocketmq:5.2.0</span></span><br><span class="line">  <span class="comment">#   container_name: rmq-broker</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - NAMESRV_ADDR=rmq-namesrv:9876</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#     - JAVA_OPT_EXT=-Xms256m -Xmx512m</span></span><br><span class="line">  <span class="comment">#   depends_on: [rocketmq-namesrv]</span></span><br><span class="line">  <span class="comment">#   ports: [&quot;10911:10911&quot;,&quot;10909:10909&quot;,&quot;10912:10912&quot;]</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># es:</span></span><br><span class="line">  <span class="comment">#   image: docker.elastic.co/elasticsearch/elasticsearch:7.17.22</span></span><br><span class="line">  <span class="comment">#   container_name: es</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - discovery.type=single-node</span></span><br><span class="line">  <span class="comment">#     - xpack.security.enabled=false</span></span><br><span class="line">  <span class="comment">#     - ES_JAVA_OPTS=-Xms512m -Xmx512m</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#   ulimits:</span></span><br><span class="line">  <span class="comment">#     memlock:</span></span><br><span class="line">  <span class="comment">#       soft: -1</span></span><br><span class="line">  <span class="comment">#       hard: -1</span></span><br><span class="line">  <span class="comment">#   ports:</span></span><br><span class="line">  <span class="comment">#     - &quot;9201:9200&quot;</span></span><br><span class="line">  <span class="comment">#   volumes:</span></span><br><span class="line">  <span class="comment">#     - es-data:/usr/share/elasticsearch/data</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># seata:</span></span><br><span class="line">  <span class="comment">#   image: seataio/seata-server:1.6.1</span></span><br><span class="line">  <span class="comment">#   container_name: seata</span></span><br><span class="line">  <span class="comment">#   environment:</span></span><br><span class="line">  <span class="comment">#     - SEATA_PORT=7091</span></span><br><span class="line">  <span class="comment">#     - TZ=$&#123;TZ&#125;</span></span><br><span class="line">  <span class="comment">#   ports: [&quot;7091:7091&quot;]</span></span><br><span class="line">  <span class="comment">#   networks: [easylive-net]</span></span><br><span class="line">  <span class="comment">#   restart: always</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># ------------------ 应用服务 ------------------</span></span><br><span class="line">  <span class="attr">gateway:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-gateway:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">gateway</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7071</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7071:7071&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">admin:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-admin:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">admin</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7070</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="comment"># 覆盖数据库与 Redis（如 Nacos 未配置完整）</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7070:7070&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">web:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-web:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7072</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7072:7072&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">interact:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-interact:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">interact</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7073</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7073:7073&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">resource:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">easylive-cloud-resource:latest</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">resource</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TZ=$&#123;TZ&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SERVER_PORT=7074</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_PROFILES_ACTIVE=dev</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_DISCOVERY_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_CLOUD_NACOS_CONFIG_SERVER_ADDR=nacos:8848</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_USERNAME=root</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_DATASOURCE_PASSWORD=$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_HOST=redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPRING_REDIS_PORT=6379</span></span><br><span class="line">      <span class="comment"># 如资源服务用到 Minio，请在 Nacos 配置或此处补充访问参数</span></span><br><span class="line">      <span class="comment"># - MINIO_ENDPOINT=http://minio:9000</span></span><br><span class="line">      <span class="comment"># - MINIO_ACCESS_KEY=$&#123;MINIO_ROOT_USER&#125;</span></span><br><span class="line">      <span class="comment"># - MINIO_SECRET_KEY=$&#123;MINIO_ROOT_PASSWORD&#125;</span></span><br><span class="line">      <span class="comment"># - MINIO_BUCKET=your-bucket</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">mysql</span>, <span class="string">redis</span>, <span class="string">nacos</span>, <span class="string">minio</span>]</span><br><span class="line">    <span class="attr">ports:</span> [<span class="string">&quot;7074:7074&quot;</span>]</span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">nginx:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.25</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">depends_on:</span> [<span class="string">gateway</span>]</span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;80:80&quot;</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./nginx/conf.d:/etc/nginx/conf.d</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./frontend/web:/usr/share/nginx/html</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./frontend/admin:/usr/share/nginx/html/admin</span></span><br><span class="line">    <span class="attr">networks:</span> [<span class="string">easylive-net</span>]</span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 放在 easylive-server/easylive-cloud/easylive-cloud-gateway/Dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> eclipse-temurin:<span class="number">8</span>-jre</span><br><span class="line"><span class="keyword">ENV</span> TZ=Asia/Shanghai</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> target/*.jar app.jar</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">7071</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;java&quot;</span>,<span class="string">&quot;-Xms<span class="variable">$&#123;JAVA_XMS:-256m&#125;</span>&quot;</span>,<span class="string">&quot;-Xmx<span class="variable">$&#123;JAVA_XMX:-512m&#125;</span>&quot;</span>,<span class="string">&quot;-jar&quot;</span>,<span class="string">&quot;/app/app.jar&quot;</span>]</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 打包全部（跳过测试）</span><br><span class="line">cd /path/to/easylive-springcloud/easylive-server</span><br><span class="line">./mvnw -v || mvn -v</span><br><span class="line">mvn -DskipTests clean package</span><br><span class="line"></span><br><span class="line"># 构建镜像（五个服务）</span><br><span class="line">docker build -t easylive-cloud-gateway:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-gateway</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-admin:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-admin</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-web:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-web</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-interact:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-interact</span><br><span class="line"></span><br><span class="line">docker build -t easylive-cloud-resource:latest \</span><br><span class="line">  easylive-cloud/easylive-cloud-resource</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name _;</span><br><span class="line"></span><br><span class="line">  # 用户端 Web 静态</span><br><span class="line">  root /usr/share/nginx/html;</span><br><span class="line">  index index.html;</span><br><span class="line"></span><br><span class="line">  # 管理端静态（访问 /admin/）</span><br><span class="line">  location /admin/ &#123;</span><br><span class="line">    alias /usr/share/nginx/html/admin/;</span><br><span class="line">    try_files $uri $uri/ /admin/index.html;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # 反向代理到网关（和 gateway 的路由保持一致）</span><br><span class="line">  location /web/       &#123; proxy_pass http://gateway:7071/web/; &#125;</span><br><span class="line">  location /interact/  &#123; proxy_pass http://gateway:7071/interact/; &#125;</span><br><span class="line">  location /user/      &#123; proxy_pass http://gateway:7071/user/; &#125;</span><br><span class="line">  location /file/      &#123; proxy_pass http://gateway:7071/file/; &#125;</span><br><span class="line">  location /adminapi/  &#123; proxy_pass http://gateway:7071/admin/; &#125; # 避免静态路径冲突，给管理端 API 换前缀</span><br><span class="line"></span><br><span class="line">  proxy_set_header Host              $host;</span><br><span class="line">  proxy_set_header X-Real-IP         $remote_addr;</span><br><span class="line">  proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;</span><br><span class="line">  proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 用户端</span><br><span class="line">cd /path/to/easylive-springcloud/easylive-front/easylive-front-web</span><br><span class="line">npm ci || npm install</span><br><span class="line">npm run build</span><br><span class="line">sudo cp -r dist/* /opt/easylive/frontend/web/</span><br><span class="line"></span><br><span class="line"># 管理端</span><br><span class="line">cd /path/to/easylive-springcloud/easylive-front/easylive-front-admin</span><br><span class="line">npm ci || npm install</span><br><span class="line">npm run build</span><br><span class="line">sudo mkdir -p /opt/easylive/frontend/admin</span><br><span class="line">sudo cp -r dist/* /opt/easylive/frontend/admin/</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm --network easylive_easylive-net -it \</span><br><span class="line">  minio/mc sh -c &quot;</span><br><span class="line">mc alias set minio http://minio:9000 $&#123;MINIO_ROOT_USER&#125; $&#123;MINIO_ROOT_PASSWORD&#125; &amp;&amp; \</span><br><span class="line">mc mb -p minio/easylive &amp;&amp; \</span><br><span class="line">mc anonymous set download minio/easylive&quot;</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">datasource:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">jdbc:mysql://mysql:3306/easylive?serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;allowMultiQueries=true&amp;useSSL=false</span></span><br><span class="line">    <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">$&#123;MYSQL_ROOT_PASSWORD&#125;</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">host:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/easylive</span><br><span class="line">docker compose pull   # 第一次可忽略</span><br><span class="line">docker compose up -d  # 启动</span><br><span class="line">docker compose ps     # 查看状态</span><br><span class="line">docker logs -f gateway</span><br><span class="line">docker logs -f admin</span><br><span class="line">docker logs -f web</span><br><span class="line">docker logs -f interact</span><br><span class="line">docker logs -f resource</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y certbot python3-certbot-nginx</span><br><span class="line">sudo certbot --nginx -d your.domain.com -m your@email \</span><br><span class="line">  --agree-tos --no-eff-email --redirect</span><br></pre></td></tr></table></figure><hr><p><strong>User</strong></p><p>4核8g的服务器是否够用能把所有的环境都配上呢，保险起见我是不是应该换个4核8g的服务器</p><hr><p><strong>Cursor</strong></p><p>结论先说：</p><ul><li>4核8G基本能把全套（MySQL/Redis/Nacos/Minio/ES/RocketMQ/Seata + 5个Java服务 + 网关）跑起来，但比较“紧”，需要严格限内存与低负载场景，属于可用但不太宽裕。</li><li>若计划“全部组件长期开启 + 有一定并发”，建议至少换到4核8G；若要更稳，优先把 ES 或 RocketMQ 单独拆机，或直接上更高规格（如8核16G）。</li></ul><p>快速内存预算（保守建议，单位≈GiB）：</p><ul><li>Nacos: 0.5</li><li>MySQL: 0.5–1.0（取决于 innodb_buffer_pool_size）</li><li>Redis: 0.1–0.3</li><li>Minio: 0.3–0.5</li><li>RocketMQ: 0.8–1.2（namesrv 0.3–0.5，broker 0.5–0.7）</li><li>Elasticsearch: 1.0–2.0（堆1–2G，且需 vm.max_map_count）</li><li>Seata: 0.3–0.5</li><li>5个SpringBoot服务: 1.3–2.5（每个 256–512M）</li><li>合计：约 5.3–8.5G（随设置和负载浮动）<br>=&gt; 4核8G在“全部开启”时边缘可用，需非常克制的JVM与DB配置。</li></ul><p>给你两种选择：</p><ul><li>想省事稳一点：换成4核8G（或更高），然后严格控内存即可全开；更理想是把 ES 或 RocketMQ 独立出去。</li><li>先不换服务器：保留4核4G/8G，只启核心链路（MySQL/Redis/Nacos/Minio/网关+业务服务），把 ES/RocketMQ/Seata 暂时关闭或托管到云上，等业务量起来再扩。</li></ul><p>若坚持在4核8G全开运行，务必：</p><ul><li>JVM：所有Java进程统一 -Xms256m -Xmx512m（Nacos、各微服务、Seata、RocketMQ），ES 堆设 1G 起步。</li><li>MySQL：innodb_buffer_pool_size 512M 起；慢慢再调大。</li><li>开启2–4G swap 兜底（仅兜底，不可依赖）。</li><li>用 docker-compose 限制每个容器内存并监控 docker stats。</li><li>优先上线无强依赖的路径；ES/RocketMQ 负载上来后优先拆分或升配。</li></ul><p>简短建议：</p><ul><li>如果你希望“一台机全家桶 + 可留有余量”，我建议换到4核8G（更稳）或把 ES/RocketMQ 外置/托管。</li><li>如果是演示/低QPS场景，4核8G可行；4核4G就建议按我给的最小化编排先跑核心链路。</li></ul>]]></content>
    
    
    <summary type="html">微服务项目GQ Video项目部署</summary>
    
    
    
    <category term="项目相关" scheme="https://itgeqian.github.io/categories/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/"/>
    
    
    <category term="项目部署" scheme="https://itgeqian.github.io/tags/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/"/>
    
    <category term="GQ Video" scheme="https://itgeqian.github.io/tags/GQ-Video/"/>
    
  </entry>
  
  <entry>
    <title>MQ相关面试题</title>
    <link href="https://itgeqian.github.io/posts/75.html"/>
    <id>https://itgeqian.github.io/posts/75.html</id>
    <published>2025-10-06T00:19:03.000Z</published>
    <updated>2025-10-23T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-MQ">GQ MQ</h1><h2 id="我看到你的GQ-Video简历上提到了RocketMQ，你来讲讲你在这个项目上为什么用上了RocketMQ？">我看到你的GQ Video简历上提到了RocketMQ，你来讲讲你在这个项目上为什么用上了RocketMQ？</h2><ul><li><p>我们最初用的是“线程池 + Redis 列表”做异步，能用但有几个痛点：服务间耦合重、突发流量容易把线程和 Redis 顶满；失败重试、死信、消息追踪都要自己造轮子；一旦进程挂了，队列里的任务容易丢，排障也不直观。</p></li><li><p>所以我把“播放事件统计、转码任务”这两条链路迁到了 RocketMQ。好处很直接：</p><ul><li>彻底解耦：发布方只管发，消费方独立扩缩容；</li><li>抗峰值更稳：堆积可观测，消费端可以水平扩展；发布端响应时间明显变短；</li><li>可靠性提升：自动重试、死信队列、顺序/延时/事务消息这些能力都是现成的，任务丢失概率大幅下降；</li><li>可观测：Topic 堆积、耗时、轨迹一目了然，问题定位快。</li></ul><h3 id="你为什么考虑的是RocketMQ这个消息队列而不是RabbitMQ或者Kafka？">你为什么考虑的是RocketMQ这个消息队列而不是RabbitMQ或者Kafka？</h3></li><li><p>之所以选 RocketMQ，而不是 RabbitMQ 或 Kafka，我主要考虑了这个项目的特点：</p><ul><li>对 RabbitMQ：它路由模型很灵活，但吞吐相对没那么高；<strong>延时消息要装插件</strong>，顺序保证容易受限于单队列瓶颈。我们的“播放事件”和“转码发布**”更偏大吞吐+延时/顺序/重试**，RocketMQ 原生支持更合适。</li><li>对 Kafka：吞吐极强，做日志/流式计算非常好。但业务型消息常用的“单条精确重试、死信、延时、事务消息”需要额外组件或自研，<strong>运维门槛也更高</strong>。我们更看重业务可靠投递和易用性，所以优先 RocketMQ。</li></ul></li><li><p>落地时我做了一个开关 <code>mq.enabled</code>：开启走 MQ，关闭就回退到原来的“线程池 + Redis 队列”，可以灰度切换、出问题一键回滚。幂等用数据库唯一键或 Redis 做了防重。</p></li></ul><p>一句话总结：上 RocketMQ 后，我们把“重活、峰值、可靠性、可观测性”这些问题一次性解决了；对这个以业务消息为主的场景，RocketMQ 比 RabbitMQ 更省插件、比 Kafka 更贴合业务消息的开箱能力。</p><h2 id="你具体讲讲播放事件统计、转码任务这两个任务，没上MQ你是怎么实现的，用了MQ你又是怎么实现的？">你具体讲讲播放事件统计、转码任务这两个任务，没上MQ你是怎么实现的，用了MQ你又是怎么实现的？</h2><p>当然可以 👍 我帮你把这段技术回答改成一个<strong>更自然、面试口语化、容易讲顺的版本</strong>👇</p><hr><h3 id="💬-面试口语版回答（MQ-改造播放统计-转码任务）">💬 面试口语版回答（MQ 改造播放统计 &amp; 转码任务）</h3><p>我用两分钟把“上 MQ 前后”的差异讲清楚。</p><hr><h4 id="一、没上-MQ-之前">一、没上 MQ 之前</h4><p>那时候我们还没引入消息队列，用的是「<strong>线程池 + Redis 列表</strong>」来异步处理任务。</p><ul><li><p><strong>播放事件</strong>：<br>前端上报播放，我这边直接把事件丢进 Redis 列表（LPUSH），后台有个线程池 while(true) 从列表里取（RPOP），<br>做三件事：视频播放数 +1、写播放历史、同步 ES 计数。</p><p>但问题挺多的：高峰期线程容易打满、Redis 队列堆积难监控，失败重试、死信都得自己写。进程挂了也不好排查。</p></li><li><p><strong>转码任务</strong>：<br>用户投稿上传完视频，我也是把转码任务信息塞进 Redis 列表，然后线程池轮询去拿，用 FFmpeg 转码、切片、传对象存储、最后更新数据库状态。<br>同样的问题：并发不好控、延时触发不方便、重试补偿全靠自己维护。</p></li></ul><hr><h4 id="二、上-MQ（RocketMQ）之后">二、上 MQ（RocketMQ）之后</h4><p>后来我们用 RocketMQ 做异步解耦，效果挺明显。</p><p>我设计了两个 Topic：</p><ul><li><code>video-play</code> 专门处理播放事件</li><li><code>video-transcode</code> 处理转码任务</li></ul><p>然后写了一个通用发布器（Publisher），再配两个 Consumer。<br>另外加了个 <code>mq.enabled</code> 开关，可以灰度切换或快速回退到 Redis 方案。</p><ul><li><strong>播放事件这块</strong>：<br>发布端接到上报后，直接把事件对象发到 MQ，不再阻塞主线程。<br>消费端收到后，还是那三件事：数据库 +1、播放历史 upsert、ES 同步计数。<br>可靠性方面 RocketMQ 自带重试、死信、堆积可查，我还做了幂等处理（比如用 userId+videoId+fileIndex 做唯一键）。</li><li><strong>转码任务这块</strong>：<br>用户提交稿件或合并分片后，我发一条转码消息到 <code>video-transcode</code>。<br>消费端收到后调转码组件，用 FFmpeg 转码、上传 MinIO、更新状态。<br>并发我用 Semaphore 控制；异常重试、超出次数进死信队列，支持延时重试退避。</li></ul><hr><h4 id="三、上-MQ-之后的变化">三、上 MQ 之后的变化</h4><ul><li><strong>性能上</strong>：主流程只负责发消息，响应速度更快。</li><li><strong>稳定性</strong>：堆积看得见，消费可水平扩，不容易被线程卡死。</li><li><strong>可靠性</strong>：MQ 自带重试、死信、轨迹，可观测性很好。</li><li><strong>扩展性</strong>：以后要加统计维度或新转码逻辑，只需多加个消费者，不改主流程。</li></ul><hr><h4 id="✅-一句话总结">✅ 一句话总结</h4><blockquote><p>以前用“线程池 + Redis 列表”能跑，但维护成本高、峰值容易崩；<br>上了 RocketMQ 后，我改成“发布订阅”模型，用它的重试、死信、延时和监控能力，把可靠性和扩展性都拉满，还能随时灰度回退，整体更稳更可控。</p></blockquote><hr><p>要不要我帮你再压缩成「30 秒速答版」？适合一开口就能讲流畅的那种。</p><h2 id="说一下-RocketMQ-中关于事务消息的实现？">说一下 RocketMQ 中关于事务消息的实现？</h2><p>这个问题其实就是在考“<strong>RocketMQ 怎么保证消息和本地事务的一致性</strong>”。<br>RocketMQ 用的是<strong>两阶段提交 + 事务回查</strong>机制。</p><h3 id="第一阶段：发送半消息（Half-Message）">第一阶段：发送半消息（Half Message）</h3><p>当我发送事务消息时，生产者会先往 MQ 里发一个“半消息”，也叫 <strong>Prepared 消息</strong>。<br>这个消息已经写入 Broker，但对消费者是<strong>不可见的</strong>。<br>然后生产者执行自己的本地事务，比如扣库存、加积分这些业务逻辑。</p><h3 id="第二阶段：提交或回滚">第二阶段：提交或回滚</h3><p>本地事务执行完后有三种结果：</p><ul><li>成功：生产者告诉 MQ “我这边事务 OK 了”，MQ 把半消息改成 <strong>正式消息</strong>，消费者就能看到。</li><li>失败：生产者通知 MQ 回滚，半消息就会被删除。</li><li>没回消息：如果 MQ 一直收不到 commit 或 rollback，它会<strong>主动回查</strong>。</li></ul><p>事务回查（Transaction Check）<br>RocketMQ 会定期去问生产者：“你上次那个事务到底成了没？”<br>生产者实现 checkLocalTransaction 回调，返回三种状态：</p><ul><li>COMMIT_MESSAGE → 确认提交</li><li>ROLLBACK_MESSAGE → 回滚消息</li><li>UNKNOWN → 还没确定，Broker 过一会儿再问</li></ul><p>这样即使网络异常、应用重启，也能靠回查机制最终确认消息状态。</p><h3 id="为什么要这么设计？">为什么要这么设计？</h3><p>如果不用事务消息，而是“本地事务先提交，再发消息”，一旦第二步发消息失败，就会造成<strong>业务成功但消息丢</strong>，数据不一致。<br>事务消息相当于<strong>先发半消息 → 执行业务 → 最后 commit</strong>，<br>就算 commit 消息失败，MQ 还能回查，最终也能补回来，保证一致性。</p><h3 id="小结">小结</h3><blockquote><p>RocketMQ 的事务消息通过“半消息 + 本地事务 + 回查机制”实现两阶段提交，<br>确保消息状态和业务事务状态保持一致，即使中途宕机也能恢复。</p></blockquote><h2 id="什么是消息队列？">什么是消息队列？</h2><blockquote><p>消息队列是一种异步通信机制，用于在分布式系统中解耦发送方和接收方的通信。它通过在消息生产者和消费者之间引入一个中间缓冲区（broker），将消息存储在broker中，然后由消费者从brker中读取和处理消息。</p></blockquote><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/zpA03afg_Snipaste_2025-11-12_17-37-08_mianshiya.png" alt="Snipaste_2025-11-12_17-37-08.png" width="100%" />我举个最常见的例子来说： 假设服务 A 每秒要发 200 个请求给服务 B，但服务 B 一秒只能处理 100 个。 这时候如果直接调用，B 很快就被压垮了。那怎么办？这时候我们就在中间加一层“消息队列”。<p>A 不再直接把请求发给 B，而是先把消息丢进队列，B 再按照自己的节奏、自己的处理能力，从队列里一点点取出来消费。<br>这样，A 和 B 就被队列隔离开了，互不影响。</p><h3 id="消息队列到底解决了什么问题？-消息队列的作用">消息队列到底解决了什么问题？(消息队列的作用)</h3><ol><li>异步处理</li></ol><ul><li><p>以前 A 发完请求得等 B 处理完才能继续，现在有了 MQ，A 发完消息直接返回。</p></li><li><p>这样响应更快、系统吞吐量也更高。流量削峰（流量控制）<br>在高峰期，比如大促、秒杀时，请求量会瞬间暴增。<br>消息队列可以当“缓冲层”，先把请求堆起来，消费者慢慢消费，防止系统被冲垮。<br>这也是很多系统抗压的关键。</p></li><li><p>比如：下单之后再去发短信、发邮件这种操作，其实不需要同步完成，放 MQ 里异步处理就行。</p></li></ul><ol start="2"><li>服务解耦</li></ol><ul><li>有了消息队列，发送方和接收方就不再强绑定。</li><li>A 只负责“发消息”，根本不用知道是谁来消费。</li><li>将来如果要多加几个消费者，比如一个做日志，一个做分析，直接订阅这个队列就行，完全不用改 A。</li></ul><ol start="3"><li>流量削峰（流量控制）</li></ol><ul><li>在高峰期，比如大促、秒杀时，请求量会瞬间暴增。</li><li>消息队列可以当“缓冲层”，先把请求堆起来，消费者慢慢消费，防止系统被冲垮。</li><li>这也是很多系统抗压的关键。</li></ul><blockquote><p>消息队列的核心价值是：<br>解耦、异步、削峰。<br>它让系统更快（异步），更松耦合（解耦），也更稳（削峰）。</p></blockquote><h2 id="为什么需要消息队列？">为什么需要消息队列？</h2><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/MFAQPXm0_Snipaste_2025-11-12_17-37-08_mianshiya.png" alt="Snipaste_2025-11-12_17-37-08.png" width="100%" />我举个最常见的例子来说：假设服务 A 每秒要发 200 个请求给服务 B，但服务 B 一秒只能处理 100 个。这时候如果直接调用，B 很快就被压垮了。<p>那怎么办？<br>这时候我们就在中间加一层“消息队列”。</p><p>A 不再直接把请求发给 B，而是先把消息丢进队列，B 再按照自己的节奏、自己的处理能力，从队列里一点点取出来消费。<br>这样，A 和 B 就<strong>被队列隔离开了</strong>，互不影响。</p><h3 id="消息队列的典型应用场景：">消息队列的典型应用场景：</h3><ul><li>订单系统：在电商系统中，订单的创建、支付、发货等步骤可以通过消息队列进行异步处理和解耦。</li><li>日志处理：使用消息队列将日志从应用系统传输到日志处理系统，实现实时分析和监控。</li><li>任务调度：在批量任务处理、任务调度系统中，通过消息队列将任务分发给多个工作节点，进行并行处理。</li><li>数据同步：在数据同步系统中，消息队列可以用于将变更的数据异步同步到不同的存储系统或服务。</li></ul><h3 id="那消息队列到底解决了什么问题？">那消息队列到底解决了什么问题？</h3><ol><li>异步处理</li></ol><ul><li><p>以前 A 发完请求得等 B 处理完才能继续，现在有了 MQ，A 发完消息直接返回。</p></li><li><p>这样响应更快、系统吞吐量也更高。流量削峰（流量控制）<br>在高峰期，比如大促、秒杀时，请求量会瞬间暴增。<br>消息队列可以当“缓冲层”，先把请求堆起来，消费者慢慢消费，防止系统被冲垮。<br>这也是很多系统抗压的关键。</p></li><li><p>比如：下单之后再去发短信、发邮件这种操作，其实不需要同步完成，放 MQ 里异步处理就行。</p></li></ul><ol start="2"><li>服务解耦</li></ol><ul><li>有了消息队列，发送方和接收方就不再强绑定。</li><li>A 只负责“发消息”，根本不用知道是谁来消费。</li><li>将来如果要多加几个消费者，比如一个做日志，一个做分析，直接订阅这个队列就行，完全不用改 A。</li></ul><ol start="3"><li>流量削峰（流量控制）</li></ol><ul><li>在高峰期，比如大促、秒杀时，请求量会瞬间暴增。</li><li>消息队列可以当“缓冲层”，先把请求堆起来，消费者慢慢消费，防止系统被冲垮。</li><li>这也是很多系统抗压的关键。</li></ul><blockquote><p>消息队列的核心价值是：<br>解耦、异步、削峰。<br>它让系统更快（异步），更松耦合（解耦），也更稳（削峰）。</p></blockquote><h2 id="说一下消息队列的模型有哪些？">说一下消息队列的模型有哪些？</h2><p>其实常见的消息队列模型主要有两种：<strong>队列模型和发布订阅模型</strong>。</p><h3 id="队列模型（也叫点对点模型）">队列模型（也叫点对点模型）</h3><p>这个模型就像排队买咖啡。<br>生产者（比如点单的人）把消息放进队列，<br>消费者（比如咖啡师）从队列里一个个取消息来处理。</p><p>特点是：</p><ul><li>每条消息只会被一个消费者处理一次（谁先拿到谁处理）。</li><li>消费完消息就从队列中删掉了。</li></ul><p>这种模型适合“<strong>一个任务只需要一个人干</strong>”的场景，比如：<br>订单处理、视频转码、短信发送这种“谁处理都行”的任务分发场景。</p><h3 id="发布-订阅模型（Publish-Subscribe）">发布 / 订阅模型（Publish / Subscribe）</h3><p>这个模型就像微信公众号。<br>生产者（比如公众号）发一条消息到一个主题（Topic），<br>所有订阅这个主题的消费者（比如订阅号的用户）都会同时收到。</p><p>特点是：</p><ul><li>一条消息会被多个订阅者同时收到。</li><li>特别适合广播通知、实时推送、监控告警这类场景。</li></ul><p>比如我发布一条“系统更新通知”，只要订阅了这个 Topic 的系统都能收到消息。</p><blockquote><p>消息队列主要有两种模型：<br><strong>队列模型</strong>   一条消息只被一个消费者处理，适合任务分发；<br><strong>发布订阅模型</strong>  一条消息可以被多个消费者收到，适合广播通知。</p></blockquote><h2 id="消息队列设计成推消息还是拉消息？推拉模式的优缺点？">消息队列设计成推消息还是拉消息？推拉模式的优缺点？</h2><p>消息队列有两种消费模式：推（Push） 和 拉（Pull）。</p><ul><li>推模式：Broker 主动把消息推给消费者。</li><li>拉模式：消费者主动去 Broker 拉取消息。</li></ul><p>RocketMQ 和 Kafka 其实都选择了“<strong>拉模式</strong>”，只是 <strong>RocketMQ 的“推”其实是封装了长轮询的拉模式</strong>，<strong>也就是消费者在后台不断长轮询去拉消息，看起来像是 Broker 在推</strong>。<br>所以本质上还是拉，只是体验像推。</p><h3 id="优缺点对比一下">优缺点对比一下</h3><ul><li><p>推模式优点：消息能实时送达，延迟很低；</p><ul><li>缺点是如果消费者处理慢，Broker 一直推消息，容易把消费者压垮，尤其是高并发时不好做流控。</li></ul></li><li><p>拉模式优点：消费者自己掌握节奏，可以根据自身负载调节拉取速率，避免过载，还能做批量拉取；</p><ul><li>缺点就是实时性稍差，拉得太慢可能延迟会高一点。</li></ul></li></ul><h3 id="为什么-RocketMQ-选拉模式">为什么 RocketMQ 选拉模式</h3><p>RocketMQ 和 Kafka 一样，选择拉模式主要是为了<strong>稳定</strong>和<strong>可控</strong>。<br>因为现在 MQ 都有“<strong>消息持久化</strong>”的需求——消息要先存好，再被消费。<br>所以用拉模式更安全，消费者按能力来拉，不会被推爆；再加上长轮询机制，也能兼顾实时性。</p><blockquote><p>一句话总结：<br>推模式实时但容易压垮消费者，<br>拉模式可控但实时性略差。<br>RocketMQ 实际上是“伪推真拉”，底层用长轮询实现拉取，这样既能稳又能快。</p></blockquote><h2 id="RocketMQ-的事务消息有什么缺点？你还了解过别的事务消息实现吗？">RocketMQ 的事务消息有什么缺点？你还了解过别的事务消息实现吗？</h2><p>先讲 RocketMQ 事务消息的优缺点，再顺带提到其他方案对比一下。</p><h3 id="RocketMQ-事务消息的缺点">RocketMQ 事务消息的缺点</h3><ol><li><p>改造成本高<br>RocketMQ 的事务消息需要你去改造业务逻辑，把原本的发送逻辑拆成两步（半消息 + 提交），<br>还要实现一个回查接口 checkLocalTransaction，保证回查不会重复、不丢、不乱。<br>对已有业务侵入性比较大。</p></li><li><p>功能受限<br>它只支持单事务消息，没法处理跨多个 Topic 或多步骤的复杂分布式事务。<br>简单说，RocketMQ 的事务消息更偏“轻量分布式事务”，不是真正的全局事务。</p></li><li><p>可用性问题<br>如果 MQ 集群挂了，事务消息就没法继续执行。<br>因为事务消息机制是“先发半消息”，Broker 不可用时半消息发不出去，后续本地事务也没法往下走。<br>等于说 MQ 是事务执行的关键环节，一旦不可用整个流程都卡住。</p></li></ol><h3 id="其他事务消息方案">其他事务消息方案</h3><ol><li><p>Kafka 事务消息<br>Kafka 的事务偏“生产者侧原子提交”，主要是保证“写入消息 + 提交 offset”一致，<br>更适合流式计算和 Exactly Once 语义，不太像 RocketMQ 这种业务型事务。</p></li><li><p>本地消息表（Outbox Pattern）<br>很多公司其实用这个方案。<br>就是业务操作和消息写入放在同一个本地事务里，然后异步任务去扫消息表发 MQ。<br>好处是实现简单、无 MQ 依赖，坏处是延迟略高、需要额外表和任务管理。</p></li><li><p>Seata 的 AT 模式 / TCC 模式<br>这类属于真正的分布式事务框架，强调强一致。<br>优点是自动补偿，缺点是侵入性更强，对性能影响更大。</p></li></ol><blockquote><p>小结<br>RocketMQ 的事务消息是通过“半消息 + 本地事务 + 回查”实现最终一致性的，但也有三个主要缺点：<br>一是改造成本高，要改业务逻辑并实现回查接口；<br>二是功能有限，只支持单事务，不适合跨 Topic；<br>三是依赖 MQ 可用性，Broker 挂了事务就卡住。<br>其他常见方案像 本地消息表 更简单易用，Seata 强一致但性能开销大。<br>所以 RocketMQ 的事务消息更适合“高可用、最终一致”的业务场景。</p></blockquote><h2 id="为什么-RocketMQ-不使用-Zookeeper-作为注册中心呢？而选择自己实现-NameServer？">为什么 RocketMQ 不使用 Zookeeper 作为注册中心呢？而选择自己实现 NameServer？</h2><h3 id="RocketMQ-为什么要自主设计一个-NameServer，而不用其他现成的注册中心-zookeeper，nacos？">RocketMQ 为什么要自主设计一个 NameServer，而不用其他现成的注册中心 zookeeper，nacos？</h3><p>答:这个问题直击 RocketMQ 的设计核心，<strong>因为 RocketMQ 的核心是金融，电商这类非常灵活的业务场景服务的</strong>，这使得 RocketMQ 的整个设计思想和 Kafka 这样追求极致的吞吐的消息中间件有根本的区别，在保证高性能的同时，对于服务的可靠性也要做到极致。</p><ul><li>一方面 NameServer 采用一种极为轻量级的集群方案，每个 NameServer 节点之间不需要和集群当中的其他节点发生任何的数据交互，这样可以保证 NameServer 集群当中只要有任何一个节点正常工作，那么整个 NameServer 集群就能够保持正常。</li><li>另一方面，业务的频繁更迭，使得 RocketMQ 也需要及时进行升级，自主研发的 NameServer 可以更灵活的应对新的业务场景</li></ul><h2 id="消息队列如何处理重复消息（保证消息的幂等性）？">消息队列如何处理重复消息（保证消息的幂等性）？</h2><blockquote><p>首先，在消息队列里<strong>重复消息是一定会发生的</strong>。无论是 MQ 重投、网络抖动、Broker 写入成功但生产者没收到 ACK，或者消费者消费成功但没来得及提交 offset，都会导致同一条消息被多次投递。所以我们不能寄希望于“消息只来一次”，<strong>真正可靠的做法是让消费者的处理逻辑具有幂等性</strong>。</p></blockquote><h3 id="1-核心思路：让业务逻辑幂等（处理多次结果一样）">1. 核心思路：让业务逻辑幂等（处理多次结果一样）</h3><h4 id="①-基于唯一幂等号（业务-ID-消息-ID）防重复"><strong>① 基于唯一幂等号（业务 ID / 消息 ID）防重复</strong></h4><p>给消息里加一个唯一 ID（比如订单号、业务流水号、UUID）。<br>消费者在处理前<strong>先检查这个 ID 是否处理过</strong>：</p><ul><li>处理过 → 直接跳过</li><li>没处理过 → 执行并记录这个 ID</li></ul><p>可以把这个记录放在：</p><ul><li>Redis（高并发读写）</li><li>数据库（唯一索引、insert ignore）</li><li>业务表中的状态字段（如“已支付”、“已发货”）</li></ul><h4 id="②-利用数据库的唯一约束实现幂等"><strong>② 利用数据库的唯一约束实现幂等</strong></h4><p>例如 MySQL 使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert into</span> ... <span class="keyword">on</span> duplicate key <span class="keyword">update</span> ...</span><br></pre></td></tr></table></figure><p>或者条件判断：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> money <span class="operator">=</span> <span class="number">150</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> money <span class="operator">=</span> <span class="number">100</span>;</span><br></pre></td></tr></table></figure><p>无论执行业务多少次，结果相同。</p><h3 id="2-为什么不能从源头完全避免重复消息？">2. 为什么不能从源头完全避免重复消息？</h3><ul><li>生产者 → Broker 的确认可能丢</li><li>Broker 已写入但 ACK 丢了 → 生产者重发</li><li>消费者处理成功但 offset 未提交 → 新的消费者会再次消费<br>因此重复消息是 <strong>无法彻底避免的</strong>，<strong>只能在消费端处理幂等</strong>。</li></ul><h3 id="小结-2">小结</h3><blockquote><p>在 MQ 里，重复消息是无法彻底避免的，比如生产者重发、ACK 丢失、消费者 offset 未提交等。所以我们不依赖“消息只来一次”，而是让<strong>消费端具备幂等性</strong>。</p></blockquote><p><strong>常用的幂等处理方式有三种：</strong></p><ol><li><p><strong>唯一业务 ID 防重（最常用）</strong><br>消息里带一个唯一的幂等号，比如订单号、流水号。消费者处理前先查这个 ID 是否处理过，处理过就跳过。</p></li><li><p><strong>Redis 防重（SETNX）</strong><br>收到消息先执行 SETNX，成功才继续处理，失败说明重复消费。</p></li><li><p><strong>数据库幂等（最终兜底）</strong></p><ul><li>条件更新：<code>update ... where status = 'UNPAID'</code></li><li>唯一键约束：<code>insert ... on duplicate key update</code><br>保证重复执行不会影响最终结果。</li></ul></li></ol><p><strong>一句话总结：</strong></p><blockquote><p><strong>重复消息不可避免，但重复消费可控。核心是：唯一业务 ID + Redis 去重 + DB 幂等更新，执行多次结果保持一致。</strong></p></blockquote><h3 id="举个例子-订单重复支付幂等处理">举个例子 订单重复支付幂等处理</h3><blockquote><p>在我们的支付项目里，支付成功后会把消息投到 MQ，因为回调重试、Broker ACK 丢失、offset 未提交等原因，消息可能会被多次投递。为了避免重复扣库存、重复更新订单，我们做了完整的幂等设计。</p></blockquote><p><strong>核心做法有三点：</strong></p><ol><li><p><strong>消息中携带唯一业务 ID（paymentId）</strong><br>每条支付消息都有唯一流水号，用于判断是否处理过。</p></li><li><p><strong>Redis 防重（SETNX）</strong><br>消费端先用 Redis 做一次快速幂等校验，SETNX 成功才继续处理。</p></li><li><p><strong>数据库层幂等</strong></p><ul><li>订单更新使用条件更新：<code>where pay_status = 'UNPAID'</code>，只会从未支付 → 已支付一次</li><li>支付记录表用唯一索引 <code>paymentId</code>，重复 insert 不会生效</li></ul></li></ol><p><strong>最终效果：</strong><br>无论 MQ 消息来几次，订单只更新一次，库存只扣一次，实现真正的幂等性。</p><h2 id="消息队列如何保证消息的有序性（顺序性）？">消息队列如何保证消息的有序性（顺序性）？</h2><blockquote><p>MQ 想保证消息顺序，核心思想其实只有一句话：<br><strong>让同一类相关的消息进入同一个队列，并让这个队列只被一个消费者、一个线程顺序处理。</strong></p></blockquote><p>下面按常见的 3 种方式总结：</p><h3 id="①-单生产者-单消费者-单队列（最简单）"><strong>① 单生产者 + 单消费者 + 单队列（最简单）</strong></h3><p>只要把消息全部发到一个队列，让消费者单线程处理，就天然有序。<br>缺点也很明显：<strong>性能瓶颈严重，不适合高并发场景</strong>。</p><h3 id="②-使用分区-分区键（Partition-Key）——Kafka-RocketMQ-最常用"><strong>② 使用分区 + 分区键（Partition Key）——Kafka / RocketMQ 最常用</strong></h3><p>做法：</p><ul><li>设置一个 <strong>顺序键（如订单号、用户 ID）</strong></li><li>用这个键做 hash 路由，让同一类业务消息始终进入同一个分区 / 队列<br>例如：订单号相同的消息全部进入 Queue #3</li></ul><p>这样每个分区内部天然是顺序的，又能通过多个分区 <strong>提高并发能力</strong>。</p><h3 id="③-使用顺序队列（Ordered-Queue）机制"><strong>③ 使用顺序队列（Ordered Queue）机制</strong></h3><p>像 RabbitMQ、某些 MQ 提供 <strong>原生顺序队列</strong>：</p><ul><li>存储顺序 = 投递顺序 = 消费顺序</li><li>但要求“同一顺序队列只能配一个消费者”，吞吐量有限</li></ul><h3 id="RocketMQ-的顺序消息（补充）"><strong>RocketMQ 的顺序消息（补充）</strong></h3><p>RocketMQ 的顺序消息除了分区路由外，还需要：</p><ul><li><strong>MessageQueueSelector 控制路由</strong></li><li><strong>MessageListenerOrderly 顺序消费模式</strong></li><li>同时在消费端 <strong>三层加锁</strong>（Broker Queue 锁、MessageQueue 锁、ProcessQueue 锁）来确保只有一个线程顺序处理队列消息</li></ul><h3 id="小结-3">小结</h3><blockquote><p>MQ 保证顺序的核心就是：<strong>让同一类消息进入同一个队列，并由一个消费者顺序处理</strong>。</p></blockquote><p>常见做法有三种：</p><ol><li><p><strong>单队列 + 单消费者</strong><br>所有消息进一个队列，单线程消费，天然有序，但吞吐量低。</p></li><li><p><strong>分区 + 分区键（最常用，如 Kafka、RocketMQ）</strong><br>通过 <strong>Partition Key（如订单号）</strong> 做路由，让同一业务的消息都落到同一个分区；分区内部天然有序，还能利用多分区并发。</p></li><li><p><strong>使用顺序队列（一些 MQ 原生支持）</strong><br>顺序队列保证写入顺序 = 投递顺序 = 消费顺序。</p></li></ol><p><strong>一句话总结：</strong></p><blockquote><p><strong>顺序性 = 相同消息路由到同一队列 + 单线程顺序消费。</strong></p></blockquote><h2 id="消息队列如何处理消息堆积？">消息队列如何处理消息堆积？</h2><blockquote><p>消息堆积本质上是 <strong>生产速度 &gt; 消费速度</strong>，导致大量消息积在队列里。所以解决思路就是提升消费能力、降低生产速度，或者清理无效消息。</p></blockquote><p>可以从以下几方面来处理：</p><h4 id="①-增加消费者的并发能力（最有效）"><strong>① 增加消费者的并发能力（最有效）</strong></h4><ul><li><strong>增加消费者线程数</strong> → 提高单实例并发度</li><li><strong>增加消费者实例数</strong> → 多机器一起消费，提高整体吞吐</li></ul><h4 id="②-优化消费者消费逻辑"><strong>② 优化消费者消费逻辑</strong></h4><ul><li>减少单条消息的处理时延</li><li>提高数据库批量写效率、减少 I/O</li><li>引入线程池异步处理</li></ul><h4 id="③-降低生产者速度（如果可控）"><strong>③ 降低生产者速度（如果可控）</strong></h4><ul><li>对生产端限流</li><li>消息分级，只优先处理关键消息</li></ul><h4 id="④-清理过期或无效消息"><strong>④ 清理过期或无效消息</strong></h4><p>如果某些消息已无业务价值，可以评估后丢弃，快速消化堆积。</p><h4 id="⑤-调整-MQ-配置-增加队列数"><strong>⑤ 调整 MQ 配置 / 增加队列数</strong></h4><ul><li>增加 Topic 的队列数量，提高并行度</li><li>调整 MQ 消费模式、拉取频率等配置</li></ul><h3 id="小结-4">小结</h3><blockquote><p>消息堆积主要是因为<strong>消费速度跟不上生产速度</strong>，所以解决方式就是提高消费能力或降低生产速度。</p></blockquote><p>常见处理办法 3 步：</p><ol><li><p><strong>扩大消费能力（最有效）</strong></p><ul><li>增加消费者实例数</li><li>增加消费者线程</li><li>增加 Topic 队列数，提高并行度</li></ul></li><li><p><strong>优化消费逻辑</strong></p><ul><li>减少单条消息处理时间</li><li>批量处理、减少 I/O、引入线程池</li></ul></li><li><p><strong>必要时限流或丢弃无效消息</strong></p><ul><li>控制生产端速度</li><li>清理过期/失败无意义的消息</li></ul></li></ol><p><strong>一句话总结：</strong></p><blockquote><p><strong>核心就是提升消费能力，加并发、加实例、提高效率；如果不行，就限流生产或清理无效消息。</strong></p></blockquote><h2 id=""></h2>]]></content>
    
    
    <summary type="html">我对MQ的相关理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="MQ" scheme="https://itgeqian.github.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>AI相关面试题</title>
    <link href="https://itgeqian.github.io/posts/69.html"/>
    <id>https://itgeqian.github.io/posts/69.html</id>
    <published>2025-10-05T00:19:03.000Z</published>
    <updated>2025-10-15T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-AI">GQ AI</h1><h2 id="什么是-RAG？RAG-的主要流程是什么？">什么是 RAG？RAG 的主要流程是什么？</h2><p>RAG (Retrieval-Augmented Generation)<strong>检索增强生成</strong></p><h3 id="什么是-RAG">什么是 RAG?</h3><p>官方定义：</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/TY0n0RgF_Snipaste_2025-11-12_21-01-16_mianshiya.png" alt="Snipaste_2025-11-12_21-01-16.png" width="70%" /></p><p>简单来说就是：RAG，全称是 Retrieval-Augmented Generation（检索增强生成）。<br>简单来说，<strong>它是一种让大模型“带脑子说话”的方式</strong>——<br>在 LLM 回答之前，<strong>先从外部知识库或企业文档里查到相关资料，再把这些资料注入到提示词中，让模型基于真实知识生成答案，这样能减少幻觉、提升准确度</strong>。</p><blockquote><p>幻觉？</p><ul><li>已读乱回</li><li>已读不回</li><li>似是而非</li></ul></blockquote><p>springai 中的 RAG</p><p><a href="https://docs.spring.io/spring-ai/reference/api/retrieval-augmented-generation.html">https://docs.spring.io/spring-ai/reference/api/retrieval-augmented-generation.html</a></p><p>springai alibaba 中的 RAG 叫做文档检索 (Document Retriever)<br><a href="https://java2ai.com/docs/1.0.0.2/tutorials/basics/retriever/?spm=5176.29160081.0.0.2856aa5cXggpMJ">https://java2ai.com/docs/1.0.0.2/tutorials/basics/retriever/?spm=5176.29160081.0.0.2856aa5cXggpMJ</a></p><h3 id="RAG-核心设计理念">RAG 核心设计理念</h3><p>RAG 技术就像给 AI 大模型装上了「实时百科大脑」，为了让大模型获取足够的上下文，以便获得更加广泛的信息源，通过先查资料后回答的机制，让 AI 摆脱传统模型的” 知识遗忘和幻觉回复” 困境</p><p>一句话</p><blockquote><p>类似考试时有不懂的，给你准备了小抄，对大模型知识盲区的一种补充</p></blockquote><h3 id="RAG-能干嘛">RAG 能干嘛</h3><p>通过引入外部知识源来增强 LLM 的输出能力，<strong>传统的 LLM 通常基于其训练数据生成响应，但这些数据可能过时或不够全面</strong>。RAG 允许模型在生成答案之前，从特定的知识库中检索相关信息，从而<strong>提供更准确和上下文相关的回答</strong></p><h3 id="RAG-流程">RAG 流程</h3><p><strong>索引和检索</strong><br>官方流程如下图：</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Mtjt7P8g_Snipaste_2025-11-12_21-13-30_mianshiya.png" alt="Snipaste_2025-11-12_21-13-30.png" width="60%" /></p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/SwT0eUYN_Snipaste_2025-11-12_21-13-59_mianshiya.png" alt="Snipaste_2025-11-12_21-13-59.png" width="60%" /></p><p>总结来说就是：</p><h4 id="①-索引阶段（Indexing）">① 索引阶段（Indexing）</h4><p>主要是“准备知识库”的过程：</p><ul><li>先加载各种原始数据，比如 PDF、Word、Markdown 等；</li><li>清洗解析成纯文本；</li><li>再把文本按段落或句子拆分成小块（chunk）；</li><li>用嵌入模型（Embedding Model）把每个块转换成向量；</li><li>最后把这些向量存入向量数据库中，方便后续做相似度搜索。</li></ul><blockquote><p>你可以理解为：这一步是“建知识库 + 做成能算距离的格式”。</p></blockquote><h4 id="②-检索阶段（Retrieval）">② 检索阶段（Retrieval）</h4><p>这一步是“模型答题前先查资料”：</p><ul><li>用户提问时，系统先把问题也转成向量；</li><li>在向量数据库中找到最相似的文本片段；</li><li>把这些相关内容和用户的问题拼在一起，送进大模型；</li><li>模型再基于这些外部知识生成最终回答。</li></ul><p>这样，模型不仅依靠自己的训练知识，还能结合实时的外部数据，回答更准确、更有依据。</p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/14LVnUDK_Snipaste_2025-11-12_21-17-27_mianshiya.png" alt="Snipaste_2025-11-12_21-17-27.png" width="20%" /></p><blockquote><p>一句话总结：<br>RAG = “查资料 + 再回答”。<br>它通过“索引阶段建知识库、检索阶段查知识”来增强大模型的上下文能力，<br>让回答更贴近事实、减少胡说八道。</p></blockquote><h2 id="什么混合检索？在基于大模型的应用开发中，混合检索主要解决什么问题？">什么混合检索？在基于大模型的应用开发中，混合检索主要解决什么问题？</h2><h3 id="什么是混合检索？它在大模型应用中主要解决什么问题？">什么是混合检索？它在大模型应用中主要解决什么问题？</h3><p>混合检索（Hybrid Retrieval）其实就是在 <strong>RAG（检索增强生成）</strong> 场景下，把<strong>向量检索</strong>和<strong>关键词检索</strong>结合起来用。<br>它的目标是利用两种方式的互补优势，让检索结果既能“理解语义”，又能“精准命中”，整体更全面、更准确。</p><h3 id="举个例子：">举个例子：</h3><p>比如用户问“猫捕老鼠”，</p><ul><li>向量检索能理解语义关系，比如把“猫”联想到“猫科动物”，</li><li>但如果问“iPhone 15”这种专有名词，向量检索可能模糊匹配不到。<br>这时候关键词检索就能精确命中这些具体词。</li></ul><p>所以混合检索的核心思想就是：</p><blockquote><p><strong>语义理解靠向量检索，精准命中靠关键词检索，两者结合取长补短。</strong></p></blockquote><h3 id="在工程实现上">在工程实现上</h3><p>混合检索一般会：</p><ol><li><strong>并行执行两种检索</strong>（向量 + 关键词）；</li><li>然后用一个融合算法（比如 QDRF 或重排模型）把结果合并、去重、排序；</li><li>最后把最优结果送进大模型生成答案。</li></ol><p>在实际落地中，比如 <strong>LlamaIndex + ElasticSearch</strong> 的组合就很常见：<br>LlamaIndex 负责语义检索，ElasticSearch 负责关键词匹配。</p><h3 id="一句话总结：">一句话总结：</h3><blockquote><p>混合检索解决了大模型在“语义理解强但命中不准、关键词命中准但不懂语义”的矛盾，<br>让 RAG 系统既能“懂你在问什么”，又能“找对内容”。</p></blockquote><h2 id="RAG-的完整流程是怎么样的？">RAG 的完整流程是怎么样的？</h2><h4 id="①-索引阶段（Indexing）-2">① 索引阶段（Indexing）</h4><p>主要是“准备知识库”的过程：</p><ul><li>先加载各种原始数据，比如 PDF、Word、Markdown 等；</li><li>清洗解析成纯文本；</li><li>再把文本按段落或句子拆分成小块（chunk）；</li><li>用嵌入模型（Embedding Model）把每个块转换成向量；</li><li>最后把这些向量存入向量数据库中，方便后续做相似度搜索。</li></ul><blockquote><p>你可以理解为：这一步是“建知识库 + 做成能算距离的格式”。</p></blockquote><h4 id="②-检索阶段（Retrieval）-2">② 检索阶段（Retrieval）</h4><p>这一步是“模型答题前先查资料”：</p><ul><li>用户提问时，系统先把问题也转成向量；</li><li>在向量数据库中找到最相似的文本片段；</li><li>把这些相关内容和用户的问题拼在一起，送进大模型；</li><li>模型再基于这些外部知识生成最终回答。</li></ul><p>这样，模型不仅依靠自己的训练知识，还能结合实时的外部数据，回答更准确、更有依据。</p><h2 id="什么提示压缩？为什么在-RAG-中需要提示压缩？">什么提示压缩？为什么在 RAG 中需要提示压缩？</h2><h3 id="什么是提示压缩？为什么在-RAG-中需要它？">什么是提示压缩？为什么在 RAG 中需要它？</h3><p>提示压缩（Prompt Compression）简单来说，就是在 RAG（检索增强生成） 里，<br><strong>把从知识库检索出来的大量文档内容进行“精简、去噪、压缩”</strong>，<br><strong>只保留最有用、最相关的信息，再送进大模型里</strong>。<br>这样既能减少无关内容占用 token，又能让模型专注在关键信息上，生成更精准的答案。</p><h3 id="为什么需要提示压缩？主要有三点原因：">为什么需要提示压缩？主要有三点原因：</h3><ul><li>模型上下文有限</li><li>检索内容可能冗余或噪声多</li><li>性能与成本考虑</li></ul><h3 id="举个例子">举个例子</h3><p>比如用户问：“如何优化代码性能？”<br>检索到的文档里可能有 10 页内容，其中 8 页是原理、2 页才是优化技巧。<br>提示压缩的作用就是自动“提炼出那 2 页关键信息”，再结合问题注入模型。<br>最终模型生成的答案会更聚焦、更高效。</p><blockquote><p>一句话总结：<br>提示压缩就是“先浓缩再喂模型”。<br>它在 RAG 中用来解决上下文超限、信息冗余和成本过高的问题，<br>让模型既能看到核心内容，又能保持高质量输出。</p></blockquote><h2 id="在-RAG-中的-Embedding-嵌入是什么？">在 RAG 中的 Embedding 嵌入是什么？</h2><p>官网-嵌入模型 (Embedding Model)</p><p><a href="https://java2ai.com/docs/1.0.0.2/tutorials/basics/embedding/?spm=5176.29160081.0.0.2856aa5cXggpMJ">https://java2ai.com/docs/1.0.0.2/tutorials/basics/embedding/?spm=5176.29160081.0.0.2856aa5cXggpMJ</a></p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Biq0HXUO_Snipaste_2025-11-18_16-28-54_mianshiya.png" alt="Snipaste_2025-11-18_16-28-54.png" width="50%" /></p><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/0iPbfGmw_Snipaste_2025-11-18_16-30-39_mianshiya.png" alt="Snipaste_2025-11-18_16-30-39.png" width="50%" /></p><p>在 RAG 里，Embedding（嵌入）就是 <strong>把文本、图像和视频变成“能让机器听得懂的数字向量”</strong> 的过程。</p><p>可以把它理解成：</p><blockquote><p>“把一句话翻译成一串数字，这些数字能表达它的语义含义。”</p></blockquote><p>Embedding 做的，就是把这些语义关系映射到一个高维空间里：</p><ul><li>语义相近的内容 → 数字距离靠得很近（聚在一起）</li><li>语义不相关的内容 → 距离会很远（分散开）</li></ul><h3 id="Embedding-在-RAG-里具体干什么？">Embedding 在 RAG 里具体干什么？</h3><p>RAG（检索增强生成）其实分两步：</p><p>① 先把所有知识库的文本 embed 成向量存到向量数据库（FAISS、Milvus 等）。</p><p>② 用户提问时，也把问题 embed 成向量然后计算两个向量的距离（比如余弦相似度）。<br>找到“最接近的问题/文档块”，再把内容喂给大模型回答。</p><blockquote><p>Embedding 决定了你的 RAG 能不能“读懂问题”和“找到正确内容”。 它是 RAG 的核心基石。</p></blockquote><h2 id="在-RAG-中，你如何选择-Embedding-Model-嵌入模型，需要考虑哪些因素？">在 RAG 中，你如何选择 Embedding Model 嵌入模型，需要考虑哪些因素？</h2><p>RAG 常用的 embedding 模型主要分三类：<br>① 开源模型，比如 BGE、M3E、Sentence Transformers、E5、GTE；<br>② 商业 embedding，比如 OpenAI text-embedding-3、Cohere、Google Gecko；<br>③ 大模型自带的向量接口，比如 GPT-4o、Qwen、Claude。<br>其中中文场景下 BGE 和 M3E 最常用；需要极致效果则用 OpenAI 或 Cohere。</p><h2 id="Copilot-模式和-Agent-模式的区别是什么？">Copilot 模式和 Agent 模式的区别是什么？</h2><p>Copilot 模式强调“<strong>协作</strong>”，<strong>用户主导、大模型辅助</strong>，需要多轮互动，比如写代码、生成文档。</p><p>Agent 模式强调“<strong>自主</strong>”，<strong>用户只给目标，Agent 会自动规划任务</strong>、自动调用工具并执行完整流程，更像一个 AI 管家。</p><p>两者最大的区别就是 自主性：Copilot 依赖用户驱动，而 Agent 是自驱动完成任务。</p><ul><li>Copilot = 助手（帮忙但全程听你的）</li><li>Agent = 执行官（你定目标，它全程帮你干会帮你规划）</li></ul><h2 id="什么是向量数据库？在基于大模型的应用开发中，向量数据库主要解决什么问题？">什么是向量数据库？在基于大模型的应用开发中，向量数据库主要解决什么问题？</h2><p>向量数据库就是专门用来<strong>存储和检索向量</strong>的系统，它能<strong>进行语义相似度搜索</strong>，而不是关键词匹配。</p><ul><li>比如 “肯德基” 和 “麦当劳” 在向量空间的距离会很近，而和 “新疆大盘鸡” 距离就远很多。</li></ul><h3 id="它解决了哪些核心问题">它解决了哪些核心问题</h3><h4 id="1-解决“高效的语义搜索”问题（关键词搜索不行）">1. 解决“高效的语义搜索”问题（关键词搜索不行）</h4><p>传统搜索是关键词匹配，比如你搜“天气”，只能匹配到包含天气两个字的内容。</p><p>但 RAG 需要的是语义搜索：</p><ul><li>用户问“上海今天下雨吗”</li><li>它也要能找到“上海今日天气预报”的内容</li></ul><p>向量数据库可以做到基于向量的“相似度搜索”，快速找到最相关的文本片段。</p><h4 id="2-解决“海量数据处理”问题">2. 解决“海量数据处理”问题</h4><p>大模型上下文是有限的（比如 8k、16k token），但企业知识库可能是几十万文档、上亿数据。<br>解决方案：</p><ul><li>所有文档 → 转成向量 → 存入向量数据库</li><li>查询时：只取“最相关”的 Top-K 文档送给大模型</li></ul><p>这样就能处理超大规模知识库。</p><ol start="3"><li>解决“实时交互”问题（低延迟、高吞吐）<br>像智能客服、智能问答、小模型 Agent 这种应用，都需要在几十毫秒内返回结果。</li></ol><p>向量数据库专门对这种“高并发 + 低延迟”的相似度检索做了优化。</p><h3 id="小结：">小结：</h3><p>向量数据库就是专门用来存储和检索向量的系统，它能进行语义相似度搜索，而不是关键词匹配。<br>在 RAG 应用中，它主要解决：找到最相关知识、处理海量数据、支持实时交互这三个核心问题。</p><h2 id="你都了解哪些向量数据库？如何选型？">你都了解哪些向量数据库？如何选型？</h2><h3 id="1-常见的向量数据库-向量检索方案">1. 常见的向量数据库/向量检索方案</h3><p>我接触过的主流向量库，大概可以分三类来说：</p><h4 id="专用向量数据库（自带服务）">专用向量数据库（自带服务）</h4><ul><li><strong>Milvus</strong><br>开源、功能比较全，支持大规模分布式存储和检索，社区很活跃，适合企业级、数据量特别大的推荐/搜索/RAG 场景。</li><li><strong>Pinecone</strong><br>全托管云服务，不用自己运维，开箱即用，性能也不错，但成本会相对高一些，更适合需要快速上线、对云厂商依赖没问题的团队。</li><li><strong>Weaviate</strong><br>支持向量 + 结构化 + 模糊搜索，Schema 比较灵活，对多模态/混合检索友好，做知识库、智能问答比较合适。</li><li><strong>Qdrant</strong><br>Rust 写的，性能不错，支持过滤、分片、副本等能力，部署也比较轻量，适合中小团队自建服务。</li><li><strong>Chroma</strong><br>偏轻量的本地向量库，Python 生态好，经常用在原型验证或本地 RAG Demo 里。</li></ul><h4 id="嵌入式-算法库">嵌入式/算法库</h4><ul><li><strong>Faiss</strong>（Facebook 出的）<br>更像是“向量检索算法库”，支持多种 ANN 索引结构和 GPU 加速，适合自己控制存储层、做离线或高性能向量检索，不直接提供服务能力。</li><li><strong>Annoy</strong><br>偏读多写少、“查询多、构建少”的场景，常用于推荐、相似度搜索的离线/准在线场景。</li></ul><h4 id="具备向量能力的“通用数据库-搜索引擎”">具备向量能力的“通用数据库 / 搜索引擎”</h4><ul><li>比如 <strong>OpenSearch / Elasticsearch</strong>、<strong>PostgreSQL + pgvector</strong>、<strong>ClickHouse</strong>、Redis 等，现在都支持向量检索。<br>优点是：一套系统里把<strong>结构化字段 + 全文检索 + 向量检索</strong>都做了，运维成本低，适合原来就大量用这些系统的团队。</li></ul><hr><h3 id="2-选型时我一般从哪些维度考虑？">2. 选型时我一般从哪些维度考虑？</h3><p>我会按几个维度和场景来选：</p><ol><li><p><strong>数据量 &amp; QPS 规模</strong></p><ul><li>小规模、PoC：Chroma、Weaviate、本地 SQLite/pgvector 就够了。</li><li>中等规模、需要高可用：Qdrant、Milvus。</li><li>超大规模、对 SLA 有要求又不想运维：Pinecone 这类托管服务。</li></ul></li><li><p><strong>团队技术栈 &amp; 运维能力</strong></p><ul><li>团队擅长 <strong>K8s / 云原生</strong>，并且有运维能力 → 选择 Milvus、Qdrant 这类专用向量库，性能和功能都比较强。</li><li>已经大量用 <strong>Elastic / Postgres</strong>，不想再引入新组件 → 优先考虑 ES/OpenSearch + 向量插件 或 pgvector，一套系统搞定。</li></ul></li><li><p><strong>功能需求</strong></p><ul><li>只要<strong>向量相似搜索</strong>，不怎么做复杂过滤 → Faiss / Annoy / 轻量库即可。</li><li>需要 <strong>向量 + 过滤条件 + 排序 + 多字段检索</strong> → Milvus、Qdrant、Weaviate 或 ES/OpenSearch 这种“向量 + 结构化/全文”混合检索更合适。</li></ul></li><li><p><strong>成本与上线速度</strong></p><ul><li>想<strong>快速上线 MVP</strong>：Pinecone/Weaviate Cloud 这类托管服务，几乎不用运维。</li><li>想长期可控、节省成本：自建 Milvus / Qdrant / 开源方案。</li></ul></li></ol><h3 id="3-“偏好组合”">3.“偏好组合”</h3><blockquote><p>小规模原型我一般用 <strong>Chroma 或 Weaviate</strong>；<br>线上中等规模业务会选 <strong>Qdrant 或 Milvus</strong> 做专用向量库；<br>如果公司本身 ES/Postgres 用得多，我会优先考虑 <strong>OpenSearch/ES + 向量插件</strong> 或 <strong>Postgres + pgvector</strong>，这样整体架构更简单；<br>对全球多 Region、SLA 要求高又不想自己运维的场景，会考虑 <strong>Pinecone</strong> 这类托管服务。</p></blockquote><h2 id="向量数据库原理是什么？-请简述下它的原理">向量数据库原理是什么？ 请简述下它的原理</h2><p>向量数据库的核心原理，其实就是一句话：<br><strong>把复杂的数据（文本、图片等）先变成向量，再通过高效的近似搜索算法，在海量向量里快速找到和查询最相似的那几个。</strong></p><h2 id="向量数据库的工作流程有哪些？请简述下">向量数据库的工作流程有哪些？请简述下</h2><p>向量数据库的核心目标是：<br><strong>把非结构化数据（如文本、图片）转成可计算的向量，并能快速做相似度检索。</strong></p><p>整体流程可以分成 <strong>五个步骤</strong>：</p><h4 id="①-数据处理（清洗与预处理）"><strong>① 数据处理（清洗与预处理）</strong></h4><p>对原始数据做清洗、去噪、归一化，提取结构化字段<br>如：标签、时间戳、作者信息等。</p><h4 id="②-向量化（模型生成向量）"><strong>② 向量化（模型生成向量）</strong></h4><p>使用 AI 模型（如 BERT、ResNet 等）提取特征，<br>把文本、图片等转换成高维向量。</p><h4 id="③-向量存储（高效格式）"><strong>③ 向量存储（高效格式）</strong></h4><p>向量与原始数据绑定，一起存入向量数据库，<br>常见使用分布式存储、块存储等方式。</p><h4 id="④-构建索引（HNSW-LSH-等-ANN-结构）"><strong>④ 构建索引（HNSW / LSH 等 ANN 结构）</strong></h4><p>为了加速搜索，对存储的向量建立高效的近似最近邻结构（ANN），<br>例如：</p><ul><li><strong>HNSW 图索引</strong></li><li><strong>LSH 哈希索引</strong></li></ul><h4 id="⑤-相似度检索（返回-Top-K）"><strong>⑤ 相似度检索（返回 Top-K）</strong></h4><p>用户查询时：</p><ol><li>查询内容也会先被转成向量</li><li>使用索引快速定位“可能相似”的向量</li><li>计算相似度（如余弦相似度）</li><li>返回最相似的 Top-K 条结果</li></ol><h3 id="小结">小结</h3><p><strong>向量数据库的流程就是：数据清洗 → 向量化 → 存储 → 建索引 → 相似检索，最终帮我们在海量数据中快速找到最相似的内容。</strong></p><h2 id="什么是-MCP-协议，它在-AI-大模型系统中的作用是什么？">什么是 MCP 协议，它在 AI 大模型系统中的作用是什么？</h2><h3 id="什么是MCP">什么是MCP</h3><p>MCP（Model Context Protocol）<strong>是一套让大模型（LLM）统一、安全地调用外部数据、工具、服务的标准协议</strong>。<br>就像 USB-C 统一了电子设备接口一样，<strong>MCP 统一了 AI 调用外部能力的方式</strong>。</p><h3 id="为什么需要-MCP？之前有什么痛点？">为什么需要 MCP？之前有什么痛点？</h3><p>以前大模型要调用工具时，每个工具都要重新写适配层（Function Calling），例如：</p><ul><li>微信写一套接口</li><li>Excel 写一套接口</li><li>Git 写一套接口</li><li>数据库再写一套……</li></ul><p>每个模型厂商都要写一遍，<strong>开发成本高、重复劳动严重</strong>。<br>而且不同模型（ChatGPT、DeepSeek、Claude）之间接口不兼容。</p><h4 id="MCP-解决的核心：统一标准，让工具写一次，所有兼容-MCP-的大模型都能调用。">MCP 解决的核心：统一标准，让工具写一次，所有兼容 MCP 的大模型都能调用。</h4><blockquote><p>“过去每个软件都要单独给 AI 做接口，现在 MCP 就像 USB-C，不用重复造轮子。”</p></blockquote><h3 id="MCP-的作用">MCP 的作用</h3><ul><li>MCP 的作用是<strong>让大模型具备一致的能力去访问“上下文资源”</strong>，例如工具、文件、数据库、API。</li><li>它让大模型不仅能“回答问题”，还能“主动调用服务”，真正变成一个可编排的智能体（Agent）。</li></ul><p align="center"><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Uy5RdEkq_Snipaste_2025-11-18_18-23-14_mianshiya.png" alt="Snipaste_2025-11-18_18-23-14.png" width="50%" /></p><h2 id="MCP-架构包含哪些核心组件？">MCP 架构包含哪些核心组件？</h2><p>MCP 的客户端-服务器架构：</p><h3 id="1-MCP-Host（主机）">1. MCP Host（主机）</h3><p>发起请求的应用，例如：</p><ul><li>ChatGPT</li><li>IDE（Cursor、VSCode）</li><li>AI Agent 应用</li></ul><p>它负责决定“什么时候需要外部工具”。</p><h3 id="2-MCP-Client（客户端）">2. MCP Client（客户端）</h3><p>Host 中的组件，负责维持与某个 MCP Server 的连接（1:1）。</p><p>可以理解为：<br>Host 的“工具管理器”。</p><h3 id="3-MCP-Server（服务器）">3. MCP Server（服务器）</h3><p>开发者编写的服务端，用来提供：</p><ul><li>工具（Tools）</li><li>上下文（Context）</li><li>资源（Resources）</li></ul><p>特点：只需要写一次，所有 MCP 模型都能用。</p><h3 id="4-Local-Resources（本地资源）">4. Local Resources（本地资源）</h3><p>例如：</p><ul><li>本地文件系统</li><li>本地数据库</li><li>本地配置</li></ul><p>服务器可安全访问。</p><h3 id="5-Remote-Resources（远程资源）">5. Remote Resources（远程资源）</h3><p>例如：</p><ul><li>Web API</li><li>云数据库</li><li>企业内部系统</li></ul><blockquote><p>结构可总结为一句话：<br>Host（模型端） → Client（连接管理） → Server（工具/数据提供者） → Resource（真实资源）</p></blockquote><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/2wqLacds_Snipaste_2025-11-18_18-25-31_mianshiya.png" alt="Snipaste_2025-11-18_18-25-31.png" width="100%" /><h2 id="MCP-协议支持哪两种模式？">MCP 协议支持哪两种模式？</h2><p>MCP 支持的通信模式</p><p><strong>STDIO</strong>（标准输入输出）</p><ul><li>常用于本地集成、命令行工具</li></ul><p><strong>SSE</strong>（服务器发送事件）</p><ul><li><p>用于 HTTP 流式长连接</p></li><li><p>支持流式输出结果（大模型常见）</p></li></ul><h2 id="MCP-与-Function-Calling-的区别是什么？">MCP 与 Function Calling 的区别是什么？</h2><table><thead><tr><th>技术</th><th>作用</th></tr></thead><tbody><tr><td><strong>Tool Calling</strong></td><td>让模型调用某个工具（例如执行一个 API）</td></tr><tr><td><strong>RAG</strong></td><td>让模型获取知识上下文（向量搜索）</td></tr><tr><td><strong>MCP</strong></td><td>让模型调用“更多更复杂的外部系统”，包括工具 + 数据 + 文件</td></tr></tbody></table><blockquote><p>RAG 解决“我知道什么”，ToolCalling 解决“我能做什么”，MCP 解决“我能连接谁”。</p></blockquote><h4 id="MCP-VS-ToolCalling">MCP VS ToolCalling</h4><ul><li>之前每个大模型(如DeepSeek、ChatGPT)需要为每个工具单独开发接口(FunctionCalling)，导致重复劳动</li><li>MCP通过统一协议<ul><li>开发者只需写一次MCP服务端，所有兼容MCP协议的模型都能调用，MCP让大模型从&quot;被动应答”变为”主动调用工具”</li><li>我调用一个MCP服务器就等价调用一个带有多个功能的Utils工具类，自己还不用受累携带</li></ul></li></ul><h2 id="MCP-的工作流程是什么？">MCP 的工作流程是什么？</h2><p>MCP 的流程分 5 步：</p><ol><li>客户端初始化后先从 MCP Server 获取工具列表；</li><li>用户提问后，客户端把问题和工具描述一起发给 LLM；</li><li>模型判断是否要调用工具，如果要就生成工具调用请求；</li><li>MCP Server 真正执行工具并返回结果；</li><li>最后模型整合执行结果生成最终回复。</li></ol><p>整个流程实现了 LLM 的“能力发现 → 决策 → 执行 → 汇总”的闭环。</p><h2 id="什么是工具调用-Tool-Calling？如何利用-Spring-AI-实现工具调用？">什么是工具调用 Tool Calling？如何利用 Spring AI 实现工具调用？</h2><h3 id="什么是工具调用（Tool-Calling）？">什么是工具调用（Tool Calling）？</h3><p>一句话：Tool Calling 就是让大模型“开口点单”，真正去干活的是我们注册的工具 / API。</p><blockquote><p>LLM 本身只会算 token，不会真的去发 HTTP、查数据库、调业务代码。<br>有了 Tool Calling 之后，大模型可以说：“请调用 getWeather(city=上海)”，然后由我们的程序去执行这个方法，拿到结果再喂回给大模型，让它继续组织自然语言回答。</p></blockquote><p>这样，大模型的“脑子”+ 外部工具的“手脚”结合起来，就能：</p><ul><li>访问实时数据（天气、股价、数据库、内部系统接口等）</li><li>执行各种业务操作（发邮件、查询订单、创建工单、调用支付网关等）</li></ul><p>可以把 Tool Calling 理解成：“LLM 的外部 utils 工具类 / 第三方插件系统”。</p><h3 id="Tool-Calling-的典型工作流程">Tool Calling 的典型工作流程</h3><ol><li>用户提问</li></ol><p>比如：“帮我查一下今天上海的天气，再顺便推荐一身穿搭。”</p><ol start="2"><li>程序把问题丢给大模型</li></ol><p>同时告诉大模型：我这里有一些工具（getWeather、getTime、查订单……）可以用。</p><ol start="3"><li>大模型判断要不要用工具</li></ol><p>它分析语义后觉得：“这题我自己编不靠谱，需要实时天气。”<br>于是产生一个“工具调用意图”，比如：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span> <span class="attr">&quot;tool&quot;</span><span class="punctuation">:</span> <span class="string">&quot;getWeather&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;上海&quot;</span> <span class="punctuation">&#125;</span> <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><ol start="4"><li>应用程序真正去调工具</li></ol><ul><li>程序解析出工具名和参数</li><li>调用对应的 Java 方法 / HTTP 接口 / 脚本等，拿到真实结果</li><li>把结果再塞回大模型：</li></ul><blockquote><p>“工具 getWeather 返回：今天 25℃，多云，有小风……”</p></blockquote><ol start="5"><li>大模型整合工具结果给出最终回复<br>比如：</li></ol><blockquote><p>“上海今天 25℃多云，建议穿衬衫+长裤，出门带件薄外套。”</p></blockquote><p>在 Spring AI 里实现工具调用很简单：用 @Tool 把 Java 方法暴露成工具，配置到 ChatClient，然后正常发起对话即可，Spring AI 会自动完成工具选择、调用和结果回填的完整闭环。</p><h2 id="什么是-Spring-AI-框架？它有哪些核心特性？">什么是 Spring AI 框架？它有哪些核心特性？</h2><p>Spring AI 是 Spring 官方推出的 AI 应用框架，核心是把“AI 集成”变成像 Spring 一样简单。</p><ul><li>它提供统一的模型调用 API，兼容几乎所有主流大模型；</li><li>支持结构化输出、工具调用、向量数据库与 RAG、ETL 文档处理、流式对话、拦截器等能力；</li><li>并通过 Spring Boot Starter 做了自动化集成，让 Java 能轻松构建企业级 AI 应用。</li></ul>]]></content>
    
    
    <summary type="html">我对AIGC的理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="AIGC" scheme="https://itgeqian.github.io/tags/AIGC/"/>
    
  </entry>
  
  <entry>
    <title>Docker Desktop安装到D盘</title>
    <link href="https://itgeqian.github.io/posts/61.html"/>
    <id>https://itgeqian.github.io/posts/61.html</id>
    <published>2025-10-02T02:09:03.000Z</published>
    <updated>2025-10-02T03:01:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Docker默认安装路径为<code>C:\Program Files\Docker</code>。</p><p>提前准备好安装包</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-1024x597.png" alt="img"></p><p>powershell中用WSL安装</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:<span class="string">\浏览器下载&gt;start</span> /w <span class="string">&quot;&quot;</span> <span class="string">&quot;Docker Desktop Installer.exe&quot;</span> install --backend=wsl-<span class="number">2</span> --installation-dir=D:<span class="string">\Program</span> Files<span class="string">\Docker\docker</span> --wsl-<span class="keyword">default</span>-data-root=D:<span class="string">\Program</span> Files<span class="string">\Docker\wsl</span> --accept-license</span><br></pre></td></tr></table></figure><p>安装后打开如果WSL版本过低无法运行Docker Desktop</p><ol><li>打开 <strong>PowerShell（以管理员身份）</strong>；</li><li>输入：</li></ol><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl <span class="comment">--update</span></span><br></pre></td></tr></table></figure><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-1-1024x529.png" alt="img"></p><p>若仍失败，可以尝试强制从微软服务器下载更新：</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">wsl</span> <span class="literal">--</span><span class="comment">update</span> <span class="literal">--</span><span class="comment">web</span><span class="literal">-</span><span class="comment">download</span></span><br></pre></td></tr></table></figure><p>更新完毕后，重启 Docker Desktop 即可。</p><p><img src="https://www.legendkiller.xyz/wp-content/uploads/2025/10/image-2-1024x581.png" alt="img"></p>]]></content>
    
    
    <summary type="html">Docker Desktop安装到D盘</summary>
    
    
    
    <category term="学习笔记" scheme="https://itgeqian.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="报错解决" scheme="https://itgeqian.github.io/tags/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/"/>
    
  </entry>
  
  <entry>
    <title>JUC面试题</title>
    <link href="https://itgeqian.github.io/posts/68.html"/>
    <id>https://itgeqian.github.io/posts/68.html</id>
    <published>2025-10-01T00:19:03.000Z</published>
    <updated>2025-10-05T03:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GQ-JUC">GQ JUC</h1><h2 id="JUC">JUC</h2><h3 id="进程、线程、协程的区别">进程、线程、协程的区别</h3><p>进程负责“资源”，线程负责“执行”，协程负责“更轻量的执行方式”。</p><h4 id="进程是什么？（资源隔离-独立内存）">进程是什么？（资源隔离+独立内存）</h4><ul><li>进程<strong>就是一个程序的运行实例</strong>，<strong>比如你打开一个微信，就是一个进程</strong>。</li><li><strong>每个进程有自己独立的内存空间、文件句柄</strong>等资源，<strong>是操作系统中资源分配的最小单位</strong>。</li><li>不同进程之间互不影响，因此<strong>稳定性高，但创建和切换成本大</strong>。</li></ul><h4 id="线程是什么？（执行单元-更轻量）">线程是什么？（执行单元+更轻量）</h4><p><strong>线程是进程内部的“执行流”，一个进程可以有多个线程</strong>。<br><strong>线程之间共享同一个进程的内存</strong>，因此通信非常方便，但安全性要靠加锁保证。<br>线程是<strong>CPU 调度的最小单位</strong>，切换比进程轻量，但仍需要 OS 参与调度。</p><h4 id="协程是什么？（用户态、极轻、高并发）">协程是什么？（用户态、极轻、高并发）</h4><p><strong>协程是比线程更轻量的“用户态调度”的执行方式，不会被 OS 感知。</strong><br>它把切换时机交给程序自己决定，而不是让 OS 抢占式调度，因此切换开销极低。<br>常用于大量 I/O 任务，比如 Go 的 goroutine、Java 的虚拟线程。</p><ul><li>进程：资源独立、安全但重 → “房子”</li><li>线程：共享资源、切换轻 → “房子里的房间”</li><li>协程：极轻量、用户态调度 → “房间里的小隔断，不需要 OS 管”</li></ul><h4 id="执行成本对比">执行成本对比</h4><table><thead><tr><th>对比项</th><th>进程</th><th>线程</th><th>协程</th></tr></thead><tbody><tr><td>创建成本</td><td>高</td><td>中</td><td>很低</td></tr><tr><td>切换成本</td><td>高（OS 切换）</td><td>中（OS 切换）</td><td>极低（用户态切换）</td></tr><tr><td>内存隔离</td><td>完全隔离</td><td>共享</td><td>共享，逻辑更轻</td></tr><tr><td>调度者</td><td>OS</td><td>OS</td><td>程序自身</td></tr></tbody></table><h4 id="小结">小结</h4><ul><li><strong>进程是操作系统分配资源的单位，每个进程有独立的内存，因此安全但切换成本高</strong>。</li><li><strong>线程是进程里的执行单元，共享进程资源，切换比进程快但需要同步锁来保证安全</strong>。</li><li><strong>协程更轻量，它在用户态调度，不需要 OS 参与，所以切换成本非常低，非常适合 I/O 密集的高并发场景，比如 Go 的 goroutine 或 Java 的虚拟线程</strong>。</li></ul><h4 id="什么是-Java-中的线程同步？">什么是 Java 中的线程同步？</h4><p>线程同步其实就是在多线程环境中，<strong>保证同一时刻只有一个线程能访问某个共享资源</strong>，<strong>避免多个线程同时操作同一个资源时出现数据不一致或竞争条件的问题。</strong></p><p>线程同步有很多方式，常用的包括 <strong>synchronized、ReentrantLock 和原子类</strong>，它们的<strong>主要目的是保证数据的一致性和线程间的协调。</strong></p><ul><li>synchronized：它可以锁定代码块或者方法，确保同一时刻只有一个线程能执行这个方法或代码块</li><li>ReentrantLock 也是一种很常用的同步工具，它提供了更高的灵活性，比如可以尝试加锁、定时加锁等</li><li>Java 还提供了 Atomic 类系列，比如 AtomicInteger、AtomicLong 等，这些类通过原子操作来保证线程安全，避免了锁的使用<ul><li>原理是这些原子类通过<strong>硬件级别的原子操作</strong>来实现操作的原子性。</li></ul></li></ul><h3 id="并行与并发-同步与异步">并行与并发,同步与异步</h3><ul><li>同步:<strong>需要等待结果返回</strong>，才能继续运行</li><li>异步:<strong>不需要等待结果返回</strong>，就能继续运行</li><li>并行：在同一时刻，有多个指令在多个 CPU 上同时执行, <strong>同一时间同时做多件事情的能力</strong>。多个人做多件事。</li><li>并发：在同一时刻，有多个指令在单个 CPU 上交替执行, <strong>同一时间段处理多件事情的能力</strong>。一个人做多件事。</li></ul><h3 id="Java-中的线程安全是什么意思？">Java 中的线程安全是什么意思？</h3><p>线程安全指的是<strong>在多线程环境下，多个线程同时访问某个共享资源时，不会出现数据不一致或修改错误的情况</strong>。当一个类或方法是线程安全的时，多个线程可以并发访问它，不需要担心在执行过程中数据会被其他线程改变。它能够确保在执行的过程中，不会出现<strong>竞争条件、死锁</strong>等问题。</p><p><strong>为什么线程安全很重要？</strong></p><p>在多线程环境中，<strong>多个线程可能会同时对同一数据进行操作</strong>。如果没有合适的同步措施，可能会导致数据被意外修改，最终产生不一致的结果。线程安全可以避免这种情况，保证每个线程访问的数据都是正确和一致的。</p><h3 id="什么是协程？Java-支持协程吗？">什么是协程？Java 支持协程吗？</h3><p>协程其实<strong>是比线程更加轻量的执行单元</strong>，它允许在执行过程中暂停，然后恢复执行，像是在线程内做任务切换，但比线程效率更高。<br>jdk19引入了虚拟线程，jdk21确认,可以认为是java对协程的一种实现。</p><p>通过虚拟线程，我们可以在同一个线程池里高效地管理成千上万个线程，这样就能大大提高并发性能，特别是在需要大量并发但每个任务执行时间短的场景下。</p><h3 id="线程的生命周期在-Java-中是如何定义的？">线程的生命周期在 Java 中是如何定义的？</h3><h4 id="从-Java-API-层面来描述的有六种状态">从 Java API 层面来描述的有六种状态</h4><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/hqsWVhAF_image-1282-1024x707_mianshiya.png" alt="image-1282-1024x707.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/aHn58qBx_image_mianshiya.png" alt="image.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/X7NwTGDu_Snipaste_2025-11-01_21-45-22_mianshiya.png" alt="Snipaste_2025-11-01_21-45-22.png" width="100%" /><h4 id="从-操作系统-层面来描述有五种状态">从 操作系统 层面来描述有五种状态</h4><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/teERwW4V_Snipaste_2025-11-01_21-46-15_mianshiya.png" alt="Snipaste_2025-11-01_21-46-15.png" width="100%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/g0PGz6c3_Snipaste_2025-11-01_21-46-35_mianshiya.png" alt="Snipaste_2025-11-01_21-46-35.png" width="100%" /><h3 id="Java-中线程之间如何进行通信？">Java 中线程之间如何进行通信？</h3><p>在 Java 中，线程之间的通信通常是为了实现多个线程在共享资源上进行协作。主要的方式包括：</p><ol><li>共享变量</li></ol><p>多个线程可以通过访问共享变量来交换信息。为了确保线程安全，必须小心使用共享数据，避免线程间的竞争条件或数据不一致。<br>2. 同步机制</p><p>常见的同步机制包括：</p><ul><li>synchronized：用 Java 中的 synchronized 关键字来保证同一时刻只有一个线程能访问共享资源。线程间通过 wait() 和 notify() 等方法进行通信。</li><li>ReentrantLock：提供了类似于 synchronized 的锁机制，允许线程在执行过程中对共享资源进行同步。</li><li>BlockingQueue：提供阻塞队列来控制生产者与消费者的消费模式。</li><li>CountDownLatch：允许一个或多个线程等待，直到其他线程完成某项操作。</li><li>CyclicBarrier：允许多个线程相互等待，直到某个条件满足才继续执行。</li><li>Semaphore：用于控制访问共享资源的线程数量，限制并发线程的数量。</li></ul><h3 id="Java-中如何创建多线程？">Java 中如何创建多线程？</h3><p>在Java中创建多线程有几种常见的方式：</p><ol><li>使用 Thread 类：<br>通过继承 Thread 类，重写 run() 方法，并调用 start() 来启动线程。这是最基础的方式，但它不够灵活，<strong>任务和线程是绑定在一起的，无法重用任务。</strong></li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    public void run() &#123;</span><br><span class="line">        <span class="type">System</span>.out.println(<span class="string">&quot;Thread running&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">MyThread</span> thread = <span class="keyword">new</span> <span class="type">MyThread</span>();</span><br><span class="line">thread.start();</span><br></pre></td></tr></table></figure><ol start="2"><li>使用 Runnable 配合 Thread：<br>这种方法通过实现 Runnable 接口来<strong>分离任务和线程</strong>。创建一个 Runnable 实例，将其传递给 Thread 来启动线程。这种方式更灵活，任务可以被多个线程重用，且更适合与线程池等高级API一起使用。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Runnable</span> <span class="variable">r</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Thread running&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">Thread</span> <span class="variable">t</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(r);</span><br><span class="line">t.start();</span><br></pre></td></tr></table></figure><ol start="3"><li>使用 FutureTask 配合 Callable：<br><strong>当线程需要返回结果时</strong>，使用 Callable 接口代替 Runnable，并配合 FutureTask 来执行任务。<strong>FutureTask 可以获取任务的返回结果，并且支持异常捕获</strong>。</li></ol><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Callable&lt;<span class="built_in">Integer</span>&gt; task = <span class="literal">new</span> Callable&lt;<span class="built_in">Integer</span>&gt;() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">Integer</span> call() throws Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">100</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">FutureTask&lt;<span class="built_in">Integer</span>&gt; futureTask = <span class="literal">new</span> FutureTask&lt;&gt;(task);</span><br><span class="line"><span class="keyword">Thread</span> <span class="keyword">thread</span> = <span class="literal">new</span> <span class="keyword">Thread</span>(futureTask);</span><br><span class="line"><span class="keyword">thread</span>.start();</span><br><span class="line"><span class="built_in">Integer</span> result = futureTask.get();  <span class="comment">// 阻塞等待结果</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="4"><li>使用线程池 (ExecutorService)：<br><strong>使用 ExecutorService 管理线程池</strong>，可以方便地提交 Runnable 或 Callable 任务，适合处理大量并发任务而不需要手动管理线程。</li></ol><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executor = Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">executor.submit<span class="function"><span class="params">(() -&gt; System.out.println(<span class="string">&quot;Running in thread pool&quot;</span>))</span>;</span></span><br><span class="line"><span class="function"><span class="title">executor</span>.<span class="title">shutdown</span><span class="params">()</span>;</span></span><br></pre></td></tr></table></figure><ol start="5"><li>使用 CompletableFuture：<br>Java 8 引入了 CompletableFuture，提供了<strong>更方便的异步任务执行和任务间的依赖关系处理</strong>。<strong>它是基于线程池（默认使用 ForkJoinPool）实现的，可以链式调用不同的异步操作</strong>。</li></ol><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture.runAsync<span class="function"><span class="params">(() -&gt; &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    System.out.println(<span class="string">&quot;Async task running&quot;</span>);</span></span></span><br><span class="line"><span class="params"><span class="function">&#125;)</span>.<span class="title">thenAccept</span><span class="params">(result -&gt; System.out.println(<span class="string">&quot;Task completed&quot;</span>))</span>;</span></span><br></pre></td></tr></table></figure><h4 id="总结：">总结：</h4><ul><li>如果只是简单的创建一个线程，可以直接使用 Thread 类。</li><li>如果想解耦任务和线程，更灵活且复用性强，推荐使用 Runnable 配合 Thread。</li><li>如果需要线程执行后有返回值，使用 Callable 和 FutureTask。</li><li>如果有大量并发任务，使用线程池来管理线程。</li><li>如果任务之间有依赖关系，使用 CompletableFuture 处理异步任务。</li></ul><h3 id="你了解-Java-线程池的原理吗？">你了解 Java 线程池的原理吗？</h3><p>线程池：一个容纳多个线程的容器，容器中的线程可以重复使用，省去了频繁创建和销毁线程对象的操作</p><p>线程池作用：</p><ul><li>降低资源消耗，减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务</li><li>提高响应速度，当任务到达时，如果有线程可以直接用，不会出现系统僵死</li><li>提高线程的可管理性，如果无限制的创建线程，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控</li></ul><p>线程池的核心思想：<strong>线程复用</strong>，同一个线程可以被重复使用，来处理多个任务</p><p>池化技术 (Pool) ：一种编程技巧，核心思想是资源复用，在请求量大时能优化应用性能，降低系统频繁建连的资源开销</p><p>线程池的工作原理可以分为几个关键步骤：</p><ul><li>核心线程数（corePoolSize）：这是线程池中最小的线程数量。即使没有任务，线程池也会维持这些线程处于空闲状态。</li><li>最大线程数（maximumPoolSize）：线程池可以创建的最大线程数量。当有大量任务同时到达时，线程池会创建新线程，直到达到最大线程数。</li><li>空闲时间（keepAliveTime）：空闲线程在一定时间内没有任务执行时，线程池会回收它们以节省资源。这个时间是可以调节的。</li><li>时间单位</li><li>工作队列（workQueue）：这是用于保存提交的任务的队列。如果线程池中所有核心线程都在忙碌，任务就会被放入队列等待。</li><li>线程工厂（ThreadFactory）：用来创建新线程的工厂，可以自定义线程的创建方式。</li><li>拒绝策略（RejectedExecutionHandler）：当线程池中的任务数量达到最大线程数且队列已满时，线程池会采取拒绝策略，<strong>通常包括丢弃任务、抛出异常或者让任务在其他地方执行</strong>。</li></ul><p>常见的线程池类型包括：</p><ul><li>FixedThreadPool：一个固定大小的线程池，适用于负载较为稳定的场景。</li><li>CachedThreadPool：可以根据需要创建新线程，但在空闲时会回收线程，适用于任务数量不确定，且任务执行时间短的情况。</li><li>ScheduledThreadPool：可以定期执行任务或延迟执行任务的线程池。</li><li>SingleThreadExecutor：只有一个线程的线程池，适用于串行执行任务的场景。</li></ul><p>总结来说，线程池是为了避免频繁创建和销毁线程的性能问题，同时也提供了灵活的线程管理和任务调度机制，适用于大规模并发处理的场景。</p><p>补充：拒绝策略</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/Is34VHXx_Snipaste_2025-11-02_20-27-12_mianshiya.png" alt="Snipaste_2025-11-02_20-27-12.png" width="100%" /><h3 id="如何合理地设置-Java-线程池的线程数？">如何合理地设置 Java 线程池的线程数？</h3><p>对于如何合理地设置 Java 线程池的线程数，可以通过<strong>分析任务的类型</strong>来进行优化。通常，任务类型可以分为两类：<strong>CPU 密集型任务</strong>和<strong>I/O 密集型任务</strong>。</p><ol><li><p><strong>CPU 密集型任务</strong>：<strong>这些任务主要依赖 CPU 进行计算，如数学运算等</strong>。在这种情况下，线程数的设置应根据 CPU 核心数来决定。为了充分利用 CPU 的计算资源，线程池的核心线程数可以设置为 <strong>CPU 核心数 + 1</strong>，这样可以充分利用 CPU 的空闲时间，避免过多线程的竞争。</p></li><li><p><strong>I/O 密集型任务</strong>：这类任务大多依赖 I/O 操作，如文件读写、网络请求等。在进行 I/O 操作时，线程并不占用 CPU 资源，因此可以增加线程池的线程数。通常可以将线程数设置为 <strong>2 倍 CPU 核心数</strong>，因为大多数 I/O 操作会阻塞线程，这时可以充分利用 CPU 执行其他任务。</p></li></ol><p>总结：</p><ul><li>对于 <strong>CPU 密集型</strong> 任务，线程数应该设置为 <strong>CPU 核心数 + 1</strong>，这样可以避免线程过多导致的上下文切换和 CPU 资源浪费。</li><li>对于 <strong>I/O 密集型</strong> 任务，线程数可以设置为 <strong>2 倍 CPU 核心数</strong>，这样可以充分利用线程池的线程而不造成过多阻塞。</li></ul><p>如果业务中同时有这两种类型的任务，推荐根据任务的比例来动态调整线程池的大小。</p><h3 id="Java-线程池有哪些拒绝策略？">Java 线程池有哪些拒绝策略？</h3><p>在 Java 中，线程池有四种拒绝策略：</p><ul><li>默认是 AbortPolicy，也就是<strong>当线程池满了，系统会抛出异常</strong>，提醒你有任务无法被处理。</li><li>CallerRunsPolicy 是<strong>让提交任务的线程（调用者线程）自己执行任务</strong>。适合你希望通过减缓任务提交的速度来避免系统过载的场景。</li><li>DiscardOldestPolicy 则会<strong>丢弃队列中最旧的任务</strong>，保留新的任务继续执行。如果你希望保留当前任务并丢弃掉早些提交的任务，这个策略就很合适。</li><li>DiscardPolicy 是最简单粗暴的，它会<strong>直接丢弃任务</strong>，不做任何处理，适合在高负载时只保留最重要的任务。</li></ul><h3 id="Java-并发库中提供了哪些线程池实现？它们有什么区别？">Java 并发库中提供了哪些线程池实现？它们有什么区别？</h3><p>在 Java 的并发库中，主要有五种常见的线程池实现，它们分别是：</p><ul><li>FixedThreadPool：这是一个<strong>固定大小的线程池</strong>。线程数是固定的，如果有任务来时，线程池会先检查当前是否有空闲线程，如果有就执行任务，如果没有，它会将任务排队等待。适合任务量稳定的场景。</li><li>CachedThreadPool：这个线程池<strong>可以动态调整线程数。线程池会根据任务需求创建新线程</strong>，如果现有的线程没有被使用，它会在60秒后自动回收。这种线程池适合处理大量短时间任务的场景，但如果任务量过多，可能会导致内存溢出（OOM）。</li><li>SingleThreadExecutor：这就是一个<strong>单线程池</strong>，它只会有一个线程来执行所有任务。如果一个任务执行失败，后续的任务也会被阻塞，直到当前任务完成。<strong>适用于需要确保任务按顺序执行的场景</strong>。</li><li>ScheduledThreadPool：这是一个<strong>支持定时任务的线程池</strong>。它可以定期或延迟执行任务，适用于定时执行任务或延时执行的场景。</li><li>WorkStealingPool：这个线程池是<strong>基于工作窃取算法设计</strong>的。它是<strong>从多个线程中窃取工作来优化任务执行</strong>，适用于任务之间相对独立，且负载不均匀的情况。</li></ul><p><strong>总结：如果你有一堆任务并且任务量比较大，固定线程池和缓存线程池更适合；如果任务量不大，但需要定时执行，使用 ScheduledThreadPool。如果任务之间有很强的顺序性，可以使用 SingleThreadExecutor。如果任务负载不均匀，WorkStealingPool 是一个不错的选择。</strong></p><h3 id="Java-线程池核心线程数在运行过程中能修改吗？如何修改？">Java 线程池核心线程数在运行过程中能修改吗？如何修改？</h3><p>在 Java 中，我们是可以动态地调整线程池的核心线程数的。可以通过调用 ThreadPoolExecutor 的 setCorePoolSize() 方法来修改核心线程数。需要注意的是，减少核心线程数时，空闲的多余线程不会立刻回收，只有等到它们一段时间没有任务执行后才会被回收。而且，这个修改不会影响正在执行的任务，所以它是即时生效的。</p><h3 id="Java-线程池中-shutdown-与-shutdownNow-的区别是什么？">Java 线程池中 shutdown 与 shutdownNow 的区别是什么？</h3><ul><li>shutdown() 用于优雅地关闭线程池，<strong>它会停止接受新任务，但会继续执行队列中已提交的任务</strong>，直到全部完成为止。</li><li>shutdownNow() 会<strong>立即尝试停止所有任务</strong>，返回当前尚未执行的任务列表，并<strong>尽可能通过中断线程来停止正在执行的任务</strong>。如果任务无法处理中断，它们仍然可能继续执行，直到任务完成。</li></ul><p>这两种方法主要的区别在于是否会强制中断正在执行的任务，shutdown() 是平稳退出，而 shutdownNow() 是立即中止。</p><h3 id="Java-线程池内部任务出异常后，如何知道是哪个线程出了异常？">Java 线程池内部任务出异常后，如何知道是哪个线程出了异常？</h3><p>在Java的线程池中，如果线程执行的任务抛出异常，<strong>默认情况下线程池并不会主动告诉你是哪个线程出了问题</strong>，但我们有几种方式可以捕获这个异常信息。</p><ul><li><p>首先，如果你使用 ThreadFactory 来创建线程池，<strong>可以自定义 UncaughtExceptionHandler 来处理每个线程中的异常</strong>。这样，线程在遇到未处理的异常时，就会调用 UncaughtExceptionHandler，你可以在其中记录线程的异常信息。</p></li><li><p>其次，在线程任务执行时，我们可以使用 <strong>Future</strong>。当使用 submit() 提交任务时，我们可以通过返回的 Future 对象来检查任务是否执行成功，如果任务有异常，可以通过 get() 方法时候try-catch捕获异常。</p></li><li><p>最后，在<strong>run方法内部</strong>，我们还可以使用 <strong>try-catch</strong> 来捕获异常，避免任务因为异常直接失败。在捕获异常后，我们可以记录或者处理异常，也能确保任务不会导致线程池停止。</p></li></ul><p>总的来说，我们可以通过 ThreadFactory 来为每个线程设置异常处理器，使用 Future 对象来捕获任务异常，并在任务内部加入 try-catch 来处理异常，确保线程池中的任务都能被监控和管理。</p><h3 id="Java-中的-DelayQueue-和-ScheduledThreadPool-有什么区别？">Java 中的 DelayQueue 和 ScheduledThreadPool 有什么区别？</h3><p>在 Java 中，DelayQueue 和 ScheduledThreadPoolExecutor 都是用于处理延迟任务的工具，但它们的实现原理和使用场景有所不同。</p><ol><li>DelayQueue：</li></ol><p>DelayQueue 是一个<strong>阻塞队列</strong>，它<strong>基于元素的延迟时间来控制任务的执行顺序</strong>。每个元素都有一个指定的延迟时间，元素不会立刻被处理，只有在延迟时间到了之后，它才会从队列中被取出执行。</p><p>它通常与 ReentrantLock 和 Condition 配合使用，确保任务在合适的时间被执行。</p><ol start="2"><li>ScheduledThreadPoolExecutor：</li></ol><p>这是一个专门<strong>用于执行定时任务和周期任务的线程池</strong>。它允许你<strong>定期执行任务或延迟执行任务</strong>，常用于周期性任务的调度。</p><p>ScheduledThreadPoolExecutor 提供了比 DelayQueue 更灵活的任务调度功能，比如支持固定延迟任务、定时执行等。</p><h3 id="什么是-Java-的-Timer？">什么是 Java 的 Timer？</h3><p>Java 中的 Timer 是用来<strong>定时执行任务的工具</strong>，通常和<strong>TimerTask</strong>搭配使用，TimerTask是需要执行的任务。你可以用 <strong>schedule() 来延时执行任务</strong>，或者用 <strong>scheduleAtFixedRate() 来做周期性任务</strong>。它内部有一个专门的线程去管理这些任务。</p><p>不过，<strong>Timer 是单线程的</strong>，如果任务的执行时间比预定的时间长，可能会影响后续任务的执行，造成任务延迟。因此在高并发场景下，Timer 可能不是最优选择，通常我们会推荐使用 <strong>ScheduledExecutorService 来替代 Timer</strong>，因为它提供了更高效的多线程任务调度。</p><h3 id="你了解时间轮（Time-Wheel）吗？有哪些应用场景？">你了解时间轮（Time Wheel）吗？有哪些应用场景？</h3><p>时间轮是一种高效的定时任务调度算法，<strong>它通过将时间切分为多个固定的时间槽，并将任务分配到这些时间槽中，来实现任务的定时执行</strong>。当时间轮转到某个槽时，槽内的任务就会执行。这个算法特别适合于需要处理大量定时任务的场景，因为它避免了频繁的时间比较，提升了效率。比如在高并发的网络服务中，时间轮可以用来优化定时任务的调度，减少系统的负担。</p><h3 id="你使用过哪些-Java-并发工具类？">你使用过哪些 Java 并发工具类？</h3><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/OqI0Cf8H_Snipaste_2025-11-04_14-15-17_mianshiya.png" alt="Snipaste_2025-11-04_14-15-17.png" width="100%" /><h3 id="什么是-Java-的-Semaphore？">什么是 Java 的 Semaphore？</h3><p>在 Java 中，Semaphore（信号量）是一个用于控制访问共享资源的工具类。<strong>它通过维护一定数量的许可证来管理线程访问资源的权限</strong>，确保在任何时刻，只有限定数量的线程能够访问资源。线程需要先通过 acquire() 获取许可证才能访问资源，使用完毕后必须通过 release() 来释放许可证。它支持两种模式：<strong>公平模式</strong>，线程按照顺序获取许可，<strong>避免饥饿</strong>；<strong>非公平模式</strong>，则是线程可以抢先获取许可证，可能导致<strong>不公平的资源分配</strong>。</p><h3 id="什么是-Java-的-CyclicBarrier？">什么是 Java 的 CyclicBarrier？</h3><p>CyclicBarrier 是一种同步工具类，<strong>允许一组线程在执行某些任务时相互等待，直到所有线程都到达某个指定的“屏障点”时，才会继续执行</strong>。它通常用于需要协调多个线程按一定顺序执行的场景。</p><blockquote><p>工作原理：</p></blockquote><p>CyclicBarrier 内部维护<strong>一个计数器</strong>，表示需要等待的线程数。<strong>每当一个线程执行 await() 方法时，计数器就会减1，直到计数器的值为0，所有等待的线程才会被唤醒，继续执行。</strong></p><p>可以通过传入一个 Runnable 的 barrierAction 来定义屏障到达时要执行的操作，这个操作会在所有线程到达屏障后执行。</p><blockquote><p>应用场景：</p></blockquote><ul><li>并行任务协调：比如，多个线程执行某些计算任务，并且在每个阶段后需要等待其他线程，保证每个阶段都同步进行。</li><li>批量任务处理：在分布式计算或者并行任务处理时，可以用来协调多个线程的工作，确保所有线程都完成了某个阶段的工作后才进入下一个阶段。</li></ul><h3 id="什么是-Java-的-CountDownLatch？">什么是 Java 的 CountDownLatch？</h3><p>CountDownLatch 是一个同步辅助工具，属于 JUC（Java 并发工具包）的一部分，<strong>它允许一个线程等待多个线程完成某项任务</strong>。通过一个计数器来实现，每当一个线程完成工作时，就会减少一个数字，当计数器的值减到零时，所有等待的线程将被唤醒并继续执行。</p><p>主要功能：</p><ul><li>等待其他线程完成任务：通过 await() 方法，线程会等待其他线程完成其任务。</li><li>减少计数器：当某个线程完成工作时，调用 countDown() 方法将计数器的值减一。</li><li>所有线程完成时再执行：当计数器的值减到零时，所有等待的线程会被唤醒，继续执行。</li></ul><p>应用场景：</p><ul><li><strong>并行任务的协同工作</strong>：比如有多个线程并行执行任务，主线程需要等所有线程都完成后再继续执行。CountDownLatch 很适合这种场景，比如启动多个线程进行并行处理，主线程在所有线程完成任务后再进行合并处理。</li></ul><p>比较CountDownLatch 和 CyclicBarrier 的区别</p><ul><li>CyclicBarrier 是可以重用的，所有线程到达屏障后自动重置。</li><li>CountDownLatch 一次性使用，一旦计数器归零就不能再使用。</li></ul><h3 id="什么是-Java-的-StampedLock？">什么是 Java 的 StampedLock？</h3><p>StampedLock 是 Java 8 新增的一种锁机制，它通过<strong>引入乐观读锁提高了性能</strong>，特别适用于<strong>读多写少的场景</strong>。它有三种锁模式：写锁、悲观读锁和乐观读锁。<br>写锁</p><ul><li>独占锁，类似于 ReentrantLock 的写锁。它确保其他线程不能获取到写锁或读锁。</li></ul><p>悲观读锁</p><ul><li>共享锁，允许多个线程同时获取读锁，但不允许有线程获取写锁。</li></ul><p>乐观读锁</p><ul><li>不加锁，允许线程在没有竞争的情况下进行快速读。只有在检测到写操作发生时，它才会回退到悲观读锁。</li></ul><p>最特别的是，StampedLock 还会返回一个时间戳，代表当前锁的状态，线程可以利用这个时间戳来判断锁是否还有效，从而决定是否继续执行操作。</p><h3 id="什么是-Java-的-CompletableFuture？">什么是 Java 的 CompletableFuture？</h3><p>在 Java 8 中，<strong>CompletableFuture 是为了简化异步编程而引入的工具</strong>。你可以把它想象成一个<strong>可以在后台执行任务的对象</strong>，它支持异步执行，也就是你可以启动一个任务，它会在后台进行计算，计算结果一旦出来，你可以拿到它做后续处理。</p><p>最核心的几个特性是：</p><ul><li><strong>异步执行</strong>：使用 runAsync() 或 supplyAsync() 方法，你可以<strong>让任务在后台异步执行，这样不会阻塞主线程</strong>。</li><li><strong>任务组合</strong>：你可以使用 thenApply() 或 thenAccept() 等方法<strong>在任务完成后进行处理，支持链式调用。</strong></li><li><strong>并行任务</strong>：CompletableFuture <strong>允许你同时执行多个任务</strong>，并且可以通过 .allOf() 来<strong>合并这些任务的结果</strong>。</li><li><strong>异常处理</strong>：如果异步任务执行过程中出错，你可以<strong>使用 exceptionally() 来处理异常</strong>，避免程序崩溃。</li></ul><p>CompletableFuture 的优势在于<strong>它让你可以轻松地处理异步操作，特别是当你需要执行多个任务并且希望它们能并行执行时，非常适合用它</strong>。而且，通过链式调用，你可以简化代码逻辑，不需要复杂的回调函数。&quot;</p><p>总结<br>CompletableFuture 是<strong>处理异步编程非常强大的工具</strong>，它提供了各种方法来<strong>执行异步任务，管理结果，处理异常，并支持多个任务的并行执行</strong>，特别适合在<strong>需要高效处理并发任务的场景中使用</strong>。</p><h3 id="什么是-Java-的-ForkJoinPool？">什么是 Java 的 ForkJoinPool？</h3><p>ForkJoinPool 是 Java 7 引入的一个线程池，主要用来<strong>处理大规模的并行任务</strong>。它采用了“<strong>分而治之</strong>”的方式，<strong>把一个大任务分解成多个小任务进行并行处理</strong>，<strong>所有任务完成后再合并结果</strong>。它的工作方式是通过两个操作：<strong>fork 来分解任务</strong>，<strong>join 来合并结果</strong>。</p><p>ForkJoinPool 使用了<strong>工作窃取算法</strong>，ForkJoinPool是WorkStealingPool的底层，<strong>这意味着如果有线程空闲，它会去偷取其他线程没有完成的任务，从而提高并行度和资源利用率</strong>。常见的相关任务类是 RecursiveTask（有返回值的任务）和 RecursiveAction（无返回值的任务）。</p><p>这个池子<strong>特别适合用于需要大量并行处理的计算任务，比如大数据处理或者需要执行递归算法的场景</strong>。</p><h3 id="如何在-Java-中控制多个线程的执行顺序？">如何在 Java 中控制多个线程的执行顺序？</h3><p>在 Java 中，控制多个线程的执行顺序有多种方式，常用的方法包括：</p><ol><li><p><strong>CompletableFuture 的 <code>thenRun</code> 方法</strong>：</p><ul><li>如果你有多个任务（例如 T1、T2、T3），你可以使用 <code>thenRun</code> 方法来保证这些任务按顺序执行。每个任务会在上一个任务完成后才开始执行。这种方法适合于处理并发任务，并且保证顺序。</li></ul><p>示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CompletableFuture.runAsync(() -&gt; &#123; doTask1(); &#125;)</span><br><span class="line">    .thenRun(() -&gt; &#123; doTask2(); &#125;)</span><br><span class="line">    .thenRun(() -&gt; &#123; doTask3(); &#125;);</span><br></pre></td></tr></table></figure></li><li><p><strong>synchronized + wait/notify</strong>：</p><ul><li>使用 <code>synchronized</code> 来加锁，结合 <code>wait</code> 和 <code>notify</code> 来控制线程间的执行顺序。<code>wait</code> 用于让一个线程暂停，直到收到其他线程的通知（<code>notify</code>）才继续执行。</li></ul></li><li><p><strong>ReentrantLock 配合 Condition 的 <code>await</code>、<code>signal</code>、<code>signalAll</code></strong>：</p><ul><li>通过 <code>ReentrantLock</code> 和 <code>Condition</code>，你可以更加细粒度地控制线程的执行顺序。例如，使用 <code>await</code> 使线程等待，直到其他线程通过 <code>signal</code> 或 <code>signalAll</code> 通知它们继续执行。</li></ul></li><li><p><strong>CountDownLatch</strong>：</p><ul><li><code>CountDownLatch</code> <strong>可以用来让多个线程等待直到其他线程完成指定的工作</strong>。通过调用 <code>countDown()</code> 来减少计数，直到计数为零，所有线程才会继续执行。</li></ul></li><li><p><strong>CyclicBarrier</strong>：</p><ul><li><code>CyclicBarrier</code> <strong>允许一组线程在一个公共点等待，直到所有线程都到达这个点后再继续执行</strong>。适用于并行处理多任务，确保每个线程都完成到达某个阶段后再继续。</li></ul></li><li><p><strong>Thread 类的 <code>join()</code> 方法</strong>：</p><ul><li><strong><code>join()</code> 方法可以让一个线程等待另一个线程完成后再执行</strong>。通过调用 <code>join()</code>，主线程可以等待其他线程执行完后再继续。</li></ul></li><li><p><strong>LockSupport 的 <code>park</code> 和 <code>unpark</code> 方法</strong>：</p><ul><li><code>LockSupport</code> 提供了更底层的控制方法，<code>park()</code> 用来挂起线程，<code>unpark()</code> 用来恢复线程的执行。</li></ul></li><li><p><strong>Semaphore</strong>：</p><ul><li><code>Semaphore</code> 控制并发的线程数量，适用于控制访问某些资源的线程数量。通过设置许可数来限制并发线程的数量。</li></ul></li><li><p><strong>ExecutorService 的单线程执行</strong>：</p><ul><li>如果不关心线程池中的线程，<code>ExecutorService</code> 提供了顺序执行任务的功能，可以将任务提交给一个单线程执行。</li></ul></li></ol><h4 id="小结：">小结：</h4><ul><li><strong>最简洁</strong>的方式是 <code>Thread.join()</code>，非常直接，适合顺序依赖的场景。</li><li>如果你需要更复杂的控制，比如多个线程并发执行后再同步，使用 <code>CountDownLatch</code> 或 <code>CyclicBarrier</code> 更合适。</li><li>你可以根据任务的复杂度选择适合的工具，比如 <code>ReentrantLock</code> 和 <code>Condition</code> 提供更细粒度的控制。</li></ul><h3 id="你使用过-Java-中的哪些阻塞队列？">你使用过 Java 中的哪些阻塞队列？</h3><p>Java 提供了几种常见的阻塞队列，主要用于在多线程环境下处理线程间的任务传递。常见的有：</p><ul><li><strong>ArrayBlockingQueue</strong>：这是一个<strong>基于数组实现</strong>的队列，容量固定。生产者往队列里放数据时，如果队列满了，就会被阻塞；消费者取数据时，如果队列空了，也会被阻塞。<strong>适用于生产者-消费者模型</strong>。</li><li><strong>LinkedBlockingQueue</strong>：这是<strong>基于链表实现</strong>的队列，<strong>可以是有界的也可以是无界的</strong>。它在队列满时阻塞生产者，在队列空时阻塞消费者。</li><li><strong>PriorityBlockingQueue</strong>：这个队列<strong>没有容量限制</strong>，且任务<strong>按优先级排队</strong>。<strong>优先级高的任务会先被处理</strong>，适合需要优先级调度的场景。</li><li><strong>DelayQueue</strong>：这是一个专门<strong>处理延迟任务的队列</strong>，<strong>只有当任务的延迟时间到达时，才能取出</strong>。这适合用在需要定时执行的任务中。</li><li><strong>SynchronousQueue</strong>：这个队列没有任何容量，每一个put操作必须等待一个take操作。因此，它常用于<strong>线程之间直接的任务传递</strong>。</li><li><strong>TransferQueue</strong>：它是<strong>在LinkedBlockingQueue的基础上新增了transfer方法的队列</strong>。put操作不会立即阻塞，直到有一个take操作时，队列才会执行传递任务。</li></ul><h3 id="你使用过-Java-中的哪些原子类？">你使用过 Java 中的哪些原子类？</h3><p>在多线程编程中，有时候我们需要对共享数据进行操作，这时<strong>为了避免线程冲突和数据不一致的问题，我们通常会使用 Java 中的原子类</strong>。它们通过内置的原子性操作来确保线程安全，避免了传统的加锁操作。</p><p>最常用的原子类包括：</p><ul><li><strong>AtomicInteger</strong> 用来原子地增加或减少整数，比如在计数器等场景下；</li><li>AtomicLong 是 AtomicInteger 的长整型版本；</li><li>AtomicBoolean 用于处理布尔值，适用于类似于标志位的场景；</li><li><strong>AtomicReference</strong> 适用于<strong>引用类型的数据</strong>，能保证在多线程环境中更新对象的引用；</li><li><strong>AtomicStampedReference 则解决了 ABA 问题，它通过添加一个版本号来避免由于值相同导致的误判断。</strong></li><li>如果需要对数组中的每个元素进行类似的原子操作，可以使用 AtomicIntegerArray 和 AtomicLongArray。</li></ul><h3 id="你使用过-Java-的累加器吗？">你使用过 Java 的累加器吗？</h3><p>前提：为什么需要累加器？</p><p>AtomicLong 在并发很高时，所有线程都会去竞争同一个变量的 CAS 操作，导致严重的总线争用（CPU cache contention），性能急剧下降。</p><p>什么是java中的累加器？</p><p>在 Java 中，“累加器”通常指的是 LongAdder 和 DoubleAdder 这两个类。</p><p>它们是 JDK 1.8 引入的，目的是在高并发场景下提升计数性能，是对传统 AtomicLong、AtomicDouble 的优化。</p><p>LongAdder和DoubleAdder它们内部通过维护多个分段计数单元（Cell），让不同线程通过CAS更新不同的单元，最后再汇总求和，从而降低 CAS 冲突，提升性能。</p><h3 id="什么是-Java-的-CAS（Compare-And-Swap）操作？">什么是 Java 的 CAS（Compare-And-Swap）操作？</h3><p>CAS，全称是 Compare And Swap（比较并交换），是一种<strong>实现并发中原子操作的机制</strong>。</p><p>在修改一个变量时，CAS 会：</p><p>1.先读取变量当前的值（内存值）；<br>2.与期望值比较；</p><ul><li>2.1如果相等，则将变量更新为新值；</li><li>2.2如果不相等，说明其他线程修改过该值，则更新失败，通常会选择自旋重试。</li></ul><p>CAS 的<strong>底层是由 CPU 的原子指令</strong>（如 x86 的 CMPXCHG） 实现的，<strong>整个过程是不可中断的</strong>，因此能保证操作的原子性。</p><h4 id="CAS-的优点">CAS 的优点</h4><ul><li><strong>无锁并发</strong>：<strong>在不使用传统锁的情况下，也能保证线程安全</strong>，提高并发性能。</li><li><strong>原子性保障</strong>：<strong>借助硬件级别的指令支持</strong>，确保修改操作不会被打断。</li></ul><h4 id="CAS-的缺点与解决方案">CAS 的缺点与解决方案</h4><p>1.ABA 问题</p><ul><li>问题：一个变量从 A → B → A，CAS 检查时发现值没变，但实际上经历了变化。</li><li>解决：使用版本号机制，如AtomicStampedReference，在 CAS 时同时比较值和版本号。</li></ul><p>2.自旋开销大</p><ul><li>问题：如果多个线程频繁失败，会导致长时间自旋，浪费 CPU 资源。</li><li>解决：在一些高并发组件（如 SynchronousQueue）中限制自旋次数或结合锁机制使用。</li></ul><blockquote><p>CAS+锁这一套组合挺常见比如CourrentHashMap就是这样实现的，CAS 用于无锁写入，如果冲突严重再退化为锁定特定桶的头结点。</p></blockquote><p>3.只能操作一个共享变量<br>问题：CAS 只能针对单一变量进行原子操作。<br>解决：使用 AtomicReference 将多个变量封装为一个对象，实现复合 CAS。</p><h4 id="总结一句话">总结一句话</h4><p>CAS 是一种基于 CPU 原子指令的无锁机制，通过比较内存值和预期值，一致则更新，否则重试。</p><p>它的优点是高并发、无锁和线程安全，但缺点是可能出现 ABA问题、自旋开销大、无法操作多个变量，可以通过版本号或 AtomicReference 来优化</p><h3 id="说说-AQS-吧？">说说 AQS 吧？</h3><p>一.AQS 是什么</p><p>AQS，全称 AbstractQueuedSynchronizer（抽象队列同步器），是 JUC（java.util.concurrent）包中构建锁和同步器的基础框架。</p><p>AQS起到了一个抽象、封装的作用，将一些排队、入队、加锁、中断等方法提取出来，便于其他相关JUC锁的使用，具体加锁时机、入队时机等都需要实现类自己控制(它通过统一的同步状态管理和队列机制，简化了各种同步器（如锁、信号量、栅栏）的实现)。</p><p>二.AQS 的核心思想</p><p>AQS 通过维护一个同步状态变量（state）和一个FIFO 等待队列，来管理多个线程对共享资源的竞争。</p><ol><li>同步状态（state）</li></ol><ul><li><p>是一个 volatile int 变量，表示资源的占用情况。</p></li><li><p>对于独占锁：state = 0 表示未加锁，state = 1 表示已加锁。</p></li><li><p>对于共享锁：state 表示可同时获取锁的线程数（例如 Semaphore 的剩余许可数）。</p></li><li><p>等待队列（FIFO）</p></li><li><p>当线程获取锁失败时，会被封装为一个 Node 节点加入队列尾部。</p></li><li><p>当锁被释放时，AQS 会唤醒队列中第一个等待线程尝试获取锁。</p></li><li><p>队列是一个基于 CLH（Craig, Landin, and Hagersten） 算法实现的双向链表结构，保证线程排队公平。</p></li></ul><p>三、AQS 的工作流程</p><ul><li><p>线程尝试获取锁 → 修改 state（CAS 操作）。</p></li><li><p>如果失败 → 封装为 Node 节点加入队列，进入等待状态。</p></li><li><p>当前持锁线程释放锁后 → AQS 唤醒队列中的下一个节点线程。</p></li></ul><p>这样，AQS 就实现了一个通用的“排队获取锁”机制。</p><p>四、AQS 的典型实现类</p><p>基于 AQS 的同步组件包括：</p><ul><li><p>独占模式：ReentrantLock</p></li><li><p>共享模式：Semaphore、CountDownLatch、ReentrantReadWriteLock</p></li><li><p>条件队列：Condition（基于 AQS 的条件队列实现）</p></li></ul><p>五.总结一句话（精简口述版）</p><p>AQS 是 JUC 中实现各种锁和同步工具的核心框架。</p><p>它通过一个 state 状态变量和一个 FIFO 队列来管理线程的竞争。</p><p>加锁失败的线程会进入队列排队，释放锁后再唤醒队首线程。</p><p>常见的实现类包括 ReentrantLock、Semaphore、CountDownLatch 等。</p><p>一句话记忆口诀：</p><p>AQS：<strong>一个 state + 一个队列，构建所有并发锁</strong>。</p><h3 id="Java-中-ReentrantLock-的实现原理是什么？">Java 中 ReentrantLock 的实现原理是什么？</h3><p>ReentrantLock 实现原理</p><p>一、ReentrantLock 是基于 AQS 的实现</p><p>ReentrantLock 是 Java 中基于 AQS（AbstractQueuedSynchronizer） 的锁实现。</p><p>它支持以下特性：</p><ul><li><p>可重入性：同一线程可以多次获取锁。</p></li><li><p>公平与非公平：支持公平锁和非公平锁的选择。</p></li><li><p>可中断：可以响应中断，避免死锁。</p></li></ul><p>二、ReentrantLock 的内部结构</p><p>内部通过一个state变量和两个队列（同步队列和等待队列）来实现</p><p>1.state 变量</p><p>ReentrantLock 使用一个 state（通常是一个整数）来记录锁的状态。</p><p>例如，state = 0 表示锁没有被占用，state &gt; 0 表示锁已被线程占用，state 值还表示该线程持有锁的次数。</p><ol start="2"><li>同步队列（Sync Queue）</li></ol><p>用于存放所有等待获取锁的线程，是一个双向链表。线程在获取锁失败时会被加入同步队列，按照 FIFO 排队，直到锁可用。</p><p>3.等待队列（Condition Queue）</p><p>用于存放等待特定条件的线程，即使用 Condition 时会涉及到的队列，存放需要等待某些条件才能继续执行的线程。它是一个单向链表。</p><p>三、锁的公平性机制</p><ul><li>公平锁（Fair Lock）：</li></ul><p>当请求锁时，公平锁会判断当前线程是否是同步队列的第一个线程。如果是，它会尝试获取锁。如果不是，它会等到前面的线程释放锁后再尝试获取。公平锁避免了“饥饿”问题，保证线程按照请求的顺序获取锁。</p><ul><li>非公平锁（Non-fair Lock）：</li></ul><p>非公平锁则不会强制按照队列顺序获取锁，它会直接尝试获取锁，如果失败才会加入同步队列。这使得非公平锁获取锁的速度更快，但可能会导致一些线程长时间得不到锁（即“线程饥饿”问题）。</p><p>四、获取锁的过程</p><p>在 公平锁 中，获取锁时：</p><ul><li><p>首先判断当前线程是否为同步队列的第一个线程，或者同步队列是否为空。</p></li><li><p>如果是第一个线程，则尝试获取锁。</p></li><li><p>否则，当前线程会加入队列，等待前一个线程释放锁后再尝试。</p></li></ul><p>在 非公平锁 中，获取锁时：</p><ul><li>直接尝试获取锁，不做任何排队判断，如果获取失败，才加入同步队列进行排队。</li></ul><p>五、总结</p><p>ReentrantLock 是一个非常强大的锁，它不仅提供了可重入性，还通过 AQS 实现了灵活的线程排队机制。</p><p>通过选择 公平锁 或 非公平锁，可以根据具体场景优化性能。</p><p>精简口述版</p><p>ReentrantLock 是基于 AQS 实现的，支持可重入、可中断以及公平/非公平模式。</p><p>它通过一个 state 变量和两个队列（同步队列、等待队列）管理线程。同步队列用于排队获取锁的线程，等待队列则用于存放等待特定条件的线程。</p><p>公平锁会优先考虑队列中第一个线程，而非公平锁则直接尝试获取锁，效率更高，但可能导致线程饥饿。</p><h3 id="Java-的-synchronized-是怎么实现的？">Java 的 synchronized 是怎么实现的？</h3><p>一、synchronized 的实现原理</p><p>synchronized 是 Java 中最基础的同步手段，它依赖 JVM 内部的 Monitor（监视器锁） 来实现线程同步。</p><p>每个对象在 JVM 层面都与一个 Monitor 相关联，当线程获取对象锁时，实际上就是获取了这个对象的 Monitor。</p><p>同时，synchronized 的加锁信息存储在对象的 对象头（Object Header） 中。</p><p>对象头包含 Mark Word 字段，其中记录了锁的状态（无锁、偏向锁、轻量级锁、重量级锁等）以及线程 ID 等信息。</p><p>二、synchronized 在字节码层面的实现</p><p>1.修饰方法</p><p>当 synchronized 修饰方法时，编译器会在该方法的字节码中添加一个 ACC_SYNCHRONIZED 标志位。</p><ul><li><p>当线程调用该方法时，JVM 会自动尝试获取该方法所属对象的 Monitor。</p></li><li><p>如果获取成功，执行方法体；否则线程会阻塞等待。</p></li><li><p>方法执行完毕后，JVM 会自动释放锁。</p></li></ul><ol start="2"><li>修饰代码块</li></ol><p>当 synchronized 修饰代码块时，编译后的字节码会在同步代码块前后生成：</p><ul><li><p>monitorenter（进入同步块，加锁）</p></li><li><p>monitorexit（退出同步块，释放锁）</p></li></ul><p>这两个字节码指令配合使用，确保线程执行完同步代码后锁能被正确释放。</p><p>三、synchronized 的锁优化机制</p><p>从 JDK 1.6 开始，JVM 对 synchronized 进行了多次性能优化，引入了锁的四种状态：</p><ul><li>无锁（Unlocked）</li><li>偏向锁（Biased Lock）</li><li>轻量级锁（Lightweight Lock）</li><li>重量级锁（Heavyweight Lock）</li></ul><p>锁会根据竞争情况在这几种状态之间自动升级，以提升并发性能。</p><p>四、总结一句话（精简口述版）</p><p>synchronized 是基于 JVM 实现的同步机制，通过对象的 Monitor（监视器锁） 来保证线程安全。</p><p>修饰方法时，会在方法标志中添加 ACC_SYNCHRONIZED 标志；</p><p>修饰代码块时，通过 monitorenter / monitorexit 字节码实现加锁和解锁。</p><p>另外，从 JDK1.6 起，JVM 还通过偏向锁、轻量级锁等机制对它进行了性能优化。</p><p>一句话口诀：</p><p>Monitor + Object Header + 字节码指令 = synchronized 的底层实现</p><h3 id="Synchronized-修饰静态方法和修饰普通方法有什么区别？">Synchronized 修饰静态方法和修饰普通方法有什么区别？</h3><p>synchronized 修饰静态方法：锁住的是类的 Class 对象，因此所有该类的实例共享同一把锁，多个线程调用同一个类的静态同步方法时会互斥执行。</p><p>synchronized 修饰实例方法：锁住的是当前对象实例，每个实例有自己独立的锁，不同实例之间可以并发执行同步方法；但同一个实例的多个线程调用实例方法时会互斥执行。</p><p>总结：</p><ul><li><p>synchronized 修饰 静态方法 时锁住的是 类级别的锁。</p></li><li><p>synchronized 修饰 实例方法 时锁住的是 实例级别的锁。</p></li></ul><h3 id="Java-中的-synchronized-轻量级锁是否会进行自旋？">Java 中的 synchronized 轻量级锁是否会进行自旋？</h3><p><strong>jdk8</strong>中轻量级锁 CAS失败了之后，会直接进入重量级锁膨胀过程。</p><p>重量级锁竞争失败会有自旋操作，轻量级锁没有这个动作。</p><h3 id="Synchronized-能不能禁止指令重排序？">Synchronized 能不能禁止指令重排序？</h3><ul><li><p>synchronized 本身并不能完全禁止指令重排序。但是它能够通过 内存屏障 保证 线程的可见性和有序性，在加锁和解锁操作时，JVM 会插入合适的内存屏障来保证语义上的顺序性。</p></li><li><p>volatile 更能保证禁止指令重排序，并且它保证变量的 可见性，但是 不能保证原子性，也无法像 synchronized 一样提供 互斥锁。</p></li></ul><p>总结:是否可以禁止指令重排序？</p><p>synchronized 能在一定程度上防止指令重排序，但不如 volatile 那么直接。</p><p>如果你需要更严格地禁止指令重排序，使用 volatile 更加合适。</p><h3 id="当-Java-的-synchronized-升级到重量级锁后，所有线程都释放锁了，此时它还是重量级锁吗？">当 Java 的 synchronized 升级到重量级锁后，所有线程都释放锁了，此时它还是重量级锁吗？</h3><ul><li><p>如果在重量级锁状态下，所有线程都释放了锁，那么该锁就会恢复为可用状态，也就是没有任何线程持有该锁(无锁状态)。</p></li><li><p>当下次有线程尝试获取锁时，JVM 会根据当前的线程竞争情况决定是否继续使用重量级锁，或者降级为轻量级锁甚至偏向锁。</p></li></ul><h3 id="什么是-Java-中的锁自适应自旋？">什么是 Java 中的锁自适应自旋？</h3><p>自适应锁是一种用来优化并发性能的锁机制，特别是在低竞争环境下。当多个线程争用同一个锁时，JVM 会首先尝试自旋，让线程在短时间内不断尝试获取锁，避免频繁的上下文切换。</p><ul><li><p>在锁竞争较轻的情况下，自旋会节省CPU资源，并且可以提高并发性能。</p></li><li><p>如果自旋失败，JVM 会根据当前的竞争情况动态调整自旋次数，避免线程一直在自旋而浪费过多的CPU时间。</p></li><li><p>自适应锁通过这种方式，减少了阻塞锁的开销，但如果线程竞争激烈，最终会转为重量级锁，并导致线程的阻塞和上下文切换。</p></li></ul><p>优点：</p><ul><li><p>在低竞争的环境中，避免了线程频繁的挂起和唤醒，提高了效率。</p></li><li><p>相比于传统的锁，能更有效地减少锁的竞争。</p></li></ul><p>缺点：</p><ul><li>自旋会浪费CPU资源，尤其在锁竞争非常激烈的情况下，线程会一直在自旋等待，反而会增加CPU的负担。</li></ul><h3 id="Synchronized-和-ReentrantLock-有什么区别？">Synchronized 和 ReentrantLock 有什么区别？</h3><p>1.实现机制：</p><ul><li><p>Synchronized 是 Java 中的关键字，基于 JVM 层面通过 Monitor（监视器锁） 实现同步。</p></li><li><p>ReentrantLock 是 java.util.concurrent 包下的类，基于 AQS（抽象队列同步器） 实现，通过自定义同步器来实现锁的获取和释放。</p></li></ul><p>2.锁的获取和释放：</p><ul><li><p>Synchronized 是隐式获取锁，线程进入同步代码块或方法时自动获取锁，执行完毕自动释放锁。</p></li><li><p>ReentrantLock 需要显式调用 lock() 获取锁，调用 unlock() 释放锁，灵活性更强。</p></li></ul><p>3.锁的公平性：</p><ul><li><p>Synchronized 默认是非公平锁，线程的获取顺序不一定按照请求顺序。</p></li><li><p>ReentrantLock 默认是非公平锁，也可以通过构造函数设置为公平锁，保证按照请求顺序获取锁，但可能会降低性能。</p></li></ul><p>4.锁的重入性：</p><ul><li><p>Synchronized 是可重入锁，同一个线程可以多次获取同一个锁。</p></li><li><p>ReentrantLock 也是可重入锁，通过内部计数器管理重入次数，直到重入次数为0时才真正释放锁。</p></li></ul><p>5.性能：</p><ul><li><p>Synchronized 在 JDK1.6 之前性能较差，但 JDK 1.6 之后进行了优化，支持偏向锁、轻量级锁等。</p></li><li><p>ReentrantLock 功能更强大，支持条件变量、读写锁等，适用于复杂的并发场景。</p></li></ul><h3 id="Volatile-与-Synchronized-的区别是什么？">Volatile 与 Synchronized 的区别是什么？</h3><p><code>volatile</code> 和 <code>synchronized</code> 都是 Java 中用于实现线程安全的机制，但是它们的工作原理和使用场景有很大的不同。</p><ol><li><p><strong><code>volatile</code> 变量：</strong></p><ul><li><code>volatile</code> <strong>用于保证某个变量的可见性</strong>。<strong>它能确保当一个线程修改了 <code>volatile</code> 变量的值后，其他线程能够立即看到这个更新</strong>。也就是说，<strong>它确保所有线程读取该变量时，会直接从主内存中读取，而不是从线程自己的缓存中读取</strong>。</li><li>但是，<code>volatile</code> 只<strong>保证了“可见性”，并不能保证“原子性”</strong>。比如你想执行 <code>i++</code> 这样的操作，虽然 <code>volatile</code> 会保证变量值的最新性，但由于这不是一个原子操作，多个线程同时修改同一个 <code>volatile</code> 变量时，仍然会出现竞争条件。</li></ul></li><li><p><strong><code>synchronized</code> 关键字：</strong></p><ul><li><code>synchronized</code> 是用来修饰方法或代码块的，它通过加锁的方式<strong>确保同一时刻只有一个线程可以执行该方法或代码块。这不仅保证了变量的可见性，还保证了操作的“原子性”</strong>。</li><li>使用 <code>synchronized</code> 会引起<strong>性能开销</strong>，因为它需要获取和释放锁。锁的获取和释放会导致线程阻塞，尤其是多个线程争用锁时，可能会发生上下文切换，影响性能。</li></ul></li></ol><p><strong>关键区别总结：</strong></p><ul><li><code>volatile</code> 主要保证变量的<strong>可见性</strong>，但不能保证<strong>原子性</strong>。</li><li><code>synchronized</code> 不仅保证变量的可见性，还能保证操作的<strong>原子性</strong>，但会导致线程的<strong>性能开销</strong>，因为它涉及到加锁和释放锁。</li></ul><h3 id="如何优化-Java-中的锁的使用？">如何优化 Java 中的锁的使用？</h3><p><strong>优化 Java 中锁的使用</strong></p><ul><li>首先要<strong>减少锁的持有时间</strong>。尽量缩小锁定范围，避免长时间占用锁资源。</li><li>其次，<strong>减少锁的粒度</strong>，可以通<strong>过加细粒度的锁</strong>来提高并发性，例如使用<strong>读写锁（ReadWriteLock）</strong> 来处理读多写少的场景。</li><li>最后我们要<strong>减少锁的使用</strong>：而在一些简单的并发场景中，我们可以用 <strong>CAS 操作或者原子类</strong>（比如 AtomicInteger）来代替传统的锁，避免不必要的性能损失。</li></ul><h3 id="你了解-Java-中的读写锁吗？">你了解 Java 中的读写锁吗？</h3><p><strong>读写锁</strong>（<code>ReadWriteLock</code>）是<strong>为了优化多线程环境下的读操作</strong>而设计的。Java 中的 <code>ReentrantReadWriteLock</code> 是实现该锁的一个主要工具。</p><ul><li><strong>读锁</strong>（Read Lock）：<strong>允许多个线程同时读取共享资源，只要没有线程在写入</strong>。这就避免了读线程之间的互斥，提升了系统的并发性。</li><li><strong>写锁</strong>（Write Lock）：是<strong>独占锁</strong>，<strong>在一个线程获取写锁后，其他所有读写操作都无法进行，直到该线程释放写锁</strong>。这保证了数据的一致性。</li></ul><p><strong>ReentrantReadWriteLock</strong> <strong>允许一个线程在获取写锁后，也可以重新获取它，这使得它支持递归锁（Reentrant）。而且，它还支持将读锁和写锁分开，极大提升了多线程读取时的效率。</strong></p><h4 id="总结：-2">总结：</h4><ul><li><strong>读锁和写锁分开</strong>，多个读线程可以并发访问，<strong>写线程必须等所有读线程完成后才能访问</strong>。</li><li><strong>适用场景</strong>：特别适合<strong>读多写少</strong>的场景，比如<strong>缓存、日志</strong>等高并发读取的系统。</li></ul><h3 id="什么是-Java-内存模型（JMM）">什么是 Java 内存模型（JMM）?</h3><p>Java 内存模型是 Java Memory Model（JMM），本身是一种抽象的概念，实际上并不存在，<strong>描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式</strong>.</p><blockquote><p>为什么需要JMM?</p></blockquote><ul><li>屏蔽各种硬件和操作系统的内存访问差异，<strong>实现让 Java 程序在各种平台下都能达到一致的内存访问效果</strong></li><li>规定了线程和内存之间的一些关系</li></ul><p>JMM 主要关注三大特性：<strong>可见性、原子性和有序性</strong>。</p><ol><li><p><strong>可见性</strong>：<br><strong>保证一个线程对变量的修改，其他线程能立即看到</strong>。比如，使用 <strong><code>volatile</code></strong> 关键字可以保证一个线程修改变量后，其他线程能立刻从主内存中读取到修改后的值。</p></li><li><p><strong>原子性</strong>：<br><strong>保证对共享变量的操作是不可分割的</strong>，某个线程执行时，不会被其他线程打断。Java 的原子类（如 <code>AtomicInteger</code>）就确保了对变量的原子操作。</p></li><li><p><strong>有序性</strong>：</p></li></ol><ul><li><p><strong>保证指令的执行顺序不会被打乱，确保代码的执行顺序符合程序的设计逻辑</strong>。例如，<code>synchronized</code> 关键字能够确保同一时刻只有一个线程能够访问某个代码块，保证操作的顺序执行。</p></li><li><p>happens-before 原则：JMM 定义了 happens-before 规则，用于约束操作之间的有序性。如果一个操作 A happens-before 操作 B，那么 A 的结果对于 B 是可见的，且 A 的执行顺序在 B 之前。</p></li></ul><p>简而言之，JMM 就是一个<strong>为多线程提供规范和规则的机制</strong>，它保证了多个线程间的同步和内存一致性问题。</p><h3 id="什么是-Java-中的原子性、可见性和有序性？">什么是 Java 中的原子性、可见性和有序性？</h3><p><strong>可见性</strong>：</p><ul><li><strong>保证一个线程对变量的修改，其他线程能立即看到</strong>。比如，使用 **volatile **关键字可以保证一个线程修改变量后，其他线程能立刻从主内存中读取到修改后的值。</li></ul><p><strong>原子性</strong>：</p><ul><li><strong>保证对共享变量的操作是不可分割的，某个线程执行时，不会被其他线程打断</strong>。Java 的原子类（如 AtomicInteger）就确保了对变量的原子操作。</li></ul><p><strong>有序性</strong>：</p><ul><li><strong>保证指令的执行顺序不会被打乱，确保代码的执行顺序符合程序的设计逻辑</strong>。例如，synchronized 关键字能够确保同一时刻只有一个线程能够访问某个代码块，保证操作的顺序执行。</li><li><strong>happens-before</strong> 原则：JMM 定义了 happens-before 规则，用于约束操作之间的有序性。如果一个操作 A happens-before 操作 B，那么 A 的结果对于 B 是可见的，且 A 的执行顺序在 B 之前。</li></ul><h3 id="什么是-Java-的-happens-before-规则？">什么是 Java 的 happens-before 规则？</h3><p>happens-before 是 JMM 中用于规定 <strong>“内存可见性与执行顺序</strong>” 的<strong>逻辑关系</strong>。<br>如果 A happens-before B，那么：</p><ul><li>A 的执行结果对 B 是可见的</li><li>A 一定发生在 B 之前</li></ul><p>happens-before 的 8 条规则（JSR-133 规定）</p><table><thead><tr><th>规则编号</th><th>描述</th><th>举例代码</th></tr></thead><tbody><tr><td>①</td><td>程序顺序规则：一个线程中语句按写的顺序执行</td><td><code>int x=1; int y=x+1;</code></td></tr><tr><td>②</td><td>监视器规则：解锁 happens-before 随后的加锁（同一锁对象）</td><td><code>synchronized(obj)</code> 块之间</td></tr><tr><td>③</td><td>volatile 规则：volatile 写 happens-before 随后的读</td><td><code>volatile boolean flag</code></td></tr><tr><td>④</td><td>线程启动规则：start () happens-before 线程内任何操作</td><td><code>main线程调用 t.start()</code></td></tr><tr><td>⑤</td><td>线程终止规则：线程内操作 happens-before 其他线程检测它结束</td><td><code>t.join()</code> 或 <code>!t.isAlive()</code></td></tr><tr><td>⑥</td><td>线程中断规则：interrupt () happens-before 被检测到中断</td><td><code>t.interrupt()</code> 后用 <code>isInterrupted()</code> 检测</td></tr><tr><td>⑦</td><td>对象终结规则：构造完成 happens-before finalize ()</td><td>Java GC 自动触发</td></tr><tr><td>⑧</td><td>传递性：A hb→B，B hb→C，则 A hb→C</td><td>A 设置值 → B 发信号 → C 读取所有结果</td></tr></tbody></table><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/lNVo2Sgh_Snipaste_2025-11-04_18-31-59_mianshiya.png" alt="Snipaste_2025-11-04_18-31-59.png" width="100%" /><h3 id="什么是-Java-中的指令重排？">什么是 Java 中的指令重排？</h3><p>指令重排是现代<strong>处理器和编译器用来优化代码执行的一种手段</strong>，它通过改变指令的执行顺序来提高程序的性能。</p><blockquote><p>为什么要有指令重排这项优化呢？从 CPU 执行指令的原理来理解一下吧</p></blockquote><p>为什么 CPU 要重排？</p><p>为了提高性能，现代 CPU 实现了以下机制：</p><ol><li>指令流水线（Pipeline）</li></ol><p>五级流水线：取指令 → 指令译码 → 执行 → 访存 → 写回<br>每条指令被分成多个阶段，这些阶段可以被多个指令<strong>并行执行</strong>。</p><p>这样做可以<strong>提高吞吐率</strong>（Throughput）。</p><ol start="2"><li>超标量（SuperScalar）</li></ol><p>现代 CPU 拥有多个执行单元（如整数、浮点、加载单元）<br>可以在一个时钟周期内<strong>执行多条指令</strong>，即 IPC &gt; 1（Instruction per Clock）</p><h4 id="指令重排的弊端">指令重排的弊端</h4><p>指令重排有时会导致<strong>并发程序中的问题，尤其是在多线程环境下</strong>。举个例子，<strong>假设有两个线程A和B，A执行某个任务后修改一个共享变量，B线程读取这个变量。如果没有适当的同步机制，由于指令重排，B可能会在A尚未修改变量时读取到一个不一致的值</strong>，这可能导致程序出现错误。</p><blockquote><p>JMM 如何应对重排？</p></blockquote><p>Java 内存模型（JMM）允许重排序，<strong>但通过 Happens-Before 规则和 volatile/synchronized 等机制来屏蔽 “坏的重排”</strong>。</p><h4 id="扩展-演示一下指令重排">扩展- 演示一下指令重排</h4><ol><li>诡异的结果</li></ol><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> num = <span class="number">0</span>;</span><br><span class="line"><span class="type">boolean</span> ready = <span class="literal">false</span>;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">actor1</span><span class="params">(I_Result r)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ready) &#123;</span><br><span class="line">        r.r1 = num + num;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        r.r1 = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">actor2</span><span class="params">(I_Result r)</span> </span>&#123;</span><br><span class="line">    num = <span class="number">2</span>;</span><br><span class="line">    ready = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你可能会觉得结果只有：</p><p>1：因为 ready == false<br>4：因为 ready == true 且 num = 2<br>但事实上，还可能出现一个诡异的结果：<code>r1  == 0</code></p><ol start="2"><li>为什么会出现 r1 == 0？</li></ol><p>这是 指令重排（Instruction Reordering） 的锅：</p><p>actor2 看似顺序是：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">num</span> = <span class="number">2</span><span class="comment">;</span></span><br><span class="line"><span class="attr">ready</span> = <span class="literal">true</span><span class="comment">;</span></span><br></pre></td></tr></table></figure><p>但实际上，JIT 编译器或 CPU 为了性能可能重排序为：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ready</span> = <span class="literal">true</span><span class="comment">;</span></span><br><span class="line"><span class="attr">num</span> = <span class="number">2</span><span class="comment">;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>线程交叉执行导致问题<br>设想线程切换如下：</li></ol><table><thead><tr><th>时间</th><th>执行线程</th><th>执行内容</th></tr></thead><tbody><tr><td>T1</td><td>actor2</td><td><code>ready = true</code> ✅ 重排了</td></tr><tr><td>T2</td><td>actor1</td><td><code>if (ready)</code> 进入 if 分支</td></tr><tr><td>T3</td><td>actor1</td><td>读取 <code>num = 0</code>，返回 <code>0</code></td></tr><tr><td>T4</td><td>actor2</td><td><code>num = 2</code> 补上了</td></tr></tbody></table><p>此时：</p><ul><li>ready = true</li><li>num 还没来得及变成 2</li><li>所以 num + num = 0 + 0 = 0</li></ul><ol start="4"><li>用 JCStress 工具验证这种微小并发问题</li></ol><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/EIyqlG3D_Snipaste_2025-11-04_18-49-45_mianshiya.png" alt="Snipaste_2025-11-04_18-49-45.png" width="100%" />5. 如何解决？<ul><li>方法一：使用 volatile</li></ul><p>修改代码为：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="type">boolean</span> ready = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><p>效果：</p><ul><li>volatile 具有 可见性 和 禁止重排序 的语义</li><li>它会在 ready = true 写操作前，确保之前所有写操作（包括 num = 2）都已完成</li><li>执行压测后，0 就不再出现了，说明问题彻底解决。</li></ul><p>总结：多线程环境下，不加 volatile 或同步机制，即使代码看起来顺序执行，也可能由于 “重排序” 导致结果诡异！</p><h3 id="Java-中的-final-关键字是否能保证变量的可见性？">Java 中的 final 关键字是否能保证变量的可见性？</h3><p>final 关键字确实<strong>能确保变量的值一旦被设置后不可再改变</strong>，但它<strong>不能保证变量在多个线程中的可见性</strong>。</p><ul><li>对于基本数据类型，它只能保证值不变；</li><li>对于引用类型的 final 变量，它只能保证引用指向的对象不可改变，但是对象内部的数据，其他线程仍然可能看不到最新的值。</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">YesFinalTest</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> a;  <span class="comment">// final 变量</span></span><br><span class="line">    <span class="type">int</span> b; <span class="comment">// 普通变量</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">YesFinalTest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        a = <span class="number">1</span>;</span><br><span class="line">        b = <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">void</span> <span class="title">main</span><span class="params">(<span class="type">String</span>[] args)</span> </span>&#123;</span><br><span class="line">        YesFinalTest testObj = <span class="keyword">new</span> <span class="built_in">YesFinalTest</span>();  <span class="comment">// 创建对象</span></span><br><span class="line">        testObj.b = <span class="number">3</span>; <span class="comment">// 允许修改</span></span><br><span class="line">        <span class="comment">// testObj.a = 4; // 不能修改，a 是 final 的</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在这个例子中，a 是 final 变量，它一旦赋值就不可更改。而 b 是普通变量，它是可以修改的。<strong>如果在多线程中对这些变量进行操作，final 并不能保证在其他线程中 a 和 b 的值能及时可见</strong>，<strong>除非使用 volatile 或其他同步机制</strong>。</p><p>为了确保线程安全和数据可见性。通常我们需要额外使用 volatile 或 synchronized 来确保数据的一致性和可见性。</p><h3 id="为什么在-Java-中需要使用-ThreadLocal？">为什么在 Java 中需要使用 ThreadLocal？</h3><p>在 Java 中使用 ThreadLocal 主要是<strong>为了避免多线程环境下共享数据的安全问题</strong>。<br>通常，多个线程同时访问共享资源时，如果没有适当的同步机制，就会导致线程安全问题。<strong>而 ThreadLocal 通过为每个线程提供一个独立的副本，避免了这种多线程争用共享资源的情况。</strong></p><p>ThreadLocal的好处如下：</p><ul><li><strong>避免竞争</strong>：ThreadLocal 是一种<strong>为每个线程提供独立副本的机制</strong>。每个线程在访问 ThreadLocal 变量时，会得到自己的副本，<strong>确保了数据隔离，避免了不同线程之间的竞争</strong>。</li><li><strong>高效</strong>：因为每个线程都有自己的副本，<strong>线程之间不需要进行同步</strong>（如 synchronized），<strong>从而提高了效率</strong>，特别是在高并发情况下。</li></ul><p><strong>适用场景</strong>：ThreadLocal <strong>非常适用于每个线程需要独立操作的数据</strong>。例如，<strong>数据库连接、会话信息</strong>等。使用 ThreadLocal 可以确保每个线程的数据独立，避免了共享资源带来的问题。</p><blockquote><p>ThreadLocal会造成什么问题</p></blockquote><p>ThreadLocal可能会造成内存泄漏的问题[<a href="https://www.mianshiya.com/bank/1789249312885223425/question/1780933295085744130">https://www.mianshiya.com/bank/1789249312885223425/question/1780933295085744130</a>]</p><h3 id="Java-中的-ThreadLocal-是如何实现线程资源隔离的？">Java 中的 ThreadLocal 是如何实现线程资源隔离的？</h3><p>ThreadLocal 为每个线程提供了一个独立的 <strong>ThreadLocalMap</strong>，该 map 的<strong>键是 ThreadLocal 对象</strong>，<strong>值是存储在线程本地的具体数据</strong>。每个线程可以通过 ThreadLocal.get() 方法获取它自己的数据副本，其他线程无法直接访问到。</p><p>主要操作：</p><ul><li>set(value)：将线程本地的值存入 ThreadLocalMap 中，键是 ThreadLocal 对象，值是具体的值。</li><li>get()：根据当前线程获取到该线程对应的 ThreadLocalMap，进而访问其中存储的值。</li></ul><p>优点：</p><ul><li>线程安全：每个线程都有自己的副本，线程之间互不干扰，不会发生竞争。</li><li>简化线程处理：避免了显式的同步操作，减少了线程间的复杂性。</li></ul><p>使用场景：</p><ul><li>ThreadLocal 适用于每个线程需要持有独立副本的情况，例如：数据库连接、Session信息、用户上下文等。</li></ul><h3 id="为什么-Java-中的-ThreadLocal-对-key-的引用为弱引用？">为什么 Java 中的 ThreadLocal 对 key 的引用为弱引用？</h3><p>在 Java 中，ThreadLocal <strong>对于存储线程局部变量的 key 使用了弱引用</strong>。弱引用的主要作用是<strong>尽可能的避免内存泄漏</strong>，<strong>并允许 JVM 在内存紧张时回收不再使用的对象</strong>。</p><ul><li>防止内存泄漏：每个线程都有一个与之关联的 ThreadLocalMap，ThreadLocal 中的 key 被弱引用，这意味着当一个线程结束或不再使用某个 ThreadLocal 对象时，ThreadLocalMap 可以被垃圾回收器回收，避免了内存泄漏。</li><li>有效管理内存：使用弱引用，当线程本地存储的对象不再被使用时，JVM 会自动回收内存。弱引用的 ThreadLocal 可以在系统内存不足时有效释放资源。</li></ul><blockquote><p>为什么value不设为弱引用？</p></blockquote><p>我们不会把 value 也设置为弱引用，主要是<strong>为了保证线程能够稳定访问到自己的局部数据。如果 value 也使用弱引用的话，可能在垃圾回收时被回收掉，这样线程就无法正常访问自己的数据了</strong>。而且，ThreadLocal 本身就用弱引用管理 key，通过清理无效的 key 来避免内存泄漏，value 用强引用确保它在生命周期内都能被正确访问</p><h3 id="Java-中使用-ThreadLocal-的最佳实践是什么？">Java 中使用 ThreadLocal 的最佳实践是什么？</h3><p>在 Java 中使用 <code>ThreadLocal</code> 时，一些最佳实践包括：</p><ol><li><p><strong>避免滥用 <code>ThreadLocal</code>：</strong><br><code>ThreadLocal</code> <strong>适用于每个线程需要维护独立变量的场景</strong>，比如数据库连接、用户会话等。<strong>如果需要共享数据，<code>ThreadLocal</code> 不适用</strong>，应该使用其他线程安全的方式。</p></li><li><p><strong>线程结束后清理：</strong><br>使用 <code>ThreadLocal</code> 时，<strong>一定要在任务完成后清理数据</strong>。可以通过调用 <code>remove()</code> 方法确保释放资源，<strong>避免因资源未清理导致内存泄漏</strong>。</p></li><li><p><strong>使用合适的生命周期：</strong><br><strong>确保 <code>ThreadLocal</code> 只在当前线程中有效，线程结束时清理资源</strong>。<strong>避免 ThreadLocal 被长时间占用</strong>，最好在任务执行完后及时清理。</p></li><li><p><strong>合理使用 <code>initialValue()</code>：</strong><br>使用 <code>ThreadLocal</code> 时，可以通过 <code>withInitial()</code> 方法<strong>提供初始值</strong>，这样可以<strong>确保每个线程有默认的值，避免没有初始化的情况</strong>。</p></li><li><p><strong>避免静态存储大型对象：</strong><br><code>ThreadLocal</code> <strong>不应被用来存储大型对象</strong>，如数据库连接池等。因为每个线程都可能对这些数据进行修改，使用 <code>ThreadLocal</code> 存储这类资源并不合适，容易引发竞争条件。</p></li></ol><p>总的来说，<code>ThreadLocal</code> 的最佳实践是：<strong>确保只在需要时使用，并且及时清理资源，避免内存泄漏或不必要的内存占用</strong>。</p><h3 id="Java-中的-InheritableThreadLocal-是什么？">Java 中的 InheritableThreadLocal 是什么？</h3><p>InheritableThreadLocal 就是 ThreadLocal 的一种变种，<strong>允许子线程访问和继承父线程中的本地变量</strong>。</p><p><strong>一般来说，如果你需要在父线程和子线程之间共享一些数据，且希望子线程能够访问父线程设置的值，可以使用 InheritableThreadLocal</strong>。</p><p>它会在创建子线程时，将父线程中 InheritableThreadLocal 的值传递给子线程。<strong>需要注意的是，子线程的修改不会影响父线程的值，而且父线程的值也不会被子线程修改</strong>。</p><h3 id="ThreadLocal-的缺点？">ThreadLocal 的缺点？</h3><ul><li><p>首先是内存泄漏的问题。ThreadLocal 对象在每个线程中有独立的副本，<strong>如果我们没有显式地使用 remove() 清除它们，这些线程局部的变量就不会被及时回收，可能会导致内存泄漏</strong>，尤其是在有大量线程的情况下。</p></li><li><p>其次是性能问题。如果我们使用 ThreadLocal 来<strong>存储大量数据</strong>，或者在一些<strong>线程池中使用 ThreadLocal 变量</strong>，可能会遇到<strong>性能瓶颈</strong>。这是因为每次获取或者设置值时，<strong>ThreadLocal 都需要访问其内部的数据结构，而这可能导致一些性能损耗，特别是当出现 hash 冲突时，性能会进一步下降</strong>(线性探测法效率低）。</p></li><li><p>最后，如果使用不当，ThreadLocal 会带来不必要的复杂性。例如，处理不同线程间的共享数据时，可能需要更多的管理工作，<strong>而 ThreadLocal 更适合一些轻量级的线程局部存储场景</strong>。”</p></li></ul><h3 id="什么是-Java-的-TransmittableThreadLocal？">什么是 Java 的 TransmittableThreadLocal？</h3><p>TransmittableThreadLocal 是为了主要用于解决 <strong>ThreadLocal 在线程池中或跨线程的传递问题</strong>，<strong>它增强了 InheritableThreadLocal 的功能。通过捕获、重放、恢复三个步骤，它确保父线程的数据能够传递到子线程，从而避免了线程池中数据丢失的问题</strong>。</p><p>这就是为什么在涉及到线程池或多线程环境时，我们可以使用 TransmittableThreadLocal，它能够更好地保证线程间的数据共享和传递</p><blockquote><p>ThreadLocal、InheritableThreadLocal 和 TransmittableThreadLocal 的简要比较</p></blockquote><ul><li>ThreadLocal <strong>用于确保每个线程有自己的变量，并且这些变量不能被其他线程访问</strong>。它适用于每个线程都需要独立存储的数据，比如数据库连接或用户信息。</li><li>InheritableThreadLocal <strong>让子线程能够继承父线程的 ThreadLocal 数据，这对于处理父子线程之间的数据传递是很有用的，但它不会在后续的子线程操作中进行更新</strong>。</li><li>TransmittableThreadLocal 则扩展了 InheritableThreadLocal，<strong>支持跨线程池传递数据，它还可以在任务执行完成后清理数据，避免内存泄漏的问题</strong>。</li></ul><h3 id="Java-中-Thread-sleep-和-Thread-yield-的区别？">Java 中 Thread.sleep 和 Thread.yield 的区别？</h3><p>Thread.sleep() 和 Thread.yield() 都是用来控制线程执行行为的方法，但它们的底层机制和效果不同。</p><p>1.从线程状态上看：</p><ul><li>sleep() 会让线程进入 TIMED_WAITING（计时等待）状态，在指定时间内不会参与 CPU 调度。</li><li>yield() 只是让当前线程从 RUNNABLE（可运行）状态 暂时让出 CPU 执行权，但不会阻塞，下一次调度时可能马上又被选中执行。</li></ul><p>2.从 CPU 调度上看：</p><ul><li>sleep() 一定会让出 CPU 执行时间；</li><li>yield() 只是“建议”调度器让出 CPU，是否让出、让给谁，由 JVM 和操作系统调度策略决定。</li></ul><ol start="3"><li>从异常机制上看：</li></ol><ul><li>sleep() 会显式抛出 InterruptedException，需要捕获或声明；</li><li>yield() 不会抛出任何异常。</li></ul><p>4.从优先级角度看：</p><ul><li>sleep() 不考虑线程优先级，直接暂停；</li><li>yield() 通常只会让给相同或更高优先级的线程。</li></ul><p>5.共同点：</p><p><strong>两者都不会释放已持有的锁</strong>。</p><p>（也就是说，如果在线程同步块里调用 sleep 或 yield，锁依旧被该线程占用。）</p><p>总结：</p><ul><li>sleep 是“强制暂停一段时间”；</li><li>yield 是“自愿让出一次 CPU 机会”；</li><li>sleep 会进入等待状态且抛异常，yield 只是回到就绪状态，不一定真的让出执行权。</li></ul><h3 id="Java-中-Thread-sleep-0-的作用是什么？">Java 中 Thread.sleep(0) 的作用是什么？</h3><p>Thread.sleep(0) 表示当前线程主动让出 CPU 的执行权，但不真正进入休眠。</p><p>它会触发一次线程调度，让系统有机会让其他同优先级或更高优先级的线程执行。</p><p>如果没有可运行的线程，调度器可能会重新选中自己执行。</p><p>可以理解为一种轻量级的线程切换，在某些系统上和 yield() 效果类似，但更“强制”一些。</p><h4 id="sleep-0-的应用：">sleep(0)的应用：</h4><p>在高性能多线程程序中，有时会用 sleep(0) 做线程调度优化，比如防止一个线程长时间占用 CPU，但这属于底层微调，一般开发中用得较少。</p><h4 id="sleep-0-与-yield-的对比">sleep(0) 与 yield()的对比:</h4><p>sleep(0) 与 yield() 的底层实现与调度策略不同：</p><ul><li><p>sleep(0) 调用的是系统级 sleep/nanosleep，会强制触发一次调度；</p></li><li><p>yield() 只是告诉调度器“我可以让出”，但调度器可以忽略这个请求。</p></li></ul><h3 id="Java-中的-wait、notify-和-notifyAll-方法有什么作用？">Java 中的 wait、notify 和 notifyAll 方法有什么作用？</h3><p><strong>这三个方法主要用于线程间的同步和通信，确保多线程之间不会相互干扰</strong>。</p><ul><li>首先，wait() 会让<strong>当前线程进入等待状态</strong>，<strong>释放锁</strong>，让其他线程可以使用该锁。</li><li>调用 notify() <strong>会唤醒一个在同一对象上等待的线程</strong>，</li><li>而 notifyAll() <strong>会唤醒所有等待的线程</strong>。</li></ul><p>这些方法<strong>都需要在 synchronized 块中使用</strong>，因为它们都涉及到共享资源的访问和修改。</p><p>简而言之，wait() 会让线程进入休眠并释放锁，notify() 唤醒一个等待的线程，而 notifyAll() 唤醒所有等待的线程。</p><h3 id="Java-中什么情况会导致死锁？如何避免？">Java 中什么情况会导致死锁？如何避免？</h3><p>死锁就是两个或多个线程互相等待对方持有的锁，导致都无法继续执行。</p><p>它产生必须满足四个条件：互斥、占有且等待、不可抢占、循环等待。</p><p>只要破坏其中任意一个条件就能避免死锁。</p><p>实际开发中常见做法是：</p><ul><li><p>保证加锁顺序一致；</p></li><li><p>对锁操作设置超时时间，避免无限等待；</p></li><li><p>尽量减小锁的粒度，降低死锁的风险；</p></li><li><p>必要时用 jstack 分析线程快照定位死锁。</p></li></ul><h4 id="补充：为什么“减小锁的粒度”有助于避免死锁？">补充：为什么“减小锁的粒度”有助于避免死锁？</h4><p>先理解死锁的本质：</p><p>死锁发生的根源在于多个线程同时争抢多个锁资源，并且形成循环等待。</p><p>如果锁的粒度太大，意味着：</p><ul><li><p>一个线程拿到的锁可能包含了多个关键资源；</p></li><li><p>另一个线程也需要访问其中部分资源时，也要等这把“大锁”；</p></li><li><p>多个线程间锁的依赖关系就复杂了，更容易形成循环等待链条。</p></li></ul><p>相反，如果我们降低锁的粒度（即让每个锁控制的范围更小）：</p><ul><li><p>各线程锁住的资源重叠减少；</p></li><li><p>同时持有多个锁的概率变小；</p></li><li><p>就不太容易出现“我等你、你等我”的循环依赖。</p></li></ul><p>结论：锁粒度小 → 资源竞争减少 → 同时持有多把锁的可能性低 → 死锁风险降低。</p><h3 id="Java-中-volatile-关键字的作用是什么？">Java 中 volatile 关键字的作用是什么？</h3><p>volatile可以用来修饰成员变量和静态成员变量，<strong>主要作用是保证变量的可见性和禁止指令重排优化</strong>。加了 volatile 之后<strong>线程不能从自己工作缓存中读取变量的值，必须去到主内存中获取变量的最新值</strong>。</p><blockquote><p>volatile 与 synchronized 的可见性对比</p></blockquote><table><thead><tr><th>特性</th><th><code>volatile</code></th><th><code>synchronized</code></th></tr></thead><tbody><tr><td>可见性</td><td>✅ 强制主内存交互</td><td>✅ 解锁前刷新主内存</td></tr><tr><td>原子性</td><td>❌</td><td>✅ 加锁保证互斥</td></tr><tr><td>性能</td><td>高</td><td>低（重量级锁）</td></tr><tr><td>语义</td><td>轻量</td><td>阻塞 / 解阻塞</td></tr></tbody></table><h4 id="volatile-原理">volatile 原理</h4><p>volatile 的底层实现原理是内存屏障，Memory Barrier（Memory Fence）</p><ul><li>对 volatile 变量的写指令后会加入写屏障</li><li>对 volatile 变量的读指令前会加入读屏障</li></ul><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>写屏障 sfence</td><td>保证之前的写操作会刷新到主内存</td></tr><tr><td>读屏障 lfence</td><td>保证之后的读操作从主内存加载最新数据</td></tr></tbody></table><h4 id="如何保证可见性">如何保证可见性</h4><ul><li>写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">actor2</span><span class="params">(I_Result r)</span> </span>&#123;</span><br><span class="line">   num = <span class="number">2</span>;</span><br><span class="line">   ready = <span class="literal">true</span>; <span class="comment">// ready 是 volatile，写操作后插入写屏障</span></span><br><span class="line">   <span class="comment">// 写屏障</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">actor1</span><span class="params">(I_Result r)</span> </span>&#123;</span><br><span class="line">   <span class="comment">// 读屏障</span></span><br><span class="line">   <span class="comment">// ready 是 volatile 读取值带读屏障</span></span><br><span class="line">   <span class="keyword">if</span>(ready) &#123;</span><br><span class="line">       r.r1 = num + num;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       r.r1 = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过 volatile ready，确保 actor2 的 num=2 先于 ready=true 被主内存可见；actor1 会在读 ready 之后拿到 num=2。</p><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/iJtGDzJL_image-1430_mianshiya.png" alt="image-1430.png" width="75%" /><h4 id="如何保证有序性（禁止指令重排序）">如何保证有序性（禁止指令重排序）</h4><ul><li>写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">actor2</span><span class="params">(I_Result r)</span> </span>&#123;</span><br><span class="line">   num = <span class="number">2</span>;</span><br><span class="line">   ready = <span class="literal">true</span>; <span class="comment">// ready 是 volatile 赋值带写屏障</span></span><br><span class="line">   <span class="comment">// 写屏障</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">actor1</span><span class="params">(I_Result r)</span> </span>&#123;</span><br><span class="line">   <span class="comment">// 读屏障</span></span><br><span class="line">   <span class="comment">// ready 是 volatile 读取值带读屏障</span></span><br><span class="line">   <span class="keyword">if</span>(ready) &#123;</span><br><span class="line">       r.r1 = num + num;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       r.r1 = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/pdbuUtag_3_mianshiya.png" alt="3.png" width="75%" /><p>还是那句话，<strong>不能解决指令交错</strong>：</p><ul><li>写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证读跑到它前面去</li><li>而有序性的保证也只是保证了本线程内相关代码不被重排序</li></ul><p><strong>即volatile无法阻止线程间指令交错执行，它只控制当前线程的读写顺序，无法强制让别的线程“看不见/先执行”</strong></p><blockquote><p>volatile无法阻止线程间指令交错执行，它只控制当前线程的读写顺序，无法强制让别的线程“看不见/先执行”与volatile禁止重排序是否矛盾？</p></blockquote><p>不矛盾</p><table><thead><tr><th>层面</th><th>代表术语</th><th>volatile 的作用</th></tr></thead><tbody><tr><td>✅ 当前线程<strong>内部</strong>顺序</td><td>指令重排序（reordering）</td><td>禁止特定重排序 ✔️</td></tr><tr><td>❌ 多线程<strong>之间</strong>交叉执行</td><td>并发交叉 / 非同步执行</td><td>无法阻止 ❌</td></tr></tbody></table><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/sqyMghdJ_4_mianshiya.png" alt="4.png" width="50%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/booE4a2G_5_mianshiya.png" alt="5.png" width="50%" /><img src="https://pic.code-nav.cn/mianshiya/question_picture/1942188251568476161/ZME2jOCp_6_mianshiya.png" alt="6.png" width="50%" /><p>volatile 禁止 自身线程内的指令重排序，<strong>保证 “我写完作业再发信号”</strong><br>volatile 无法阻止 线程之间的交错执行，<strong>不能保证 “别人不抢先读取信号”</strong></p><p>两句话不矛盾，分别针对：</p><ul><li>内部顺序保障（禁止重排）</li><li>外部同步保障（需要锁）</li></ul><h3 id="什么是-Java-中的-ABA-问题？">什么是 Java 中的 ABA 问题？</h3><p>ABA 问题</p><ul><li>问题：一个变量从 A → B → A，CAS 检查时发现值没变，但实际上经历了变化，从而导致错误的判断和操作</li><li>解决：使用版本号机制，在每次更新一个变量时,不仅更新变量的值,还更新一个版本号。如AtomicStampedReference，在 CAS 时同时比较值和版本号。</li></ul><h3 id="在-Java-中主线程如何知晓创建的子线程是否执行成功？">在 Java 中主线程如何知晓创建的子线程是否执行成功？</h3><p>主线程通常有几种方式来知道子线程是否成功执行。总结来说，常见的方式包括：</p><h4 id="1-使用-Thread-join-方法">1. 使用 <code>Thread.join()</code> 方法</h4><ul><li><strong>原理</strong>：<strong>当主线程调用子线程的 <code>join()</code> 方法时，它会阻塞等待直到子线程执行完毕</strong>。如果子线程正常执行结束，主线程会继续执行，否则如果子线程抛出异常，主线程可以捕获到这些异常。</li><li><strong>应用场景</strong>：这种方式<strong>适合于简单的线程等待和执行结果的检查</strong>。</li></ul><h4 id="2-使用-Callable-和-Future">2. 使用 <code>Callable</code> 和 <code>Future</code></h4><ul><li><strong>原理</strong>：<strong>使用 <code>Callable</code> 接口创建返回结果的任务</strong>，并<strong>通过 <code>Future.get()</code> 方法来获取子线程的执行结果</strong>。如果子线程执行成功，<strong><code>get()</code> 返回正常结果</strong>；如果抛出异常，<code>get()</code> 会抛出相应的异常。</li><li><strong>应用场景</strong>：这种方式<strong>更适合需要返回结果的任务</strong>，或者需要捕获子线程异常的场景。</li></ul><h4 id="3-使用回调机制">3. 使用回调机制</h4><ul><li><strong>原理</strong>：回调机制是<strong>通过主线程传递一个回调函数给子线程，子线程执行完任务后调用回调函数通知主线程</strong>。主线程可以通过这些回调函数来检查任务是否成功完成。</li><li><strong>应用场景</strong>：适用于<strong>复杂的多线程场景</strong>，可以在任务结束时获取执行状态。</li></ul><h4 id="4-使用-CountDownLatch-或其他-JUC-类">4. 使用 <code>CountDownLatch</code> 或其他 JUC 类</h4><ul><li><strong>原理</strong>：通过 <code>CountDownLatch</code> 等同步工具类，<strong>主线程可以等待子线程完成任务。当子线程完成任务时，会调用 <code>countDown()</code> 方法来通知主线程任务已完成</strong>。<strong>主线程通过 <code>await()</code> 方法等待直到所有子线程完成</strong>。</li><li><strong>应用场景</strong>：适用于等待多个子线程的场景。</li></ul><p>结合具体的业务需求选择合适的方案。例如，当只关心子线程是否完成任务时，可以使用 <code>join()</code>；当需要获取任务结果或者捕获异常时，推荐使用 <code>Callable</code> 和 <code>Future</code>。</p><h3 id="Java-创建线程池有哪些方式？">Java 创建线程池有哪些方式？</h3><p><strong>Java 创建线程池的方式</strong></p><ol><li><p><strong>使用 <code>Executors</code> 工具类</strong></p><ul><li><p>Java 提供了 <code>Executors</code> 工具类来方便地创建线程池。最常见的是 <code>Executors.newFixedThreadPool(int n)</code>，它创建一个固定大小的线程池。线程池中有固定数量的线程来执行任务，一旦任务完成，线程就会被复用。</p></li><li><p>示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ExecutorService</span> <span class="variable">threadPool</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">10</span>);</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>使用 <code>ThreadPoolExecutor</code> 直接创建线程池</strong></p><ul><li><p>如果需要更灵活的配置，可以使用 <code>ThreadPoolExecutor</code> 类直接创建线程池。它可以让你自定义线程池的参数，如核心线程数、最大线程数、线程空闲保持时间等。</p></li><li><p>示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ExecutorService</span> <span class="variable">threadPool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(</span><br><span class="line">    <span class="number">5</span>,                  <span class="comment">// corePoolSize</span></span><br><span class="line">    <span class="number">10</span>,                 <span class="comment">// maximumPoolSize</span></span><br><span class="line">    <span class="number">60</span>,                 <span class="comment">// keepAliveTime</span></span><br><span class="line">    TimeUnit.SECONDS,   <span class="comment">// TimeUnit</span></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;&gt;(<span class="number">100</span>)  <span class="comment">// BlockingQueue</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>使用 <code>ForkJoinPool</code> 创建线程池</strong></p><ul><li><p><code>ForkJoinPool</code> 用于并行任务的执行，它在任务拆分和合并方面非常高效。它特别适合需要递归任务或任务能拆分的场景。</p></li><li><p>示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ForkJoinPool</span> <span class="variable">forkJoinPool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ForkJoinPool</span>();</span><br><span class="line">forkJoinPool.submit(() -&gt; &#123;</span><br><span class="line">    <span class="comment">// Task</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li></ul></li></ol><p>具体选择哪个方式取决于你的应用场景。</p><ul><li>如果需要简单的线程池，可以用 <code>Executors</code> 工具类；</li><li>如果需要更高的定制性，选择 <code>ThreadPoolExecutor</code>；</li><li>对于递归任务，<code>ForkJoinPool</code> 是一个很好的选择。</li></ul><h3 id="Java-线程安全的集合有哪些">Java 线程安全的集合有哪些?</h3><p><strong>Java 线程安全的集合</strong><br>常见的线程安全集合包括：</p><ol><li><p><strong>Vector</strong></p><ul><li>类型：线程安全的动态数组</li><li>特点：每个方法都有锁，适用于多线程修改的场景。但由于性能较差，已经不推荐使用。</li></ul></li><li><p><strong>Hashtable</strong></p><ul><li>类型：线程安全的哈希表</li><li>特点：每个方法都有锁，适用于多线程共享的哈希表，但性能较低，已被 <code>ConcurrentHashMap</code> 替代。</li></ul></li><li><p><strong>ConcurrentHashMap</strong></p><ul><li>类型：线程安全的哈希表</li><li>特点：分段锁设计，支持高并发，适用于高并发环境，如缓存、分布式系统等。</li></ul></li><li><p><strong>CopyOnWriteArrayList</strong></p><ul><li>类型：线程安全的动态数组</li><li>特点：用于读多写少的场景，每次写操作时会复制整个数组，避免锁，适合监听集合等场景。</li></ul></li><li><p><strong>CopyOnWriteArraySet</strong></p><ul><li>类型：线程安全的集合</li><li>特点：基于 <code>CopyOnWriteArrayList</code> 实现，适合读多写少的场景。</li></ul></li><li><p><strong>BlockingQueue</strong></p><ul><li>类型：线程安全的队列</li><li>特点：用于生产者-消费者模式，支持阻塞操作，适用于多线程的队列操作。</li></ul></li><li><p><strong>ConcurrentSkipListMap 和 ConcurrentSkipListSet</strong></p><ul><li>类型：线程安全的 Map 和 Set</li><li>特点：基于跳表实现，支持高并发操作，适合需要顺序访问的集合操作。</li></ul></li><li><p><strong>LinkedBlockingQueue</strong></p><ul><li>类型：线程安全的阻塞队列</li><li>特点：支持高并发的队列操作，适用于任务队列等场景。</li></ul></li></ol>]]></content>
    
    
    <summary type="html">我对JUC的理解</summary>
    
    
    
    <category term="面试" scheme="https://itgeqian.github.io/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
    <category term="JUC" scheme="https://itgeqian.github.io/tags/JUC/"/>
    
  </entry>
  
</feed>
